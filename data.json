[
 {
  "repo": "microsoft/roosterjs-react",
  "language": "TypeScript",
  "readme_contents": "\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/vscode-azure-iot-toolkit",
  "language": "HTML",
  "readme_contents": "# Azure IoT Hub\n\n[![Join the chat at https://gitter.im/Microsoft/azure-iot-toolkit](https://badges.gitter.im/Microsoft/azure-iot-toolkit.svg)](https://gitter.im/Microsoft/azure-iot-toolkit?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) [![Marketplace Version](https://vsmarketplacebadge.apphb.com/version-short/vsciot-vscode.azure-iot-toolkit.svg)](https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-toolkit)\n\n***[Azure IoT Hub extension](https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-toolkit) is now a part of [Azure IoT Tools](https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-tools) extension pack. We highly recommend installing [Azure IoT Tools](https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-tools) extension pack, which makes it easy to discover and interact with Azure IoT Hub that power your IoT Edge and device applications.** This extension pack can help you:*\n- *Develop and connect your [Azure IoT Applications](https://azure.microsoft.com/en-us/overview/iot/) to Azure. With this extension, you can interact with an Azure IoT Hub, manage connected devices, and enable distributed tracing for your Azure IoT applications.*\n- *Develop and debug [Certifies Azure IoT Devices](https://catalog.azureiotsolutions.com/alldevices) (including [MXChip IoT DevKit](https://aka.ms/iot-devkit), [ESP32](https://catalog.azureiotsolutions.com/details?title=ESP32_DevKitC&source=all-devices-page), [Raspberry Pi](https://www.adafruit.com/category/288)) to Azure. This extension pack makes it easy to code, build, deploy and debug your IoT applications with popular IoT development boards.*\n- *Develop and deploy artificial intelligence and your custom logic to [Azure IoT Edge](https://azure.microsoft.com/en-us/services/iot-edge/). This extension pack makes it easy to code, build, deploy, and debug your IoT Edge applications.*\n\n## Overview\n\nInteract with Azure IoT Hub, IoT Device Management, IoT Edge Management, IoT Hub Device Simulation, IoT Hub Code Generation and IoT Hub Device Provisioning Service.\n\n## Device Explorer\nThe [Wiki page](https://github.com/Microsoft/vscode-azure-iot-toolkit/wiki) includes a comprehensive getting started guide as well as  detailed usage instructions of the following features:\n\n* IoT Hub management\n    * Create IoT Hub\n    * Select IoT Hub\n    * Copy IoT Hub Connection String\n    * Generate SAS Token for IoT Hub\n* Device management\n    * List devices\n    * Get device info\n    * Create IoT device\n    * Create Edge device\n    * Delete device\n    * Copy Device Connection String\n    * Generate SAS Token for Device\n* Module management\n    * List Modules\n    * Get Module Info\n    * Create Module\n    * Edit Module Twin\n    * Invoke Module Direct Method\n    * Copy Module Connection String\n    * Delete Module\n* Interact with Azure IoT Hub\n    * Generate Code for C#, F#, Go, Java, Node.js, PHP, Python, Ruby or REST API\n    * Send D2C message to IoT Hub\n    * Monitor Built-in Event Endpoint\n    * Send C2D message to device\n    * Receive C2D message from IoT Hub\n    * Invoke Device Direct Method\n    * Edit Device Twin\n    * Manage Azure IoT distributed tracing\n* Interact with Azure IoT Edge (Install [Azure IoT Edge](https://marketplace.visualstudio.com/items?itemName=vsciot-vscode.azure-iot-edge) for more IoT Edge support)\n    * List Modules \n    * Edit Module Twin\n    * Create deployment for Single Device\n    * Create Deployment at Scale\n* Endpoints management\n    * List Built-in and Custom Endpoints\n    * Monitor Custom Event Hub Endpoint\n\n### Prerequisites\n\n1. In Explorer of VS Code, click \"Azure IoT Hub\" in the bottom left corner.\n\n  ![Click Device Explorer](images/device-explorer-click.png)\n\n2. Click \"Set IoT Hub Connection String\" in context menu.\n\n  ![Set Connection String](images/set-connection-string.png)\n\n3. An input box will pop up, then enter your IoT Hub Connection String (It is one-time configuration, and please make sure it is **IoT Hub Connection String** not **Device Connection String**. The format is `HostName=<my-hub>.azure-devices.net;SharedAccessKeyName=<my-policy>;SharedAccessKey=<my-policy-key>`).\n\n  ![Enter Connection String](images/enter-connection-string.png)\n\n4. The devices list will be shown.\n\n  ![Device Explorer](images/device-explorer.png)\n\n### Sign in to Azure\n\nInstead of copying and pasting to set IoT Hub Connection String, you could sign in to Azure to select IoT Hub from your Azure Subscription.\n\n1. Click \"Select IoT Hub\" in context menu.\n\n  ![Select IoT Hub](images/select-iot-hub.png)\n\n2. If you have not signed in to Azure, a pop-up will show to let you sign in to Azure.\n3. After you sign in, your Azure Subscription list will be shown, then select an Azure Subscription.\n4. Your IoT Hub list will be shown, then select an IoT Hub.\n5. The devices and endpoints list will be shown.\n\n  ![IoT Hub Explorer](images/iot-hub-explorer.png)\n\n## Device Provisioning Service Explorer\n\n1. Open \"Azure\" view on the Activity Bar, and expand \"IOT HUB DEVICE PROVISIONING SERVICE\".\n\n![DPS Explorer](images/dps-explorer.png)\n\n2. If you're not signed in, click \"Sign in to Azure...\" to sign in.\n\n3. Expand one subscription to start exploring your device provisioning services.\n\n\n## Code Generation\n\n![Code Generation](images/code-generation.gif)\n\n## Code Snippets\n\n| Trigger | Content |\n| ---- | ---- |\n| iotSendD2CMessage | Send D2C message to IoT Hub |\n| iotMonitorD2CMessage | Monitor D2C message for IoT Hub |\n| iotSendC2DMessage | Send C2D message to device |\n| iotMonitorC2DMessage | Monitor C2D message from IoT Hub |\n| iotCallDirectMethods | Send direct methods to device |\n| iotReceiveDirectMethods | Receive direct methods from IoT Hub |\n\n![Snippet](images/snippet.gif)\n\n> After code snippet is created, you need to install corresponding npm package (e.g. [azure-iot-device-mqtt](https://www.npmjs.com/package/azure-iot-device-mqtt)) to run the code snippet.\n> If you want to 'Run Code' directly, you need to install [Code Runner](https://marketplace.visualstudio.com/items?itemName=formulahendry.code-runner).\n\n## Configuration\n\nIoT Hub Consumer Group (default is `\"$Default\"`):\n```json\n{\n    \"azure-iot-toolkit.iotHubConsumerGroup\": \"$Default\"\n}\n```\n\nThe time span (in minutes) of monitoring D2C message before current time (default is `0`):\n```json\n{\n    \"azure-iot-toolkit.monitorD2CBeforeNowInMinutes\": 0\n}\n```\n\nWhether to show verbose info when monitoring messages (default is `false`):\n```json\n{\n    \"azure-iot-toolkit.showVerboseMessage\": false\n}\n```\n\nWhether to stringify device-to-cloud messages (default is `false`):\n```json\n{ \n    \"azure-iot-toolkit.iotHubD2CMessageStringify\": false\n}\n```\n\nWhether to show IoT Hub info when IoT Hub Connection String is not set (default is `true`):\n```json\n{ \n    \"azure-iot-toolkit.showIoTHubInfo\": true\n}\n```\n\nWhether to enable auto refresh of tree view (default is `false`):\n```json\n{ \n    \"azure-iot-toolkit.treeViewAutoRefreshEnable\": false\n}\n```\n\nTime interval in seconds for tree view auto refresh, auto refresh has to be enabled for it to work. (default is `60`):\n```json\n{ \n    \"azure-iot-toolkit.treeViewAutoRefreshIntervalInSeconds\": 60\n}\n```\n\n## Resources\n- [Channel 9 video: Walkthrough of Azure IoT Hub extension](https://channel9.msdn.com/Shows/Internet-of-Things-Show/Azure-IoT-Toolkit-extension-for-Visual-Studio-Code)\n- [Channel 9 video: What's new in the IoT Hub extension for VS Code](https://channel9.msdn.com/Shows/Internet-of-Things-Show/Whats-new-in-the-IoT-Toolkit-extension-for-VS-Code)\n- [Create an IoT hub using the Azure IoT Tools for Visual Studio Code](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-create-use-iot-toolkit)\n- [Use Azure IoT Tools to send and receive messages between your device and IoT Hub](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-vscode-iot-toolkit-cloud-device-messaging)\n- [Use Azure IoT Tools for Azure IoT Hub device management](https://docs.microsoft.com/en-us/azure/iot-hub/iot-hub-device-management-iot-toolkit)\n- [Quickly build your Azure IoT application with Node.js, Python or REST API](https://devblogs.microsoft.com/iotdev/azure-iot-toolkit-1-2-0-quickly-build-your-azure-iot-application-in-vs-code-with-node-js-python-or-rest-api/)\n- [Azure IoT Hub extension supports C#, Go, Java, Node.js, PHP, Python and Ruby to develop Azure IoT application in VS Code](https://devblogs.microsoft.com/iotdev/azure-iot-toolkit-supports-c-go-java-node-js-php-python-and-ruby-to-develop-azure-iot-application-in-vs-code/)\n- [Use VS Code as IoT Hub Device Simulator](https://blogs.msdn.microsoft.com/iotdev/2018/07/12/use-vs-code-as-iot-hub-device-simulator-say-hello-to-azure-iot-hub-in-5-minutes/)\n- [Use VS Code to call Azure IoT Hub REST APIs](https://blogs.msdn.microsoft.com/iotdev/2018/07/19/call-azure-iot-hub-rest-apis-in-vs-code/)\n- [Create and control an IoT device connected to an IoT hub (Node.js)](https://github.com/Microsoft/vscode-azure-iot-toolkit/wiki/Quickstart-Node.js)\n- [Create and control an IoT device connected to an IoT hub (.NET)](https://github.com/Microsoft/vscode-azure-iot-toolkit/wiki/Quickstart-.NET)\n- [Handy Tool When You Develop With Azure IoT](https://blogs.msdn.microsoft.com/iotdev/2017/09/01/handy-tool-when-you-develop-with-azure-iot/)\n- [Azure IoT Hub extension for Visual Studio Code generally available for managing Azure IoT Hub and Devices with ease](https://blogs.msdn.microsoft.com/iotdev/2018/06/30/azure-iot-toolkit-for-visual-studio-code-generally-available-for-managing-azure-iot-hub-and-devices-with-ease/)\n\n## \u2764\ufe0f Contributors\n\nThanks to all the [contributors](https://github.com/Microsoft/vscode-azure-iot-toolkit/graphs/contributors)!\n\n\n\n## Data/Telemetry\nThis project collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](http://go.microsoft.com/fwlink/?LinkId=521839) to learn more. \nIf you don\u2019t wish to send usage data to Microsoft, you can set the `telemetry.enableTelemetry` setting to `false`. Learn more in our [FAQ](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting).\n"
 },
 {
  "repo": "microsoft/vscode-azuretools",
  "language": "TypeScript",
  "readme_contents": "# VSCode Azure SDK for Node.js\n\n[![Build Status](https://dev.azure.com/ms-azuretools/AzCode/_apis/build/status/vscode-azuretools)](https://dev.azure.com/ms-azuretools/AzCode/_build/latest?definitionId=17)\n\nThis project provides Node.js packages that make it easy to consume and manage Azure Services in Visual Studio Code.\n\n## Modules\n\n* [Azure Kudu](kudu/)\n* [Azure App Service](appservice/)\n* [Azure UI](ui/)\n* [Azure Dev](dev/)\n\n## Developing locally\n\nIn order to quickly develop and debug these packages locally, follow these instructions:\n1. Navigate to the package you are developing and run `npm install`, `npm run build`, and `npm link`\n1. Navigate to the project that references the package you're developing and run `npm link <name of package>`\n\nExample:\n```\n    cd ~/repos/vscode-azuretools/ui\n    npm install\n    npm run build\n    npm link\n    cd ~/repos/vscode-azurestorage\n    npm link vscode-azureextensionui\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n[MIT](LICENSE.md)"
 },
 {
  "repo": "microsoft/knack",
  "language": "Python",
  "readme_contents": "Knack\n=====\n\n.. image:: https://img.shields.io/pypi/v/knack.svg\n    :target: https://pypi.python.org/pypi/knack\n\n.. image:: https://img.shields.io/pypi/pyversions/knack.svg\n    :target: https://pypi.python.org/pypi/knack\n\n.. image:: https://dev.azure.com/azure-sdk/public/_apis/build/status/cli/microsoft.knack?branchName=dev\n    :target: https://dev.azure.com/azure-sdk/public/_build/latest?definitionId=1643&branchName=dev\n\n\n------------\n\n\n::\n\n    _                     _\n   | | ___ __   __ _  ___| | __\n   | |/ / '_ \\ / _` |/ __| |/ /\n   |   <| | | | (_| | (__|   <\n   |_|\\_\\_| |_|\\__,_|\\___|_|\\_\\\n\n\n**A Command-Line Interface framework**\n\nInstallation is easy via pip:\n\n.. code-block:: bash\n\n    pip install knack\n\nKnack can be installed as a non-privileged user to your home directory by adding \"--user\" as below:\n\n.. code-block:: bash\n\n    pip install knack --user\n\n------------\n\n.. note:: The project is in `initial development phase <https://semver.org/#how-should-i-deal-with-revisions-in-the-0yz-initial-development-phase>`__. We recommend pinning to at least a specific minor version when marking **knack** as a dependency in your project.\n\n------------\n\n\nUsage\n=====\n\n\n.. code-block:: python\n\n    import sys\n    from collections import OrderedDict\n\n    from knack import CLI, ArgumentsContext, CLICommandsLoader\n    from knack.commands import CommandGroup\n\n\n    def abc_str(length=3):\n        import string\n        return string.ascii_lowercase[:length]\n\n\n    class MyCommandsLoader(CLICommandsLoader):\n        def load_command_table(self, args):\n            with CommandGroup(self, 'abc', '__main__#{}') as g:\n                g.command('str', 'abc_str')\n            return OrderedDict(self.command_table)\n\n        def load_arguments(self, command):\n            with ArgumentsContext(self, 'abc str') as ac:\n                ac.argument('length', type=int)\n            super(MyCommandsLoader, self).load_arguments(command)\n\n\n    mycli = CLI(cli_name='mycli', commands_loader_cls=MyCommandsLoader)\n    exit_code = mycli.invoke(sys.argv[1:])\n    sys.exit(exit_code)\n\n    # $ python mycli.py abc str\n    # \"abc\"\n\n    # $ python mycli.py abc str --length 5\n    # \"abcde\"\n\n    # $ python mycli.py abc str --length 100\n    # \"abcdefghijklmnopqrstuvwxyz\"\n\n\nMore samples and snippets are available at `examples <https://github.com/Microsoft/knack/tree/dev/examples>`__.\n\n\nDocumentation\n=============\n\nDocumentation is available at `docs <https://github.com/Microsoft/knack/tree/dev/docs>`__.\n\nDeveloper Setup\n===============\n\nIn a virtual environment, install the `requirements.txt` file.\n\n.. code-block:: bash\n\n    pip install -r requirements.txt\n    pip install -e .\n\nRun Automation\n==============\n\nThis project supports running automation using `tox <https://tox.readthedocs.io/en/latest/>`__.\n\n.. code-block:: bash\n\n    pip install tox\n    tox\n\n\nReal-world uses\n===============\n\n- `Azure CLI <https://github.com/Azure/azure-cli/>`__: The Azure CLI 2.0 is Azure's new command line experience for managing Azure resources.\n- `VSTS CLI <https://github.com/Microsoft/vsts-cli>`__: A command-line interface for Visual Studio Team Services (VSTS) and Team Foundation Server (TFS). With the VSTS CLI, you can manage and work with resources including pull requests, work items, builds, and more.\n- `Service Fabric CLI <https://github.com/Azure/service-fabric-cli>`__: A command-line interface for interacting with Azure Service Fabric clusters and their related entities.\n\nDo you use knack in your CLI as well? Open a pull request to include it here. We would love to have it in our list.\n\n\nRelease History\n===============\n\nSee `GitHub Releases <https://github.com/Microsoft/knack/releases>`__.\n\n\nContribute Code\n===============\n\nThis project has adopted the `Microsoft Open Source Code of Conduct <https://opensource.microsoft.com/codeofconduct/>`__.\n\nFor more information see the `Code of Conduct FAQ <https://opensource.microsoft.com/codeofconduct/faq/>`__ or contact `opencode@microsoft.com <mailto:opencode@microsoft.com>`__ with any additional questions or comments.\n\nIf you would like to become an active contributor to this project, please\nfollow the instructions provided in `Contribution License Agreement <https://cla.microsoft.com/>`__.\n\n\nLicense\n=======\n\nKnack is licensed under `MIT <LICENSE>`__.\n"
 },
 {
  "repo": "microsoft/browsecloud",
  "language": "TypeScript",
  "readme_contents": "**BrowseCloud - Public Demo**\n\n[Try out BrowseCloud with a demonstration model trained on the English dictionary here.](https://aka.ms/browsecloud-demo)\n\n**BrowseCloud - Microsoft Internal**\n\n[If you're a Microsoft full-time employee, try out our full site.](https://aka.ms/browsecloud)\n\nIt supports creating custom visualizations with your own data set and correlate metadata with topics. This site also has a Gallery of models and visualizations with data such as the Microsoft employee engagement survey, called MSPoll, and feedback on the Windows Engineering System.\n\n# BrowseCloud [![Build Status](https://dev.azure.com/ms/browsecloud/_apis/build/status/microsoft.browsecloud?branchName=master)](https://dev.azure.com/ms/browsecloud/_build/latest?definitionId=161&branchName=master)\n![alt text](https://github.com/microsoft/browsecloud/blob/master/Images/browsecloud-screenshot.png \"A screenshot of the BrowseCloud visualization of feedback on the Windows & Devices Group Engineering Systems in 2018.\")\n\nIt's a laborious task to collect and synthesize the perspectives of customers.\nThere's an immense amount of customer data from a variety of digital channels: survey data, StackOverflow, Reddit, email, etc.\nEven for internal tools teams at Microsoft, there are at least 10,000 user feedback documents generated per quarter.\n\nTo help solve this problem, BrowseCloud is an application that summarizes feedback data via smart word clouds, called counting grids.\nOn a word cloud, the size of the text simply scales with the frequency of the word.\nText is scattered randomly on word clouds. In BrowseCloud, we have a word cloud where the position of the word matters.\nAs the user scans along the visualization, themes smoothly transition between each other.\n\n\n<a href=\"https://www.youtube.com/watch?v=pcsZPozC9uA\"><img src=\"https://raw.githubusercontent.com/microsoft/browsecloud/master/Images/IntroToBrowseCloudYouTube.PNG\" alt=\"Introduction to BrowseCloud\" /></a>\n\n<a href=\"https://www.youtube.com/watch?v=OjHaiafkZXs\"><img src=\"https://raw.githubusercontent.com/microsoft/browsecloud/master/Images/BrowseCloudTutorial.PNG\" alt=\"BrowseCloud Tutorial\" /></a>\n\n## Features\n- Add your custom text data set to the site. &ast;\n- Visualize the text data by inspecting the largest words in clusters around the screen.\n- Drop a pin by clicking on the visualization to view a ranked list of verbatims (shown on the far right-hand side of the screen) related to the micro-topic you pinned!\n- Search for a word to narrow down the visualization and ranked list further.\n- Correlate topics with positive or negative sentiment on the screen by looking at the color of the the words in a region, after applying the sentiment analysis job. &ast;\n- Correlate your own custom metadata with topic. We support numeric data, nominal data with two categories, and ordinal data. &ast;\n- Download the relevant verbatims into Excel!\n\n&ast; <sub><sup>These features are not supported in the demo application. They are in the full version.</sup></sub>\n\n## Getting Started\nOur documentation is available on this repository's [wiki](https://github.com/microsoft/browsecloud/wiki).\n\n# Build and Test\nWe have Azure Pipelines set up on the pull request workflow for pre-check-in validation. The pipeline will also deploy the demo site on merge with master.\n\nNote that it is not required that you use the service to get up and running with the app.\nYou can quickly visualize your data by using the Python command line application to train your data,\nand copying the resulting model files to the `/browsecloud-client/src/assets/demo` folder.\nYou can then run the demo client app by following the client setup steps and running `npm run start:demo`.\n\n## Client\n\nThe client is a simple Angular CLI generated application.\n\n- Ensure you have Node and NPM installed according to [Angular CLI requirements](https://angular.io/guide/setup-local).\n- change directories to `/browsecloud-client`.\n- run `npm install` and then `npm start`.\n- open http://localhost:4200 in your browser.\n\nAt this point the client should load in your browser for local development.\nYou will need to adjust some of the values in `src/environments/environment.ts` in order to login with your AAD app and point the app to the correct service URL.\nFor more information on how to create an AAD app,\nvisit the [azure docs](https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal).\n\nIf instead you want to build to host on your own webserver, you can run `npm run build` or `npm run build:prod`. You can then host these files in a simple Azure App Service or elsewhere.\n\nThere are currently no tests, but we would love it if someone would contribute some \ud83d\ude09\n\n## Service\n\nThe service is an ASP.NET Core application that has many Azure dependencies. We will first get these dependencies set up.\n\n- Visit the Azure Portal and create a new resource of type \"Template Deployment\".\nOn the next page, select \"Build your own template in the editor\", and upload the template file `/deployment/az-service-template.json`.\nOn the next page, fill in the resource and resource group names. Purchase this resource group.\n- Create an AAD app for the service. For more information on how to create an AAD app,\nvisit the [azure docs](https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal).\n- Perform some setup tasks on these resources.\n  - Visit the newly created Azure KeyVault, and add yourself to access the secrets in the \"Access policies\" pane.\n  - In the KeyVault's \"Secrets\" pane, you will find some secret names have been generated.\n  Populate these secrets with a secret for your AAD app, your Document DB secret,\n  and your Redis connection string (all generated by the template file). After setting up the Azure Batch infrastructure for training the models,\n  you can populate the rest of the secrets.\n  - On the newly created Cosmos Document DB account, create two new containers named \"BatchJob\" and \"Document\".\n- Download and install [Visual Studio 2019](https://visualstudio.microsoft.com/downloads) with the \"ASP.NET and web development\" workload.\n- In `/BrowseCloud.Service/BrowseCloud.Service/appsettings.json`, configure your development environment using the information from the services you just created.\n- You can then build and run using Visual Studio's built in build and run feature.\n\nThis can be built and deployed to the Azure App Service generated in the steps above for everyday use.\nThe easiest method is to right click on the BrowseCloud.Service project and \"Publish\", but we should recommend a CI/CD pipeline of some type.\nWe have our Azure DevOps build pipelines checked in as yaml files which you are welcomed to use.\n\nThere are currently no tests on the Service, but we welcome contribution on this front.\n\n## Trainer Jobs\nThis is the machine learning backend that powers BrowseCloud. It has many Azure dependencies.\n\n- Visit the Azure Portal and create a new resource of type \"Template Deployment\".\nOn the next page, select \"Build your own template in the editor\", and upload the template file `/deployment/az-ml-backend-template.json`.\nOn the next page, fill in the resource and resource group names. Purchase this resource group.\n\nNext, we will setup our VM. The work to setup dependencies on a machine in the cloud like this is automatable, but it hasn't been done. \n- Visit the Azure Portal and choose to create a new resource of type \"Windows Server 2016 Datacenter\". In this initial setup, make sure you have RDP enabled to setup the VM. \n- RDP into the non-production VM and [follow the setup instructions to get the CountingGridsPy library running on the VM](https://github.com/microsoft/browsecloud/wiki/Environment-Setup-&-Dependencies-to-run-CountingGridsPy-Locally). In your production instance of the VM, we recommend that you have RDP turned off. \n- Save your VM as an image within the new virtual machine resource on the Azure Portal. This will destabilize the VM, so you should delete the VM.\n\n- Next, we'll take a look at the Batch resource you generated from the template. The purpose of Batch is to manage and scale computational power with the machine learning work to do. \n\nCreate two jobs and two pools within this Batch resource, one for your dev environment and another for your production environment. You can do this by using the Azure portal or by using `\\Batch\\Batch\\src\\deployBrowseCloudBatchPool.py`. In our design, jobs are permenant, and each training request is a task underneath each job.\n\nWe recommend that you scale the number of VMs elastically with the number of tasks running on your queue, so work can be done in parallel. You can even have multiple tasks running on the same machine using Batch. Lastly, recommend that you always have one Windows VM running and ready to go due to in the autoScale Formula.\n\nAn example scaling configuration could be:\n\n```json\n\"scaleSettings\": {\n    \"autoScale\": {\n        \"formula\": \"maxNumberofVMs = 5;sample =$PendingTasks.GetSample(10);pendingTaskSamplePercent = avg(sample);startingNumberOfVMs = 1; pendingTaskSamples = pendingTaskSamplePercent < 2 ? startingNumberOfVMs : avg($PendingTasks.GetSample(180 * TimeInterval_Second));$TargetDedicatedNodes=min(maxNumberofVMs, pendingTaskSamples);\",\n        \"evaluationInterval\": \"PT5M\"\n    }\n}\n```\n\nWe also recommend that you use a more powerful VM in your production instance than in your development instance. We use \"vmSize\" of \"STANDARD_D16_V3\" on our production site for training new models. We use a \"vmSize\" of \"STANDARD_A1\" in our development instance.\n\n- In `/Batch/Batch/src/metadata.json` and `/Batch/Batch/src/keys.json` (which are not checked into this repo), configure your development environment using the information from the services you just created.\n\n\n# Contributing\nThis project welcomes contributions and suggestions. Most contributions require you to\nagree to a Contributor License Agreement (CLA) declaring that you have the right to,\nand actually do, grant us the rights to use your contribution. For details, visit\nhttps://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need\nto provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the\ninstructions provided by the bot. You will only need to do this once across all repositories using our CLA.\n\n## Feedback\nYour pull request will now go through extensive checks by the subject matter experts on our team.\nPlease be patient; we have hundreds of pull requests across all of our repositories.\nUpdate your pull request according to feedback until it is approved by one of the team members.\n\n## Code of conduct\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Privacy Notice\n\nThere are also some features in the software that may enable you and Microsoft to collect data from users of your applications.\nIf you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together\nwith a copy of Microsoft's privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. \nYou can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.\n\n# Reporting Security Issues\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security\nResponse Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should\nreceive a response within 24 hours. If for some reason you do not, please follow up via\nemail to ensure we received your original message. Further information, including the\n[MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in\nthe [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\n"
 },
 {
  "repo": "microsoft/FluidFramework",
  "language": "TypeScript",
  "readme_contents": "# Fluid\n\nThe Fluid Framework is a TypeScript library for building distributed, real-time collaborative web\napplications.\n\n## Getting started using the Fluid Framework\n\nYou may be here because you want to...\n\n* Learn more about the Fluid Framework\n* Build a Fluid object\n\nDocumentation and guides can be found at <https://fluidframework.com/>.\n\nHello World repo can be found at <https://github.com/microsoft/FluidHelloWorld>.\n\nCore Examples repo can be found at <https://github.com/microsoft/FluidExamples>.\n\nHave questions? Engage with other Fluid Framework users and developers on\n[StackOverflow](https://stackoverflow.com/questions/tagged/fluid-framework)\n\n## Code structure\n\nThe core code for both the Fluid client packages _and_ the reference ordering service is contained within this repo.\n\nThe repo structure is somewhat unique because it contains two monorepos as well as several standalone packages. The\nmonorepos are managed using [Lerna](https://lerna.js.org/) and are versioned separately from one another, but internally\nall packages in a monorepo are versioned together. Outside the monorepos there are plenty of packages which are\nversioned independently.\n\nHere's the breakdown of the repo:\n\n* Fluid Framework Client Monorepo ([lerna.json](./lerna.json))\n  * [Packages](./packages)\n  * [Fluid Examples](./examples)\n* Reference Fluid Ordering Service (\"Routerlicious\") Monorepo ([dir](./server/routerlicious) | [lerna.json](server/routerlicious/lerna.json))\n  * [Packages](./server/routerlicious/packages)\n* Common Packages\n  * [Common Definitions](./common/lib/common-definitions)\n  * [Common Utils](./common/lib/common-utils)\n* Auxiliary Microservice Packages (supporting Routerlicious)\n  * [Server dir](./server) (excluding [Routerlicious](./server/routerlicious) itself)\n* Internal/Misc Packages\n  * [Build Common](./common/build/build-common)\n  * [ESlint Config](./common/build/eslint-config-fluid)\n  * [Docs](./docs)\n  * [Tools](./tools)\n\nDependencies between packages in various layers of the system are enforced via a build step called\n[layer-check](./tools/build-tools/src/layerCheck). You can view the full list of packages and layers in\n[docs/PACKAGES.md](./docs/PACKAGES.md).\n\n## Building\nIn order to build the Fluid Framework, ensure that you have installed [Git](https://git-scm.com/downloads) and the version of\n[Node.js](https://nodejs.org/) noted in the [.nvmrc file](https://raw.githubusercontent.com/microsoft/FluidFramework/main/.nvmrc).\n\nNote: we recommend using nvm (for [Windows](https://github.com/coreybutler/nvm-windows) or\n[MacOS/Linux](https://github.com/nvm-sh/nvm)) to install Node.js, in case you find yourself needing to install different\nversions of Node.js side-by-side.\n\nClone a copy of the repo and change to the repo root directory:\n\n```shell\ngit clone https://github.com/microsoft/FluidFramework.git\ncd FluidFramework\n```\n\nRun the following to build the client packages:\n\n```shell\nnpm install\nnpm run build:fast\n```\n\nSee also: [Contributing](#Contributing)\n\n## Testing\n\nYou can run all of our tests from the root of the repo, or you can run a scoped set of tests by running the `test`\ncommand from the package you're interested in.\n\nNote: Some of the tests depend on test collateral that lives in a submodule here:\n<https://github.com/microsoft/FluidFrameworkTestData>.  You may choose to fetch that collateral into your local\nrepository, which is required to run all the tests - otherwise some will be skipped.\n\nFirst install Git LFS from <https://git-lfs.github.com/>. Then, from the repo root:\n\n```shell\ngit lfs install\ngit submodule init\ngit submodule update\n```\n\n### Run the tests\n\n```shell\nnpm run test\n```\n\n### Include code coverage\n\n```shell\nnpm run test:coverage\n```\n\n### Mimic the official CI build\n\nOur CI pipelines run on Linux machines, and the npm scripts all have the `ci` prefix.\nTo replicate the test steps from the CI pipeline locally, run the following commands for the packages or Lerna monorepos:\n\nRun      | Non-Windows                | Windows                                               |\n---------|----------------------------|-------------------------------------------------------|\nPR       | `npm run ci:test`          | `npm run test:report && npm run test:copyresults`     |\nOfficial | `npm run ci:test:coverage` | `npm run test:coverage && npm run test:copyresults`   |\n\n### Run tests from within VS Code\n\nWe've checked in [VS Code configuration](https://github.com/microsoft/FluidFramework/blob/main/.vscode/launch.json)\nenabling F5 from a `spec.ts` file to run those tests if you set the debug configuration to \"Debug Current Test\".\n\n## Run it locally\n\n### Single browser window, two panes\n\n_This will use an in-memory implementation of the Fluid server to sync between the two panes in the browser window._\n\n* Choose an example under `/examples`\n* Navigate to the example's directory, e.g. `/examples/data-objects/clicker`\n* `npm run start`\n* Browse to <http://localhost:8080> to interact with two copies of the example side-by-side\n\n### Multiple browser instances on the same device\n\n_This will run the local Fluid server implementation we call \"Tinylicious\", so you can sync between multiple browser\ninstances._\n\nFirst, start Tinylicious by running these commands from `/server/tinylicious`:\n\n```shell\nnpm install\nnpm run build\nnpm run start\n```\n\nThen:\n\n* Navigate to the example of your choice (same as above)\n* `npm run start:tinylicious`\n* Browse to <http://localhost:8080,> copy the full URL you're redirected to, and open in a second window to collaborate\n\n## Contributing\n\nThere are many ways to [contribute](https://github.com/microsoft/FluidFramework/blob/main/CONTRIBUTING.md) to Fluid.\n\n* Participate in Q&A on [StackOverflow](https://stackoverflow.com/questions/tagged/fluid-framework)\n* [Submit bugs](https://github.com/microsoft/FluidFramework/issues) and help us verify fixes as they are checked in.\n* Review the [source code changes](https://github.com/microsoft/FluidFramework/pulls).\n* [Contribute bug fixes](https://github.com/microsoft/FluidFramework/blob/main/CONTRIBUTING.md).\n\nDetailed instructions for working in the repo can be found in the\n[Wiki](https://github.com/microsoft/FluidFramework/wiki).\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact\n[opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nThis project may contain Microsoft trademarks or logos for Microsoft projects, products, or services. Use of these\ntrademarks or logos must follow Microsoft\u2019s [Trademark & Brand Guidelines](https://www.microsoft.com/trademarks). Use of\nMicrosoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft\nsponsorship.\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-CardBrowser",
  "language": "TypeScript",
  "readme_contents": "\n[![Node.js CI](https://github.com/microsoft/PowerBI-visuals-CardBrowser/workflows/Node.js%20CI/badge.svg)](https://github.com/microsoft/PowerBI-visuals-CardBrowser/actions)\n\n# Card Browser\nBrowse documents using double-sided cards, and click to view in place.\n\nCard Browser is a document set viewer featuring flippable, double-sided cards for natural navigation of media collections. \n\nThe Preview face of each card renders the headline image, title, and origin of the story with a text sample, enabling rapid discovery of documents of interest.  Flipping the cards reveals the MetaData face, which lists document properties. Clicking on a card expands it in place for detailed reading.\n\n![Alt text](assets/2-reader.png?raw=true \"Card Browser Reader\")\n\n![Alt text](assets/3-metadata.png?raw=true \"Card Browser Metadata\")\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Debugging\n\n* Install ssl certificate by running `yarn run install-certificate` and following the steps from: [https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/CertificateSetup.md](https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/CertificateSetup.md)\n* Enable Developer Tools in PowerBI: [https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/DebugVisualSetup.md](https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/DebugVisualSetup.md)\n* Run `yarn start` to start development.\n\n## Building\n\n* Run `yarn run package` to package the visual.\n* `.pbiviz` file will be generated in the `dist` folder\n\n## Testing\n\n* Run `yarn test`\n"
 },
 {
  "repo": "microsoft/Azure-Sphere-DevX",
  "language": "C",
  "readme_contents": "# Azure Sphere DevX library\n\nThe DevX library can accelerate your development and improve your developer experience with Azure Sphere. The DevX library addresses many common Azure Sphere scenarios, it will help reduce the amount of code you write and improve readability and long-term application maintenance.\n\nTo learn more about Azure Sphere and Azure RTOS check out [Combining Azure Sphere IoT security with Azure RTOS real-time capabilities](https://techcommunity.microsoft.com/t5/internet-of-things/combining-azure-sphere-iot-security-with-azure-rtos-real-time/ba-p/1992869) article.\n\nThere are two Microsoft Learn modules which include hands-on labs you can download to start your Azure Sphere and Azure RTOS journey.\n\n- [Develop secure IoT solutions for Azure Sphere, Azure RTOS and Azure IoT Central](https://docs.microsoft.com/en-us/learn/modules/develop-secure-iot-solutions-azure-sphere-iot-central?WT.mc_id=iot-10976-dglover)\n- [Develop secure IoT Solutions for Azure Sphere, Azure RTOS and IoT Hub](https://docs.microsoft.com/en-us/learn/modules/develop-secure-iot-solutions-azure-sphere-iot-hub?WT.mc_id=iot-11691-dglover)\n\nThe DevX library is built from the [Azure Sphere samples](https://github.com/Azure/azure-sphere-samples), it's well tested, and aims to facilitate Azure Sphere best practices. The DevX library is lightweight, addresses common scenarios, and will sit alongside your existing code base.\n\nThe DevX library design is context-based, you declare a context and implement a context handler (or callback). See the [Encapsulate Pattern](https://accu.org/journals/overload/12/63/kelly_246/), it's a fair description of how this library works.\n\nThe library prefixes all file names, functions, structures, and enums with DX_ or dx_ to avoid clashes with existing code and file names.\n\nThe library supports the following contexts:\n\nNote, you will find examples of each context in the [examples folder](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples) of this repo or you can click on the context type to navigate to an example in your web browser.\n\n1. [Azure IoT messaging](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/send_message).\n1. [Direct Methods](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/direct_methods).\n1. [Device Twins](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/device_twins).\n1. [GPIO](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/gpio_example). Note, GPIO is supported as it's use can be generalized. There are no plans to generalize the use of ADC, PWM, I2C and SPI peripherals given the varied nature of their use.\n1. [Intercore communications](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/intercore_example).\n1. [Termination](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/terminate_example).\n1. [Timers](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples/timer_example).\n\n---\n\n## How to use the library\n\nThis example assumes you are using git, otherwise download the [Azure Sphere DevX library](https://github.com/microsoft/Azure-Sphere-DevX) and add to the directory to your project.\n\n```bash\ngit submodule add https://github.com/microsoft/Azure-Sphere-DevX.git\n```\n\n### Update your CMakeLists.txt to include the DevX library\n\n#### Add the library sub directory\n\n```text\nadd_subdirectory(\"Azure-Sphere-DevX\" out)\n```\n\n#### Add *azure_sphere_devx* to the link libraries\n\n```text\ntarget_link_libraries (${PROJECT_NAME} applibs pthread gcc_s c azure_sphere_devx)\n```\n\n#### Add to include directories\n\n```text\ntarget_include_directories(${PROJECT_NAME} PUBLIC Azure-Sphere-DevX/include )\n```\n\n---\n\n## Example CMakeLists.txt file\n\nThe following is an example of what the completed CMakeLists.txt file could look like.\n\n```text\ncmake_minimum_required (VERSION 3.10)\nproject (AzureSphereAzureIoT C)\n\nazsphere_configure_tools(TOOLS_REVISION \"21.01\")\nazsphere_configure_api(TARGET_API_SET \"8\")\n\nadd_subdirectory(\"Azure-Sphere-DevX\" out)\n\nset(Source\n    \"main.c\"\n)\nsource_group(\"Source\" FILES ${Source})\n\nset(ALL_FILES\n    ${Source}\n)\n\n# Create executable\nadd_executable(${PROJECT_NAME} ${ALL_FILES})\n\ntarget_compile_definitions(${PROJECT_NAME} PUBLIC AZURE_IOT_HUB_CONFIGURED)\ntarget_link_libraries(${PROJECT_NAME} applibs pthread gcc_s c azure_sphere_devx )\n\ntarget_include_directories(${PROJECT_NAME} PUBLIC Azure-Sphere-DevX/include . )\n\ntarget_compile_options(${PROJECT_NAME} PRIVATE -Wno-unknown-pragmas)\n\nazsphere_target_add_image_package(${PROJECT_NAME})\n```\n\n---\n\n## Examples\n\nYou can find fully documented examples in the [examples folder](https://github.com/microsoft/Azure-Sphere-DevX/tree/main/examples).\n\nThe following is an example of how you can declare a number of device twins context objects.\n\n```c\nstatic DX_DEVICE_TWIN_BINDING dt_desired_sample_rate = {\n\t.twinProperty = \"DesiredSampleRate\",\n\t.twinType = DX_TYPE_INT,\n\t.handler = dt_desired_sample_rate_handler };\n```\n\n```c\nstatic DX_DEVICE_TWIN_BINDING dt_reported_temperature = {\n\t.twinProperty = \"ReportedCurrentTime\",\n\t.twinType = DX_TYPE_STRING };\n```\n\nYou will see that the declarations include the property name, the type, and the handler function to call when a device twin update for the property is received.\n\nNext the each device twins needs to be added by reference to an array (or set) of device twins.\n\n```c\nDX_DEVICE_TWIN_BINDING* deviceTwinBindingSet[] = { &dt_desired_sample_rate, &dt_reported_temperature };\n```\n\nand finally the array of device twins needs to be initialized or started.\n\n```c\ndx_timerSetStart(timerSet, NELEMS(timerSet));\n```\n\nWhen a device twin message is received, this set of device twins is checked for a matching property name, when a match is found, the JSON payload is deserialized, the type is checked to ensure it is of the correct type as declared in the device twin context. Then the device twin context handler is called passing the context by reference to the handler function.\n\nThe following is an example of the device twin handler that is called.\n\n```c\nstatic void dt_desired_sample_rate_handler(DX_DEVICE_TWIN_BINDING* deviceTwinBinding) {\n\t// validate data is sensible range before applying\n\tif (deviceTwinBinding->twinType == DX_TYPE_INT && *(int*)deviceTwinBinding->twinState >= 0 && *(int*)deviceTwinBinding->twinState <= 120) {\n\t\tdx_timerChange(&report_now_timer, &(struct timespec){*(int*)deviceTwinBinding->twinState, 0});\n\t\tdx_deviceTwinAckDesiredState(deviceTwinBinding, deviceTwinBinding->twinState, DX_DEVICE_TWIN_COMPLETED);\n\t} else {\n\t\tdx_deviceTwinAckDesiredState(deviceTwinBinding, deviceTwinBinding->twinState, DX_DEVICE_TWIN_ERROR);\n\t}\n\n\t/*\tCasting device twin state examples\n\n\t\tfloat value = *(float*)deviceTwinBinding->twinState;\n\t\tint value = *(int*)deviceTwinBinding->twinState;\n\t\tbool value = *(bool*)deviceTwinBinding->twinState;\n\t\tchar* value = (char*)deviceTwinBinding->twinState;\n\t*/\n}\n```\n\nThis is how the context model works. You declare the object and you pass by reference to a function that understands the context object.  You don't have to deal with all the underlying code for managing the device twin callback, the JSON deserialisation, or the type checking. That is all done for you, the function is called, and you have access to the context to make further decisions in your code.\n"
 },
 {
  "repo": "microsoft/ai.ed",
  "language": "Python",
  "readme_contents": "# AI.Ed\n\nThis is the AI for (programming) EDucation project.  The goal is to provide a great set of tools to provide AI-powered\nassistance to students taking programming classes and educators teaching them.\n\nThis project is open source and freely available for educational purposes.  All of the source code in this repository is\navailable under the MIT license.\n\n**Please note:** this project depends on the Microsoft PROSE SDK, which is a separate, closed-source binary licensed\nunder separate, proprietary terms.  When the Microsoft PROSE SDK is included in the project at build time, the terms of\nthe Microsoft PROSE SDK may limit what you can do with your build of this project (e.g., non-commercial use only).  See\nthe [LICENSE](LICENSE) file for more information.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a Contributor License\nAgreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For\ndetails, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate\nthe PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only\nneed to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact\n[opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks\nor logos is subject to and must follow [Microsoft's Trademark & Brand\nGuidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft\ntrademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any\nuse of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/vscode-hydrate",
  "language": "TypeScript",
  "readme_contents": "# Hydrate Extension for Visual Studio Code\r\n[![Build Status](https://dev.azure.com/epicstuff/vscode-hydrate/_apis/build/status/microsoft.vscode-hydrate?branchName=master)](https://dev.azure.com/epicstuff/vscode-hydrate/_build/latest?definitionId=104&branchName=master)\r\n## Overview\r\nThis is the Visual Studio Code Hydrate extension, which builds upon the [VSCode Kubernetes Extension](https://github.com/Azure/vscode-kubernetes-tools). It allows developers to use [Hydrate](https://github.com/microsoft/hydrate) within VSCode, which crawls a Kubernetes cluster and generates a high level description in a `component.yaml` file for its deployments.\r\n\r\nInstead of running Hydrate from the command line and entering flags and options manually, this extension allows users to select a Kubernetes cluster and run Hydrate within VSCode.\r\n \r\n## Install the Extension!\r\nFirst, make sure that you have [Docker](https://www.docker.com/) set up (the extension runs Hydrate on Docker). Next, download the extension [here](https://marketplace.visualstudio.com/items?itemName=madelineliao.vscode-hydrate). If you do not have the [VSCode Kubernetes Extension](https://github.com/Azure/vscode-kubernetes-tools) installed, it will automatically be installed during the Hydrate extension installation. A window reload is required after installation.\r\n\r\nNavigate to the Kubernetes view by clicking the Kubernetes icon in the sidebar. Right-click the cluster you would like to run Hydrate on, and select `Hydrate Cluster`. You will be prompted step-by-step through selecting options for Hydrate (e.g. output file path).\r\n\r\nNote: all clusters displayed in the sidebar are associated with the same `kubeconfig` file. To test out a different kubeconfig, click the \"options\" icon (the three dots) in the Kubernetes extension cluster explorer and click `Set Kubeconfig` to change the current `kubeconfig` file used. Then, you can run Hydrate on the newly displayed clusters with the new kubeconfig. \r\n\r\n![](https://thumbs.gfycat.com/DifficultPiercingIndianjackal-size_restricted.gif)\r\n\r\nFor example, the results of running a verbose dry-run:\r\n\r\n![alt text](https://thumbs.gfycat.com/CreativeSpectacularHound-size_restricted.gif)\r\n## Testing the Extension\r\nFirst, clone the repo locally by running the following command:\r\n```\r\ngit clone https://github.com/microsoft/vscode-hydrate\r\n```\r\n\r\nThere are two ways to run tests:\r\n1. From the command line, within the `vscode-hydrate` directory, run:\r\n```\r\nnpm test\r\n```\r\n2. Alternatively, tests can be run in VSCode. From wherever the cloned repo lives, run:\r\n```\r\ncode ./vscode-hydrate\r\n```\r\nThen, navigate to the Debugger view in the sidebar. Click the dropdown next to the green 'play' button, and click `Extension Tests`. Then click the play button to run the tests. Output will be printed to the VSCode `Debug Console`.\r\n\r\n## Dependencies\r\n* [VSCode Kubernetes Tools and its dependencies](https://github.com/Azure/vscode-kubernetes-tools)\r\n* [Hydrate](https://github.com/microsoft/hydrate) and its dependencies\r\n\r\n# Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/BuildXL",
  "language": "C#",
  "readme_contents": "# Microsoft Build Accelerator\r\n\r\n<img alt=\"BuildXL Icon\" src=\"Public/Src/Branding/BuildXL.png\" width=15%>\r\n\r\n## Introduction\r\n\r\nBuild Accelerator, BuildXL for short, is a build engine originally developed for large internal teams at Microsoft, and owned by the [Tools for Software Engineers](https://www.microsoft.com/en-us/research/project/tools-for-software-engineers/) team, part of the Microsoft One Engineering System internal engineering group. Internally at Microsoft, BuildXL runs 30,000+ builds per day on [monorepo](https://en.wikipedia.org/wiki/Monorepo) codebases up to a half-terabyte in size with a half-million process executions per build, using distribution to thousands of data center machines and petabytes of source code, package, and build output caching. Thousands of developers use BuildXL on their desktops for faster builds even on mega-sized codebases.\r\n\r\nBuildXL accelerates multiple build languages, including:\r\n\r\n* MSBuild (using new features under development in MSBuild 16 which will ship in future versions of Visual Studio 2019 and the .NET Core SDK)\r\n* CMake (under development)\r\n* Its own internal scripting language, DScript, an experimental TypeScript based format used as an intermediate language by a small number of teams inside Microsoft\r\n\r\nBuildXL has a command-line interface. There are currently no plans to integrate it into Visual Studio. The project is open source in the spirit of transparency of our engineering system. You may find our technology useful if you face similar issues of scale. Note that BuildXL is not intended as a replacement for MSBuild or to indicate any future direction of build languages from Microsoft.\r\n\r\n## Documentation\r\nThe BuildXL documentation main page is [here](Documentation/INDEX.md).\r\n\r\n## Examples and Demos\r\nSee the `Examples/` folder for basic project examples. See the [Demos](Public/Src/Demos/Demos.md) page for information about various technical demos like using the process sandboxing code.\r\n\r\n# Building the Code\r\n\r\n## Build Status - Azure DevOps Pipelines\r\n[![Build status](https://dev.azure.com/mseng/Domino/_apis/build/status/8196?branchName=master)](https://dev.azure.com/mseng/Domino/_build/latest?definitionId=8196)\r\n\r\n## Command Line Build and Test\r\nSee the [Developer Guide](Documentation/Wiki/DeveloperGuide.md) for instructions on compiling BuildXL.\r\n\r\n# Contributing\r\nSee [CONTRIBUTING](CONTRIBUTING.md).\r\n"
 },
 {
  "repo": "microsoft/vscode-css-languageservice",
  "language": "TypeScript",
  "readme_contents": "# vscode-css-languageservice\nLanguage services for CSS, LESS and SCSS\n\n[![npm Package](https://img.shields.io/npm/v/vscode-css-languageservice.svg?style=flat-square)](https://www.npmjs.org/package/vscode-css-languageservice)\n[![NPM Downloads](https://img.shields.io/npm/dm/vscode-css-languageservice.svg)](https://npmjs.org/package/vscode-css-languageservice)\n[![Azure DevOps Build Status](https://img.shields.io/azure-devops/build/vscode/2377f926-a00b-46ed-9fb1-79465b3e998b/20.svg?label=Azure%20DevOps)](https://dev.azure.com/vscode/vscode-css-languageservice/_build?definitionId=20)\n[![Travis Build Status](https://img.shields.io/travis/microsoft/vscode-css-languageservice.svg?label=Travis)](https://travis-ci.org/Microsoft/vscode-css-languageservice)\n\nWhy?\n----\nThe _vscode-css-languageservice_ contains the language smarts behind the CSS, LESS and SCSS editing experience of Visual Studio Code\nand the Monaco editor.\n - *doValidation* analyses an input string and returns syntax and lint errors.\n - *doComplete* provides completion proposals for a given location.\n - *doHover* provides a hover text for a given location.\n - *findDefinition* finds the definition of the symbol at the given location.\n - *findReferences* finds all references to the symbol at the given location.\n - *findDocumentHighlights* finds all symbols connected to the given location.\n - *findDocumentSymbols* provides all symbols in the given document\n - *doCodeActions* evaluates code actions for the given location, typically to fix a problem.\n - *findColorSymbols* evaluates all color symbols in the given document\n - *doRename* renames all symbols connected to the given location.\n  - *getFoldingRanges* returns folding ranges in the given document.\n\nInstallation\n------------\n\n    npm install --save vscode-css-languageservice\n    \n    \nAPI\n---\n\nFor the complete API see [cssLanguageService.ts](./src/cssLanguageService.ts) and [cssLanguageTypes.ts](./src/cssLanguageTypes.ts) \n\n\nDevelopment\n-----------\n\n\n- clone this repo, run yarn\n- `yarn test` to compile and run tests\n\nHow can I run and debug the service?\n\n- open the folder in VSCode.\n- set breakpoints, e.g. in `cssCompletion.ts`\n- run the Unit tests from the run viewlet and wait until a breakpoint is hit:\n![image](https://user-images.githubusercontent.com/6461412/94239202-bdad4e80-ff11-11ea-99c3-cb9dbeb1c0b2.png)\n\n\nHow can I run and debug the service inside an instance of VSCode?\n\n- run VSCode out of sources setup as described here: https://github.com/Microsoft/vscode/wiki/How-to-Contribute\n- use `yarn link vscode-css-languageservice` in `vscode/extensions/css-language-features/server` to run VSCode with the latest changes from `vscode-css-languageservice`\n- run VSCode out of source (`vscode/scripts/code.sh|bat`) and open a `.css` file\n- in VSCode window that is open on the `vscode-css-languageservice` sources, run command `Debug: Attach to Node process` and pick the `code-oss` process with the `css-language-features` path\n![image](https://user-images.githubusercontent.com/6461412/94242567-842b1200-ff16-11ea-8f85-3ebb72d06ba8.png)\n- set breakpoints, e.g. in `cssCompletion.ts`\n- in the instance run from sources, invoke code completion in the `.css` file\n\n\n\n**Note: All CSS entities (properties, at-rules, etc) are sourced from https://github.com/microsoft/vscode-custom-data/tree/master/web-data and transpiled here. For adding new property or fixing existing properties' completion/hover description, please open PR there).**\n\n\nLicense\n-------\n\n(MIT License)\n\nCopyright 2016, 20 Microsoft\n\nWith the exceptions of `build/mdn-documentation.js`, which is built upon content from [Mozilla Developer Network](https://developer.mozilla.org/en-US/docs/Web)\nand distributed under CC BY-SA 2.5.\n"
 },
 {
  "repo": "microsoft/BotFramework-Composer-Nightlies",
  "language": null,
  "readme_contents": "\n# Nightly Releases of [Bot Framework Composer](https://github.com/microsoft/BotFramework-Composer)\n\nThis repository is where nightly releases of [Bot Framework Composer](https://github.com/microsoft/BotFramework-Composer) are published.\n\n**Note:** These releases aren't considered stable and contain the latest features in Composer.\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/FHIR-Converter",
  "language": "Liquid",
  "readme_contents": "# FHIR Converter\n\nFHIR Converter is an open source project that enables conversion of health data from legacy formats to FHIR.\n\nThe first version of the FHIR Converter released to open source on Mar 6th, 2020. It used Handlebars template language and Javascript runtime. A new converter engine was released on Nov 13, 2020 that uses Liquid templating language and .Net runtime.\n\nBoth Handlebars and Liquid converters, and corresponding templates/filters, are supported by Microsoft. We recommend using Liquid converter for better alignment with [Azure API for FHIR](https://azure.microsoft.com/en-us/services/azure-api-for-fhir/), [FHIR Server for Azure](https://github.com/microsoft/fhir-server), and [Microsoft Logic Apps](https://azure.microsoft.com/en-us/services/logic-apps/).\n\nThe following table compares the two converter engines:\n\n|  | Handlebars Engine | Liquid Engine | \n| ----- | ----- | ----- |\n| **Template language** | [Handlebars](https://handlebarsjs.com/) | [Liquid](https://shopify.github.io/liquid/) |\n| **Template authoring tool** | Self-hosted web-app | [VS Code extension](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-health-fhir-converter)|\n| **Supported conversions** | 1. HL7v2 to FHIR <br> 2. C-CDA to FHIR | 1. HL7 v2 to FHIR <br> 2. *C-CDA to FHIR (to be released soon)*|\n| **Available as** | 1. Self-deployed web service <br> (on-prem or on Azure)| 1. Command line tool <br> 2. $convert-data operation in  FHIR Server for Azure <br> 3. $convert-data operation in Azure API for FHIR.|\n\n\n\u26a0 Rest of this document is about the Liquid converter. For the Handlebars converter, refer to the [Handlebars branch](https://github.com/microsoft/FHIR-Converter/tree/handlebars).\n\nThe Converter makes use of templates that define the mappings between different data formats.\nThe templates are written in [Liquid](https://shopify.github.io/liquid/) templating language and make use of custom [filters](docs/FiltersSummary.md), which make it easy with work with HL7 v2 messages.\n\nThe converter comes with ready to use templates for HL7v2 to FHIR conversion. These templates are based on the [spreadsheet](https://docs.google.com/spreadsheets/d/1PaFYPSSq4oplTvw_4OgOn6h2Bs_CMvCAU9CqC4tPBgk/edit#gid=0) created by the HL7 [2-To-FHIR project](https://confluence.hl7.org/display/OO/2-To-FHIR+Project). If needed, you can create new, or modify existing templates to meet your specific conversion requirements.\n\nFHIR Converter with DotLiquid engine is integrated into the [Azure API for FHIR](https://azure.microsoft.com/en-us/services/azure-api-for-fhir/), and [FHIR Server for Azure](https://github.com/microsoft/fhir-server) as the [$convert-data](https://docs.microsoft.com/en-us/azure/healthcare-apis/convert-data) operation. In addition, it is also available as a command-line tool. The converter transforms the input data into FHIR bundles that can be persisted to a FHIR server.\n\nThis project consists of the following components:\n\n1. A command-line tool) for converting data and managing templates.\n2. [Templates](data/Templates) for HL7 v2 to FHIR conversion.\n3. [Sample data](data/SampleData) for testing purpose.\n\n## Using the FHIR Converter\n\n### $convert-data operation in the Azure API for FHIR\n\nFHIR Converter is integrated into Azure API for FHIR, and FHIR Server for Azure to run as part of the service. Refer to the [$convert-data](https://docs.microsoft.com/en-us/azure/healthcare-apis/convert-data) documentation for using the FHIR converter in the FHIR Server for Azure.\n\n### Command-line tool\n\n**Convert Data**\n\nThe command-line tool can be used to convert a folder containing HL7 v2 messages to FHIR resources.\nHere are the parameters that the tool accepts:\n\n| Option | Name | Optionality | Default | Description |\n| ----- | ----- | ----- |----- |----- |\n| -d | TemplateDirectory | Required | | Root directory of templates. |\n| -r | RootTemplate | Required | | Name of root template. Valid values are ADT_A01, OML_O21, ORU_R01, VXU_V04. |\n| -c | InputDataContent | Optional| | Input data content. Specify OutputDataFile to get the results. |\n| -f | OutputDataFile | Optional | | Output data file. |\n| -i | InputDataFolder | Optional | | Input data folder. Specify OutputDataFolder to get the results. |\n| -o | OutputDataFolder | Optional | | Output data folder. |\n| -t | IsTraceInfo | Optional | | Provide trace information in the output if \"-t\" is set. |\n| --version | Version | Optional | | Display version information. |\n| --help | Help | Optional | | Display usage information of this tool. |\n\nExample usage to convert HL7 v2 messages to FHIR resources in a folder:\n```\n>.\\Microsoft.Health.Fhir.Liquid.Converter.Tool.exe convert -d myTemplateDirectory -r ADT_A01 -i myInputDataFolder -o myOutputDataFolder\n```\n\n**Manage Templates**\n\nThe command-line tool also supports managing different versions of templates from Azure Container Registry (ACR). Users can customize templates and store them on ACR if default templates can not meet requirements. After [ACR authentication](docs/TemplateManagementCLI.md), users can pull and push templates from/to a remote ACR through our tool.\n\nExample command to push a collection of templates to ACR image from a folder:\n```\n>.\\Microsoft.Health.Fhir.Liquid.Converter.Tool.exe push testacr.azurecr.io/templatetest:default myInputFolder\n```\nExample usage of pulling an image of templates in a folder:\n\n```\n>.\\Microsoft.Health.Fhir.Liquid.Converter.Tool.exe pull testacr.azurecr.io/templatetest@sha256:412ea84f1bb1a9d98345efb7b427ba89616ec29ac332d543eff9a2161ca12a58 myOutputFolder\n\n```\nMore details of usage are given in [Template Management CLI tool](docs/TemplateManagementCLI.md).\n\nBesides current version of [templates](data/Templates) given in our project, other versions that released by Microsoft are stored in a public ACR: healthplatformregistry.azurecr.io, users can directly pull templates from ``` healthplatformregistry.azurecr.io/hl7v2defaulttemplates:<version> ``` without authentication.\n>Note!: Template version is aligned with the version of FHIR Converter. \n\n## Usage Notes\n\n### Resource ID generation\n\nThe default templates provided with the Converter computes resource ids using the fields present in the input data. In order to preserve the generated resource ids, the converter created PUT requests, instead of POST requests in the generated bundles.\n\nA set of [templates](data/Templates/Hl7v2/ID) help generate FHIR resource IDs from HL7 v2 messages. An ID generation template does 3 things: 1) extract identifiers from input segment or field; 2) combine the identifers with resource type and base ID (optional) as hash seed; 3) compute hash as output ID.\n\nThe Converter introduces a concept of \"base resource/base ID\". Base resources are independent entities, like Patient, Organization, Device, etc, whose IDs are defined as base ID. Base IDs could be used to generate IDs for other resources that relate to them. It helps enrich the input for hash and thus reduce ID collision.\nFor example, a Patient ID is used as part of hash input for an AllergyIntolerance ID, as this resource is closely related with a specific patient.\n\nBelow is an example where an AllergyIntolerance ID is generated, using ID/AllergyIntolerance template, AL1 segment and patient ID as its base ID.\nThe syntax is `{% evaluate [id] using [template] [variables] -%}`.\n\n```liquid\n{% evaluate allergyIntoleranceId using 'ID/AllergyIntolerance' AL1: al1Segment, baseId: patientId -%}\n```\n\n### Resource validation and post-processing\n\nReal world HL7 messages vary in richness and level of conformance with the spec. The output of converter depends on the templates as well as the quality and richness of input messages. Therefore, it is important that you review and validate the Converter output before using those in production.\n\nIn general, you can use [HL7 FHIR validator](https://wiki.hl7.org/Using_the_FHIR_Validator) to validate a FHIR resource. You may be able to fix some of the conversion issues by appropriately changing the templates. For other issues, you may need to have a post-processing step in your pipeline.\n\nIn some cases, due to lack of field level data in the incoming messages, the Converter may produce resources without useful information or even without ID. You can use `Hl7.Fhir.R4` .NET library to filter such resources in your pipeline. Here is the sample code for such purpose.\n\n```C#\nusing Hl7.Fhir.Model;\nusing Hl7.Fhir.Serialization;\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\n\npublic class PostProcessor\n{\n    private readonly FhirJsonParser _parser = new FhirJsonParser();\n\n    public IEnumerable<Resource> FilterResources(IEnumerable<string> fhirResources)\n    {\n        return fhirResources\n            .Select(fhirResource => _parser.Parse<Resource>(fhirResource))\n            .Where(resource => !IsEmptyResource(resource))\n            .Where(resource => !IsIdAbsentResource(resource));\n    }\n\n    public bool IsEmptyResource(Resource resource)\n    {\n        try\n        {\n            var fhirResource = resource.ToJObject();\n            var properties = fhirResource.Properties().Select(property => property.Name);\n            // an empty resource contains no properties other than \"resourceType\" and \"id\"\n            return !properties\n                .Where(property => !property.Equals(\"resourceType\"))\n                .Where(property => !property.Equals(\"id\"))\n                .Any();\n        }\n        catch (Exception e)\n        {\n            Console.Error.WriteLine(e.Message);\n            // deal with the exception...\n        }\n\n        return false;\n    }\n\n    public bool IsIdAbsentResource(Resource resource)\n    {\n        try\n        {\n            return string.IsNullOrWhiteSpace(resource.Id);\n        }\n        catch (Exception e)\n        {\n            Console.Error.WriteLine(e.Message);\n            // deal with the exception...\n        }\n        return false;\n    }\n}\n```\n\n\n\n## Reference documentation\n- [Filters summary](docs/FiltersSummary.md)\n- [Snippet concept](docs/SnippetConcept.md)\n\n## External resources\n- [DotLiquid wiki](https://github.com/dotliquid/dotliquid/wiki)\n- [HL7 Community 2-To-FHIR-Project](https://confluence.hl7.org/display/OO/2-To-FHIR+Project)\n \n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [the CLA site](https://cla.opensource.microsoft.com).\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/CBL-MarinerCoreUI",
  "language": "Shell",
  "readme_contents": "# CBL-MarinerCoreUI\n\nCBL-MarinerCoreUI is an internal extension of the internal [CBL-Mariner](https://github.com/microsoft/CBL-Mariner) Linux distribution for Microsoft\u2019s cloud infrastructure and edge products and services. CBL-Mariner is designed to provide a consistent platform for these devices and services and will enhance Microsoft\u2019s ability to stay current on Linux updates. This initiative is part of Microsoft\u2019s increasing investment in a wide range of Linux technologies.  CBL-MarinerCoreUI is being shared publicly as part of Microsoft\u2019s commitment to Open Source and to contribute back to the Linux community. \n\nAs with CBL-Mariner, CBL-MarinerCoreUI makes the latest security patches and fixes available for download with the goal of fast turn-around times.\n\nCBL-MarinerCoreUI uses the same build system as CBL-Mariner.\n\n# Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n\n# Acknowledgments \n\nThe CBL-MarinerCoreUI project, benefits from contributions by the open software community. We gratefully acknowledge all contributions made from the broader open source community, in particular:\n\n1) [The Fedora Project](https://start.fedoraproject.org/) for SPEC files. \n\n2) [OpenSUSE](https://www.opensuse.org/) for SPEC files.\n\n3) [GNU](https://www.gnu.org/) and the [Free Software Foundation](https://www.fsf.org/)\n"
 },
 {
  "repo": "microsoft/mixed-reality-extension-sdk-samples",
  "language": "JavaScript",
  "readme_contents": "# Mixed Reality Extension SDK Samples\n\n<img width='200' height='200' src='https://github.com/Microsoft/mixed-reality-extension-sdk/blob/master/branding/MRe-RGB.png'/>\n\nThe Mixed Reality Extension SDK Samples is the easiest way to build and run\nyour first [AltspaceVR](https://altvr.com/) extension using the [Mixed Reality\nExtension SDK](\nhttps://github.com/Microsoft/mixed-reality-extension-sdk).\n\n## Prerequisites\n* Install [Node.js 8.12](https://nodejs.org/download/release/v8.12.0/) or\nnewer, which includes NPM 6.4.1 or newer, from nodejs.org\n\n## How to Build and Run the Hello World sample\nFrom command prompt:\n* `git clone http://github.com/microsoft/mixed-reality-extension-sdk-samples`\n* `cd mixed-reality-extension-sdk-samples\\samples\\hello-world`\n* `npm install` This will install all dependent packages. (and will do very\nlittle if there are no changes)\n* `npm run build` This should not report any errors.\n* `npm start` This should print \"INF: Multi-peer Adapter listening on...\"\n\nIn AltspaceVR\n* Go to your personal home\n* Make sure you are signed in properly, not a guest\n* Activate the Space Editor (only available if you indicate you want to participate in the Early Access Program in your AltspaceVR settings)\n* Click Basics group\n* Click on SDKApp\n* For the URL field, enter `ws://localhost:3901`\n* Enter a session ID (This step will eventually be optional. For now, put in\nany random value)\n* Click Confirm\n* If the app doesn't seem to load, click on the gear icon next the MRE object\nin to the present objects list, and make sure \"Is Playing\" is checked.\n* After the app has been placed, you will see the MRE Anchor (the white box\nwith red/green/blue spikes on it), rendering on top of the MRE. You can use the\nanchor to move the MRE around. To hide the anchor, uncheck \"Edit Mode\".\n\nYou should now see the words \"Hello World\" above a spinning cube.\nCongratulations, you have now deployed a Node.js server with the MRE SDK onto\nyour local machine and connected to it from AltspaceVR.\n\n### Hosting in the Cloud\nIn order for other AltspaceVR users to see your SDK app running, it must be hosted in a way they can connect to it. To learn about cloud hosting and other solutions, checkout [DEPLOYING.md](https://github.com/Microsoft/mixed-reality-extension-sdk/blob/master/DEPLOYING.md) in the SDK repo.\n\nTo learn more about the SDK, please read the [MRE SDK readme](\nhttps://github.com/Microsoft/mixed-reality-extension-sdk/blob/master/README.md).\n\n## Sample Descriptions\n* Hello World - Shows text and a cube that animates when highlighted or clicked. Demonstrates basic scene creation and interaction.\n* Solar System - Loads a 3d model for each planet and animates planetary motion. Demonstrates animation generation and more advanced scene creation.\n* Tic-Tac-Toe - The classic game also known as \"Noughts & Crosses\". Demonstrates gameplay with win/lose conditions.\n* Wear A Hat - Users can choose a hat from a menu and it will appear on their head. Demonstrates attachments.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/vscode-node-debug",
  "language": "TypeScript",
  "readme_contents": "# Node Debug (legacy)\n\n[![build status](https://travis-ci.org/Microsoft/vscode-node-debug.svg?branch=master)](https://travis-ci.org/Microsoft/vscode-node-debug)\n[![build status](https://ci.appveyor.com/api/projects/status/t74psolxi3k7bcjp/branch/master?svg=true)](https://ci.appveyor.com/project/weinand/vscode-node-debug)\n\nThis extension is bundled with Visual Studio Code and together with **Node Debug** forms the [Node.js](https://nodejs.org) debugging experience.\n\n**Node debug (legacy)** is the debugger for Node.js versions < 8.0.\n\nSee a general overview of debugging in VS Code [here](https://code.visualstudio.com/docs/editor/debugging).\n\nDocumentation for Node.js specific debugging can be found [here](https://code.visualstudio.com/docs/nodejs/nodejs-debugging).\n\nPlease submit bugs and feature requests to the [VS Code repository](https://github.com/microsoft/vscode/issues).\n\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE.txt) License.\n"
 },
 {
  "repo": "microsoft/sarif-js-sdk",
  "language": "JavaScript",
  "readme_contents": "# SARIF JS SDK\n\nJavaScript code and supporting files for working with the 'Static Analysis Results Interchange Format' [SARIF][sarif].\n\n| Package                                              | Version                                                                                                                     | Description                                          |\n| ---------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------- |\n| [@microsoft/jest-sarif][@microsoft/jest-sarif]       | [![Version](https://img.shields.io/npm/v/@microsoft/jest-sarif.svg)](https://npmjs.org/package/@microsoft/jest-sarif)       | Custom SARIF matchers for [Jest][jest].              |\n| [@microsoft/sarif-builder][@microsoft/sarif-builder] | [![Version](https://img.shields.io/npm/v/@microsoft/sarif-builder.svg)](https://npmjs.org/package/@microsoft/sarif-builder) | A builder library for authoring [SARIF][sarif] logs. |\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n\n[@microsoft/jest-sarif]: https://github.com/microsoft/sarif-js-sdk/tree/main/packages/jest-sarif\n[@microsoft/sarif-builder]: https://github.com/microsoft/sarif-js-sdk/tree/main/packages/sarif-builder\n[sarif]: https://github.com/oasis-tcs/sarif-spec\n[jest]: https://facebook.github.io/jest/\n"
 },
 {
  "repo": "microsoft/react-native-tscodegen",
  "language": "TypeScript",
  "readme_contents": "# react-native-tscodegen\r\n\r\nTypeScript Code Generation for React Native Turbo Module\r\n\r\n- Index\r\n  - Contributing\r\n  - Building this repo\r\n  - Packages\r\n  - Deploying\r\n  - Development\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n## Building this repo\r\n\r\n```cmd\r\nyarn\r\nyarn build\r\nyarn test\r\n```\r\n\r\n## Packages\r\n\r\n### tslint-shared\r\n\r\nThis is the shared tslint configuration for all other packages.\r\n\r\n### RN-TSCodegen\r\n\r\nThis is the TypeScript code generation for TurboModule in react native.\r\n\r\nThere are two important exported functions:\r\n\r\n- **typeScriptToCodeSchema** function:\r\n  - **fileName** argument: Full path to a TypeScript source file, a module name.\r\n  - **moduleName** argument: The module name. It is not reflected in generated files.\r\n  - **targetName** argument (optional): It will be used in **the entry header file**, if this TypeScript source file registers a native module.\r\n  - Output: A `SchemaType` data structure.\r\n- **generator.generate** function\r\n  - **options** argument:\r\n    - **libraryName** property: A string that becomes part of type names in generated files.\r\n    - **schema** property: Result from `typeScriptToCodeSchema`\r\n    - **outputDirectory** property: Full path to a folder to write files. Multiple files will be generated and most of the file names are hard-coded.\r\n    - **moduleSpecName** property: Name of **the entry header file**, no file extension.\r\n  - **config** arguments:\r\n    - **generators** property: An array that is or a subset of `['descriptors', 'events', 'props', 'tests', 'shadow-nodes', 'modules']` to control what files are generated.\r\n\r\n### RN-TSCodegen-Test\r\n\r\nThis package contains all test cases for RN-TSCodegen, with unit test code.\r\n\r\n### minimum-flow-parser\r\n\r\nThis is a Flow parser, just enough to convert necessary files to TypeScript for this repo.\r\n\r\n### update-test-files\r\n\r\nGet generated files sync to `facebook/react-native`\r\n\r\n## Deploying\r\n\r\n- [npm install react-native-tscodegen-types](https://www.npmjs.com/package/react-native-tscodegen-types)\r\n- [npm install react-native-tscodegen](https://www.npmjs.com/package/react-native-tscodegen)\r\n  - Follow the description to build your first Turbo Module program!\r\n- [Demo project](https://github.com/ZihanChen-MSFT/react-native-tscodegen-demo) (not ready)\r\n\r\nYou are welcome to use cli tool `react-native-tscodegen` instead of calling functions in build scripts by yourself if possible.\r\nBasically, just add `react-native-tscodegen ./react-native-tscodegen.json` to npm scripts, after getting `react-native-tscodegen.json` prepared.\r\nThe file name is not important.\r\n\r\n```json\r\n{\r\n    \"libraryName\": \"PlaygroundModule\",\r\n    \"outputDirectory\": \"./lib/cpp-generated\",\r\n    \"moduleSpecName\": \"PlaygroundModuleSpec\",\r\n    \"generators\": [\r\n        \"descriptors\",\r\n        \"events\",\r\n        \"props\",\r\n        \"tests\",\r\n        \"shadow-nodes\",\r\n        \"modules\"\r\n    ],\r\n    \"inputFile\": \"./src/turboModule.ts\"\r\n}\r\n```\r\n\r\n`libraryName` and `moduleSpecName` control file names and some generated C++ class names.\r\n`generators` controls what files get generated.\r\nAfter the cli tool is successfully executed,\r\nfiles will be created under `outputDirectory`.\r\n\r\n## Development\r\n\r\n### Sync react-native after pull\r\n\r\n```cmd\r\ngit submodule update\r\n```\r\n\r\n### Sync react-native to a new version\r\n\r\n```cmd\r\npushd react-native\r\ngit fetch\r\ngit merge origin/master\r\npopd\r\ngit status\r\n```\r\n\r\n### Works to do after updating react-native\r\n\r\n```cmd\r\nyarn\r\nyarn build\r\npushd update-test-files\r\nnpm run start\r\npopd\r\ngit status\r\n```\r\n\r\n### Fixing test case codegen\r\n\r\n```cmd\r\ncls & pushd packages\\update-test-files & npm run build & cd ..\\RN-TSCodegen-Test & npm run build & popd\r\n```\r\n\r\n### Fixing compiler\r\n\r\n```cmd\r\ncls & pushd packages\\RN-TSCodegen & npm run build & cd ..\\RN-TSCodegen-Test & npm run build & npm run test & popd\r\n```\r\n"
 },
 {
  "repo": "microsoft/vscode-python",
  "language": "TypeScript",
  "readme_contents": "# Python extension for Visual Studio Code\n\nA [Visual Studio Code](https://code.visualstudio.com/) [extension](https://marketplace.visualstudio.com/VSCode) with rich support for the [Python language](https://www.python.org/) (for all [actively supported versions](https://devguide.python.org/#status-of-python-branches) of the language: >=3.6), including features such as IntelliSense (Pylance), linting, debugging, code navigation, code formatting, refactoring, variable explorer, test explorer, and more!\n\n## Installed extensions\n\nThe Python extension will automatically install the [Pylance](https://marketplace.visualstudio.com/items?itemName=ms-python.vscode-pylance) and [Jupyter](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) extensions to give you the best experience when working with Python files and Jupyter notebooks. However, Pylance is an optional dependency, meaning the Python extension will remain fully functional if it fails to be installed. You can also [uninstall](https://code.visualstudio.com/docs/editor/extension-marketplace#_uninstall-an-extension) it at the expense of some features if you\u2019re using a different language server.\n\nExtensions installed through the marketplace are subject to the [Marketplace Terms of Use](https://cdn.vsassets.io/v/M146_20190123.39/_content/Microsoft-Visual-Studio-Marketplace-Terms-of-Use.pdf).\n\n## Quick start\n\n-   **Step 1.** [Install a supported version of Python on your system](https://code.visualstudio.com/docs/python/python-tutorial#_prerequisites) (note: that the system install of Python on macOS is not supported).\n-   **Step 2.** Install the Python extension for Visual Studio Code.\n-   **Step 3.** Open or create a Python file and start coding!\n\n## Set up your environment\n\n<!-- use less words -->\n\n-   Select your Python interpreter by clicking on the status bar\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-python/main/images/InterpreterSelectionZoom.gif width=280 height=100>\n\n-   Configure the debugger through the Debug Activity Bar\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-python/main/images/ConfigureDebugger.gif width=734 height=413>\n\n-   Configure tests by running the `Configure Tests` command\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-python/main/images/ConfigureTests.gif width=734 height=413>\n\n## Jupyter Notebook quick start\n\nThe Python extension and the [Jupyter extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) work together to give you a great Notebook experience in VS Code.\n\n-   Open or create a Jupyter Notebook file (.ipynb) and start coding in our Notebook Editor!\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-python/main/images/OpenOrCreateNotebook.gif width=1029 height=602>\n\nFor more information you can:\n\n-   [Follow our Python tutorial](https://code.visualstudio.com/docs/python/python-tutorial#_prerequisites) with step-by-step instructions for building a simple app.\n-   Check out the [Python documentation on the VS Code site](https://code.visualstudio.com/docs/languages/python) for general information about using the extension.\n-   Check out the [Jupyter Notebook documentation on the VS Code site](https://code.visualstudio.com/docs/python/jupyter-support) for information about using Jupyter Notebooks in VS Code.\n\n## Useful commands\n\nOpen the Command Palette (Command+Shift+P on macOS and Ctrl+Shift+P on Windows/Linux) and type in one of the following commands:\n\n| Command                               | Description                                                                                                                                                    |\n| ------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `Python: Select Interpreter`          | Switch between Python interpreters, versions, and environments.                                                                                                |\n| `Python: Start REPL`                  | Start an interactive Python REPL using the selected interpreter in the VS Code terminal.                                                                       |\n| `Python: Run Python File in Terminal` | Runs the active Python file in the VS Code terminal. You can also run a Python file by right-clicking on the file and selecting `Run Python File in Terminal`. |\n| `Python: Select Linter`               | Switch from Pylint to Flake8 or other supported linters.                                                                                                       |\n| `Format Document`                     | Formats code using the provided [formatter](https://code.visualstudio.com/docs/python/editing#_formatting) in the `settings.json` file.                        |\n| `Python: Configure Tests`             | Select a test framework and configure it to display the Test Explorer.                                                                                         |\n\nTo see all available Python commands, open the Command Palette and type `Python`. For Jupyter extension commands, just type `Jupyter`.\n\n## Feature details\n\nLearn more about the rich features of the Python extension:\n\n-   [IntelliSense](https://code.visualstudio.com/docs/python/editing#_autocomplete-and-intellisense): Edit your code with auto-completion, code navigation, syntax checking and more\n-   [Linting](https://code.visualstudio.com/docs/python/linting): Get additional code analysis with Pylint, Flake8 and more\n-   [Code formatting](https://code.visualstudio.com/docs/python/editing#_formatting): Format your code with black, autopep or yapf\n\n-   [Debugging](https://code.visualstudio.com/docs/python/debugging): Debug your Python scripts, web apps, remote or multi-threaded processes\n\n-   [Testing](https://code.visualstudio.com/docs/python/unit-testing): Run and debug tests through the Test Explorer with unittest, pytest or nose\n\n-   [Jupyter Notebooks](https://code.visualstudio.com/docs/python/jupyter-support): Create and edit Jupyter Notebooks, add and run code cells, render plots, visualize variables through the variable explorer, visualize dataframes with the data viewer, and more\n\n-   [Environments](https://code.visualstudio.com/docs/python/environments): Automatically activate and switch between virtualenv, venv, pipenv, conda and pyenv environments\n\n-   [Refactoring](https://code.visualstudio.com/docs/python/editing#_refactoring): Restructure your Python code with variable extraction, method extraction and import sorting\n\n## Supported locales\n\nThe extension is available in multiple languages: `de`, `en`, `es`, `fa`, `fr`, `it`, `ja`, `ko-kr`, `nl`, `pl`, `pt-br`, `ru`, `tr`, `zh-cn`, `zh-tw`\n\n## Questions, issues, feature requests, and contributions\n\n-   If you have a question about how to accomplish something with the extension, please [ask on Stack Overflow](https://stackoverflow.com/questions/tagged/visual-studio-code+python)\n-   If you come across a problem with the extension, please [file an issue](https://github.com/microsoft/vscode-python)\n-   Contributions are always welcome! Please see our [contributing guide](https://github.com/Microsoft/vscode-python/blob/main/CONTRIBUTING.md) for more details\n-   Any and all feedback is appreciated and welcome!\n    -   If someone has already [filed an issue](https://github.com/Microsoft/vscode-python) that encompasses your feedback, please leave a \ud83d\udc4d/\ud83d\udc4e reaction on the issue\n    -   Otherwise please start a [new discussion](https://github.com/microsoft/vscode-python/discussions/categories/ideas)\n-   If you're interested in the development of the extension, you can read about our [development process](https://github.com/Microsoft/vscode-python/blob/main/CONTRIBUTING.md#development-process)\n\n## Data and telemetry\n\nThe Microsoft Python Extension for Visual Studio Code collects usage\ndata and sends it to Microsoft to help improve our products and\nservices. Read our\n[privacy statement](https://privacy.microsoft.com/privacystatement) to\nlearn more. This extension respects the `telemetry.enableTelemetry`\nsetting which you can learn more about at\nhttps://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting.\n"
 },
 {
  "repo": "microsoft/Dynamics-365-Fraud-Protection-ManualReview",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Dynamics 365 Fraud Protection - Manual review\n\n## Main documents\n* [FE README](./frontend/README.md)\n* [FE Contribution guide](./frontend/CONTRIBUTION.md)\n* [BE README](./backend/README.md)\n* [BE Contribution guide](./backend/CONTRIBUTION.md)\n* [Deployment README](./arm/README.md)\n\n## Solution structure\n![FunctionalSegregation](./documentation/pictures/MRStructureDiagrams-SolutionArchitecture.png)  \n\n## Business description\n\n### Terms\n**Order/Purchase/Transaction** : \nThe main object that describes a particular act of interaction between a Merchant and a User. It's stored in \nDynamics 365 Fraud Protection (DFP) and sometime retrived by Manual Reviev tool (MR) for synchronization and local storing.\n\n**Item** : \nOne element in MR system that represents a particular purchase.\n\n**Decision** : \nA reflection of the Purchase Status entity. Shows the decision about aparticular purchase. Could be generated on merchant side and in MR tool.\n\n**Enrichment** : \nWhen purchase event is consumed by the MR application, it has no information about the purchase, just a reference to it via purchase ID. The process of filling the item with actual purchase data is called enrichment.\n\n**Queue** : \nA logical container in the storage dynamically filled by items based on some filters.\n\n**Filter** : \nA set of parameters that define a set of items in a queue. A filter is created alongside the queue.\n\n**Escalation queue** : \nA queue that contains items with ESCALATE or HOLD labels. This is just specific view of the related main queue. Items in an escalated queue could be reviewed only by supervisors.\n\n**Residual queue** : \nA queue that consists of orders which are not matching filters of any existing queue.\n\n**Locked queue** : \nA queue that has sorting by one of the order fields. An analyst can review items only from the top of the sorted queue.\n\n**Unlocked queue** : \nA queue where an analyst can pick items in random order for review.\n\n**Label** : \nA mark for an order in the queue that is applied by an analyst or senior analyst as a result of a manual review. \nLabels are divided into two groups: final labels that forms decisions (GOOD, BAD, WATCH_INCONCLUSIVE, WATCH_NA) \nand intermediate labels for internal usage in MR (ESCALATE and HOLD). Final labels form a resolution object.\n\n**Resolution** : \nA particular final decision that was made in the MR tool. Could be retrieved during resolution lifetime.\n\n**Tag** : \nTag is a short mark for specifying item specific. Tags can be applied by analysts and viewed in item/resolution surfing.\n\n**Note** : \nNote is a comment left by an analyst in the order.\n\n\n### Permissions\nManual Review has role-based access which means every user should have a particular role to use particular features. There are three main kinds of roles: \n* fraud analyst, \n* senior fraud analyst\n* manager/administrator\nAll roles should be defined for the DFP Service principal in Azure AD. \nRole assignments can be done both by the Azure portal and by the DFP User Access tab (the second way is more preferable).\nIn addition to main roles, some privileges can be provided to users based on in-tool actions and assignments.\n\nAll frontend-intended APIs are protected with the OAuth2.0 Implicit flow grant. \nThe frontend is responsible for routing the user on Azure Active Directory login page and for the token extracting. \nOnce the token obtained the frontend attach this token to each call to the backend.  \nThe backend uses stateless token processing with role enrichment (in Azure AD, it uses caching).\n\nRole permissions:\n\n| The Analyst                                                                   | The Senior Analyst                                                            | The Fraud Manager                                                              |\n| ----------------------------------------------------------------------------- | ----------------------------------------------------------------------------- | ------------------------------------------------------------------------------ |\n| view queues assigned to him                                                   | view any queue                                                                | view any queue                                                                 |\n|                                                                               | create queues                                                                 | create queues                                                                  |\n|                                                                               | assign people to any queue                                                    | assign people to any queue                                                     |\n|                                                                               |                                                                               | update any queue (change name and deadline) where possible                     |\n|                                                                               |                                                                               | delete any queue                                                               |\n| view any order on queues visible to him                                       | view any item                                                                 | view any item                                                                  |\n| lock items in queues assigned to him in accordance with sorting settings      | lock items in queues assigned to him in accordance with sorting settings      | lock any order in any queue                                                    |\n| label, tag, comment, unlock items locked on him                               | label, tag, comment, unlock items locked on him                               | label, tag, comment, unlock items locked on him                                |\n| apply bulk decisions on items that are visible for the analyst                | apply bulk decisions on any unlocked item (including already labeled)         | apply bulk decisions on any item                                               |\n|                                                                               |                                                                               | search items among the queues                                                  |\n|                                                                               |                                                                               | release any lock for any analyst (future feature)                              |\n|                                                                               | view demand/supply dashboard                                                  | view demand/supply dashboard                                                   |\n| view performance dashboard for themselves (including per-queue activity view) | view performance dashboard for themselves (including per-queue activity view) | view performance dashboard for any analyst (including per-queue activity view) |\n|                                                                               |                                                                               | view performance dashboard for any queue (including per-analyst activity view) |\n| view historical queue settings for participated queues                        | view historical queue settings for any queues                                 | view historical queue settings for any queues                                  |\n|                                                                               | view historical analyst info                                                  | view historical analyst info                                                   |\n\nAssignment-based permissions:\n\n| Queue reviewer       | Queue supervisor                                                                          |\n| -------------------- | ----------------------------------------------------------------------------------------- |\n| lock items           | lock items                                                                                |\n|                      | lock escalated items (in escalated queue)                                                 |\n| process locked items | process locked items                                                                      |\n|                      | receive notifications about orders being escalated in a supervised queue (future feature) |\n\n## Microsoft Open Source code of conduct\n\nFor additional information, see the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct)."
 },
 {
  "repo": "microsoft/MixedRealityToolkit-Unity",
  "language": "C#",
  "readme_contents": "# The docs have moved!\n\n**Starting from MRTK 2.6, we are publishing both conceptual docs and API references on docs.microsoft.com. For conceptual docs, please visit <a href=\"https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/\">our new landing page</a>. For API references, please visit <a href=\"https://docs.microsoft.com/dotnet/api/microsoft.mixedreality.toolkit\">the MRTK-Unity section of the dot net API explorer</a>. All links on this page have been updated.** \n\n**Existing content will remain here but will not be updated further.**\n\n![Mixed Reality Toolkit](Documentation/Images/Logo_MRTK_Unity_Banner.png)\n\n# What is the Mixed Reality Toolkit\n\nMRTK-Unity is a Microsoft-driven project that provides a set of components and features, used to accelerate cross-platform MR app development in Unity. Here are some of its functions:\n\n* Provides the **cross-platform input system and building blocks for spatial interactions and UI**.\n* Enables **rapid prototyping** via in-editor simulation that allows you to see changes immediately.\n* Operates as an **extensible framework** that provides developers the ability to swap out core components.\n* **Supports a wide range of platforms**, including\n  * OpenXR (Unity 2020.2 or newer)\n    * Microsoft HoloLens 2\n    * Windows Mixed Reality headsets\n  * Windows Mixed Reality\n    * Microsoft HoloLens\n    * Microsoft HoloLens 2\n    * Windows Mixed Reality headsets\n  * Oculus (Unity 2019.3 or newer)\n    * Oculus Quest\n  * OpenVR\n    * Windows Mixed Reality headsets\n    * HTC Vive\n    * Oculus Rift\n  * Ultraleap Hand Tracking\n  * Mobile devices such as iOS and Android\n\n# Getting started with MRTK\n\nIf you're new to MRTK or Mixed Reality development in Unity, **we recommend you start at the beginning of our** [Unity development journey](https://docs.microsoft.com/windows/mixed-reality/unity-development-overview?tabs=mrtk%2Chl2) in the Microsoft Docs. The Unity development journey is specifically tailored to walk new developers through the installation, core concepts, and usage of MRTK.\n\n| IMPORTANT: The Unity development journey currently uses **MRTK version 2.4.0** and **Unity 2019.4**. |\n| --- |\n\nIf you're an experienced Mixed Reality or MRTK developer, check the links in the next section for the newest packages and release notes.\n\n# Documentation\n\n| [![Release notes](Documentation/Images/MRTK_Icon_ReleaseNotes.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/release-notes/mrtk-26-release-notes)<br/>[Release Notes](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/release-notes/mrtk-26-release-notes)| [![MRTK Overview](Documentation/Images/MRTK_Icon_ArchitectureOverview.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/architecture/overview)<br/>[MRTK Overview](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/architecture/overview)| [![Feature Guides](Documentation/Images/MRTK_Icon_FeatureGuides.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/button)<br/>[Feature Guides](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/button)| [![API Reference](Documentation/Images/MRTK_Icon_APIReference.png)](https://docs.microsoft.com/dotnet/api/Microsoft.MixedReality.Toolkit?view=mixed-reality-toolkit-unity-2020-dotnet-2.6.0)<br/>[API Reference](https://docs.microsoft.com/dotnet/api/Microsoft.MixedReality.Toolkit?view=mixed-reality-toolkit-unity-2020-dotnet-2.6.0)|\n|:---|:---|:---|:---|\n\n# Build status\n\n| Branch | CI Status | Docs Status |\n|---|---|---|\n| `main` |[![CI Status](https://dev.azure.com/aipmr/MixedRealityToolkit-Unity-CI/_apis/build/status/public/mrtk_CI?branchName=main)](https://dev.azure.com/aipmr/MixedRealityToolkit-Unity-CI/_build/latest?definitionId=15)|[![Docs Status](https://dev.azure.com/aipmr/MixedRealityToolkit-Unity-CI/_apis/build/status/public/mrtk_docs?branchName=main)](https://dev.azure.com/aipmr/MixedRealityToolkit-Unity-CI/_build/latest?definitionId=7)\n\n# Required software\n\n | [![Windows SDK 18362+](Documentation/Images/MRTK170802_Short_17.png)](https://developer.microsoft.com/windows/downloads/windows-10-sdk) [Windows SDK 18362+](https://developer.microsoft.com/windows/downloads/windows-10-sdk)| [![Unity](Documentation/Images/MRTK170802_Short_18.png)](https://unity3d.com/get-unity/download/archive) [Unity 2018.4.x](https://unity3d.com/get-unity/download/archive)| [![Visual Studio 2019](Documentation/Images/MRTK170802_Short_19.png)](http://dev.windows.com/downloads) [Visual Studio 2019](http://dev.windows.com/downloads)| [![Emulators (optional)](Documentation/Images/MRTK170802_Short_20.png)](https://docs.microsoft.com/windows/mixed-reality/using-the-hololens-emulator) [Emulators (optional)](https://docs.microsoft.com/windows/mixed-reality/using-the-hololens-emulator)|\n| :--- | :--- | :--- | :--- |\n| To build apps with MRTK v2, you need the Windows 10 May 2019 Update SDK. <br> To run apps for immersive headsets, you need the Windows 10 Fall Creators Update. | The Unity 3D engine provides support for building mixed reality projects in Windows 10 | Visual Studio is used for code editing, deploying and building UWP app packages | The Emulators allow you to test your app without the device in a simulated environment |\n\n# Feature areas\n\n| ![Input System](Documentation/Images/MRTK_Icon_InputSystem.png) [Input System](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/overview)<br/>&nbsp;  | ![Hand Tracking<br/> (HoloLens 2)](Documentation/Images/MRTK_Icon_HandTracking.png) [Hand Tracking<br/> (HoloLens 2)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/hand-tracking) | ![Eye Tracking<br/> (HoloLens 2)](Documentation/Images/MRTK_Icon_EyeTracking.png) [Eye Tracking<br/> (HoloLens 2)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-main) | ![Profiles](Documentation/Images/MRTK_Icon_Profiles.png) [Profiles](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/configuration/mixed-reality-configuration-guide)<br/>&nbsp; | ![Hand Tracking<br/> (Ultraleap)](Documentation/Images/MRTK_Icon_HandTracking.png) [Hand Tracking (Ultraleap)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/cross-platform/leap-motion-mrtk)|\n| :--- | :--- | :--- | :--- | :--- |\n| ![UI Controls](Documentation/Images/MRTK_Icon_UIControls.png) [UI Controls](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/#ux-building-blocks)<br/>&nbsp; | ![Solvers](Documentation/Images/MRTK_Icon_Solver.png) [Solvers](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/solvers/solver)<br/>&nbsp; | ![Multi-Scene<br/> Manager](Documentation/Images/MRTK_Icon_SceneSystem.png) [Multi-Scene<br/> Manager](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/scene-system/scene-system-getting-started) | ![Spatial<br/> Awareness](Documentation/Images/MRTK_Icon_SpatialUnderstanding.png) [Spatial<br/> Awareness](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/spatial-awareness/spatial-awareness-getting-started) | ![Diagnostic<br/> Tool](Documentation/Images/MRTK_Icon_Diagnostics.png) [Diagnostic<br/> Tool](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/diagnostics/diagnostics-system-getting-started) |\n| ![MRTK Standard Shader](Documentation/Images/MRTK_Icon_StandardShader.png) [MRTK Standard Shader](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/rendering/mrtk-standard-shader) | ![Speech & Dictation](Documentation/Images/MRTK_Icon_VoiceCommand.png) [Speech](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/speech)<br/> & [Dictation](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/dictation) | ![Boundary<br/>System](Documentation/Images/MRTK_Icon_Boundary.png) [Boundary<br/>System](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/boundary/boundary-system-getting-started)| ![In-Editor<br/>Simulation](Documentation/Images/MRTK_Icon_InputSystem.png) [In-Editor<br/>Simulation](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input-simulation/input-simulation-service) | ![Experimental<br/>Features](Documentation/Images/MRTK_Icon_Experimental.png) [Experimental<br/>Features](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/contributing/experimental-features)|\n\n# UX building blocks\n\n|  [![Button](Documentation/Images/Button/MRTK_Button_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/button) [Button](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/button) | [![Bounds Control](Documentation/Images/BoundsControl/MRTK_BoundsControl_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/bounds-control) [Bounds Control](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/bounds-control) | [![Object Manipulator](Documentation/Images/ManipulationHandler/MRTK_Manipulation_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/object-manipulator) [Object Manipulator](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/object-manipulator) |\n|:--- | :--- | :--- |\n| A button control which supports various input methods, including HoloLens 2's articulated hand | Standard UI for manipulating objects in 3D space | Script for manipulating objects with one or two hands |\n|  [![Slate](Documentation/Images/Slate/MRTK_Slate_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/slate) [Slate](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/slate) | [![System Keyboard](Documentation/Images/SystemKeyboard/MRTK_SystemKeyboard_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/system-keyboard) [System Keyboard](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/system-keyboard) | [![Interactable](Documentation/Images/Interactable/InteractableExamples.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/interactable) [Interactable](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/interactable) |\n| 2D style plane which supports scrolling with articulated hand input | Example script of using the system keyboard in Unity  | A script for making objects interactable with visual states and theme support |\n|  [![Solver](Documentation/Images/Solver/MRTK_Solver_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/solvers/solver) [Solver](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/solvers/solver) | [![Object Collection](Documentation/Images/ObjectCollection/MRTK_ObjectCollection_Main.jpg)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/object-collection) [Object Collection](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/object-collection) | [![Tooltip](Documentation/Images/Tooltip/MRTK_Tooltip_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/tooltip) [Tooltip](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/tooltip) |\n| Various object positioning behaviors such as tag-along, body-lock, constant view size and surface magnetism | Script for laying out an array of objects in a three-dimensional shape | Annotation UI with a flexible anchor/pivot system, which can be used for labeling motion controllers and objects |\n|  [![Slider](Documentation/Images/Slider/MRTK_UX_Slider_Main.jpg)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/sliders) [Slider](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/sliders) | [![MRTK Standard Shader](Documentation/Images/MRTKStandardShader/MRTK_StandardShader.jpg)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/rendering/mrtk-standard-shader) [MRTK Standard Shader](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/rendering/mrtk-standard-shader) | [![Hand Menu](Documentation/Images/Solver/MRTK_UX_HandMenu.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/hand-menu) [Hand Menu](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/hand-menu) |\n| Slider UI for adjusting values supporting direct hand tracking interaction | MRTK's Standard shader supports various Fluent design elements with performance | Hand-locked UI for quick access, using the Hand Constraint Solver |\n|  [![App Bar](Documentation/Images/AppBar/MRTK_AppBar_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/app-bar) [App Bar](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/app-bar) | [![Pointers](Documentation/Images/Pointers/MRTK_Pointer_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/pointers) [Pointers](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/pointers) | [![Fingertip Visualization](Documentation/Images/Fingertip/MRTK_FingertipVisualization_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/fingertip-visualization) [Fingertip Visualization](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/fingertip-visualization) |\n| UI for Bounds Control's manual activation | Learn about various types of pointers | Visual affordance on the fingertip which improves the confidence for the direct interaction |\n|  [![Near Menu](Documentation/Images/NearMenu/MRTK_UX_NearMenu.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/near-menu) [Near Menu](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/near-menu) | [![Spatial Awareness](Documentation/Images/SpatialAwareness/MRTK_SpatialAwareness_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/spatial-awareness/spatial-awareness-getting-started) [Spatial Awareness](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/spatial-awareness/spatial-awareness-getting-started) | [![Voice Command](Documentation/Images/Input/MRTK_Input_Speech.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/speech) [Voice Command](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/speech) / [Dictation](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/dictation) |\n| Floating menu UI for the near interactions | Make your holographic objects interact with the physical environments | Scripts and examples for integrating speech input |\n|  [![Progress Indicator](Documentation/Images/ProgressIndicator/MRTK_ProgressIndicator_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/progress-indicator) [Progress Indicator](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/progress-indicator) | [![Dialog](Documentation/Images/Dialog/MRTK_UX_Dialog_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/dialog) [Dialog [Experimental]](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/dialog) | [![Hand Coach](Documentation/Images/HandCoach/MRTK_UX_HandCoach_Main.jpg)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/hand-coach) [Hand Coach](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/hand-coach) |\n| Visual indicator for communicating data process or operation | UI for asking for user's confirmation or acknowledgement  | Component that helps guide the user when the gesture has not been taught |\n|  [![Hand Physics Service](Documentation/Images/HandPhysics/MRTK_UX_HandPhysics_Main.jpg)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/experimental/hand-physics-service) [Hand Physics Service [Experimental]](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/experimental/hand-physics-service) | [![Scrolling Collection](Documentation/Images/ScrollingCollection/ScrollingCollection_Main.jpg)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/scrolling-object-collection) [Scrolling Collection](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/ux-building-blocks/scrolling-object-collection) | [![Dock](Documentation/Images/Dock/MRTK_UX_Dock_Main.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/experimental/dock) [Dock [Experimental]](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/experimental/dock) |\n| The hand physics service enables rigid body collision events and interactions with articulated hands | An Object Collection that natively scrolls 3D objects | The Dock allows objects to be moved in and out of predetermined positions |\n|  [![Eye Tracking: Target Selection](Documentation/Images/EyeTracking/mrtk_et_targetselect.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-target-selection) [Eye Tracking: Target Selection](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-target-selection) | [![Eye Tracking: Navigation](Documentation/Images/EyeTracking/mrtk_et_navigation.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-navigation) [Eye Tracking: Navigation](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-navigation) | [![Eye Tracking: Heat Map](Documentation/Images/EyeTracking/mrtk_et_heatmaps.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/eye-tracking-examples-overview#visualization-of-visual-attention) [Eye Tracking: Heat Map](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/eye-tracking-examples-overview#visualization-of-visual-attention) |\n| Combine eyes, voice and hand input to quickly and effortlessly select holograms across your scene | Learn how to auto-scroll text or fluently zoom into focused content based on what you are looking at | Examples for logging, loading and visualizing what users have been looking at in your app |\n\n# Tools\n\n|  [![Optimize Window](Documentation/Images/MRTK_Icon_OptimizeWindow.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/tools/optimize-window) [Optimize Window](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/tools/optimize-window) | [![Dependency Window](Documentation/Images/MRTK_Icon_DependencyWindow.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/tools/dependency-window) [Dependency Window](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/tools/dependency-window) | ![Build Window](Documentation/Images/MRTK_Icon_BuildWindow.png) Build Window | [![Input recording](Documentation/Images/MRTK_Icon_InputRecording.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input-simulation/input-animation-recording) [Input recording](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/input-simulation/input-animation-recording) |\n|:--- | :--- | :--- | :--- |\n| Automate configuration of Mixed Reality projects for performance optimizations | Analyze dependencies between assets and identify unused assets |  Configure and execute an end-to-end build process for Mixed Reality applications | Record and playback head movement and hand tracking data in editor |\n\n# Example scenes\n\nExplore MRTK's various types of interactions and UI controls through the example scenes. You can find example scenes under [**Assets/MRTK/Examples/Demos**](/Assets/MixedRealityToolkit.Examples/Demos) folder.\n\n[![Example Scene](Documentation/Images/MRTK_Examples.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/hand-interaction-examples)\n\n# MRTK examples hub\n\nWith the MRTK Examples Hub, you can try various example scenes in MRTK. On HoloLens 2, you can download and install [MRTK Examples Hub through the Microsoft Store app](https://www.microsoft.com/p/mrtk-examples-hub/9mv8c39l2sj4).\n\nSee [Examples Hub README page](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/example-hub) to learn about the details on creating a multi-scene hub with MRTK's scene system and scene transition service.\n\n[![Example Scene](Documentation/Images/MRTK_ExamplesHub.png)](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/hand-interaction-examples)\n\n# Sample apps made with MRTK\n\n| [![Periodic Table of the Elements](Documentation/Images/MRDL_PeriodicTable.jpg)](https://medium.com/@dongyoonpark/bringing-the-periodic-table-of-the-elements-app-to-hololens-2-with-mrtk-v2-a6e3d8362158)| [![Galaxy Explorer](Documentation/Images/MRTK_GalaxyExplorer.jpg)](https://docs.microsoft.com/windows/mixed-reality/galaxy-explorer-update)| [![Galaxy Explorer](Documentation/Images/MRDL_Surfaces.jpg)](https://docs.microsoft.com/windows/mixed-reality/galaxy-explorer-update)|\n|:--- | :--- | :--- |\n| [Periodic Table of the Elements](https://github.com/Microsoft/MRDL_Unity_PeriodicTable) is an open-source sample app which demonstrates how to use MRTK's input system and building blocks to create an app experience for HoloLens and Immersive headsets. Read the porting story: [Bringing the Periodic Table of the Elements app to HoloLens 2 with MRTK v2](https://medium.com/@dongyoonpark/bringing-the-periodic-table-of-the-elements-app-to-hololens-2-with-mrtk-v2-a6e3d8362158) |[Galaxy Explorer](https://github.com/Microsoft/GalaxyExplorer) is an open-source sample app that was originally developed in March 2016 as part of the HoloLens 'Share Your Idea' campaign. Galaxy Explorer has been updated with new features for HoloLens 2, using MRTK v2. Read the story: [The Making of Galaxy Explorer for HoloLens 2](https://docs.microsoft.com/windows/mixed-reality/galaxy-explorer-update) |[Surfaces](https://github.com/Microsoft/GalaxyExplorer) is an open-source sample app for HoloLens 2 which explores how we can create a tactile sensation with visual, audio, and fully articulated hand-tracking. Check out Microsoft MR Dev Days session [Learnings from the Surfaces app](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Learnings-from-the-MR-Surfaces-App) for the detailed design and development story. |\n\n# Session videos from Mixed Reality Dev Days 2020\n\n| [![MRDevDays](Documentation/Images/MRDevDays_Session1.png)](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-MRTK-Unity)| [![MRDevDays](Documentation/Images/MRDevDays_Session2.png)](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTKs-UX-Building-Blocks)| [![MRDevDays](Documentation/Images/MRDevDays_Session3.png)](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Performance-and-Shaders)|\n|:--- | :--- | :--- |\n| Tutorial on how to create a simple MRTK app from start to finish. Learn about interaction concepts and MRTK\u2019s multi-platform capabilities. | Deep dive on the MRTK\u2019s UX building blocks that help you build beautiful mixed reality experiences. | An introduction to performance tools, both in MRTK and external, as well as an overview of the MRTK Standard Shader.\t |\n\nSee [Mixed Reality Dev Days](https://docs.microsoft.com/windows/mixed-reality/mr-dev-days-sessions) to explore more session videos.\n\n# Engage with the community\n\n- Join the conversation around MRTK on [Slack](https://holodevelopers.slack.com/). You can join the Slack community via the [automatic invitation sender](https://holodevelopersslack.azurewebsites.net/).\n\n- Ask questions about using MRTK on [Stack Overflow](https://stackoverflow.com/questions/tagged/mrtk) using the **MRTK** tag.\n\n- Search for [known issues](https://github.com/Microsoft/MixedRealityToolkit-Unity/issues) or file a [new issue](https://github.com/Microsoft/MixedRealityToolkit-Unity/issues) if you find something broken in MRTK code.\n\n- For questions about contributing to MRTK, go to the [mixed-reality-toolkit](https://holodevelopers.slack.com/messages/C2H4HT858) channel on slack.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information, see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Useful resources on the Mixed Reality Dev Center\n\n| ![Discover](Documentation/Images/mrdevcenter/icon-discover.png) [Discover](https://docs.microsoft.com/windows/mixed-reality/)| ![Design](Documentation/Images/mrdevcenter/icon-design.png) [Design](https://docs.microsoft.com/windows/mixed-reality/design)| ![Develop](Documentation/Images/mrdevcenter/icon-develop.png) [Develop](https://docs.microsoft.com/windows/mixed-reality/development)| ![Distribute)](Documentation/Images/mrdevcenter/icon-distribute.png) [Distribute](https://docs.microsoft.com/windows/mixed-reality/implementing-3d-app-launchers)|\n| :--------------------- | :----------------- | :------------------ | :------------------------ |\n| Learn to build mixed reality experiences for HoloLens and immersive headsets (VR).          | Get design guides. Build user interface. Learn interactions and input.     | Get development guides. Learn the technology. Understand the science.       | Get your app ready for others and consider creating a 3D launcher. |\n\n# Useful resources on Azure\n\n| ![Spatial Anchors](Documentation/Images/mrdevcenter/icon-azurespatialanchors.png)<br> [Spatial Anchors](https://docs.microsoft.com/azure/spatial-anchors/)| ![Speech Services](Documentation/Images/mrdevcenter/icon-azurespeechservices.png) [Speech Services](https://docs.microsoft.com/azure/cognitive-services/speech-service/)| ![Vision Services](Documentation/Images/mrdevcenter/icon-azurevisionservices.png) [Vision Services](https://docs.microsoft.com/azure/cognitive-services/computer-vision/)|\n| :------------------------| :--------------------- | :---------------------- |\n| Spatial Anchors is a cross-platform service that allows you to create Mixed Reality experiences using objects that persist their location across devices over time.| Discover and integrate Azure powered speech capabilities like speech to text, speaker recognition or speech translation into your application.| Identify and analyze your image or video content using Vision Services like computer vision, face detection, emotion recognition or video indexer. |\n\n# Learn more about the MRTK project\n\nYou can find our planning material on [our wiki](https://github.com/Microsoft/MixedRealityToolkit-Unity/wiki) under the Project Management Section. You can always see the items the team is actively working on in the Iteration Plan issue.\n\n# How to contribute\n\nLearn how you can contribute to MRTK at [Contributing](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/contributing/contributing).\n\n**For details on the different branches used in the Mixed Reality Toolkit repositories, check this [Branch Guide here](https://github.com/Microsoft/MixedRealityToolkit-Unity/wiki/Branch-Guide).**\n"
 },
 {
  "repo": "microsoft/vscode-jupyter",
  "language": "TypeScript",
  "readme_contents": "# Jupyter Extension for Visual Studio Code\n\nA [Visual Studio Code](https://code.visualstudio.com/) [extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter) that provides basic notebook support for [language kernels](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels) that are supported in [Jupyter Notebooks](https://jupyter.org/) today. Many language kernels will work with no modification. To enable advanced features, modifications may be needed in the VS Code language extensions.\n\n\n## Working with Python\n\nWhether you are on VS Code Stable or VS Code Insiders, if you would like to work with Python just make sure you're using the latest version of the [Python Extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python) to enjoy the joint partnership of the Python and Juypter Extensions.\n\nPlease follow the [Python Extension ReadMe](https://github.com/microsoft/vscode-python/blob/main/README.md) instructions to get started and visit the [Python Documentation](https://code.visualstudio.com/docs/python/jupyter-support) to learn more about how the Python and Jupyter Extension are working together to provide an optimum Python notebooks experience.\n\n## Working with other Languages\n\nThe Jupyter Extension supports other languages in addition to Python such as Julia, R, and C# in VS Code Insiders with our latest Native VS Code Notebooks Experience!\n\n### Quick Start\n\n-   **Step 1.** Install [VS Code Insiders](https://code.visualstudio.com/insiders/)\n\n-   **Step 2** If not working with Python, make sure to have a Jupyter kernelspec that corresponds to the language you would like to use installed on your machine.\n\n-   **Step 3.** Install the [Jupyter Extension](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)\n\n-   **Step 4.** Open or create a notebook file and start coding!\n\n- **Special Note:**  The Jupyter Extension in VS Code Insiders will include our Native Notebooks experience by default. Because we are running in VS Code Insiders and this build is updated every day, there may be times when our extension may fail to work at all. We do attempt to ensure that this doesn't happen frequently. If it does, we strive to provide an updated extension build by the next business day. However, if you'd like to opt out of the native experience while working in VS Code Insiders:\n    - Open the command palette (Windows: Ctrl + Shift + P, iOS: Command + Shift + P) and select \"Preferences: Open Settings (JSON)\"\n    - Add the following code to your JSON settings:\n     `\"jupyter.experiments.optOutFrom\": [\"NativeNotebookEditor\"],`\n\n## Notebooks Quick Start\n\n- To create a new notebook open the command palette (Windows: Ctrl + Shift + P, iOS: Command + Shift + P) and select the command `\"Jupyter: Create New Blank Notebook\"`\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-jupyter/main/images/Jupyter%20README/CreateNewNotebook.png>\n\n- Select your kernel by clicking on the kernel picker in the bottom right of the status bar or by invoking the `\"Notebook: Select Notebook Kernel\"` command.\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-jupyter/main/images/Jupyter%20README/KernelPicker.gif?>\n\n- Change the cell language by clicking the language picker or by invoking the `\"Notebook: Change Cell Language\"` command.\n\n     <img src=https://raw.githubusercontent.com/microsoft/vscode-jupyter/main/images/Jupyter%20README/LanguagePicker.gif?>\n\n\n\n## Useful commands\n\nOpen the Command Palette (Command+Shift+P on macOS and Ctrl+Shift+P on Windows/Linux) and type in one of the following commands:\n\n| Command                               | Description                                                                                                                                                    |\n| ------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `Jupyter: Create New Blank Notebook`| Create a new blank Jupyter Notebook   |\n| `Notebook: Select Notebook Kernel`        | Select or switch kernels within your notebook|\n| `Notebook: Change Cell Language`        | Change the language of the cell currently in focus |\n| `Jupyter: Export to HTML Jupyter: Export to PDF` | Create a presentation-friendly version of your notebook in HTML or PDF\n\nTo see all available Jupyter Notebook commands, open the Command Palette and type `Jupyter` or `Notebook`.\n\n## Feature details\n\nLearn more about the rich features of the Jupyter extension:\n\n-   [IntelliSense](https://code.visualstudio.com/docs/python/editing#_autocomplete-and-intellisense): Edit your code with auto-completion, code navigation, syntax checking and more!\n     - *May be limited due to kernelspec of choice*\n\n-   [Jupyter Notebooks](https://code.visualstudio.com/docs/python/jupyter-support): Create and edit Jupyter Notebooks, add and run code/markdown cells, render plots, create presentation-friendly versions of your notebook by exporting to HTML or PDF and more!\n\n\n## Supported locales\n\nThe extension is available in multiple languages: `de`, `en`, `es`, `fa`, `fr`, `it`, `ja`, `ko-kr`, `nl`, `pl`, `pt-br`, `ru`, `tr`, `zh-cn`, `zh-tw`\n\n## Questions, issues, feature requests, and contributions\n\n-   If you have a question about how to accomplish something with the extension, please [ask on Stack Overflow](https://stackoverflow.com/questions/tagged/visual-studio-code+jupyter). Our [wiki](https://github.com/microsoft/vscode-jupyter/wiki) is also updated periodically with useful information.\n-   Any and all feedback is appreciated and welcome! If you come across a problem with the extension, please [file an issue](https://github.com/microsoft/vscode-jupyter).\n      - If someone has already [filed an issue](https://github.com/Microsoft/vscode-jupyter) that encompasses your feedback, please leave a \ud83d\udc4d/\ud83d\udc4e reaction on the issue.\n\n- Contributions are always welcome! Please see our [contributing guide](https://github.com/Microsoft/vscode-jupyter/blob/main/CONTRIBUTING.md) for more details.\n\n-   If you're interested in the development of the extension, you can read about our [development process](https://github.com/microsoft/vscode-jupyter/blob/main/CONTRIBUTING.md#development-process)\n\n## Data and telemetry\n\nThe Microsoft Jupyter Extension for Visual Studio Code collects usage\ndata and sends it to Microsoft to help improve our products and\nservices. Read our\n[privacy statement](https://privacy.microsoft.com/privacystatement) to\nlearn more. This extension respects the `telemetry.enableTelemetry`\nsetting which you can learn more about at\nhttps://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/ComplianceCxE",
  "language": null,
  "readme_contents": "# Project\n\n> This repo has been populated by an initial template to help get you started. Please\n> make sure to update the content to build a great experience for community-building.\n\nAs the maintainer of this project, please make a few updates:\n\n- Improving this README.MD file to provide a great experience\n- Updating SUPPORT.MD with content about this project's support experience\n- Understanding the security reporting process in SECURITY.MD\n- Remove this section from the README\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/vscode-react-native",
  "language": "TypeScript",
  "readme_contents": "# React Native Tools\n\n[![Build Status](https://dev.azure.com/vscode-webdiag-extensions/VS%20Code%20WebDiag%20extensions/_apis/build/status/%5BUnit%20tests%5D%20vscode-react-native%20%5Bmaster%5D?branchName=master)](https://dev.azure.com/vscode-webdiag-extensions/VS%20Code%20WebDiag%20extensions/_build/latest?definitionId=60&branchName=master)\n\nStable:\n![Stable version](https://vsmarketplacebadge.apphb.com/version-short/msjsdiag.vscode-react-native.svg)\n![VS Marketplace rating](https://vsmarketplacebadge.apphb.com/rating-star/msjsdiag.vscode-react-native.svg)\n\nPreview:\n![VS Marketplace version](https://vsmarketplacebadge.apphb.com/version-short/msjsdiag.vscode-react-native-preview.svg)\n![VS Marketplace rating](https://vsmarketplacebadge.apphb.com/rating-star/msjsdiag.vscode-react-native-preview.svg)\n\n## React Native Tools Preview\n\nThe extension has a [nightly version](https://marketplace.visualstudio.com/items?itemName=msjsdiag.vscode-react-native-preview) which is released on a daily basis at 9 PM PST on each day that changes occur.\nTo avoid conflicts, if both extensions are installed - the only stable version will be activated. So to use the preview version it is needed to disable or remove the stable version and reload VS Code.\n\n## About the extension\n\nThis VS Code extension provides a development environment for React Native projects.\nUsing this extension, you can **debug your code and quickly run `react-native` commands** from the command palette.\n\n![React Native features](images/react-features.gif)\n\n<!-- TABLE OF CONTENTS -->\n\n# Table of Contents\n\n- [React Native Tools Preview](#react-native-tools-preview)\n- [About the extension](#about-the-extension)\n- [Getting started](#getting-started)\n- [React Native commands in the Command Palette](#react-native-commands-in-the-command-palette)\n- [Debugging React Native applications](#debugging-react-native-applications)\n  - [Hermes engine](#hermes-engine)\n  - [iOS applications](#ios-applications)\n    - [iOS devices](#ios-devices)\n    - [Custom scheme for iOS apps](#custom-scheme-for-ios-apps)\n    - [iOS direct debugging](#iOS-direct-debugging)\n    - [iOS Hermes debugging](#ios-hermes-debugging)\n  - [Expo applications](#expo-applications)\n    - [Configuring Expo](#configuring-expo)\n  - [Windows applications](#react-native-for-windows)\n  - [macOS applications](#react-native-for-macos)\n    - [macOS Hermes debugging](#macos-hermes-debugging)\n  - [TypeScript and Haul based applications](#typescript-and-haul)\n  - [Debugger configuration properties](#debugger-configuration-properties)\n- [Customization](#customization)\n  - [Logging](#logging)\n  - [Build APK and generate bundle](#build-apk-and-generate-bundle)\n  - [Specifying custom arguments for `react-native run-*` command](#specifying-custom-arguments-for-react-native-run--command)\n  - [Setting up the React Native packager](#setting-up-the-react-native-packager)\n  - [Change project root](#change-project-root)\n  - [Configure an Android LogCat Monitor](#configure-an-android-logcat-monitor)\n- [Network Inspector](#network-inspector)\n- [Developing inside a Docker Container](#developing-inside-a-docker-container)\n- [Contributing](#contributing)\n- [Known Issues](#known-issues)\n\n# Getting started\n\nBefore going any further make sure that you:\n\n- [have a working React Native environment](https://reactnative.dev/docs/environment-setup).\n- are using [VS Code](https://code.visualstudio.com) and have [installed this extension from the Marketplace](https://marketplace.visualstudio.com/items?itemName=msjsdiag.vscode-react-native).\n- have your React Native project root folder open in VS Code.\n\nPlease notice that the extension uses `.vscode/.react` directory at the project root to store intermediate files required for debugging. Although these files usually get removed after debug session ends, you may want to add this directory to your project's `.gitignore` file.\n\n# React Native commands in the Command Palette\n\nIn the Command Palette, type `React Native` and choose a command.\n\n![React Native commands](images/command-palette.png)\n\nThe **Run Android** command triggers `react-native run-android` and starts your app for Android.\n\nThe **Run iOS** command similarly triggers `react-native run-ios` and starts your app in the iOS simulator (e.g. iPhone 6).\n\nThe **Packager** commands allow you to start/stop the [**Metro Bundler**](https://github.com/facebook/metro-bundler) (formerly React Packager).\n\nThe full list of commands is:\n\n| Name                             | Description                                                                                                                                                                                                                                |\n| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n| Launch Android Emulator          | Prompts you to select the name of the available emulator and launch it. If only one emulator is installed in the system, it will be selected automatically                                                                                 |\n| Run Android on Emulator          | Run an Android application on Emulator. Launch order: check target platform support, load run arguments, start Packager, run app in all connected emulators                                                                                |\n| Run Android on Device            | Run an Android application on Device. Launch order: check target platform support, load run arguments, start Packager, run app in all connected devices                                                                                    |\n| Run iOS on Simulator             | Run an iOS application on Simulator. Launch order: load run arguments, check target platform support, start Packager, run app in only one connected emulator                                                                               |\n| Run iOS on Device                | Run an iOS application on Device. Launch order: load run arguments, check target platform support, start Packager, run app in only one connected device                                                                                    |\n| Run Expo                         | Run Exponent application. Launch order: login to exponent, load run arguments, start Packager, run app                                                                                                                                     |\n| Start Packager                   | Start Packager in context project workspace folder                                                                                                                                                                                         |\n| Stop Packager                    | Stop Packager                                                                                                                                                                                                                              |\n| Restart Packager                 | Restart Packager                                                                                                                                                                                                                           |\n| Publish To Expo                  | Publish to Exponent Host. Launch order: login to exponent, execute `Run Expo` command, then publish app to host                                                                                                                            |\n| Show Dev Menu                    | Show development menu for running aplication on iOS or Android device or emulator                                                                                                                                                          |\n| ReloadApp                        | Reload an application                                                                                                                                                                                                                      |\n| Run Element Inspector            | Load development tools for inspect application UI elements                                                                                                                                                                                 |\n| Run React Native LogCat Monitor  | Creates a LogCat Monitor for the chosen online Android device to see the device LogCat logs. Default filtering arguments: [\"*:S\", \"ReactNative:V\", \"ReactNativeJS:V\"]. [How to configure filtering.](#configure-an-Android-LogCat-Monitor) |\n| Stop React Native LogCat Monitor | Stops an existing LogCat Monitor and removes its output channel                                                                                                                                                                            |\n| Run Network Inspector            | Run [Network inspector](#network-inspector)                                                                                                                                                                                                |\n| Stop Network Inspector           | Stop [Network inspector](#network-inspector)                                                                                                                                                                                               |\n\n# Debugging React Native applications\n\nTo start debugging create a new debug configuration for your ReactNative app in your `.vscode/launch.json`. Adding a new configuration can be done by opening your `launch.json` file and clicking on `Add Configuration...` button and choosing a relevant debug configuration. All available debug configurations for ReactNative can be accessed by typing in _ReactNative_ and picking one from the list populated by Intellisense as shown in the image below.\n\n![Add React Native debug configuration](images/add-debug-configuration.gif)\n\nIn case you haven't created the `.vscode/launch.json` file yet, you can add a whole default debug configuration set. To do that click the debug icon ![Choose React Native debugger](images/debug-view-icon.png) in the View bar, and then click the configuration (gear) icon ![Configure-gear](images/configure-gear-icon.png), then choose the React Native debug environment.\n\n![Choose React Native debugger](images/choose-debugger.png)\n\nVS Code will generate a `launch.json` in your project with some default configuration settings as shown below. You can safely close this file, choose the appropriate configuration in the Configuration dropdown, and then press F5 (or click _Green Arrow_ ![Configure-gear](images/debug-icon.png) button) to start debugging your app in VS Code.\n\n![React Native launch targets](images/debug-targets.png)\n\nOnce app is loaded and running, [open the developer menu](https://reactnative.dev/docs/debugging#accessing-the-in-app-developer-menu) inside your application and enable remote debugging by clicking on `Debug JS Remotely` button.\n\n![React Native enable remote debug](images/enable-remote-debug.png)\n\nThe extension allows you to debug multiple devices and configurations, please read the following sections for more information for your particular use case.\n\n## Hermes engine\n\nThe Hermes engine is an open source JavaScript engine created by Facebook to optimize building and running React Native applications. It improves app performance and decreases app size.\n\nClick [here](https://reactnative.dev/docs/hermes) to learn more about Hermes and how to enable it for your application.\n\nDebugging apps with Hermes enabled is currently experimental. Please, see [this issue](https://github.com/microsoft/vscode-react-native/issues/1073) for current known issues on Hermes support.\n\n### Android Hermes\n\nTo debug while using Hermes engine use `Debug Android Hermes - Experimental` launch configuration:\n\n```json\n{\n  \"name\": \"Debug Android Hermes - Experimental\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnativedirect\",\n  \"request\": \"launch\",\n  \"platform\": \"android\"\n}\n```\n\n### iOS Hermes\n\nThe extension provides experimental support of debugging iOS Hermes applications. See [iOS Hermes debugging](#ios-hermes-debugging) for more details.\n\n### macOS Hermes\n\nThe extension provides experimental support of debugging macOS Hermes applications. See [macOS Hermes debugging](#macos-hermes-debugging) for more details.\n\n### Attach to Hermes application\n\nTo attach to a running Hermes application use `Attach to Hermes application - Experimental` launch configuration:\n\n```json\n{\n  \"name\": \"Attach to Hermes application - Experimental\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnativedirect\",\n  \"request\": \"attach\"\n}\n```\n\n## iOS applications\n\n### iOS devices\n\nDebugging on an iOS device requires following manual steps:\n\n- Install [ios-deploy](https://www.npmjs.com/package/ios-deploy) `npm install -g ios-deploy`.\n- Install a valid iOS development certificate.\n- In your project's `launch.json` file set `target` to `device`. If you need to specify the exact device to run, you can set `target` to `device=<iOS_device_name>`, or you can also use `runArguments` property to specify a particular device to run on in case multiple devices are connected (e.g. `\"runArguments\": [ \"--device\", \"My iPhone\" ]`)\n- Choose the **Debug iOS** option from the \"Configuration\" dropdown and press F5.\n- Shake the device to open the development menu and select \"Debug JS Remotely\".\n\n### Custom scheme for iOS apps\n\nIf you want to use a custom scheme for your application you can either pass it as part of the `runArguments` parameter arguments, or set the `scheme` configuration parameter as shown below:\n\n```js\n\"runArguments\": [\"--scheme\", \"customScheme\", ...]\n// or\n\"runArguments\": [\"--scheme=customScheme\", ...]\n// or\n\"scheme\" : \"customScheme\"\n```\n\nPlease be aware, specifying the scheme value as a part of the `runArguments` parameter arguments will override the `scheme` configuration parameter value, if it set.\n\n### iOS direct debugging\n\nThe extension provides experimental support of iOS direct debugging. See more info here: [react-native-community/discussions-and-proposals#40](https://github.com/react-native-community/discussions-and-proposals/issues/40), [react-native-community/discussions-and-proposals#206](https://github.com/react-native-community/discussions-and-proposals/issues/206)\n\nFor now the extension supports iOS direct debugging only on real iOS devices.\n\nTo be able to debug an iOS app directly, you need to instal [ios-webkit-debug-proxy](https://github.com/google/ios-webkit-debug-proxy):\n\n- Install [HomeBrew](https://brew.sh) on your Mac.\n- Open a Terminal and run `brew install ideviceinstaller ios-webkit-debug-proxy`\n\nYou can use the following debug scenarios to debug iOS apps directly:\n\n- React Native Direct: Debug Direct iOS - Experimental\n\n```json\n    \"name\": \"Debug Direct iOS - Experimental\",\n    \"cwd\": \"${workspaceFolder}\",\n    \"type\": \"reactnativedirect\",\n    \"request\": \"launch\",\n    \"platform\": \"ios\",\n    \"port\": 9221,\n    \"target\": \"device\"\n```\n\n- React Native Direct: Attach to the React Native iOS - Experimental\n\n```json\n    \"name\": \"Attach to the React Native iOS - Experimental\",\n    \"cwd\": \"${workspaceFolder}\",\n    \"type\": \"reactnativedirect\",\n    \"request\": \"attach\",\n    \"platform\": \"ios\",\n    \"port\": 9221\n```\n\n### iOS Hermes debugging\n\nYou can enable Hermes engine for an iOS application by editing `ios/Podfile` file the following way:\n\n```diff\n-  use_react_native!(:path => config[:reactNativePath])\n+  use_react_native!(:path => config[:reactNativePath], :hermes_enabled => true)\n```\n\nAfter this change you need to execute `pod install` command in `ios` folder. After that you can use `Debug iOS Hermes - Experimental` launch configuration to debug an iOS Hermes application:\n\n```json\n{\n  \"name\": \"Debug iOS Hermes - Experimental\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnativedirect\",\n  \"request\": \"launch\",\n  \"platform\": \"ios\"\n}\n```\n\n## Expo applications\n\nTo debug a project created using Expo or the `create-react-native-app` task, you can use embedded support for Expo.\n\nPrepare your environment by following the [Expo CLI Quickstart instruction](https://reactnative.dev/docs/environment-setup).\nFor correct work with Expo this extension **`requires Android SDK`**.\nSo also pay attention to the `React Native CLI Quickstart` tab, where you can find the Android SDK installation guide:\n\n- Install the [Expo app](https://getexponent.com/) on the target device or emulator\n- Ensure that the `Android SDK` is installed on your computer (You may install it using the [`React Native CLI Quickstart` guide](https://reactnative.dev/docs/environment-setup))\n- Ensure that the `expo-cli` is installed globally (`npm install -g expo-cli`)\n\nYou can verify that everything is working correctly and that the environment is ready for use with the `npx react-native doctor` command.\n\nTo start debugging in Expo follow these steps:\n\n1. Open your project in VS Code with this extension installed.\n1. Create a debug configuration (as described in [Debugging React Native applications](#debugging-react-native-applications)), select `Debug in Exponent` in the debug drop-down menu, and start debugging\n1. Wait while some dependencies are configured - the extension will install [`Expo Development Library(xdl)`](https://www.npmjs.com/package/xdl) when this feature is used for the first time.\n1. If you have not used Exponent on this system before, you will be prompted for an Exponent username and password.\n   Exponent account allows you to use Expo cloud services. More info about how it works is available [here](https://docs.expo.io/versions/latest/workflow/how-expo-works/).\n   If you have not created an Exponent account, then specifying a new username and password will create one.\n   Note that there is no e-mail associated with the account, and no way to recover a forgotten password.\n   If you don't want to create an Exponent account, you can specify `expoHostType` parameter in your debug configuration to make Expo work locally (via LAN or on localhost).\n1. Once the packager starts, the extension will open a separate tab with QR code to scan from the Exponent app. Once you do so, the Exponent app will connect to the packager and begin running your app.\n1. Once the app is loaded and running, [open the developer menu](https://reactnative.dev/docs/debugging#accessing-the-in-app-developer-menu) and enable remote debugging by clicking on `Debug JS Remotely` button.\n\n   ![React Native developer menu](./images/enable-remote-debug.png)\n\n   From here you can run and debug the app as normal.\n\n### Configuring Expo\n\nThe extension supports running through Exponent not just the applications created with Expo but even pure React Native applications (in that case you need to add `expo` package to `node_modules` in order to make it work with Expo: `npm install expo --save-dev`. In either cases it uses `app.json` configuration file in the root of the project.\n\nIf you are running `Debug in Exponent` configuration or any of pallette commands like `Run in Exponent`, `Publish to Exponent` then this file will be created automatically if absent or updated with the following basic configuration section:\n\n```json\n{\n  \"expo\": {\n    \"slug\": \"MyApp\", // Project slug\n    \"name\": \"MyApp\", // Project name\n    \"sdkVersion\": \"31.0.0\", // Expo SDK version\n    \"entryPoint\": \".vscode\\\\exponentIndex.js\" // Entrypoint for the project\n  },\n  \"name\": \"MyApp\" // Project name\n}\n```\n\nFull list of configuration parameters for `expo` section in `app.json` may be found on [official Expo documentation page](https://docs.expo.io/versions/latest/workflow/configuration).\n\nFor running **pure React Native app**, the extension, creates and uses `.vscode/exponentIndex.js` which points to the app entrypoint (`index.js` or `index.android.js` or `index.ios.js`) file.\n\nIf you want to change your app entrypoint (for example, from `index.js` to `index.android.js`), delete `.vscode/exponentIndex.js` and then restart your debugging session.\n\n**NOTE**: The extension caches the version of the exponent SDK used by your project. This is helpful since we don't want to install the SDK each time you run exponent. If you want the extension to update the SDK version based on your React Native version, just restart VS Code and if it is supported it should work. If it does not please open an issue.\n\n## React Native for Windows\n\n### How to launch and debug a React Native for Windows application\n\nBefore launching and debugging a React Native for Windows application, please make sure that your development environment is configured properly in accordance with [the official system requirements](https://microsoft.github.io/react-native-windows/docs/rnw-dependencies).\n\nYou can debug UWP React Native for Windows applications by changing the `platform` in your `launch.json` configuration to `windows`:\n\n```json\n{\n  \"name\": \"Debug Windows\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnative\",\n  \"request\": \"launch\",\n  \"platform\": \"windows\"\n}\n```\n\n### How to attach to a running React Native for Windows application\n\n1. Add the `Attach to packager` configuration to `.vscode/launch.json` in your project\n\n   ```json\n   {\n     \"name\": \"Attach to packager\",\n     \"cwd\": \"${workspaceFolder}\",\n     \"type\": \"reactnative\",\n     \"request\": \"attach\"\n   }\n   ```\n\n1. (**Optional**) Start Metro packager by means of the `React Native: Start Packager` Command Palette command or run `npx react-native start` command in the terminal in the project root folder\n1. Select the `Attach to packager` configuration and click the `play` button. If Metro packager isn't running yet, the extensnion will start it automatically.\n1. Launch your React Native Windows application. Please make sure that the application is on remote debugging mode.\n\nThen the extension should attach to the running application.\n\nYou can find more information on how to setup your application to work with Windows in [React Native for Windows Getting started instruction](https://microsoft.github.io/react-native-windows/docs/getting-started)\n\n## React Native for macOS\n\nYou can debug React Native for macOS applications by changing the `platform` in your `launch.json` configuration to `macos`:\n\n```json\n{\n  \"name\": \"Debug macOS\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnative\",\n  \"request\": \"launch\",\n  \"platform\": \"macos\"\n}\n```\n\nTo attach to a running macOS application you can use the default `Attach to packager` debugging configuration. Please make sure that the application is on remote debugging mode.\n\n```json\n{\n  \"name\": \"Attach to packager\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnative\",\n  \"request\": \"attach\"\n}\n```\n\nYou can find more information on how to setup your application to work with macOS in [React Native for macOS Getting started instruction](https://microsoft.github.io/react-native-windows/docs/rnm-getting-started)\n\n### macOS Hermes debugging\n\nPlease follow [the official guide](https://microsoft.github.io/react-native-windows/docs/hermes#available-on-macos) to enable Hermes engine for a macOS application.\n\nTo debug a macOS Hermes application you can use `Debug macOS Hermes - Experimental` debugging scenario:\n\n```json\n{\n  \"name\": \"Debug macOS Hermes - Experimental\",\n  \"request\": \"launch\",\n  \"type\": \"reactnativedirect\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"platform\": \"macos\"\n}\n```\n\n## TypeScript and Haul\n\n### Sourcemaps\n\nThe debugger uses sourcemaps to let you debug with your original sources, but sometimes the sourcemaps aren't generated properly and overrides are needed. In the config we support `sourceMapPathOverrides`, a mapping of source paths from the sourcemap, to the locations of these sources on disk. Useful when the sourcemap isn't accurate or can't be fixed in the build process.\n\nThe left hand side of the mapping is a pattern that can contain a wildcard, and will be tested against the `sourceRoot` + `sources` entry in the source map. If it matches, the source file will be resolved to the path on the right hand side, which should be an absolute path to the source file on disk.\n\nBelow there are some examples of how sourcemaps could be resolved in different scenarios:\n\n```javascript\n// webRoot = /Users/me/project\n\"sourceMapPathOverrides\": {\n    \"webpack:///./~/*\": \"${webRoot}/node_modules/*\",       // Example: \"webpack:///./~/querystring/index.js\" -> \"/Users/me/project/node_modules/querystring/index.js\"\n    \"webpack:///./*\":   \"${webRoot}/*\",                    // Example: \"webpack:///./src/app.js\" -> \"/Users/me/project/src/app.js\",\n    \"webpack:///*\":     \"*\",                               // Example: \"webpack:///project/app.ts\" -> \"/project/app.ts\"\n    \"webpack:///src/*\": \"${webRoot}/*\"                     // Example: \"webpack:///src/app.js\" -> \"/Users/me/project/app.js\"\n}\n```\n\n### Haul debugging\n\nThe extension provides functional to attach to [Haul packager](https://callstack.github.io/haul/) based applications. You can use the `Attach to packager` scenario to attach to a Haul based app and debug it. For now launch scenarios aren't supported. You can find more info in [the issue](https://github.com/microsoft/vscode-react-native/issues/883).\n\nYou can prepare your React Native application to work with `Haul` by following the [`Haul Getting started` guide](https://github.com/callstack/haul#getting-started).\n\nIf you use the [legacy version](https://github.com/callstack/haul/tree/legacy) of `Haul` as your React Native bundler instead of the default [Metro](https://facebook.github.io/metro/), it could be required to add `sourceMapPathOverrides` to the `launch.json` file.\n\nFor example:\n\n```json\n{\n  // Other configurations\n  \"sourceMapPathOverrides\": {\n    \"webpack:///./~/*\": \"${workspaceRoot}/node_modules/*\",\n    \"webpack:///./*\": \"${workspaceRoot}/*\",\n    \"webpack:///*\": \"*\"\n  }\n}\n```\n\n## Debugger configuration properties\n\nThe following is a list of all the configuration properties the debugger accepts in `launch.json`:\n\n| Name                               | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Type       | Defaults                                      |\n| ---------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------- | --------------------------------------------- |\n| `cwd`                              | The path to the project root folder                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | `string`   | `${workspaceFolder}`                          |\n| `sourceMaps`                       | Whether to use JavaScript source maps to map the generated bundled code back to its original sources                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | `boolean`  | `true`                                        |\n| `sourceMapPathOverrides`           | A set of mappings for rewriting the locations of source files from what the source map says, to their locations on disk. See [Sourcemaps](#sourcemaps) for details                                                                                                                                                                                                                                                                                                                                                                                                                                           | `object`   | n/a                                           |\n| `enableDebug`                      | Whether to enable debug mode. If set to \"false\", an application will be launched without debugging                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | `boolean`  | `true`                                        |\n| `webkitRangeMin`, `webkitRangeMax` | Combines to specify the port range that you want the [ios-webkit-debug-proxy](https://github.com/google/ios-webkit-debug-proxy) to use to find the specific device described in the Direct iOS debug configuration                                                                                                                                                                                                                                                                                                                                                                                           | 9223, 9322 |\n| `trace`                            | Logging level in debugger process. May be useful for diagnostics. If set to \"Trace\" all debugger process logs will be available in `Debug Console` output window                                                                                                                                                                                                                                                                                                                                                                                                                                             | `string`   | `log`                                         |\n| `address`                          | TCP/IP address of packager to attach to for debugging                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | `string`   | `localhost`                                   |\n| `port`                             | Port of packager to attach to for debugging                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | `string`   | `8081`                                        |\n| `remoteRoot`                       | The source root of the remote host                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | `string`   | `null`                                        |\n| `localRoot`                        | The local source root that corresponds to the 'remoteRoot'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | `string`   | `${workspaceFolder}`                          |\n| `skipFiles`                        | An array of file or folder names, or glob patterns, to skip when debugging                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | `array`    | `[]`                                          |\n| `debuggerWorkerUrlPath`            | Path to the app debugger worker to override. For example, if debugger tries to attach to http://localhost:8081/debugger-ui/debuggerWorker.js and you get 404 error from packager output then you may want to change debuggerWorkerUrlPath to another value suitable for your packager (\\\"debugger-ui\\\" will be replaced with the value you provide)                                                                                                                                                                                                                                                          | `string`   | `debugger-ui/`                                |\n| `platform`                         | The platform to target. Possible values: `android`, `ios`, `exponent`, `windows`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | `string`   | n/a                                           |\n| `target`                           | Target to run on. Possible values: `simulator`, `device`, `device=<iOS device name>`, [`<Android emulator/device id>`](https://github.com/react-native-community/cli/blob/master/docs/commands.md#--deviceid-string), `<Android emulator name>`, `<iOS simulator name>`, `<iOS simulator id>`. If the value is `simulator` then the quick pick window will be expanded with the names of the available virtual devices, then the target value in `launch.json` will be changed to the name of the selected virtual device. If you have only one virtual device available, it will be selected automatically. | `string`   | `simulator`                                   |\n| `logCatArguments`                  | Arguments to be used for LogCat (The LogCat output will appear on an Output Channel). It can be an array such as: `[\":S\", \"ReactNative:V\", \"ReactNativeJS:V\"]`                                                                                                                                                                                                                                                                                                                                                                                                                                               | `array`    | `[\"*:S\", \"ReactNative:V\", \"ReactNativeJS:V\"]` |\n| `runArguments`                     | Run arguments to be passed to `react-native run-<platform>` command (override all other configuration params)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | `array`    | n/a                                           |\n| `launchActivity`                   | The Android activity to be launched for debugging, e.g. it specifies [`--main-activity`](https://github.com/react-native-community/cli/blob/master/docs/commands.md#--main-activity-string) parameter in `react-native` run arguments                                                                                                                                                                                                                                                                                                                                                                        | `string`   | `MainActivity`                                |\n| `expoHostType`                     | The connection type to be used on Expo debugging to communicate with a device or an emulator. Possible values: <ul><li>`tunnel` - allows to deploy and debug an application by means of Expo cloud services</li><li>`lan` - allows to deploy and install an application via your LAN</li><li>`local` - allows to debug an application on an emulator or an Android device without network connection</li></ul>                                                                                                                                                                                               | `string`   | `lan`                                         |\n| `env`                              | Environment variables passed to the debugger and `react-native run-<platform>` command                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | `object`   | `{}`                                          |\n| `envFile`                          | Absolute path to a file containing environment variable definitions                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | `string`   | `${workspaceFolder}/.env`                     |\n| `variant`                          | A variant to be passed to `react-native run-android`, e.g. use `devDebug` to specify `--variant=devDebug`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | `string`   | n/a                                           |\n| `scheme`                           | A scheme name to be passed to `react-native run-ios`, e.g. `devDebug` to specify `--scheme=devDebug`                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | `string`   | n/a                                           |\n| `productName`                      | iOS bundle display name e.g. `AwesomeProject` value means that the extension will search for `AwesomeProject.app` bundle                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | `string`   | n/a                                           |\n\n# Customization\n\nThe extension can be further customized for other React Native scenarios. These are the most common:\n\n## Logging\n\nThe extension logging is divided by several output channels:\n\n- React Native - the main extension channel which collects outputs from React Native Packager and shows critical errors in the extension\n- These channels are spawned only when the specific launch scenario is executed:\n  - React Native: Run Android\n    - LogCat monitor(to get LogCat output from Android device, can be filtered by debug configuration settings)\n  - React Native: Run iOS\n  - React Native: Run macOS\n  - React Native: Run exponent\n- Debug Console which is used to receive application logs and logs generated by the debug adapter (`console.log` and other `std` outputs from the app)\n- Extension debugger verbose logs (these logs are shown up only if the `trace: \"verbose\"` option is enabled in debug scenarios)\n  - React Native Chrome Proxy - shows what runs in and out to the debugger and application\n  - Debug Console becomes more informative and contains some debugging information from the debug adapter\n  - Global extension errors are controlled by VS Code and printed in VS Code Developer Tools\n\nThere are also some global extension technical logs that might be exposed to the output. To see them set the following properties:\n\n```json\n{\n  \"react-native-tools\": {\n    \"logLevel\": \"Trace\"\n  }\n}\n```\n\n`logLevel` can be `None` (no logs), `Error`, `Warning`, `Info`, `Debug`, `Trace` (all logs). Default is `Info`.\n\n## Build APK and generate bundle\n\nYou can add VSCode tasks to build an `.apk` file and generate iOS/Android bundles.\n\nThe following is an example of a `tasks.json` for `react-native init` projects.\nPlace it in the `.vscode` folder in your project to use it:\n\n```json\n{\n  \"version\": \"2.0.0\",\n  \"presentation\": {\n    \"reveal\": \"always\",\n    \"panel\": \"new\"\n  },\n  \"tasks\": [\n    {\n      \"taskName\": \"Build APK Debug\",\n      \"group\": \"build\",\n      \"type\": \"shell\",\n      \"windows\": {\n        \"command\": \"cd android; if($?) {./gradlew assembleDebug}\"\n      },\n      \"linux\": {\n        \"command\": \"cd android && ./gradlew assembleDebug\"\n      }\n    },\n    {\n      \"taskName\": \"Build APK Release\",\n      \"group\": \"build\",\n      \"type\": \"shell\",\n      \"windows\": {\n        \"command\": \"cd android; if($?) {./gradlew assembleRelease}\"\n      },\n      \"linux\": {\n        \"command\": \"cd android && ./gradlew assembleRelease\"\n      }\n    },\n    {\n      \"taskName\": \"Generate Android Bundle\",\n      \"group\": \"build\",\n      \"type\": \"shell\",\n      \"command\": \"react-native bundle --platform android --dev false --entry-file index.js --bundle-output android/main.jsbundle\"\n    },\n    {\n      \"taskName\": \"Generate iOS Bundle\",\n      \"group\": \"build\",\n      \"type\": \"shell\",\n      \"command\": \"react-native bundle --platform ios --dev false --entry-file index.js --bundle-output ios/main.jsbundle\"\n    }\n  ]\n}\n```\n\nTo learn more about `tasks` in VSCode read [the official documentation](https://code.visualstudio.com/docs/editor/tasks).\n\nVisit [generating Signed APK](https://reactnative.dev/docs/signed-apk-android.html) to learn more about this subject.\n\n## Specifying custom arguments for `react-native run-*` command\n\nUsing custom run arguments for `react-native run-<platform>`:\n**NOTE:** This overrides all other configuration parameters.\n\n```json\n{\n  \"react-native.android.runArguments.simulator\": [\n    \"--appFolder\",\n    \"/Users/test/AwesomeProject/android/app\",\n    \"--deviceId\",\n    \"emulator-5555\"\n  ],\n  \"react-native.ios.runArguments.device\": [\n    \"--project-path\",\n    \"ios\",\n    \"--device\",\n    \"Max's iPhone\"\n  ]\n}\n```\n\n**NOTE:** You can get the list of installed simulator devices by:\n\niOS devices (macOS only):\n\n```\nxcrun simctl list --json devices\n```\n\nAndroid devices:\n\n```\nadb devices\n```\n\n**NOTE:** If you want to run the application on an iOS device, make sure you have `ios-deploy` installed globally.\n\n`npm install -g ios-deploy`\n\n## Setting up the React Native packager\n\nTo use a custom port for the `react-native` packager:\n\n```json\n{\n  \"react-native\": {\n    \"packager\": {\n      \"port\": portNumber\n    }\n  }\n}\n```\n\nIf you change this port, then for iOS device and simulator scenarios you will have to modify the native code files. [Instructions here](https://blog.binoy.io/running-react-native-on-a-different-port-7deb43887cd4).\n\nIf you use Android, you need to change the debug server by:\n\n1. `CTRL+M`(`CMD+M`) in the emulator\n2. Go to `Dev Settings`\n3. Debug server host for device => enter `localhost:<yourPortNumber>`.\n4. Reload application (press `R` twice)\n5. (Hermes only) Hermes engine listens port 8081 for debugging by default, to change it you might need to modify your [`metro.config.js` file adding `\"port\": portNumber` argument in there to the server settings](https://facebook.github.io/metro/docs/configuration/#port).\n\n```js\n// Example of metro.config.js\nmodule.exports = {\n  server: {\n    port: 9091,\n  },\n};\n```\n\n<details>\n<summary>Port setup instruction</summary>\n\n![image](images/select-dev-menu.png)\n\n![image](images/dev-menu-setup-custom-host.png)\n\n![image](images/custom-host-and-port.png)\n\n</details>\n\n**NOTE:** Some aspects of React Native hard-code the port to the default as specified in [this issue](https://github.com/facebook/react-native/issues/9145).\n\n### Custom environment variables\n\nExtension supports passing custom environment variables to the React Native Packager process context. To add custom variables you can create `.env` file in the root folder of your project and add needed environment variables in the following format:\n\n```\n\nVariable1_name=Variable1_value\nVariable2_name=Variable2_value\n\n```\n\nVariables that are declared in this `.env` file can override the original environment variables from `process.env` of the Packager process.\n\nIt is possible to transfer environment variables (via `env` and `envFile` arguments in `launch.json`) from the `launch` or `attach` debug scenarios to the Packager. If these variables are defined, then they will be used, otherwise the `.env` file is used.\n\n## Change project root\n\nTo specify a subfolder in which the react-native project is located, set `react-native-tools.projectRoot`. You can use either an absolute or relative path here:\n\n```json\n{\n  \"react-native-tools\": {\n    \"projectRoot\": \"./your/react-native/project\"\n  }\n}\n```\n\n## Configure an Android LogCat Monitor\n\nThere are two ways to filter your LogCat Monitor output depending on how LogCat Monitor was launched:\n\n1. Since LogCat Monitor is launched for all Android launch scenarios by default, you can add `logCatArguments` to your debug scenario in `launch.json` file like in the following example:\n\n```json\n{\n  \"name\": \"Debug Android\",\n  \"cwd\": \"${workspaceFolder}\",\n  \"type\": \"reactnative\",\n  \"request\": \"launch\",\n  \"platform\": \"android\",\n  \"logCatArguments\": [\"ReactNativeJS:V\"]\n}\n```\n\n2. If you want to launch LogCat Monitor from the Command Pallette command `React Native: Run React Native LogCat Monitor` with filtering options set `react-native.android.logCatArguments` settings in your `settings.json`:\n\n```json\n{\n  \"react-native.android.logCatArguments\": [\n    \"*:S\",\n    \"ReactNative:V\",\n    \"ReactNativeJS:V\"\n  ]\n}\n```\n\nTo have better understanding on how LogCat filtering works take into account that the extension launches LogCat with flag `-s` and then adds user-provided filters as arguments. Please see the [official instruction on how does LogCat filtering works](https://developer.android.com/studio/command-line/logcat#filteringOutput).\n\n# Network Inspector\n\nThe extension provides `Network inspector` feature to inspect outgoing network traffic in your apps. You can browse all requests being made and their responses in VS Code DevTools console.\n\n![image](images/network-inspector.png)\n\n### Network inspector requirements\n\nBefore using the Network inspector, please make sure that your system meets the following requirements:\n\n- `OpenSSL` utility is installed and added to PATH. You can install `OpenSSL` the following way:\n  - Windows: `choco install openssl`\n  - macOS: `brew install openssl`\n  - Linux: `sudo apt-get install openssl`\n- (macOS only) [`idb`](https://fbidb.io/docs/installation/) utility is installed. It's required to interact with iOS physical devices\n\n### Network inspector usage\n\n- To run the Network inspector you can use `Run Network Inspector` Command Palette command</br>\n  When the Network inspector detects a React Native application and connects to it, VS Code DevTools window will be opened automatically. But you can also open it manually, by opening `Help` menu and clicking `Toggle Developer Tools` option. After that you just need to open `Console` tab in DevTools, where network requests will be printed.\n- To stop the Network inspector you can use `Stop Network Inspector` Command Palette command\n\nFor now the Network inspector doesn't support Expo applications.\n\n# Developing inside a Docker Container\n\nThe extension supports [VS Code Remote Development](https://code.visualstudio.com/docs/remote/remote-overview) features on Linux. Please follow the [VS Code official documentation](https://code.visualstudio.com/docs/remote/containers) to setup your environment to use a remote development approach.\n\nYou can use [official React Native Docker image](https://hub.docker.com/r/reactnativecommunity/react-native-android) provided by the [react-native-community](https://github.com/react-native-community/docker-android).\n\nHere are the steps to run React Native debugging inside a Docker Container on a real Android device:\n\n1. Open Command Palette and run the following command\n   ```\n   Remote-Containers: Add Development Container Configuration Files...\n   ```\n   Then select `Existing Dockerfile` to create `.devcontainer/devcontainer.json` configuration file.\n1. \u0421reate Dockerfile extending [reactnativecommunity/react-native-android image](https://hub.docker.com/r/reactnativecommunity/react-native-android). For example you can use the following Dockerfile:\n\n   ```\n   FROM reactnativecommunity/react-native-android:latest\n\n   RUN npm install -g expo-cli react-native-cli\n   ```\n\n1. Configure your `devcontainer.json` file as needed. Below is a sample configuration:\n\n   ```json\n   {\n     \"name\": \"React Native Android Container\",\n\n     // Sets the run context to one level up instead of the .devcontainer folder.\n     \"context\": \"..\",\n\n     // Update the 'dockerFile' property if you aren't using the standard 'Dockerfile' filename.\n     \"dockerFile\": \"Dockerfile\",\n\n     // The optional 'runArgs' property can be used to specify additional runtime arguments.\n     \"runArgs\": [\n       \"--privileged\", // give all capabilities to a container, in other words, the container can then do almost everything that the host can do\n       \"--net\",\n       \"host\", // forwarding all host machine ports\n       \"-v\",\n       \"/dev/bus/usb:/dev/bus/usb\" // mount connected USB devices to a container\n     ],\n\n     \"settings\": {\n       // This will ignore your local shell user setting for Linux since shells like zsh are typically\n       // not in base container images. You can also update this to an specific shell to ensure VS Code\n       // uses the right one for terminals and tasks. For example, /bin/bash (or /bin/ash for Alpine).\n       \"terminal.integrated.shell.linux\": null\n     },\n\n     // Add the IDs of extensions you want installed when the container is created in the array below.\n     \"extensions\": [\"msjsdiag.vscode-react-native\"]\n   }\n   ```\n\n1. Open Command Palette and run the following command `Remote-Containers: Open Folder in Container` to reopen your project in a container\n1. Connect your device via USB and start debugging the same way as on local machine.\n\nCurrently the above scenario doesn't work on macOS and Windows. Docker Container implementation on these OS uses Virtual Machine tools which may have problems with USB forwarding for mobile devices.\n\n# Contributing\n\nPlease see our [contributing guide](CONTRIBUTING.md) for more information.\n\n# Known Issues\n\nHere is the list of common known issues you may experience while using the extension:\n\n| Issue                                                                                                      | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |\n| ---------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| Debugger doesn't stop at breakpoints                                                                       | Breakpoints require sourcemaps to be correctly configured. If you are using TypeScript, then make sure to follow the `Getting started` section for how to ensure sourcemaps are correctly set up. Also, similar issues may occur on React Native version `0.58.*` in some special cases (see [#928](https://github.com/microsoft/vscode-react-native/issues/928), [#907](https://github.com/microsoft/vscode-react-native/issues/907)), bumping dependencies versions of `react` and `react-native` package to the more recent ones should resolve these. If you are on Linux, make sure that the project folder which is opened is not a symbolic link to the real folder, that might cause problems with sourcemaps (see [#1456](https://github.com/microsoft/vscode-react-native/issues/1456)) |\n| 'adb: command not found'                                                                                   | If you receive an error `adb: command not found`, you need to update your system Path to include the location of your _ADB_ executable.The _ADB_ executable file is located in a subdirectory along with your other Android SDK files.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n| Targeting iPhone 6 doesn't work                                                                            | There was a known issue with React Native ([#5850](https://github.com/facebook/react-native/issues/5850)) but it was fixed. Please upgrade your version of React Native.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n| Can't communicate with socket pipe                                                                         | (Linux only) If you have two workspaces open that only differ in casing, the extension will fail to communicate effectively.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |\n| \"Add configuration\" button doesn't work when trying to add debug configuration to `launch.json`            | You have to add some json configuration to `launch.json` manually. Please, see ([#985](https://github.com/microsoft/vscode-react-native/issues/985)).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n| Error `None of these files exist: * .vscode/exponentIndex` appears when running React Native apps via Expo | On some project configurations (mostly on macOS) there could be problems with running RN app via Expo for the first time. You can resolve this by explicitly adding `module.exports.watchFolders = ['.vscode'];` to your Metro config. This will help Metro bundler to find the custom entry point generated by the extension needed to work with Expo. For details you can see the issue ([#1327](https://github.com/microsoft/vscode-react-native/issues/1327)).                                                                                                                                                                                                                                                                                                                                |\n\n[Known-Issues](https://github.com/microsoft/vscode-react-native/issues?q=is%3Aissue+label%3Aknown-issues) provides a complete list of active and resolved issues.\n\n# Telemetry reporting\n\nVS Code React Native extension collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://www.visualstudio.com/en-us/dn948229) to learn more.\n\nIf you don\u2019t wish to send usage data to Microsoft, edit `VSCodeTelemetrySettings.json` file at `~/.vscode-react-native` and add `optIn:false`.\n\n# Code of conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/helium-ui",
  "language": "TypeScript",
  "readme_contents": "# Helium UI\r\n\r\nHelium UI is a React application built in TypeScript created to test and display REST API endpoints. Helium UI's core functionality includes:\r\n- Display all movies from endpoint (GET)\r\n- Add a new movie to the list of movies (POST)\r\n- Delete a movie from the list of movies (DELETE) - in progress\r\n\r\n## Packages Used:\r\n- Material UI - Styling of the application\r\n- Axios - Performing CRUD requests and operations\r\n- Formik - Handling state using React Forms and Dialogs\r\n  \r\n\r\n# Getting Started\r\n\r\n## Run Locally with npm\r\n\r\n1. Clone the repository\r\n2. Open a terminal in the local respository directory\r\n3. Run the application using\r\n```\r\nnpm build && npm start\r\n```\r\n\r\n## Run Locally with Docker\r\n\r\n1. Clone the repository\r\n2. Open a terminal in the local repository directory\r\n3. Build the application using\r\n```\r\ndocker build -t helium-ui .\r\n```\r\n\r\n4. Run the application using\r\n```\r\ndocker run -it -P helium-ui\r\n```\r\n\r\n   In another terminal, run:\r\n```\r\ndocker ps\r\n```\r\n\r\n   Output will show the port number the image is running on:\r\n```\r\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                  \r\n1dafc0296c23        helium-ui           \"npm start\"              24 seconds ago      Up 23 seconds       0.0.0.0:32770->3000/tcp\r\n```\r\n\r\n5. In a browser, navigate to `http://localhost:<port number from previous step>` and the Helium UI should appear.\r\n\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/DirectXShaderCompiler",
  "language": "C++",
  "readme_contents": "# DirectX Shader Compiler\n\n[![Build status](https://ci.appveyor.com/api/projects/status/6sx47j66g4dbyem9/branch/master?svg=true)](https://ci.appveyor.com/project/dnovillo/directxshadercompiler/branch/master)\n\nThe DirectX Shader Compiler project includes a compiler and related tools used to compile High-Level Shader Language (HLSL) programs into DirectX Intermediate Language (DXIL) representation. Applications that make use of DirectX for graphics, games, and computation can use it to generate shader programs.\n\nFor more information, see the [Wiki](https://github.com/microsoft/DirectXShaderCompiler/wiki).\n\n## Downloads\nYou can download the latest successful build's artifacts (built by Appveyor) for the master branch:\n| Downloads |        |\n|-----------|--------|\n| Windows   | [\u2b07](https://ci.appveyor.com/api/projects/dnovillo/directxshadercompiler/artifacts/build%2FRelease%2Fdxc-artifacts.zip?branch=master&pr=false&job=image%3A%20Visual%20Studio%202019) |\n| Ubuntu    | [\u2b07](https://ci.appveyor.com/api/projects/dnovillo/directxshadercompiler/artifacts/build%2Fdxc-artifacts.tar.gz?branch=master&pr=false&job=image%3A%20Ubuntu) |\n\n## Features and Goals\n\nThe starting point of the project is a fork of the [LLVM](http://llvm.org/) and [Clang](http://clang.llvm.org/) projects, modified to accept HLSL and emit a validated container that can be consumed by GPU drivers.\n\nAt the moment, the DirectX HLSL Compiler provides the following components:\n\n- dxc.exe, a command-line tool that can compile HLSL programs for shader model 6.0 or higher\n\n- dxcompiler.dll, a DLL providing a componentized compiler, assembler, disassembler, and validator\n\n- dxilconv.dll, a DLL providing a converter from DXBC (older shader bytecode format)\n\n- various other tools based on the above components\n\nThe Microsoft Windows SDK releases include a supported version of the compiler and validator.\n\nThe goal of the project is to allow the broader community of shader developers to contribute to the language and representation of shader programs, maintaining the principles of compatibility and supportability for the platform. It's currently in active development across two axes: language evolution (with no impact to DXIL representation), and surfacing hardware capabilities (with impact to DXIL, and thus requiring coordination with GPU implementations).\n\n### Pre-built Releases\n\nBinary packages containing the output of this project are available from appveyor. Development kits containing only the dxc.exe driver app, the dxcompiler.dll, and the dxil.dll signing binary are available [here](https://github.com/microsoft/DirectXShaderCompiler/wiki/Releases), or in the [releases tab](https://github.com/microsoft/DirectXShaderCompiler/releases).\n\n### SPIR-V CodeGen\n\nAs an example of community contribution, this project can also target the [SPIR-V](https://www.khronos.org/registry/spir-v/) intermediate representation. Please see the [doc](docs/SPIR-V.rst) for how HLSL features are mapped to SPIR-V, and the [wiki](https://github.com/microsoft/DirectXShaderCompiler/wiki/SPIR%E2%80%90V-CodeGen) page for how to build, use, and contribute to the SPIR-V CodeGen.\n\n## Building Sources\nNote: If you intend to build from sources on Linux/macOS, follow [these instructions](docs/DxcOnUnix.rst).\n\nBefore you build, you will need to have some additional software installed. This is the most straightforward path - see [Building Sources](https://github.com/microsoft/DirectXShaderCompiler/wiki/Building-Sources) on the Wiki for more options, including Visual Studio 2015 and Ninja support.\n\n* [Git](http://git-scm.com/downloads).\n* [Python](https://www.python.org/downloads/) - version 3.x is required\n* [Visual Studio 2017](https://www.visualstudio.com/downloads) - select the following workloads: \n    * Universal Windows Platform Development\n    * Desktop Development with C++\n* [Windows SDK](https://developer.microsoft.com/en-US/windows/downloads/windows-10-sdk) - version 10.0.18362.0 or newer\n* [Windows Driver Kit](https://docs.microsoft.com/en-us/windows-hardware/drivers/download-the-wdk) - same version as the SDK\n\nAfter cloning the project, you can set up a build environment shortcut by double-clicking the `utils\\hct\\hctshortcut.js` file. This will create a shortcut on your desktop with a default configuration. If your system doesn't have the requisite association for .js files, this may not work. If so, open a cmd window and invoke: `wscript.exe utils\\hct\\hctshortcut.js`.\n\nTests are built using the TAEF framework which is included in the Windows Driver Kit.\n\nTo build, run this command on the HLSL Console.\n\n    hctbuild\n\nYou can also clean, build and run tests with this command.\n\n    hctcheckin\n\n\nTo see a list of additional commands available, run `hcthelp`\n\n## Running Tests\n\nTo run tests, open the HLSL Console and run this command after a successful build.\n\n    hcttest\n\nSome tests will run shaders and verify their behavior. These tests also involve a driver that can run these execute these shaders. See the next section on how this should be currently set up.\n\n## Running Shaders\n\nTo run shaders compiled as DXIL, you will need support from the operating system as well as from the driver for your graphics adapter. Windows 10 Creators Update is the first version to support DXIL shaders. See the [Wiki](https://github.com/microsoft/DirectXShaderCompiler/wiki/Running-Shaders) for information on using experimental support or the software adapter.\n\n### Hardware Support\n\nHardware GPU support for DXIL is provided by the following vendors:\n\n#### NVIDIA\nNVIDIA's r396 drivers (r397.64 and later) provide release mode support for DXIL\n1.1 and Shader Model 6.1 on Win10 1709 and later, and experimental mode support\nfor DXIL 1.2 and Shader Model 6.2 on Win10 1803 and later. These drivers also\nsupport DXR in experimental mode.\n\nDrivers can be downloaded from [geforce.com](https://www.geforce.com/drivers).\n\n#### AMD\nAMD\u2019s driver (Radeon Software Adrenalin Edition 18.4.1 or later) provides release mode support for DXIL 1.1 and Shader Model 6.1. Drivers can be downloaded from [AMD's download site](https://support.amd.com/en-us/download).\n\n### Intel\nIntel's 15.60 drivers (15.60.0.4849 and later) support release mode for DXIL 1.0 and Shader Model 6.0 as well as\nrelease mode for DXIL 1.1 and Shader Model 6.1 (View Instancing support only).\n\nDrivers can be downloaded from the following link [Intel Graphics Drivers](https://downloadcenter.intel.com/product/80939/Graphics-Drivers)\n\nDirect access to 15.60 driver (latest as of of this update) is provided below:\n\n[Installer](https://downloadmirror.intel.com/27412/a08/win64_15.60.2.4901.exe)\n\n[Release Notes related to DXIL](https://downloadmirror.intel.com/27266/eng/ReleaseNotes_GFX_15600.4849.pdf)\n\n## Making Changes\n\nTo make contributions, see the [CONTRIBUTING.md](CONTRIBUTING.md) file in this project.\n\n## Documentation\n\nYou can find documentation for this project in the `docs` directory. These contain the original LLVM documentation files, as well as two new files worth nothing:\n\n* [HLSLChanges.rst](docs/HLSLChanges.rst): this is the starting point for how this fork diverges from the original llvm/clang sources\n* [DXIL.rst](docs/DXIL.rst): this file contains the specification for the DXIL format\n* [tools/clang/docs/UsingDxc.rst](tools/clang/docs/UsingDxc.rst): this file contains a user guide for dxc.exe\n\n## License\n\nDirectX Shader Compiler is distributed under the terms of the University of Illinois Open Source License.\n\nSee [LICENSE.txt](LICENSE.TXT) and [ThirdPartyNotices.txt](ThirdPartyNotices.txt) for details.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/roosterjs",
  "language": "TypeScript",
  "readme_contents": "[![Build Status](https://api.travis-ci.org/microsoft/roosterjs.svg?branch=master)](https://www.travis-ci.org/microsoft/roosterjs)\r\n\r\n# Rooster\r\n\r\nRooster is a framework-independent JavaScript rich-text editor neatly nested\r\ninside one HTML `<div>` element. Editing operations performed by end users are\r\nhandled in simple ways to generate the final HTML.\r\n\r\nTo view the sample site, please click the link below:\r\n\r\n[RoosterJs Sample Site](https://microsoft.github.io/roosterjs/index.html).\r\n\r\n## Upgrade from RoosterJs 7.\\*\r\n\r\nPlease see [here](https://github.com/microsoft/roosterjs/wiki/RoosterJs-8).\r\n\r\n## Features\r\n\r\n### Packages\r\n\r\nRooster contains 6 packages.\r\n\r\n1. [roosterjs](https://microsoft.github.io/roosterjs/docs/modules/roosterjs.html):\r\n   A facade of all Rooster code for those who want a quick start. Use the\r\n   `createEditor()` function in roosterjs to create an editor with default\r\n   configurations.\r\n\r\n2. [roosterjs-editor-core](https://microsoft.github.io/roosterjs/docs/modules/roosterjs_editor_core.html):\r\n   Defines the core editor and plugin infrastructure. Use `roosterjs-editor-core`\r\n   instead of `roosterjs` to build and customize your own editor.\r\n\r\n3. [roosterjs-editor-api](https://microsoft.github.io/roosterjs/docs/modules/roosterjs_editor_api.html):\r\n   Defines APIs for editor operations. Use these APIs to modify content and\r\n   formatting in the editor you built using `roosterjs-editor-core`.\r\n\r\n4. [roosterjs-editor-dom](https://microsoft.github.io/roosterjs/docs/modules/roosterjs_editor_dom.html):\r\n   Defines APIs for DOM operations. Use `roosterjs-editor-api` instead unless\r\n   you want to access DOM API directly.\r\n\r\n5. [roosterjs-editor-plugins](https://microsoft.github.io/roosterjs/docs/modules/roosterjs_editor_plugins.html):\r\n   Defines basic plugins for common features. Examples: making hyperlinks,\r\n   pasting HTML content, inserting inline images.\r\n\r\n6. [roosterjs-editor-types](https://microsoft.github.io/roosterjs/docs/modules/roosterjs_editor_types.html):\r\n   Defines public interfaces and enumerations.\r\n\r\n### APIs\r\n\r\nRooster provides DOM level APIs (in `roosterjs-editor-dom`), core APIs (in `roosterjs-editor-core`), and formatting APIs\r\n(in `roosterjs-editor-api`) to perform editing operations.\r\n\r\n`roosterjs-editor-dom` provides several levels of DOM operations:\r\n\r\n-   Perform basic DOM operations such as `fromHtml()`, `wrap()`, `unwrap()`, ...\r\n-   Wrap a given DOM node with `InlineElement` or `BlockElement` and perform\r\n    operations with DOM Walker API.\r\n-   Perform DOM operations on a given scope using scopers.\r\n-   Travel among `InlineElements` and `BlockElements` with scope using\r\n    ContentTraverser API.\r\n\r\n`roosterjs-editor-core` provides APIs for editor core. Editor class will call such\r\nAPIs to perform basic editor operations. These APIs are overridable by specifying\r\nAPI overrides in Editor options when creating the editor.\r\n\r\n`roosterjs-editor-api` provides APIs for scenario-based operations triggered by\r\nuser interaction.\r\n\r\n## Plugins\r\n\r\nRooster supports plugins. You can use built-in plugins or build your own.\r\nPlugins call APIs to communicate with the editor. When an operation is\r\nperformed by the user or when content is changed by code, the editor will\r\ntrigger events for the plugins to handle.\r\n\r\nHere's a sample plugin which will show a dialog containing \"Hello Rooster\" when\r\nan \"a\" is typed in the editor:\r\n\r\n```typescript\r\nclass HelloRooster implements EditorPlugin {\r\n    getName() {\r\n        return 'HelloRooster';\r\n    }\r\n\r\n    initialize(editor: IEditor) {}\r\n\r\n    dispose() {}\r\n\r\n    onPluginEvent(e: PluginEvent) {\r\n        if (e.eventType == PluginEventType.KeyPress && e.rawEvent.which == 65) {\r\n            alert('Hello Rooster');\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n## Installation\r\n\r\nInstall via NPM or Yarn:\r\n\r\n`yarn add roosterjs`\r\n\r\nor\r\n\r\n`npm install roosterjs --save`\r\n\r\nYou can also install sub packages separately:\r\n\r\n`yarn add roosterjs-editor-core`\r\n\r\n`yarn add roosterjs-editor-api`\r\n\r\n`...`\r\n\r\nor\r\n\r\n`npm install roosterjs-editor-core --save`\r\n\r\n`npm install roosterjs-editor-api --save`\r\n\r\n`...`\r\n\r\nIn order to run the code below, you may also need to install [webpack](https://webpack.js.org/):\r\n\r\n`yarn add webpack -g`\r\n\r\nor\r\n\r\n`npm install webpack -g`\r\n\r\n## Usage\r\n\r\n### A quick start\r\n\r\n1. Create `editor.htm` contains a DIV with some styles, and a reference to a\r\n   .js file:\r\n\r\n```html\r\n<html>\r\n    <body>\r\n        <div\r\n            id=\"editorDiv\"\r\n            style=\"width: 500px; height: 300px; overflow: auto;\r\n        border: solid 1px black\"\r\n        ></div>\r\n        <script src=\"editor.js\"></script>\r\n    </body>\r\n</html>\r\n```\r\n\r\n2. Create `source.js` to import roosterjs and create an editor:\r\n\r\n```javascript\r\nvar roosterjs = require('roosterjs');\r\nvar editorDiv = document.getElementById('editorDiv');\r\nvar editor = roosterjs.createEditor(editorDiv);\r\neditor.setContent('Welcome to <b>RoosterJs</b>!');\r\n```\r\n\r\n3. Compile the javascript file using webpack:\r\n\r\n`webpack source.js editor.js`\r\n\r\n4. Navigate to editor.htm, you will see a editor shown in the page.\r\n\r\n### Add some format buttons\r\n\r\n1. Add some buttons into `editor.htm`:\r\n\r\n```html\r\n<html>\r\n    <body>\r\n        <div\r\n            id=\"editorDiv\"\r\n            style=\"width: 500px; height: 300px; overflow: auto;\r\n        border: solid 1px black\"\r\n        ></div>\r\n        <button id=\"buttonB\">B</button> <button id=\"buttonI\">I</button>\r\n        <button id=\"buttonU\">U</button>\r\n        <script src=\"editor.js\"></script>\r\n    </body>\r\n</html>\r\n```\r\n\r\n2. Add code to `source.js` to handle click event of the buttons:\r\n\r\n```javascript\r\nvar roosterjs = require('roosterjs');\r\nvar editorDiv = document.getElementById('editorDiv');\r\nvar editor = roosterjs.createEditor(editorDiv);\r\neditor.setContent('Welcome to <b>RoosterJs</b>!');\r\n\r\ndocument.getElementById('buttonB').addEventListener('click', function () {\r\n    roosterjs.toggleBold(editor);\r\n});\r\ndocument.getElementById('buttonI').addEventListener('click', function () {\r\n    roosterjs.toggleItalic(editor);\r\n});\r\ndocument.getElementById('buttonU').addEventListener('click', function () {\r\n    roosterjs.toggleUnderline(editor);\r\n});\r\n```\r\n\r\n3. Compile the javascript file using webpack:\r\n\r\n`webpack source.js editor.js`\r\n\r\n4. Navigate to editor.htm, you will see buttons with bold, italic, underline\r\n   actions in the page.\r\n\r\n## Sample code\r\n\r\nTo view the sample site, please click [here](https://microsoft.github.io/roosterjs/index.html).\r\n\r\nTo build the sample site code yourself, follow these instructions:\r\n\r\n1. Get dependencies using [yarn](https://yarnpkg.com) or [npm](https://www.npmjs.com/):\r\n\r\n    ```cmd\r\n    yarn\r\n    ```\r\n\r\n    or\r\n\r\n    ```cmd\r\n    npm install\r\n    ```\r\n\r\n2. Build the source code, and start the sample editor:\r\n\r\n    ```\r\n    yarn start\r\n    ```\r\n\r\n    or\r\n\r\n    ```\r\n    npm start\r\n    ```\r\n\r\n3. Navigate to the sample editor at http://localhost:3000/\r\n\r\n## Debugging\r\n\r\nThere are two options for debugging:\r\n\r\n1. Debugging from VSCode\r\n\r\n    - Ensure the sample editor is running\r\n    - Set the breakpoints within VSCode\r\n    - Select \"Debug app in Chrome\" from the VSCode debugging configuration dropdown\r\n      <img src=\"/assets/readme-images/debug-in-VSCode.png\" width=\"411\" height=\"278\"><br>\r\n    - Run the scenario that needs to be debugged\r\n\r\n2. Debugging directly from the development tools within the web browser\r\n    - The directions for how to do this are specific to each web browser. By opening the developer\r\n      tools for the web browser that Rooster is running on, you will be able to set breakpoints in\r\n      the code and debug accordingly.\r\n\r\n## Running tests\r\n\r\nThere are two ways that tests can be run:\r\n\r\n1. Run all tests or a single test from VSCode<br>\r\n    - (Skip if running all tests) Ensure the file that you want to test is selected (ie: toggleBold.ts\r\n      or toggleBoldTest.ts)\r\n    - Select \"Test all files\" or \"Test current file\" from the VSCode debugging configuration dropdown\r\n      <img src=\"/assets/readme-images/test-in-VSCode.png\" width=\"402\" height=\"268\">\r\n2. Run all tests from command line\r\n    ```\r\n    yarn test\r\n    ```\r\n\r\n## Dependencies\r\n\r\nAs a NodeJs package, RoosterJs has dependencies for runtime (specified in package.json under each sub\r\npackages in \"dependencies\" section) and dependencies for build time (specified in package.json under\r\nroot path in \"devDependencies\" section).\r\n\r\nFor runtime dependencies, there are two parts:\r\n\r\n-   Internal dependencies (a RoosterJs package depends on other RoosterJs packages)\r\n-   External dependencies (RoosterJs depends on other NPM packages)\r\n\r\nCurrently we have very few external dependencies. Before adding any new dependency, we need to check:\r\n\r\n1. What's the value of the new dependency and the code using the dependency bring into roosterjs?\r\n   If we add a new dependency and create our new API to just call into the dependency, that new API\r\n   doesn't actually bring too much value, and people who uses roosterjs in their project can do this\r\n   themselves in their code, and we should not add such dependency to people who don't really need it.\r\n\r\n2. What's the dependency tree of the dependency?\r\n   If we introduce a new dependency which has a deep dependency tree, we need to be careful since it\r\n   means we are actually adding a lot of new dependencies and our code size may be increased a lot.\r\n\r\n3. How much functionalities do we need from the dependency?\r\n   If the dependency provides a lot of functionalities but we actually only need a small piece of them,\r\n   we may need to consider other solutions, such as find another smaller one, or do it ourselves.\r\n\r\n4. What's the license of the dependency?\r\n   A dependency package under MIT license is good to be used for RoosterJs. For other licenses, we need\r\n   to review and see if we can take it as a dependency.\r\n\r\nIf you still feel a new dependency is required after checking these 3 questions, we can review it and\r\nfinally decide whether we should add the new dependency.\r\n\r\nFor build time dependencies, it is more flexable to add new dependencies since it won't increase runtime\r\ncode size or dependencies.\r\n\r\n## More documentation\r\n\r\nWe are still working on more documentation in [roosterjs wiki](https://github.com/Microsoft/roosterjs/wiki) and [API reference](https://microsoft.github.io/roosterjs/docs/index.html).\r\n\r\n## License - MIT\r\n\r\nLicense\r\nCopyright (c) Microsoft Corporation. All rights reserved.\r\n\r\nLicensed under the [MIT](LICENSE) License.\r\n"
 },
 {
  "repo": "microsoft/fluentui-apple",
  "language": "Swift",
  "readme_contents": "# Fluent UI Apple\nFluent UI Apple contains native UIKit and AppKit controls aligned with [Microsoft's Fluent UI design system](https://www.microsoft.com/design/fluent/#/). \n\n![Build Status](https://github.com/microsoft/fluentui-apple/workflows/CI/badge.svg?branch=main)\n![Localization Status](https://github.com/microsoft/fluentui-apple/workflows/Localize/badge.svg)\n![CocoaPod Publishing](https://github.com/microsoft/fluentui-apple/workflows/Pod-Publish/badge.svg)\n[![Build Status](https://dev.azure.com/microsoftdesign/fluentui-native/_apis/build/status/microsoft.fluentui-apple?branchName=main)](https://dev.azure.com/microsoftdesign/fluentui-native/_build/latest?definitionId=144&branchName=main)\n![License](https://img.shields.io/github/license/Microsoft/fluentui-apple)\n[![Carthage Compatible](https://img.shields.io/badge/Carthage-compatible-4BC51D.svg?style=flat)](https://github.com/Carthage/Carthage)\n[![CocoaPods Compatible](https://img.shields.io/cocoapods/v/MicrosoftFluentUI)](https://cocoapods.org/pods/MicrosoftFluentUI)\n![Platform](https://img.shields.io/cocoapods/p/MicrosoftFluentUI.svg?style=flat)\n\n## Getting Started\n### Install and use FluentUI\n\n#### Requirements\n\n- iOS 13+ or macOS 10.14+\n- Xcode 11+\n- Swift 5.0+\n\n#### Using Carthage\n\nTo integrate FluentUI using Carthage, specify it in your Cartfile:\n\n```\ngithub \"Microsoft/fluentui-apple\" ~> X.X.X\n```\n\nthen follow the Carthage [integration steps](https://github.com/Carthage/Carthage#adding-frameworks-to-an-application) to add the `FluentUI.framework` into your Xcode project\n\n#### Using CocoaPods\n\nTo get set up with CocoaPods visit their [getting started guide](https://guides.cocoapods.org/using/getting-started.html).\n\nTo integrate FluentUI into your Xcode project using CocoaPods, specify it in your Podfile:\n```ruby\npod 'MicrosoftFluentUI', '~> X.X.X'\n```\n\n#### Manual installation\n\n- Download the latest changes from the [FluentUI for Apple](https://github.com/microsoft/fluentui-apple) repository.\n- Move the `fluentui-apple` folder into your project folder.\n- Move the relevant `FluentUI.xcodeproj` into your Xcode project depending on which platform you want to support.\n- In Xcode select your project -> your target -> General -> Embedded Binaries -> add `FluentUI.framework`.\n\n#### Swift Package Manager\nAs of this writing, the version of Swift Package Manager shipped with the latest Xcode does not support packages that require resource bundles. As Fluent UI Apple does  require resource bundles, we do not currently support Swift Package Manager.\n\n### Import and use FluentUI\n\nAfter the framework has been added you can import the module to use it:\n\nFor Swift\n```swift\nimport FluentUI\n```\nFor Objective-C\n```objective-c\n#import <FluentUI/FluentUI.h>\n```\n\n## Contributing\n\nPost bug reports, feature requests, and questions in [Issues](https://github.com/microsoft/fluentui-apple/issues).\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Developing in the repo\n\nFluent UI Apple requires all [pull requests](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests) to come from forks of the repository. Please see [Fork a Repo - GitHub Help](https://help.github.com/en/github/getting-started-with-github/fork-a-repo) for more details on how to set up a fork of Microsoft/fluentui-apple, keep it up-to-date, and submit pull requests back to this repository.\n\nFluent UI Apple doesn't have any external code dependencies, so developing in the repository is as easy as launching the appropriate Xcode project or workspace and building and running a test app.\n\nFor more platform-specific information, please see [the iOS readme file](ios/README.md) and the [the macOS readme file](macos/README.md).\n\n#### Swift Lint\nThis project uses [SwiftLint](https://github.com/realm/SwiftLint) to automatically lint our Swift code for common errors. Please install it when developing in this repo by following the [SwiftLint Installation Instructions](https://realm.github.io/SwiftLint/).\n\n## Changelog\n\nWe use [GitHub Releases](https://github.com/blog/1547-release-your-software) to manage our releases, including the changelog between every release. You'll find a complete list of additions, fixes, and changes on the [Releases page](https://github.com/microsoft/fluentui-apple/releases).\n\n## License\n\nAll files on the FluentUI Apple GitHub repository are subject to the MIT license. Please read the [LICENSE](LICENSE) file at the root of the project.\n\nUsage of the logos and icons referenced in FluentUI Apple is subject to the terms of the [assets license agreement](https://aka.ms/fabric-assets-license).\n"
 },
 {
  "repo": "microsoft/FLAML",
  "language": "Jupyter Notebook",
  "readme_contents": "[![PyPI version](https://badge.fury.io/py/FLAML.svg)](https://badge.fury.io/py/FLAML)\n[![Build](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml/badge.svg)](https://github.com/microsoft/FLAML/actions/workflows/python-package.yml)\n![Python Version](https://img.shields.io/badge/3.6%20%7C%203.7%20%7C%203.8-blue)\n[![Downloads](https://pepy.tech/badge/flaml/month)](https://pepy.tech/project/flaml)\n[![Join the chat at https://gitter.im/FLAMLer/community](https://badges.gitter.im/FLAMLer/community.svg)](https://gitter.im/FLAMLer/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n# FLAML - Fast and Lightweight AutoML\n\n<p align=\"center\">\n    <img src=\"https://github.com/microsoft/FLAML/blob/main/docs/images/FLAML.png\"  width=200>\n    <br>\n</p>\n\nFLAML is a lightweight Python library that finds accurate machine\nlearning models automatically, efficiently and economically. It frees users from selecting\nlearners and hyperparameters for each learner. It is fast and economical. \nThe simple and lightweight design makes it easy to extend, such as\nadding customized learners or metrics. FLAML is powered by a new, [cost-effective\nhyperparameter optimization](https://github.com/microsoft/FLAML/tree/main/flaml/tune)\nand learner selection method invented by Microsoft Research.\nFLAML leverages the structure of the search space to choose a search order optimized for both cost and error. For example, the system tends to propose cheap configurations at the beginning stage of the search,\nbut quickly moves to configurations with high model complexity and large sample size when needed in the later stage of the search. For another example, it favors cheap learners in the beginning but penalizes them later if the error improvement is slow. The cost-bounded search and cost-based prioritization make a big difference in the search efficiency under budget constraints.\n\n## Installation\n\nFLAML requires **Python version >= 3.6**. It can be installed from pip:\n\n```bash\npip install flaml\n```\n\nTo run the [`notebook example`](https://github.com/microsoft/FLAML/tree/main/notebook),\ninstall flaml with the [notebook] option:\n\n```bash\npip install flaml[notebook]\n```\n\n## Quickstart\n\n* With three lines of code, you can start using this economical and fast\nAutoML engine as a scikit-learn style estimator.\n```python\nfrom flaml import AutoML\nautoml = AutoML()\nautoml.fit(X_train, y_train, task=\"classification\")\n```\n\n* You can restrict the learners and use FLAML as a fast hyperparameter tuning\ntool for XGBoost, LightGBM, Random Forest etc. or a customized learner.\n```python\nautoml.fit(X_train, y_train, task=\"classification\", estimator_list=[\"lgbm\"])\n```\n\n* You can also run generic ray-tune style hyperparameter tuning for a custom function.\n```python\nfrom flaml import tune\ntune.run(train_with_config, config={\u2026}, low_cost_partial_config={\u2026}, time_budget_s=3600)\n```\n\n## Advantages\n\n* For classification and regression tasks, find quality models with lower computational resources.\n* Users can choose their desired customizability: minimal customization (computational resource budget), medium customization (e.g., scikit-style learner, search space and metric), full customization (arbitrary training and evaluation code).\n* Allow human guidance in hyperparameter tuning to respect prior on certain subspaces but also able to explore other subspaces.\n\n## Examples\n\nA basic classification example.\n\n```python\nfrom flaml import AutoML\nfrom sklearn.datasets import load_iris\n# Initialize an AutoML instance\nautoml = AutoML()\n# Specify automl goal and constraint\nautoml_settings = {\n    \"time_budget\": 10,  # in seconds\n    \"metric\": 'accuracy',\n    \"task\": 'classification',\n    \"log_file_name\": \"test/iris.log\",\n}\nX_train, y_train = load_iris(return_X_y=True)\n# Train with labeled input data\nautoml.fit(X_train=X_train, y_train=y_train,\n                        **automl_settings)\n# Predict\nprint(automl.predict_proba(X_train))\n# Export the best model\nprint(automl.model)\n```\n\nA basic regression example.\n\n```python\nfrom flaml import AutoML\nfrom sklearn.datasets import load_boston\n# Initialize an AutoML instance\nautoml = AutoML()\n# Specify automl goal and constraint\nautoml_settings = {\n    \"time_budget\": 10,  # in seconds\n    \"metric\": 'r2',\n    \"task\": 'regression',\n    \"log_file_name\": \"test/boston.log\",\n}\nX_train, y_train = load_boston(return_X_y=True)\n# Train with labeled input data\nautoml.fit(X_train=X_train, y_train=y_train,\n                        **automl_settings)\n# Predict\nprint(automl.predict(X_train))\n# Export the best model\nprint(automl.model)\n```\n\nMore examples can be found in [notebooks](https://github.com/microsoft/FLAML/tree/main/notebook/).\n\n## Documentation\n\nThe API documentation is [here](https://microsoft.github.io/FLAML/).\n\nRead more about the \nhyperparameter optimization methods\nin FLAML [here](https://github.com/microsoft/FLAML/tree/main/flaml/tune). They can be used beyond the AutoML context. \nAnd they can be used in distributed HPO frameworks such as ray tune or nni.\n\nFor more technical details, please check our papers.\n\n* [FLAML: A Fast and Lightweight AutoML Library](https://www.microsoft.com/en-us/research/publication/flaml-a-fast-and-lightweight-automl-library/). Chi Wang, Qingyun Wu, Markus Weimer, Erkang Zhu. MLSys, 2021.\n```\n@inproceedings{wang2021flaml,\n    title={FLAML: A Fast and Lightweight AutoML Library},\n    author={Chi Wang and Qingyun Wu and Markus Weimer and Erkang Zhu},\n    year={2021},\n    booktitle={MLSys},\n}\n```\n* [Frugal Optimization for Cost-related Hyperparameters](https://arxiv.org/abs/2005.01571). Qingyun Wu, Chi Wang, Silu Huang. AAAI 2021.\n* [Economical Hyperparameter Optimization With Blended Search Strategy](https://www.microsoft.com/en-us/research/publication/economical-hyperparameter-optimization-with-blended-search-strategy/). Chi Wang, Qingyun Wu, Silu Huang, Amin Saied. ICLR 2021.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\n\nIf you are new to GitHub [here](https://help.github.com/categories/collaborating-with-issues-and-pull-requests/) is a detailed help source on getting involved with development on GitHub.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Developing\n\n### Setup:\n\n```\ngit clone https://github.com/microsoft/FLAML.git\npip install -e .[test,notebook]\n```\n\n### Coverage\nAny code you commit should generally not significantly impact coverage. To run all unit tests:\n```\ncoverage run -m pytest test\n```\n\nIf all the tests are passed, please also test run notebook/flaml_automl to make sure your commit does not break the notebook example.\n\n## Authors\n\n* Chi Wang\n* Qingyun Wu\n\nContributors (alphabetical order): Sebastien Bubeck, Surajit Chaudhuri, Nadiia Chepurko, Ofer Dekel, Alex Deng, Anshuman Dutt, Nicolo Fusi, Jianfeng Gao, Johannes Gehrke, Silu Huang, Dongwoo Kim, Christian Konig, John Langford, Amin Saied, Neil Tenenholtz, Markus Weimer, Haozhe Zhang, Erkang Zhu.\n\n## License\n\n[MIT License](LICENSE)\n"
 },
 {
  "repo": "microsoft/winget-pkgs",
  "language": "PowerShell",
  "readme_contents": "# Welcome to the Windows Package Manager Community repo\nThis repository contains the manifest files for the **Windows Package Manager**.  You are highly encouraged to submit manifests for your favorite application.\n\nThe **Windows Package Manager** is an open source client.  You will find the source code [here](https://github.com/microsoft/winget-cli).\n\n# Submitting a Package\nTo submit a package to the repository, you should follow these steps:\n1) Follow the **Contributing** guidelines below\n2) Author a Manifest\n3) Test your manifest\n4) Submit your PR\n5) Respond to any feedback\n\n>Note: Please check that the package's manifest you intend to submit does not already exist in the manifests folder, and that there are no open PRs for it in order to avoid duplicates.\n\n## Authoring a Manifest\n\nThe minimal manifest syntax is below. Additional information on writing manifests can be found on [Microsoft Docs](https://docs.microsoft.com/en-us/windows/package-manager/package/manifest) or on the [v1.0 manifest spec](https://github.com/microsoft/winget-cli/blob/master/doc/ManifestSpecv1.0.md).\n\nCurrent limitations are:\n* One manifest per PR\n\nBe sure the manifest filenames match the `PackageIdentifier` manifest naming conventions and the manifest is located in the folder path matching `manifests\\<first lower case letter of publisher>\\<publisher>\\<package>\\<version>\\.yaml`\n\n### Using the YAMLCreate.ps1\nTo help author manifest files, we have provided a YAMLCreate.ps1 powershell script located in the Tools folder.  \nThe script will prompt you for the URL to the installer, then will prompt you to fill in metadata.\n\nI recommend running the script in the location where you want to produce the manifest file.  For example: `manifests\\<publisher>\\<package>\\`.  After successful completion, it will produce the YAML file.\n\n### Using Windows Package Manager YAML Generator\nIf you prefer to use a GUI to generate YAML files, you can use the **Windows Package Manager YAML Generator**. It is available as an app [in the Microsoft Store](https://www.microsoft.com/en-us/p/windows-package-manager-yaml-generator/9p3n60fs22k5) and the code is also available [on GitHub](https://github.com/ptorr-msft/WinGetYamlGenerator).\n\nAlthough the Windows Package Manager YAML Generator can create YAML files with multiple installers, winget does not support more than one installer for now.\n\n## Test your manifest\nNow that you have authored your manifest, you should make sure it works as expected.\n\n### Locally\n1) Verify the syntax.  You can do that by typing the following command: `winget validate <manifest>`\n2) Test the install.  You can do that by installing the manifest: `winget install -m <manifest>`\nFor more details, see [packages](https://docs.microsoft.com/windows/package-manager/package).\n\n### In Windows Sandbox\nYou can use the [`Tools\\SandboxTest.ps1`](Tools/SandboxTest.ps1) script for testing a manifest installation in [Windows Sandbox](https://docs.microsoft.com/en-us/windows/security/threat-protection/windows-sandbox/windows-sandbox-overview). The manifest will be also validated.\n\nJust provide the path to manifest as parameter:\n```powershell\n.\\Tools\\SandboxTest.ps1 <path-to-manifest>\n```\n\n## Submit your PR\nWith the manifest verified, you will need to submit a PR.  Your manifest should be located in the folder path matching `manifests\\<first lower case letter of publisher>\\<publisher>\\<package>\\<version>.yaml`\n\n### Validation Process\nThe PR request will go through a validation process.  During the process, the PR request will get labels to help drive the validation.\nIn the event of a failure, the BOT will suggest where the problem is with the submission and assign the PR back to you.  \n\n### Respond to PR feedback\nIf the PR has been assigned to you, a timer is triggered.  You will have 7 days to resolve the issue, or the PR will be closed automatically by the BOT.  \n\nThe installer may be identified as malware. If you believe it's a false positive you can submit the installer to the defender team for analysis from [here](https://www.microsoft.com/wdsi/filesubmission).\n\nFor a list of the BOT labels, see [packages](https://docs.microsoft.com/windows/package-manager/package/repository#pull-request-labels).\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nFor the avoidance of doubt, you may not make any Submissions linking to third party materials if such \nSubmission is prohibited by the applicable third party and/or otherwise violates such third party's rights.\n"
 },
 {
  "repo": "microsoft/azure-devops-extension-sample",
  "language": "TypeScript",
  "readme_contents": "# Azure DevOps Web Sample Extension\n\n[![Build Status](https://dev.azure.com/ms/azure-devops-extension-sample/_apis/build/status/Microsoft.azure-devops-extension-sample)](https://dev.azure.com/ms/azure-devops-extension-sample/_build/latest?definitionId=14)\n\nThis repository generates an [Azure DevOps extension](https://docs.microsoft.com/en-us/azure/devops/extend/overview?view=vsts) containing a number of different contributions of various types.\n\n## Dependencies\n\nThe sample repository depends on a few Azure DevOps packages:\n\n- [azure-devops-extension-sdk](https://github.com/Microsoft/azure-devops-extension-sdk): Required module for Azure DevOps extensions which allows communication between the host page and the extension iframe.\n- [azure-devops-extension-api](https://github.com/Microsoft/azure-devops-extension-api): Contains REST client libraries for the various Azure DevOps feature areas.\n- [azure-devops-ui](https://developer.microsoft.com/azure-devops): UI library containing the React components used in the Azure DevOps web UI.\n\nSome external dependencies:\n\n- `React` - Is used to render the UI in the samples, and is a dependency of `azure-devops-ui`.\n- `TypeScript` - Samples are written in TypeScript and complied to JavaScript\n- `SASS` - Extension samples are styled using SASS (which is compiled to CSS and delivered in webpack js bundles).\n- `webpack` - Is used to gather dependencies into a single javascript bundle for each sample.\n\n## Building the sample project\n\nJust run:\n\n    npm run build\n\nThis produces a .vsix file which can be uploaded to the [Visual Studio Marketplace](https://marketplace.visualstudio.com/azuredevops)\n\n## Using the extension\n\nThe preferred way to get started is to use the `tfx extension init` command which will clone from this sample and prompt you for replacement information (like your publisher id). Just run:\n\n    npm install -g tfx-cli\n    tfx extension init\n\nYou can also clone the sample project and change the `publisher` property in `azure-devops-extension.json` to your own Marketplace publisher id. Refer to the online [documentation](https://docs.microsoft.com/en-us/azure/devops/extend/publish/overview?view=vsts) for setting up your own publisher and publishing an extension.\n\n# Samples\n\nIndividual sample contributions are self-contained folders under `./src/Samples`. Within each sample you will find:\n\n1. `{SampleName}.json` - describes the contribution objects being added to Azure DevOps\n2. `{SampleName}.html` - page which is rendered within an iframe on the appropriate Azure DevOps page or pages. It may be visible UI (such as a Hub) or a background iframe (such as a Menu action handler). This will include a sample reference for `{SampleName}.js`, and for visible frames it will contain a single `<div>` element with an id of `root`.\n3. `{SampleName}.ts(x)` - Root script that is run when the frame is loaded. A webpack entry is added for this file which will generate a single `js` file with this content and all its dependencies.\n4. `{SampleName}.scss` - optional sass file containing the styles (CSS) for the UI\n5. Additional ts/tsx files - For samples that are too big for one file, the code will be broken up appropriately\n\n## BreadcrumbService\n\nThis sample adds a breadcrumb service which adds a \"Sample Breadcrumb Item\" global breadcrumb item to the sample hub.  Visit the \"Sample Hub\" in the `Pipelines` hub group to see this item.\n\n## CodeEditorContribution\n\nThis sample adds a language definition and a JSON schema for the code editor.\n\nTo see the language definition in action, add a new file to git or TFVC called \"sample.mylog\", then copy the example log content from [the Monaco playground](https://microsoft.github.io/monaco-editor/playground.html#extending-language-services-custom-languages).\n\nTo see the JSON schema in action, add a new file to git or TFVC called \"myconfig.json\", then begin editing it.\n\n## Feature\n\nThis sample shows how to hook into the Preview Features panel (under the user profile menu). It adds a simple hub that is only shown when an \"ABC\" feature is turned on. The feature can be toggled per-user or per-organization.\n\nThis also defines a second feature (ABC v2) which controls whether v1 or v2 of the ABC hub is used (when the ABC feature is turned on). When enabled, a \"property-provider\" contribution modifies the name and url of the hub contribution. Here we add a v2=true query parameter to our existing hub page, but you could also\nspecify a completely different html page here. This feature shows off a bit more advanced functionality provided by preview features. It can be toggled per-user, per-project, or per-organization (the \"null\" hostScopeValue). It is on by default (defaultState: true). And it has an override rule which causes the v2 feature to be OFF (and disabled in the preview features panel) whenever the ABC feature is off.\n\n## Hub\n\nThis sample adds a hub named \"Sample Hub\" into the `Pipelines` hub group. If you visit a project-level page, you will find Sample Hub under the `Pipelines` navigation element in the vertical navigation menu on the left of the page.\n\nThe hub uses a Pivot component to draw 4 different tabs:\n\n1. An `Overview` tab contains some simple details about the current user and project\n2. A `Navigation` tab contains a few actions that allow you to integrate with the page's URL and title\n3. An `Extension Data` tab demonstrates reading and writing to the extension data service\n4. A `Messages` tab shows how to display global messages\n\nThere are also actions at the top-right of the hub which demonstrate opening dialogs and panels, including custom content within them (used in the `Panel` sample).\n\n## Menu\n\nThis sample adds a \"Sample build definition menu item\" to the `Builds` hub in the dropdown actions menu in the top-right of the page. The menu handler gets the current build definition from the context that is passed to it, it makes a REST call, and shows the result in a message box.\n\n## Panel\n\nThis sample is leveraged within the `Hub` sample. It is content that contains a toggle button along with OK/Cancel buttons. It can be used as custom panel or dialog content.\n\n## Pivot\n\nThis sample adds a \"Sample Pivot\" pivot (tab) to the Organization (Project Collection) home page, next to \"Projects\", \"My work items\", and \"My pull requests\".\n\nThis pivot makes a REST call for all the projects in the organization and it displays them in a grid view.\n\n## Pill\n\nThis sample adds pills to the title of the Pipeline definition (Runs) page.\n\n## QueryParamsHandler\n\nThis sample adds a service that gets loaded on any page whenever a \"showMyPanel\" query parameter is present\nin the URL when any page is loaded. The startup service shows the custom panel from the Panel sample, using\nan optional \"myPanelTitle\" query parameter as the panel title.\n\n## RepositoryActions\n\nThis sample adds a \"Sample repository action\" menu item to the repository picker in the header of code hub pages. If a \"href\" property is provided, clicking on the action will navigate to the given url. If a \"uri\" is provided, that code will be executed when the action is clicked.\n\n## RepositoryServiceHub\n\nThis sample adds a \"Repository Information\" hub to the `Code` hub group. It demonstrates how to interact with the `IVersionControlRepositoryService` to obtain basic information about a user's currently selected Git repository.\n\n## WorkItemFormGroup\n\nThis sample adds a \"Sample WorkItem Form Group\" extension to workitem form to show how to interact with the `IWorkItemFormService` service and `IWorkItemNotificationListener`. It gives UI to show case how to change field values using the form service and displaying workitem form notification events.\n\nThis sample also provides a unit testing example with minimal necessary mocks.\n\n## WorkItemOpen\n\nThis sample adds a \"Sample WorkItem Open\" hub to the Boards hub group to show how to interact with the `IWorkItemFormNavigationService` service. It gives UI for you to open an existing work item (by id) or open the work item form for a new work item (by work item type). Either of these options open a dialog in the host frame.\n\n# References\n\nThe full set of documentation for developing extensions can be found at [https://docs.microsoft.com/en-us/azure/devops/extend](https://docs.microsoft.com/en-us/azure/devops/extend/?view=vsts).\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit <https://cla.microsoft.com>.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/BotFramework-WebChat",
  "language": "JavaScript",
  "readme_contents": "# ![Bot Framework Web Chat](https://raw.githubusercontent.com/microsoft/BotFramework-WebChat/main/media/BotFrameworkWebChat_header.png)\n\n### [Click here to find out what is new in Web Chat](https://github.com/microsoft/BotFramework-WebChat/blob/main/CHANGELOG.md)\n\n# Bot Framework Web Chat\n\n[![npm version](https://badge.fury.io/js/botframework-webchat.svg)](https://badge.fury.io/js/botframework-webchat)\n[![Build Status](https://fuselabs.visualstudio.com/BotFramework-WebChat/_apis/build/status/BotFramework-WebChat-daily?branchName=main)](https://fuselabs.visualstudio.com/BotFramework-WebChat/_build/latest?definitionId=498&branchName=main)\n\nThis repository contains code for the Bot Framework Web Chat component. The Bot Framework Web Chat component is a highly-customizable web-based client for the Bot Framework V4 SDK. The Bot Framework SDK v4 enables developers to model conversation and build sophisticated bot applications.\n\nThis repo is part of the [Microsoft Bot Framework](https://github.com/microsoft/botframework) - a comprehensive framework for building enterprise-grade conversational AI experiences.\n\n<hr />\n\n# Version notes\n\n> This section points out important version notes. For further information, please see the related links and check the [`CHANGELOG.md`](https://github.com/microsoft/BotFramework-WebChat/blob/main/CHANGELOG.md\n\n### 4.12.1 patch: New style property `adaptiveCardsParserMaxVersion`\n\nWeb Chat 4.12.1 patch includes a new style property allowing developers to choose the max Adaptive Cards schema version. See [PR #3778](https://github.com/microsoft/BotFramework-WebChat/pull/3778) for code changes.\n\nTo specify a different max version, you can adjust the style options, shown below:\n\n```js\nwindow.WebChat.renderWebChat(\n   {\n      directLine,\n      store,\n      styleOptions: {\n         adaptiveCardsParserMaxVersion: '1.2'\n      }\n   },\n   document.getElementById('webchat')\n);\n```\n\n-  Web Chat will apply the maximum schema available according to the Adaptive Cards version (as of this patch, schema 1.3) by default.\n-  An invalid version will revert to Web Chat's default.\n\n## Visual focus changes to transcript in Web Chat 4.12.0\n\nA new accessibility update has been added to Web Chat from PR [#3703](https://github.com/microsoft/BotFramework-WebChat/pull/3703). This change creates visual focus for the transcript (bold black border) and `aria-activedescendent` focused activity (black dashed border) by default. Where applicable, `transcriptVisualKeyboardIndicator...` values will also be applied to carousel (`CarouselFilmStrip.js`) children. This is done in order to match current default focus styling for Adaptive Cards, which may be a child of a carousel.\n\nTo modify these styles, you can change the following props via `styleOptions`:\n\n```\n  transcriptActivityVisualKeyboardIndicatorColor: DEFAULT_SUBTLE,\n  transcriptActivityVisualKeyboardIndicatorStyle: 'dashed',\n  transcriptActivityVisualKeyboardIndicatorWidth: 1,\n  transcriptVisualKeyboardIndicatorColor: 'Black',\n  transcriptVisualKeyboardIndicatorStyle: 'solid',\n  transcriptVisualKeyboardIndicatorWidth: 2,\n```\n\nThe above code shows the default values you will see in Web Chat.\n\n## API refactor into new package in Web Chat 4.11.0\n\nThe Web Chat API has been refactored into a separate package. To learn more, check out the [API refactor summary](https://github.com/microsoft/BotFramework-WebChat/pull/3543).\n\n## Direct Line Speech support in Web Chat 4.7.0\n\nStarting from Web Chat 4.7.0, Direct Line Speech is supported, and it is the preferred way to provide an integrated speech functionality in Web Chat. We are working on [closing feature gaps](https://github.com/microsoft/BotFramework-WebChat/labels/Direct%20Line%20Speech) between Direct Line Speech and Web Speech API (includes Cognitive Services and browser-provided speech functionality).\n\n## Upgrading to 4.6.0\n\nStarting from Web Chat 4.6.0, Web Chat requires React 16.8.6 or up.\n\nAlthough we recommend that you upgrade your host app at your earliest convenience, we understand that host app may need some time before its React dependencies are updated, especially in regards to huge applications.\n\nIf your app is not ready for React 16.8.6 yet, you can follow the [hybrid React sample](https://github.com/microsoft/BotFramework-WebChat/tree/main/samples/01.getting-started/g.hybrid-react-npm) to dual-host React in your app.\n\n## Speech changes in Web Chat 4.5.0\n\nThere is a breaking change on behavior expectations regarding speech and input hint in Web Chat. Please refer to the section on [input hint behavior before 4.5.0](https://github.com/microsoft/BotFramework-WebChat/blob/main/docs/SPEECH.md#input-hint-behavior-before-4-5-0) for details.\n\n## Migrating from Web Chat v3 to v4\n\n[View migration docs](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/MIGRATION.md) to learn about migrating from Web Chat v3.\n\n<hr />\n\n# How to use\n\nFirst, create a bot using [Azure Bot Service](https://azure.microsoft.com/en-us/services/bot-service/).\nOnce the bot is created, you will need to [obtain the bot's Web Chat secret](https://docs.microsoft.com/en-us/azure/bot-service/bot-service-channel-connect-webchat?view=azure-bot-service-3.0#step-1) in Azure Portal. Then use the secret to [generate a token](https://docs.microsoft.com/en-us/azure/bot-service/rest-api/bot-framework-rest-direct-line-3-0-authentication?view=azure-bot-service-4.0) and pass it to your Web Chat.\n\n## Connect a client app to bot\n\nWeb Chat provides UI on top of the Direct Line and Direct Line Speech Channels. There are two ways to connect to your bot through HTTP calls from the client: by sending the Bot secret or generating a token via the secret.\n\n<!-- TODO: https://github.com/microsoft/BotFramework-WebChat/issues/2151 (ongoing) -->\n<!-- Update the following paragraph and the API table (`directline`) with new documentation when updated docs are published  -->\n\nWe strongly recommend using the token API instead of providing the app with your secret. To learn more about why, see the [authentication documentation](https://docs.microsoft.com/en-us/azure/bot-service/rest-api/bot-framework-rest-direct-line-3-0-authentication?view=azure-bot-service-4.0) on the [token API](https://docs.microsoft.com/en-us/azure/bot-service/rest-api/bot-framework-rest-direct-line-3-0-api-reference?view=azure-bot-service-4.0) and client security.\n\nFor further reading, please see the following links:\n\n-  Using Web Chat with [Azure Bot Services authentication](https://blog.botframework.com/2018/09/01/using-webchat-with-azure-bot-services-authentication/)\n\n-  [Enhanced Direct Line authentication features](https://blog.botframework.com/2018/09/25/enhanced-direct-line-authentication-features/)\n\n## Integrate with JavaScript\n\nWeb Chat is designed to integrate with your existing website using JavaScript or React. Integrating with JavaScript will give you moderate styling and customizability options.\n\nYou can use the full, typical Web Chat package (called full-feature bundle) that contains the most typically used features.\n\nHere is how how you can add Web Chat control to your website:\n\n<!-- prettier-ignore-start -->\n```html\n<!DOCTYPE html>\n<html>\n  <head>\n    <script\n      crossorigin=\"anonymous\"\n      src=\"https://cdn.botframework.com/botframework-webchat/latest/webchat.js\"\n    ></script>\n    <style>\n      html,\n      body {\n         height: 100%;\n      }\n\n      body {\n        margin: 0;\n      }\n\n      #webchat {\n        height: 100%;\n        width: 100%;\n      }\n    </style>\n  </head>\n  <body>\n    <div id=\"webchat\" role=\"main\"></div>\n    <script>\n      window.WebChat.renderWebChat(\n        {\n          directLine: window.WebChat.createDirectLine({\n            token: 'YOUR_DIRECT_LINE_TOKEN'\n          }),\n          userID: 'YOUR_USER_ID',\n          username: 'Web Chat User',\n          locale: 'en-US'\n        },\n        document.getElementById('webchat')\n      );\n    </script>\n  </body>\n</html>\n```\n<!-- prettier-ignore-end -->\n\n> `userID`, `username`, and `locale` are all optional parameters to pass into the `renderWebChat` method. To learn more about Web Chat props, look at the [Web Chat API Reference](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/API.md) documentation.\n\n> Assigning `userID` as a static value is not recommended since this will cause all users to share state. Please see the [`API userID entry`](https://github.com/microsoft/BotFramework-WebChat/blob/main/docs/API.md#userID) for more information.\n\nMore information on localization can be found in the [Localization](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/LOCALIZATION.md) documentation.\n\n![Screenshot of Web Chat](https://raw.githubusercontent.com/microsoft/BotFramework-WebChat/main/media/weatherquery.png.jpg)\n\nSee the working sample of the [full Web Chat bundle](https://github.com/microsoft/BotFramework-WebChat/tree/main/samples/01.getting-started/a.full-bundle).\n\n## Integrate with React\n\nFor full customizability, you can use React to recompose components of Web Chat.\n\nTo install the production build from NPM, run `npm install botframework-webchat`.\n\n<!-- prettier-ignore-start -->\n```js\nimport React, { useMemo } from 'react';\nimport ReactWebChat, { createDirectLine } from 'botframework-webchat';\n\nexport default () => {\n  const directLine = useMemo(() => createDirectLine({ token: 'YOUR_DIRECT_LINE_TOKEN' }), []);\n\n  return <ReactWebChat directLine={directLine} userID=\"YOUR_USER_ID\" />;\n};\n```\n<!-- prettier-ignore-end -->\n\n> You can also run `npm install botframework-webchat@main` to install a development build that is synced with Web Chat's GitHub `main` branch.\n\nSee the working sample of [Web Chat rendered via React](https://github.com/microsoft/BotFramework-WebChat/tree/main/samples/01.getting-started/e.host-with-react/).\n\n### Experimental support for Redux DevTools\n\nWeb Chat internally use Redux for state management. [Redux DevTools](https://github.com/reduxjs/redux-devtools) is enabled in the NPM build as an opt-in feature.\n\nThis is for glancing into how Web Chat works. This is not an API explorer and is not an endorsement of using the Redux store to programmatically access the UI. The [hooks API](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/HOOKS.md) should be used instead.\n\nTo use Redux DevTools, use the `createStoreWithDevTools` function for creating a Redux DevTools-enabled store.\n\n<!-- prettier-ignore-start -->\n```diff\n  import React, { useMemo } from 'react';\n- import ReactWebChat, { createDirectLine, createStore } from 'botframework-webchat';\n+ import ReactWebChat, { createDirectLine, createStoreWithDevTools } from 'botframework-webchat';\n\n  export default () => {\n    const directLine = useMemo(() => createDirectLine({ token: 'YOUR_DIRECT_LINE_TOKEN' }), []);\n-   const store = useMemo(() => createStore(), []);\n+   const store = useMemo(() => createStoreWithDevTools(), []);\n\n    return <ReactWebChat directLine={directLine} store={store} userID=\"YOUR_USER_ID\" />;\n  };\n```\n<!-- prettier-ignore-end -->\n\nThere are some limitations when using the Redux DevTools:\n\n-  The Redux store uses side-effects via [`redux-saga`](https://github.com/redux-saga/redux-saga). Time-traveling may break the UI.\n-  Many UI states are stored in React context and state. They are not exposed in the Redux store.\n-  Some time-sensitive UIs are based on real-time clock and not affected by time-traveling.\n-  Dispatching actions are not officially supported. Please use [hooks API](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/HOOKS.md) instead.\n-  Actions and reducers may move in and out of Redux store across versions. [Hooks API](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/HOOKS.md) is the official API for accessing the UI.\n\n# Customizing the Web Chat UI\n\nWeb Chat is designed to be customizable without forking the source code. The table below outlines what kind of customizations you can achieve when you are importing Web Chat in different ways. This list is not exhaustive.\n\n|                               | CDN bundle |  React   |\n| ----------------------------- | :--------: | :------: |\n| Change colors                 |  &#10004;  | &#10004; |\n| Change sizes                  |  &#10004;  | &#10004; |\n| Update/replace CSS styles     |  &#10004;  | &#10004; |\n| Listen to events              |  &#10004;  | &#10004; |\n| Interact with hosting webpage |  &#10004;  | &#10004; |\n| Custom render activities      |            | &#10004; |\n| Custom render attachments     |            | &#10004; |\n| Add new UI components         |            | &#10004; |\n| Recompose the whole UI        |            | &#10004; |\n\nSee more about [customizing Web Chat](https://github.com/microsoft/BotFramework-WebChat/blob/main/samples/README.md) to learn more on customization.\n\n## Supported Activity Types on the Web Chat Client\n\nBot Framework has many activity types, but not all are supported in Web Chat. [View activity types docs](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/ACTIVITYTYPES.md) to learn more.\n\n# Samples list\n\n[View the complete list of Web Chat samples](https://github.com/microsoft/BotFramework-WebChat/tree/main/samples) for more ideas on customizing Web Chat.\n\n# Further reading\n\n## API Reference\n\nView the [API documentation](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/API.md) for implementing Web Chat.\n\n## Browser compatibility\n\nWeb Chat supports the latest 2 versions of modern browsers like Chrome, Microsoft Edge, and FireFox.\nIf you need Web Chat in Internet Explorer 11, please see the [ES5 bundle demo](https://microsoft.github.io/BotFramework-WebChat/01.getting-started/c.es5-bundle).\n\nPlease note, however:\n\n-  Web Chat does not support Internet Explorer older than version 11\n-  Customization as shown in non-ES5 samples are not supported for Internet Explorer. Because IE11 is a non-modern browser, it does not support ES6, and many samples that use arrow functions and modern promises would need to be manually converted to ES5. If you are in need of heavy customization for your app, we strongly recommend developing your app for a modern browser like Google Chrome or Microsoft Edge.\n-  Web Chat has no plan to support samples for IE11 (ES5).\n   -  For customers who wish to manually rewrite our other samples to work in IE11, we recommend looking into converting code from ES6+ to ES5 using polyfills and transpilers like [`babel`](https://babeljs.io/docs/en/next/babel-standalone.html).\n\n## Accessibility\n\nView the [accessibility documentation](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/ACCESSIBILITY.md).\n\n## Localization\n\nView the [localization documentation](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/LOCALIZATION.md) for implementing in Web Chat.\n\n## Notifications\n\nView the [notification documentation](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/NOTIFICATION.md) for implementing in Web Chat.\n\n## Telemetry\n\nView the [telemetry documentation](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/TELEMETRY.md) for implementing in Web Chat.\n\n## Technical Support Guide\n\nView the [Technical Support Guide](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/TECHNICAL_SUPPORT_GUIDE.md) to get guidance and help on troubleshooting in the Web Chat repo for more information before filing a new issue.\n\n## Speech\n\nWeb Chat supports a wide-range of speech engines for a natural chat experience with a bot. This section outlines the different engines that are supported:\n\n-  [Direct Line Speech](#integrate-with-direct-line-speech)\n-  [Cognitive Services Speech Services](#integrate-with-cognitive-services-speech-services)\n-  [Browser-provided engine or other engines](#browser-provided-engine-or-other-engines)\n\n### Integrate with Direct Line Speech\n\nDirect Line Speech is the preferred way to add speech functionality in Web Chat. Please refer to the [Direct Line Speech](https://github.com/microsoft/BotFramework-WebChat/blob/main/docs/DIRECT_LINE_SPEECH.md) documentation for details.\n\n### Integrate with Cognitive Services Speech Services\n\nYou can use Cognitive Services Speech Services to add speech functionality to Web Chat. Please refer to the [Cognitive Services Speech Services](https://github.com/microsoft/BotFramework-WebChat/blob/main/docs/SPEECH.md) documentation for details.\n\n### Browser-provided engine or other engines\n\nYou can also use any speech engines which support [W3C Web Speech API standard](https://wicg.github.io/speech-api/). Some browsers support the [Speech Recognition API](https://caniuse.com/#feat=mdn-api_speechrecognition) and the [Speech Synthesis API](https://caniuse.com/#feat=mdn-api_speechsynthesis). You can mix-and-match different engines - including Cognitive Services Speech Services - to provide best user experience.\n\n<hr />\n\n# How to test with Web Chat's latest bits\n\nWeb Chat latest bits are available on the [Web Chat daily releases page](https://github.com/microsoft/BotFramework-WebChat/releases/daily).\n\nDailies will be released after 3:00AM Pacific Standard Time when changes have been committed to the main branch.\n\n# Contributing\n\nSee our [Contributing page](https://github.com/microsoft/BotFramework-WebChat/tree/main/.github/CONTRIBUTING.md) for details on how to build the project and our repository guidelines for Pull Requests.\n\nSee our [CODE OF CONDUCT page](https://github.com/microsoft/BotFramework-WebChat/blob/main/.github/CODE_OF_CONDUCT.md) for details about the Microsoft Code of Conduct.\n\n# Reporting Security Issues\n\n[View the security documentation](https://github.com/microsoft/BotFramework-WebChat/tree/main/docs/SECURITY.md) to learn more about reporting security issues.\n"
 },
 {
  "repo": "microsoft/cookie.gulp",
  "language": "JavaScript",
  "readme_contents": "\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-linedotchart",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-linedotchart\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-linedotchart.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-linedotchart) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-linedotchart/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-linedotchart?branch=master) [![Build Status](https://dev.azure.com/customvisuals/public/_apis/build/status/Microsoft.powerbi-visuals-linedotchart)](https://dev.azure.com/customvisuals/public/_build/latest?definitionId=1)\n\n> The LineDot chart is an animated line chart with fun animated dots. Use the LineDot chart to engage your audience especially in a presentation context. The bubbles size can be dynamic based on data you provide. A counter is provided that you can use to show a running value as the chart animates. Format options are provided for Lines, Dots, and Animation.\n\n![linedotchart screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680588/Asset_79376a97-0a89-48f3-9b3d-5396b4e5808b/LineDotChartscreenshot2.png)\n# Overview\nThe LineDot chart is an animated line chart with fun animated dots.\n\nUse the LineDot chart to engage your audience when presenting data. The size of the bubbles can be customized based on data.\n\nUse the counter to show a running total as the chart animates. Format options are provided for Lines, Dots, and Animation.\n\nSee also [LineDot Chart at AppSource](https://appsource.microsoft.com/en-us/product/power-bi-visuals/WA104380766)\n"
 },
 {
  "repo": "microsoft/CameraTraps",
  "language": "Jupyter Notebook",
  "readme_contents": "# Overview\n\nThis repo contains the tools for training, running, and evaluating detectors and classifiers for images collected from motion-triggered camera traps.  The core functionality provided is:\n\n- Data parsing from frequently-used camera trap metadata formats into a common format\n- Training and evaluation of detectors, particularly our \"MegaDetector\", which does a pretty good job finding terrestrial animals in a variety of ecosystems\n- Training and evaluation of species-level classifiers for specific data sets\n- A Web-based demo that runs our models via a REST API that hosts them on a Web endpoint\n- Miscellaneous useful tools for manipulating camera trap data\n- Research experiments we're doing around camera trap data (i.e., some directories are highly experimental and you should take them with a grain of salt)\n\nClassifiers and detectors are trained using TensorFlow.\n\nThis repo is maintained by folks in the [Microsoft AI for Earth](http://aka.ms/aiforearth) program who like looking at pictures of animals.  I mean, we want to use machine learning to support conservation too, but we also really like looking at pictures of animals.\n\n# Who is using the AI for Earth camera trap tools?\n\nWe work with ecologists all over the world to help them spend less time annotating images and more time thinking about conservation.  You can read a little more about how this works on our [AI for Earth camera trap collaborations page](collaborations.md).\n\nYou can also read about what we do to support camera trap researchers in our recent [blog post](https://medium.com/microsoftazure/accelerating-biodiversity-surveys-with-azure-machine-learning-9be53f41e674).\n\nHere are a few of the organizations that have used AI for Earth camera trap tools... we're only listing organizations who (a) we know about and (b) have generously allowed us to refer to them here, so if you're using MegaDetector or other tools from this repo and would like to be added to this list, <a href=\"mailto:cameratraps@microsoft.com\">email us</a>!\n\n* Idaho Department of Fish and Game\n* San Diego Zoo Global\n* University of Washington Quantitative Ecology Lab\n* University of Idaho\n* Borderlands Research Institute at Sul Ross State University\n* Borneo Nature Foundation\n* Parks Canada\n* Australian Wildlife Conservancy\n* Lab of Dr. Bilal Habib at the Wildlife Institute of India\n* Royal Society for the Protection of Birds (RSPB)\n* Wildlife Protection Solutions\n* Island Conservation\n* Synthetaic\n* School of Natural Sciences, University of Tasmania\n* Arizona Department of Environmental Quality\n* Wildlife Research, Oregon Department of Fish and Wildlife\n* National Wildlife Refuge System, Southwest Region, US Fish and Wildlife\n* Mammal Spatial Ecology and Conservation Lab at Washington State University\n* Point No Point Treaty Council\n* SPEA (Portuguese Society for the Study of Birds)\n* Ghost Cat Analytics\n* EcoLogic Consultants Ltd.\n* Smithsonian Northern Great Plains Program\n* Federal University of Amap\u00e1, Ecology and Conservation of Amazonian Vertebrates Research Group\n* Hamaarag, The Steinhardt Museum of Natural History, Tel Aviv University\n* Czech University of Life Sciences Prague\n* Ramat Hanadiv Nature Park, Israel\n* TU Berlin, Department of Ecology\n* DC Cat Count, led by the Humane Rescue Alliance\n* Center for Biodiversity and Conservation at the American Museum of Natural History\n* Camelot\n* Graeme Shannon's Research Group at Bangor University \n* Snapshot USA\n* University of British Columbia Wildlife Coexistence Lab\n\n\n# Data\n\nThis repo does not directly host camera trap data, but we work with our collaborators to make data and annotations available whenever possible on [lila.science](http://lila.science).\n\n\n# Models\n\nThis repo does not extensively host species classification models, though we will release models when they are at a level of generality that they might be useful to other people.  But...\n\n\n## MegaDetector\n\nSpeaking of models that might be useful to other people, we have trained a one-class animal detector trained on several hundred thousand bounding boxes from a variety of ecosystems.  Lots more information &ndash; including download links &ndash; on the [MegaDetector page](megadetector.md).\n\nHere's a \"teaser\" image of what detector output looks like:\n\n![Red bounding box on fox](images/detector_example.jpg)\n\nImage credit University of Washington.\n\n\n# Contact\n\nFor questions about this repo, contact [cameratraps@microsoft.com](mailto:cameratraps@microsoft.com).\n\n\n# Contents\n\nThis repo is organized into the following folders...\n\n\n## api\n\nCode for hosting our models as an API, either for synchronous operation (e.g. for real-time inference or for our Web-based demo) or as a batch process (for large biodiversity surveys).\n\n\n## classification\n\nCode for training species classifiers on new data sets, generally trained on crops generated via an existing detector.  We'll release some classifiers soon, but more importantly, here's a [tutorial](https://github.com/microsoft/CameraTraps/blob/master/archive/classification_marcel/TUTORIAL.md) on training your own classifier using our detector and our training pipeline.\n\nOh, and here's another \"teaser image\" of what you get at the end of training a classifier:\n\n<img src=\"images/warthog_classifications.jpg\" width=\"700\">\n\n## data_management\n\nCode for:\n\n- Converting frequently-used metadata formats to [COCO Camera Traps](https://github.com/Microsoft/CameraTraps/blob/master/data_management/README.md#coco-cameratraps-format) format\n- Creating, visualizing, and  editing COCO Camera Traps .json databases\n- Generating tfrecords\n\n## demo\n\nSource for the Web-based demo of our MegaDetector model (we'll release the demo soon!).\n\n\n## detection\n\nCode for training and evaluating detectors.\n\n\n## research\n\nOngoing research projects that use this repository in one way or another; as of the time I'm editing this README, there are projects in this folder around active learning and the use of simulated environments for training data augmentation.\n\n\n## sandbox\n\nRandom things that don't fit in any other directory.  Currently contains a single file, a not-super-useful but super-duper-satisfying and mostly-successful attempt to use OCR to pull metadata out of image pixels in a fairly generic way, to handle those pesky cases when image metadata is lost.\n\n\n# Installation\n\nWe use [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) to manage our Python package dependencies. Conda is a package and environment management system. You can install a lightweight distribution of conda (Miniconda) for your OS via installers at [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html).\n\n## Initial setup\n\n### Utility and visualization scripts\n\nThe required Python packages for running utility and visualization scripts in this repo are listed in [environment.yml](environment.yml).  To set up your environment for these scripts, in your shell, navigate to the root directory of this repo and issue the following command to create a virtual environment via conda called `cameratraps` (specified in the environment file) and install the required packages:\n\n```\nconda env create --file environment.yml\n```\n\nFor unix users, you need to have gcc installed in order to compile the pip packages. If you do not already have gcc installed, run the following command before creating the conda environment:\n\n```bash\nsudo apt update\nsudo apt install build-essential\n```\n\n### Machine learning scripts\n\nScripts that execute machine learning code &ndash; specifically, scripts in the folders `api`, `detection`, and `classification` &ndash; require additional depdendencies.  In particular, the `detection/run_tf_detector*.py` scripts should use [environment-detector.yml](environment-detector.yml) to set up the environment, as follows:\n\n```\nconda env create --file environment-detector.yml\n```\n\nThis environment file allows any TensorFlow version from 1.9 to 1.15 to be installed, but you may need to adjust that version for your environment.  Specifically, if you are running on an Azure Data Science Virtual Machine (which has CUDA 10.1 as of the time I'm writing this), you may receive a CUDA error, in which case you should change the line:\n\n`- tensorflow-gpu>=1.9.0, <1.15.0`\n\n...to:\n\n`- tensorflow-gpu=1.13.1`\n\n...before creating your environment.\n\n### Troubleshooting\n\nIf you run into an error while creating either of the above environments, try updating conda to version 4.5.11 or above. Check the version of conda using `conda --version`.\n\n## Usage\n\nTo enter the conda virtual environment at your current shell, run:\n\n`conda activate cameratraps`\n\n...or, if you used the environment-detector.yml file above:\n\n`conda activate cameratraps-detector`\n\nYou should see `(cameratraps)` prepended to the command line prompt. Invoking `python` or `jupyter notebook` will now be using the interpreter and packages available in this virtual env.\n\nTo exit the virtual env, issue `conda deactivate`.\n\n## Add additional packages\n\nIf you need to use additional packages, add them to the environment file and run\n\n```bash\nconda env update --name cameratraps --file environment.yml --prune\n```\nor\n```bash\nconda env update --name cameratraps-detector --file environment-detector.yml --prune\n```\n\n## Other notes\n\nIn some scripts, we also assume that you have the [AI for Earth utilities repo](https://github.com/Microsoft/ai4eutils) (`ai4eutils`) cloned and its path appended to `PYTHONPATH`. You can append a path to `PYTHONPATH` for the current shell session by executing the following on Windows:\n\n```set PYTHONPATH=\"%PYTHONPATH%;c:\\wherever_you_put_the_ai4eutils_repo\"```\n\nYou can do this with the following on Linux:\n\n```export PYTHONPATH=\"$PYTHONPATH:/absolute/path/to/repo/ai4eutils\"```\n\nAdding this line to your `~/.bashrc` (on Linux) modifies `PYTHONPATH` permanently.\n\nWe also do our best to follow [Google's Python Style Guide](http://google.github.io/styleguide/pyguide.html), and we have adopted their `pylintrc` file, with the following differences:\n- indent code blocks with 4 spaces (instead of 2)\n\nTo lint a file, run `pylint` with the CameraTraps repo folder as the current working directory. This allows pylint to recognize the `pylintrc` file. For example,\n\n```bash\npylint classification/train_classifier.py\n```\n\n\n# Gratuitous pretty camera trap picture\n\n![Bird flying above water](images/nacti.jpg)\n\nImage credit USDA, from the [NACTI](http://lila.science/datasets/nacti) data set.\n\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nThis repository is licensed with the [MIT license](https://github.com/Microsoft/dotnet/blob/master/LICENSE).\n"
 },
 {
  "repo": "microsoft/presidio",
  "language": "Python",
  "readme_contents": "# Presidio - Data Protection and Anonymization API\n\n**Context aware, pluggable and customizable PII anonymization service for text and images.**\n\n---\n\n[![Build Status](https://dev.azure.com/csedevil/Presidio/_apis/build/status/Presidio-CI%20V2?branchName=V2)](https://dev.azure.com/csedevil/Presidio/_build/latest?definitionId=207&branchName=V2)\n[![MIT license](https://img.shields.io/badge/license-MIT-brightgreen.svg)](http://opensource.org/licenses/MIT)\n![Release](https://img.shields.io/github/release/Microsoft/presidio.svg)\n[![Pypi Downloads](https://img.shields.io/pypi/dm/presidio-analyzer.svg)](https://img.shields.io/pypi/dm/presidio-analyzer.svg)\n[![PyPI package version](https://badge.fury.io/py/presidio-analyzer.svg)](https://badge.fury.io/py/presidio-analyzer.svg)\n\n\nAnalyzer [![PyPI pyversions](https://img.shields.io/pypi/pyversions/presidio-analyzer.svg)](https://pypi.python.org/pypi/presidio-analyzer/)\n\nAnonymizer [![PyPI pyversions](https://img.shields.io/pypi/pyversions/presidio-anonymizer.svg)](https://pypi.python.org/pypi/presidio-anonymizer/)\n\nImage-Redactor [![PyPI pyversions](https://img.shields.io/pypi/pyversions/presidio-image-redactor.svg)](https://pypi.python.org/pypi/presidio-image-redactor/)\n\n## What is Presidio\n\nPresidio _(Origin from Latin praesidium \u2018protection, garrison\u2019)_ helps to ensure sensitive data is properly managed and governed. It provides fast **_identification_** and **_anonymization_** modules for private entities in text such as credit card numbers, names, locations, social security numbers, bitcoin wallets, US phone numbers, financial data and more.\n\n![Presidio demo gif](docs/assets/changing_text.gif)\n\n### Goals\n\n- Allow organizations to preserve privacy in a simpler way by democratizing de-identification technologies and introducing transparency in decisions.\n- Embrace extensibility and customizability to a specific business need.\n- Facilitate both fully automated and semi-automated PII de-identification flows on multiple platforms.\n\n### Main features\n\n1. **Predefined** or **custom PII recognizers** leveraging *Named Entity Recognition*, *regular expressions*, *rule based logic* and *checksum* with relevant context in multiple languages.\n2. Options for connecting to external PII detection models.\n3. Multiple usage options, **from Python or PySpark workloads through Docker to Kubernetes**.\n4. **Customizability** in PII identification and anonymization.\n5. Module for **redacting PII text in images**.\n\n:warning: Presidio can help identify sensitive/PII data in un/structured text. However, because Presidio is using trained ML models, there is no guarantee that Presidio will find all sensitive information. Consequently, additional systems and protections should be employed.\n\n### :notebook_with_decorative_cover: [Full documentation](https://microsoft.github.io/presidio)\n### :thought_balloon: [Try Presidio with your own data](https://aka.ms/presidio-demo) \n\n\n## Installing Presidio\n\n1. [Using pip](https://microsoft.github.io/presidio/installation/#using-pip)\n2. [Using Docker](https://microsoft.github.io/presidio/installation/#using-docker)\n3. [From source](https://microsoft.github.io/presidio/installation/#install-from-source)\n4. [Migrating from V1 to V2](./docs/presidio_V2.md)\n\n## Running Presidio\n1. [Getting started](https://microsoft.github.io/presidio/getting_started)\n2. [Setting up a development environment](https://microsoft.github.io/presidio/development)\n3. [PII anonymization in text](https://microsoft.github.io/presidio/text_anonymization)\n4. [PII anonymization in images](https://microsoft.github.io/presidio/image-redactor)\n5. [Usage samples and example deployments](https://microsoft.github.io/presidio/samples)\n\n---\n\n## Support\n\n- Before you submit an issue, please go over the [documentation](https://microsoft.github.io/presidio/). \n- For general discussions, please use the [Github repo's discussion board](https://github.com/microsoft/presidio/discussions).\n- If you have a usage question, found a bug or have a suggestion for improvement, please file a [Github issue](https://github.com/microsoft/presidio/issues).\n- For other matters, please email [presidio@microsoft.com](mailto:presidio@microsoft.com).\n\n## Contributing\n\nFor details on contributing to this repository, see the [contributing guide](CONTRIBUTING.md).\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [https://cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/playwright",
  "language": "TypeScript",
  "readme_contents": "# \ud83c\udfad Playwright\n\n[![npm version](https://img.shields.io/npm/v/playwright.svg?style=flat)](https://www.npmjs.com/package/playwright) [![Join Slack](https://img.shields.io/badge/join-slack-infomational)](https://aka.ms/playwright-slack) <!-- GEN:chromium-version-badge -->[![Chromium version](https://img.shields.io/badge/chromium-92.0.4498.0-blue.svg?logo=google-chrome)](https://www.chromium.org/Home)<!-- GEN:stop --> <!-- GEN:firefox-version-badge -->[![Firefox version](https://img.shields.io/badge/firefox-89.0b9-blue.svg?logo=mozilla-firefox)](https://www.mozilla.org/en-US/firefox/new/)<!-- GEN:stop --> <!-- GEN:webkit-version-badge -->[![WebKit version](https://img.shields.io/badge/webkit-14.2-blue.svg?logo=safari)](https://webkit.org/)<!-- GEN:stop -->\n\n## [Documentation](https://playwright.dev) | [API reference](https://playwright.dev/docs/api/class-playwright/)\n\nPlaywright is a Node.js library to automate [Chromium](https://www.chromium.org/Home), [Firefox](https://www.mozilla.org/en-US/firefox/new/) and [WebKit](https://webkit.org/) with a single API. Playwright is built to enable cross-browser web automation that is **ever-green**, **capable**, **reliable** and **fast**.\n\n|          | Linux | macOS | Windows |\n|   :---   | :---: | :---: | :---:   |\n| Chromium <!-- GEN:chromium-version -->92.0.4498.0<!-- GEN:stop --> | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| WebKit <!-- GEN:webkit-version -->14.2<!-- GEN:stop --> | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n| Firefox <!-- GEN:firefox-version -->89.0b9<!-- GEN:stop --> | :white_check_mark: | :white_check_mark: | :white_check_mark: |\n\nHeadless execution is supported for all the browsers on all platforms. Check out [system requirements](https://playwright.dev/docs/intro/#system-requirements) for details.\n\n## Usage\n\n```\nnpm i -D playwright\n```\n\nThis installs Playwright and browser binaries for Chromium, Firefox and WebKit. Once installed, you can `require` Playwright in a Node.js script and automate web browser interactions.\n\n* [Getting started](https://playwright.dev/docs/intro)\n* [Installation configuration](https://playwright.dev/docs/installation)\n* [API reference](https://playwright.dev/docs/api/class-playwright)\n\n## Capabilities\n\nPlaywright is built to automate the broad and growing set of web browser capabilities used by Single Page Apps and Progressive Web Apps.\n\n* Scenarios that span multiple page, domains and iframes\n* Auto-wait for elements to be ready before executing actions (like click, fill)\n* Intercept network activity for stubbing and mocking network requests\n* Emulate mobile devices, geolocation, permissions\n* Support for web components via shadow-piercing selectors\n* Native input events for mouse and keyboard\n* Upload and download files\n\n## Examples\n\n#### Page screenshot\n\nThis code snippet navigates to whatsmyuseragent.org in Chromium, Firefox and WebKit, and saves 3 screenshots.\n\n```js\nconst playwright = require('playwright');\n\n(async () => {\n  for (const browserType of ['chromium', 'firefox', 'webkit']) {\n    const browser = await playwright[browserType].launch();\n    const context = await browser.newContext();\n    const page = await context.newPage();\n    await page.goto('http://whatsmyuseragent.org/');\n    await page.screenshot({ path: `example-${browserType}.png` });\n    await browser.close();\n  }\n})();\n```\n\n#### Mobile and geolocation\n\nThis snippet emulates Mobile Safari on a device at a given geolocation, navigates to maps.google.com, performs action and takes a screenshot.\n\n```js\nconst { webkit, devices } = require('playwright');\nconst iPhone11 = devices['iPhone 11 Pro'];\n\n(async () => {\n  const browser = await webkit.launch();\n  const context = await browser.newContext({\n    ...iPhone11,\n    locale: 'en-US',\n    geolocation: { longitude: 12.492507, latitude: 41.889938 },\n    permissions: ['geolocation']\n  });\n  const page = await context.newPage();\n  await page.goto('https://maps.google.com');\n  await page.click('text=\"Your location\"');\n  await page.waitForRequest(/.*preview\\/pwa/);\n  await page.screenshot({ path: 'colosseum-iphone.png' });\n  await browser.close();\n})();\n```\n\n#### Evaluate in browser context\n\nThis code snippet navigates to example.com in Firefox, and executes a script in the page context.\n\n```js\nconst { firefox } = require('playwright');\n\n(async () => {\n  const browser = await firefox.launch();\n  const context = await browser.newContext();\n  const page = await context.newPage();\n  await page.goto('https://www.example.com/');\n  const dimensions = await page.evaluate(() => {\n    return {\n      width: document.documentElement.clientWidth,\n      height: document.documentElement.clientHeight,\n      deviceScaleFactor: window.devicePixelRatio\n    }\n  });\n  console.log(dimensions);\n\n  await browser.close();\n})();\n```\n\n#### Intercept network requests\n\nThis code snippet sets up request routing for a WebKit page to log all network requests.\n\n```js\nconst { webkit } = require('playwright');\n\n(async () => {\n  const browser = await webkit.launch();\n  const context = await browser.newContext();\n  const page = await context.newPage();\n\n  // Log and continue all network requests\n  page.route('**', route => {\n    console.log(route.request().url());\n    route.continue();\n  });\n\n  await page.goto('http://todomvc.com');\n  await browser.close();\n})();\n```\n\n## Resources\n\n* [Documentation](https://playwright.dev/docs/intro/)\n* [API reference](https://playwright.dev/docs/api/class-playwright/)\n* [Community showcase](https://playwright.dev/docs/showcase/)\n* [Contribution guide](CONTRIBUTING.md)\n* [Changelog](https://github.com/microsoft/playwright/releases)\n"
 },
 {
  "repo": "microsoft/language-server-protocol",
  "language": null,
  "readme_contents": "# Language Server Protocol\n\nThe Language Server Protocol is now available through its own [website](https://microsoft.github.io/language-server-protocol/). The website contains information about :\n\n* How the protocol [works](https://microsoft.github.io/language-server-protocol/overview)\n* A better readable [specification](https://microsoft.github.io/language-server-protocol/specifications/specification-current/)\n* Documents about protocol [implementations](https://microsoft.github.io/language-server-protocol/implementors/servers/).\n\n## Contributing\n\nIf you are interested in fixing issues like typos you can either file an issue or provide a pull request containing the changes to the relevant [specification file](https://github.com/microsoft/language-server-protocol/tree/gh-pages/_specifications).\n\nWhen proposing an extension to the specification, then please refer to the [How to Contribute to the Language Server Protocol](contributing.md) document.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## The Language Server Protocol\n\nSee the [Web site](https://microsoft.github.io/language-server-protocol/specifications/specification-current/)\n\n## License\n\n[Creative Commons Attribution / MIT](License.txt)\n"
 },
 {
  "repo": "microsoft/electionguard-ballot-box",
  "language": "TypeScript",
  "readme_contents": "\r\n![Microsoft Defending Democracy Program: ElectionGuard](images/electionguard-banner.svg)\r\n\r\n# ElectionGuard Ballot Box\r\n\r\n![build](https://github.com/microsoft/electionguard-ballot-box/workflows/Package/badge.svg)\r\n[![license](https://img.shields.io/github/license/microsoft/electionguard-ballot-box)](LICENSE)\r\n\r\n---------------------\r\n\r\n### Note: This repository has been deprecated & transitioned\r\n\r\nAs of 06/15/2020, this repository is no longer being actively maintained. ElectionGuard development has transitioned to the [ElectionGuard-Python](https://github.com/microsoft/electionguard-python) Repo.\r\n\r\nThis repository will remain open sourced and available, but will no longer be actively maintained or updated. Development is underway for a replacement and will be posted on our [Main repository Page](https://github.com/microsoft/ElectionGuard). This URL will become archived and read-only in Summer of 2020.\r\n\r\n--------------------------\r\n\r\nThe ElectionGuard Ballot Box is a fully functional\r\nimplementation built in ReactJS. It is a counter for the ballot box to count and store cast or spoil ballots.\r\nThis reference implementation is meant to demonstrate a possible use case of the ElectionGuard SDK.\r\n\r\n## Contributing\r\n\r\nHelp defend democracy and [contribute to the project](CONTRIBUTING).\r\n\r\n<!-- \r\nGuidelines on README format: https://review.docs.microsoft.com/help/onboard/admin/samples/concepts/readme-template?branch=master\r\n\r\nGuidance on onboarding samples to docs.microsoft.com/samples: https://review.docs.microsoft.com/help/onboard/admin/samples/process/onboarding?branch=master\r\n\r\nTaxonomies for products and languages: https://review.docs.microsoft.com/new-hope/information-architecture/metadata/taxonomies?branch=master\r\n-->\r\n"
 },
 {
  "repo": "microsoft/TypeScript",
  "language": "TypeScript",
  "readme_contents": "\r\n# TypeScript\r\n\r\n[![GitHub Actions CI](https://github.com/microsoft/TypeScript/workflows/CI/badge.svg)](https://github.com/microsoft/TypeScript/actions?query=workflow%3ACI)\r\n[![Devops Build Status](https://dev.azure.com/typescript/TypeScript/_apis/build/status/Typescript/node10)](https://dev.azure.com/typescript/TypeScript/_build?definitionId=7)\r\n[![npm version](https://badge.fury.io/js/typescript.svg)](https://www.npmjs.com/package/typescript)\r\n[![Downloads](https://img.shields.io/npm/dm/typescript.svg)](https://www.npmjs.com/package/typescript)\r\n\r\n[TypeScript](https://www.typescriptlang.org/) is a language for application-scale JavaScript. TypeScript adds optional types to JavaScript that support tools for large-scale JavaScript applications for any browser, for any host, on any OS. TypeScript compiles to readable, standards-based JavaScript. Try it out at the [playground](https://www.typescriptlang.org/play/), and stay up to date via [our blog](https://blogs.msdn.microsoft.com/typescript) and [Twitter account](https://twitter.com/typescript).\r\n\r\nFind others who are using TypeScript at [our community page](https://www.typescriptlang.org/community/).\r\n\r\n## Installing\r\n\r\nFor the latest stable version:\r\n\r\n```bash\r\nnpm install -g typescript\r\n```\r\n\r\nFor our nightly builds:\r\n\r\n```bash\r\nnpm install -g typescript@next\r\n```\r\n\r\n## Contribute\r\n\r\nThere are many ways to [contribute](https://github.com/microsoft/TypeScript/blob/master/CONTRIBUTING.md) to TypeScript.\r\n* [Submit bugs](https://github.com/microsoft/TypeScript/issues) and help us verify fixes as they are checked in.\r\n* Review the [source code changes](https://github.com/microsoft/TypeScript/pulls).\r\n* Engage with other TypeScript users and developers on [StackOverflow](https://stackoverflow.com/questions/tagged/typescript).\r\n* Help each other in the [TypeScript Community Discord](https://discord.gg/typescript).\r\n* Join the [#typescript](https://twitter.com/search?q=%23TypeScript) discussion on Twitter.\r\n* [Contribute bug fixes](https://github.com/microsoft/TypeScript/blob/master/CONTRIBUTING.md).\r\n* Read the archived language specification ([docx](https://github.com/microsoft/TypeScript/blob/master/doc/TypeScript%20Language%20Specification%20-%20ARCHIVED.docx?raw=true),\r\n [pdf](https://github.com/microsoft/TypeScript/blob/master/doc/TypeScript%20Language%20Specification%20-%20ARCHIVED.pdf?raw=true), [md](https://github.com/microsoft/TypeScript/blob/master/doc/spec-ARCHIVED.md)).\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see\r\nthe [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)\r\nwith any additional questions or comments.\r\n\r\n## Documentation\r\n\r\n*  [TypeScript in 5 minutes](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html)\r\n*  [Programming handbook](https://www.typescriptlang.org/docs/handbook/intro.html)\r\n*  [Homepage](https://www.typescriptlang.org/)\r\n\r\n## Building\r\n\r\nIn order to build the TypeScript compiler, ensure that you have [Git](https://git-scm.com/downloads) and [Node.js](https://nodejs.org/) installed.\r\n\r\nClone a copy of the repo:\r\n\r\n```bash\r\ngit clone https://github.com/microsoft/TypeScript.git\r\n```\r\n\r\nChange to the TypeScript directory:\r\n\r\n```bash\r\ncd TypeScript\r\n```\r\n\r\nInstall [Gulp](https://gulpjs.com/) tools and dev dependencies:\r\n\r\n```bash\r\nnpm install -g gulp\r\nnpm ci\r\n```\r\n\r\nUse one of the following to build and test:\r\n\r\n```\r\ngulp local             # Build the compiler into built/local.\r\ngulp clean             # Delete the built compiler.\r\ngulp LKG               # Replace the last known good with the built one.\r\n                       # Bootstrapping step to be executed when the built compiler reaches a stable state.\r\ngulp tests             # Build the test infrastructure using the built compiler.\r\ngulp runtests          # Run tests using the built compiler and test infrastructure.\r\n                       # You can override the specific suite runner used or specify a test for this command.\r\n                       # Use --tests=<testPath> for a specific test and/or --runner=<runnerName> for a specific suite.\r\n                       # Valid runners include conformance, compiler, fourslash, project, user, and docker\r\n                       # The user and docker runners are extended test suite runners - the user runner\r\n                       # works on disk in the tests/cases/user directory, while the docker runner works in containers.\r\n                       # You'll need to have the docker executable in your system path for the docker runner to work.\r\ngulp runtests-parallel # Like runtests, but split across multiple threads. Uses a number of threads equal to the system\r\n                       # core count by default. Use --workers=<number> to adjust this.\r\ngulp baseline-accept   # This replaces the baseline test results with the results obtained from gulp runtests.\r\ngulp lint              # Runs eslint on the TypeScript source.\r\ngulp help              # List the above commands.\r\n```\r\n\r\n\r\n## Usage\r\n\r\n```bash\r\nnode built/local/tsc.js hello.ts\r\n```\r\n\r\n\r\n## Roadmap\r\n\r\nFor details on our planned features and future direction please refer to our [roadmap](https://github.com/microsoft/TypeScript/wiki/Roadmap).\r\n"
 },
 {
  "repo": "microsoft/BotBuilder-V3",
  "language": "C#",
  "readme_contents": "# V3 Deprecation Notification\n\nMicrosoft Bot Framework SDK V4 was released in September 2018, and since then we have shipped a few dot-release improvements. As announced previously, the V3  SDK is being retired with final long-term support ending on December 31st, 2019.\nAccordingly, there will be no more development in this repo. **Existing V3 bot workloads will continue to run without interruption. We have no plans to disrupt any running workloads**.\n\nWe highly recommend that you start migrating your V3 bots to V4. In order to support this migration we have produced migration documentation and will provide extended support for migration initiatives (via standard channels such as Stack Overflow and Microsoft Customer Support).\n\nFor more information please refer to the following references:\n* Migration Documentation: https://aka.ms/bf-migration-overview\n* End of lifetime support announcement: https://aka.ms/bfmigfaq\n* Primary V4 Repositories to develop Bot Framework bots\n  * [Botbuilder for dotnet](https://github.com/microsoft/botbuilder-dotnet)\n  * [Botbuilder for JS](https://github.com/microsoft/botbuilder-js) \n* QnA Maker Libraries were replaced with the following V4 libraries:\n  * [Libraries for dotnet](https://github.com/Microsoft/botbuilder-dotnet/tree/master/libraries/Microsoft.Bot.Builder.AI.QnA)\n  * [Libraries for JS](https://github.com/Microsoft/botbuilder-js/blob/master/libraries/botbuilder-ai/src/qnaMaker.ts)\n* Azure Libraries were replaced with the following V4 libraries:\n  * [Botbuilder for JS Azure](https://github.com/Microsoft/botbuilder-js/tree/master/libraries/botbuilder-azure)\n  * [Botbuilder for dotnet Azure](https://github.com/Microsoft/botbuilder-dotnet/tree/master/libraries/Microsoft.Bot.Builder.Azure)\n\n\n# Bot Builder SDK \n\nIf you are new to the Bot Builder SDK, we strongly encourage you to build your bot using the [v4 SDK](https://github.com/Microsoft/botbuilder).  \n\nThis repo contains version 3.\n\nThe Bot Builder SDK enables you to build bots that support different types of interactions with users. You can design conversations in your bot to be freeform. Your bot can also have more guided interactions where it provides the user choices or actions. The conversation can use simple text or more complex rich cards that contain text, images, and action buttons. You can add natural language interactions and questions and answers, which let your users interact with your bots in a natural way.\n\n![Bot Framework](https://botframework.blob.core.windows.net/web/images/bot-framework.png)\n\nThe Bot Builder includes a set of [command line tools](https://github.com/microsoft/botbuilder-tools) to streamline end-to-end conversation centric development experience, and an [emulator](https://github.com/microsoft/botframework-emulator) for debugging your bot locally or in the cloud. \n\nYou can create a bot with Bot Builder v3 SDK using your favorite language: \n- [.NET](https://docs.microsoft.com/en-us/azure/bot-service/?view=azure-bot-service-3.0)\n- [JavaScript](https://docs.microsoft.com/en-us/azure/bot-service/?view=azure-bot-service-3.0)\n\n## Documentation\nVisit azure.com for the primary [Azure Bot Service documentation page](https://docs.microsoft.com/en-us/azure/bot-service/?view=azure-bot-service-3.0) to learn about building bots using Bot Builder. There is additional documentation on the SDK, oriented towards contributors. The v3 SDK currently supports two programing language: \n- [.NET](https://github.com/Microsoft/BotBuilder-v3/tree/master/CSharp)\n- [JavaScript](https://github.com/Microsoft/BotBuilder-V3/tree/master/Node)\n\n## Samples\nBot builder SDK v3 includes samples for all supported languages:\n- [.NET](https://github.com/Microsoft/BotBuilder-Samples/tree/v3-sdk-samples/CSharp)\n- [JavaScript](https://github.com/Microsoft/BotBuilder-Samples/tree/v3-sdk-samples/Node)\n\n## Questions and Help \nIf you have questions about Bot Builder SDK v3 or using Azure Bot Service, we encourage you to reach out to the community and Azure Bot Service dev team for help.\n- For questions which fit the Stack Overflow format (\"how does this work?\"), we monitor the both [Azure-bot-service](https://stackoverflow.com/questions/tagged/azure-bot-service) and [bot framework](https://stackoverflow.com/questions/tagged/botframework) tags (search [both](https://stackoverflow.com/questions/tagged/azure-bot-service+or+botframework))\n- You can also tweet/follow [@msbotframework](https://twitter.com/msbotframework) \n\nWhile we do our best to help out on a timely basis, we don't have any promise around the above resources. If you need an SLA on support from us, it's recommended you invest in an [Azure Support plan](https://azure.microsoft.com/en-us/support/options/).\n\n## Issues and feature requests \nWe track functional issues and features asks for and Bot Builder and Azure Bot Service in a variety of locations. If you have found an issue or have a feature request, please submit an issue to the below repositories.\n\n|Item|Description|Link|\n|----|-----|-----|\n|SDK v3 (.NET and JS)| core bot runtime, abstractions, prompts, dialogs, FormFlow, etc. | [File an issue](https://github.com/Microsoft/BotBuilder-V3/issues) |\n|Documentation | Docs for Bot Builder and Azure Bot Service | [File an issue](https://github.com/Microsoft/BotBuilder-V3/issues)|\n|CLI tools| MSBot, chatdown, ludown, LUIS, LUISGen, QnA Maker, dispatch  | [File an issue](https://github.com/microsoft/botbuilder-tools/issues)|\n|Emulator| view transcripts, connect to services, debug your bot | [File an issue](https://github.com/Microsoft/BotFramework-Emulator/issues)| \n\n## Helpful links\n### GitHub repositories \n- [SDK v3 (.NET and node)](https://github.com/Microsoft/BotBuilder-V3/)\n- [SDK v4 - .NET](https://github.com/Microsoft/botbuilder-dotnet)\n- [SDK v4 - JavaScript](https://github.com/Microsoft/botbuilder-js)\n- [SDK v4 - Python](https://github.com/Microsoft/botbuilder-python)\n- [SDK v4 - Java](https://github.com/Microsoft/botbuilder-java)\n- [Bot Builder tools](https://github.com/Microsoft/botbuilder-tools)\n- [Bot Builder Emulator](https://github.com/Microsoft/BotFramework-Emulator) \n\n### Documentation \n- [SDK v3](https://docs.microsoft.com/en-us/azure/bot-service/?view=azure-bot-service-3.0)\n- [SDK v4](https://docs.microsoft.com/en-us/azure/bot-service/?view=azure-bot-service-4.0)\n\n## Adding intelligence to your bot\nYour bot can provide a great conversational experience without using any Azure Cognitive Services. You can increase your customers' delight with adding a more natural interaction using one or multiple Azure Cognitive Services.  The following are common services integrated to bots: \n- [LUIS](https://www.luis.ai)\n- [QnA Maker](https://www.qnamaker.ai/)\n- [Speech](https://azure.microsoft.com/services/cognitive-services/directory/speech/)\n- [Personality Chat](https://github.com/Microsoft/BotBuilder-PersonalityChat) - Handles Small-Talk/Chitchat for any bot, in line with a distinct personality.\n- all [Azure Cognitive Services](https://azure.microsoft.com/services/cognitive-services/)\n\nGet started quickly with our samples:\n\n* Bot Builder samples [GitHub repo](https://github.com/Microsoft/BotBuilder-Samples)\n* More samples are available within the SDK [C#](https://github.com/Microsoft/BotBuilder/tree/master/CSharp/Samples), [Node.js](https://github.com/Microsoft/BotBuilder/tree/master/Node/examples)\n\nJoin the conversation on **[Gitter](https://gitter.im/Microsoft/BotBuilder)**.\n\nSee all the support options **[here](https://docs.microsoft.com/en-us/bot-framework/resources-support)**.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/vscode-java-dependency",
  "language": "TypeScript",
  "readme_contents": "# Project Manager for Java\n\n> Manage Java projects in Visual Studio Code\n\n[![GitHub Actions](https://img.shields.io/github/workflow/status/microsoft/vscode-java-dependency/CI/master?style=flat-square)](https://github.com/microsoft/vscode-java-dependency/actions?query=workflow%3ACI+branch%3Amaster)\n\n## Overview\n\nA lightweight extension to provide additional Java project explorer features. It works with [Language Support for Java by Red Hat](https://marketplace.visualstudio.com/items?itemName=redhat.java) to provide the following features:\n\n* Project View\n\n![project-view](https://raw.githubusercontent.com/Microsoft/vscode-java-dependency/master/images/project-explorer.png)\n\n* Create Java Projects\n\n![create project](https://raw.githubusercontent.com/Microsoft/vscode-java-dependency/master/images/create-project.png)\n\n* Export Jar\n> Note: For Spring Boot projects, please use the build tool to build the executable jar, for example: `mvn package`.\n\n![export jar](https://raw.githubusercontent.com/Microsoft/vscode-java-dependency/master/images/export-jar.png)\n\n## Requirements\n\n- JDK (version 11 or later)\n- VS Code (version 1.44.0 or later)\n- [Language Support for Java by Red Hat](https://marketplace.visualstudio.com/items?itemName=redhat.java) (version 0.32.0 or later)\n\n\n## Settings\n\n| Setting Name | Description | Default Value |\n|---|---|---|\n| `java.dependency.showMembers` | Specify whether to show the members in the Java Projects explorer. | `false` |\n| `java.dependency.syncWithFolderExplorer` | Specify whether to sync the folder with Java Projects explorer when browsing files.  | `true` |\n| `java.dependency.autoRefresh` | Specify whether to automatically sync the change from editor to the Java Projects explorer. | `true` |\n| `java.dependency.refreshDelay` | The delay time (ms) the auto refresh is invoked when changes are detected. | `2000ms` |\n| `java.dependency.packagePresentation` | Specify how to display the package. Supported values are: `flat`, `hierarchical`.| `flat` |\n| `java.project.exportJar.targetPath` | The output path of export jar. When this setting is **empty** or equals `askUser`, a file explorer will pop up to let the user select the output location.| `${workspaceFolder}/${workspaceFolderBasename}.jar` |\n\n## Contribution\n\n### Build\n* Prerequirement\n    - Node.js\n    - Java SDK 11 or above\n\n* Go to root folder:\n```\nnpm install -g gulp\nnpm install\ngulp build_server\n```\n\n## Telemetry\nVS Code collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://go.microsoft.com/fwlink/?LinkID=528096&clcid=0x409) to learn more. If you don't wish to send usage data to Microsoft, you can set the `telemetry.enableTelemetry` setting to `false`. Learn more in our [FAQ](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting).\n\n\n---\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/SmartKG",
  "language": "C#",
  "readme_contents": "# Contributing  \r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n\r\n# Usage\r\n\r\nSmartKG\u662f\u4e00\u6b3e\u8f7b\u91cf\u7ea7\u77e5\u8bc6\u56fe\u8c31\u53ef\u89c6\u5316+\u667a\u80fd\u5bf9\u8bdd\u6846\u67b6\u3002\u5b83\u80fd\u591f\u6839\u636e\u7528\u6237\u8f93\u5165\u7684\u5b9e\u4f53\u548c\u5173\u7cfb\u6570\u636e\u81ea\u52a8\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u63d0\u4f9b\u56fe\u8c31\u53ef\u89c6\u5316\u53ca\u57fa\u4e8e\u56fe\u8c31\u7684\u667a\u80fd\u5bf9\u8bdd\u673a\u5668\u4eba\u3002\r\n\r\n## 0. \u66f4\u52a0\u8be6\u7ec6\u7684\u5b89\u88c5\u3001\u7f16\u8bd1\u548c\u4f7f\u7528\u65b9\u6cd5\u8bf7\u89c1\uff1ahttps://github.com/microsoft/SmartKG/blob/master/SmartKG_Spec.pdf\r\n\r\n## 1. \u4e0b\u8f7d SmartKG\r\n\r\n### 1.1 \u4e0b\u8f7d\u5b89\u88c5\u4e0b\u5217\u8f6f\u4ef6\uff1a \r\n\r\n\t(1) git: https://gitforwindows.org/\r\n\t(2) .NET Core 2.1 \u8fd0\u884c\u65f6\u73af\u5883\t\r\n\t(3) Node.JS: https://nodejs.org/zh-cn/download/ (\u63a8\u8350 14.15.4)\r\n\t(4) \u5982\u679c\u8981\u6539\u5199\u6216\u91cd\u65b0\u7f16\u8bd1\u6e90\u4ee3\u7801\uff0c\u8fd8\u9700\u8981\u5b89\u88c5 Visual Studio 2019: https://visualstudio.microsoft.com/zh-hans/downloads/ \r\n\r\n### 1.2 Clone Repositry\r\n\r\n\t(1) \u8fdb\u5165 ${SourceCode_Base_Path}\r\n\t(2) \u8fd0\u884c\uff1a\r\n\t\tgit clone https://github.com/microsoft/SmartKG\r\n\r\n### 1.3 \u76ee\u5f55\u7ed3\u6784\r\n\r\n\t\u5728\u76ee\u5f55dockers\u91cc\uff0c\u662f\u5df2\u7ecf\u7f16\u8bd1\u597d\u524d\u540e\u7aef\u670d\u52a1\u7684\u4e8c\u8fdb\u5236\u7801\u3001\u914d\u7f6e\u6587\u4ef6\uff0c\u4ee5\u53ca\u5bf9\u5e94\u7684docker image\u3002\r\n\r\n\t\u5728\u76ee\u5f55Resources\u91cc\uff0c\u6709\u7528\u6237\u4e0a\u4f20\u6570\u636e\u7684\u6a21\u677f\u548c\u7528\u6765\u505a\u6d4b\u8bd5\u7684\u56fe\u8c31\u6570\u636e\u3002\u5176\u4e2d\uff0ctemplate\u5b50\u76ee\u5f55\u4e2d\u662f\u6a21\u677f\uff0c\u7528\u6237\u5982\u679c\u8981\u521b\u5efa\u81ea\u5df1\u7684\u77e5\u8bc6\u56fe\u8c31\uff0c\u5c31\u9700\u8981\u6309\u7167\u6a21\u677f\u7684\u683c\u5f0f\u8981\u6c42\uff0c\u586b\u5165\u76f8\u5e94\u5b9e\u4f53\u548c\u5b9e\u4f53\u5173\u7cfb\u3002Input\u5b50\u76ee\u5f55\u5185\u6709\u5305\u62ec\u897f\u6e38\u8bb0\u3001\u7ea2\u697c\u68a6\u3001\u4e2d\u5b66\u7269\u7406\u8bfe\u4ee5\u53caCOVID19\u7b49\u6570\u636e\u3002\r\n\r\n\t\u5728\u76ee\u5f55SmartKGLocalBase\u91cc\uff0c\u662fSmartKG\u540e\u7aef\u670d\u52a1\u4f1a\u8c03\u7528\u7684\u4e00\u4e9bPython\u6587\u4ef6\u548c\u7528\u4e8e\u5b58\u50a8\u8fd0\u884c\u65f6\u6570\u636e\u7684\u672c\u5730\u6587\u4ef6\u7684\u76ee\u5f55\u3002\r\n\r\n\t\u5728\u76ee\u5f55SmartKGUI\u4e0b\u9762\uff0c\u662fSmartKG UI\u7684\u6e90\u4ee3\u7801\u3002\u662f\u57fa\u4e8eNode.js, \u7528JavaScript\u5f00\u53d1\u7684\u3002\r\n\r\n\t\u5728\u76ee\u5f55src\u4e0b\u9762\uff0c\u662fSmartKG\u540e\u7aef\u670d\u52a1\u7684\u6e90\u4ee3\u7801\u3002\u8fd9\u90e8\u5206\u6e90\u4ee3\u7801\u662f\u57fa\u4e8eAsp.NET \u6846\u67b6\uff0c\u7528C# \u5f00\u53d1\u7684\u3002\r\n\r\n## 2. \u8fd0\u884cSmartKG\r\n\r\n### 2.1 Windows \u4e0a\u8fd0\u884c SmartKG\r\n\r\n\t\r\n\t(1) \u5728Windows\u73af\u5883\u91cc\u542f\u52a8 SmartKG\uff0c\u9996\u5148\u5e94\u8be5\u65b0\u5efa\u4e00\u4e2a\u76ee\u5f55\uff0c\u4f8b\u5982\uff0c\u6211\u4eec\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a temp \u7684\u76ee\u5f55\u3002\u7136\u540e\uff0c\u4ece\u672c\u5730 Repo \u4e2ddockers\u76ee\u5f55\u5185\u7684smartkg\u5b50\u76ee\u5f55\u4e2d\uff0c\u5c06\u4e24\u4e2azip\u6587\u4ef6\u548clocal_config\u6587\u4ef6\u5939\u590d\u5236\u5230temp\u6587\u4ef6\u5939\u4e2d\u3002\u8fd8\u9700\u8981\u4ecedockers\u76ee\u5f55\u7684ui \u5b50\u76ee\u5f55\u4e2d\uff0c\u5c06\u552f\u4e00\u4e00\u4e2azip\u6587\u4ef6\u548clocal_config\u6587\u4ef6\u5939\u590d\u5236\u5230temp\u6587\u4ef6\u5939\u4e2d\u3002\r\n\r\n\t(2) \u628atemp\u76ee\u5f55\u4e2d\u7684\u4e09\u4e2a\u538b\u7f29\u6587\u4ef6\u76f4\u63a5\u5c31\u5730\u89e3\u538b\u7f29\uff08Extraction Here\uff09\u3002\r\n\r\n\t(3) \u5e76\u5c06temp/local_config\u4e2d\u7684config.js\u79fb\u52a8\u5230\u89e3\u538b\u7f29\u540e\u7684 temp/smartkgui/public\u4e2d\u3002\r\n\r\n\t(4) \u5c06local_confing\u7684appsettings.File.json\u6587\u4ef6\u590d\u5236\u4e00\u4efd\uff0c\u5e76\u6539\u540d\u4e3aappsettings.json\uff0c\u79fb\u52a8\u5230temp/smartkg\u4e2d\u3002\r\n\r\n\t(5) \u3010\u542f\u52a8\u540e\u7aef\u3011\r\n\t    \u547d\u4ee4\u884c\u8fdb\u5165 temp/smartkg\uff0c\u8fd0\u884c\u547d\u4ee4\uff1adotnet SmartKG.KGBot.dll\r\n\t    \u6b64\u547d\u4ee4\u7528\u4e8e\u542f\u52a8 SmartKG \u540e\u7aef\u3002\u542f\u52a8\u540e\uff0c\u4f1a\u751f\u6210\u4e00\u4e2aNow listening on\u5730\u5740\uff0c\u6211\u4eec\u76f4\u63a5\u8bbf\u95ee\u5730\u5740\u5c31\u53ef\u4ee5\u3002\u5728\u6d4f\u89c8\u5668\u4e2d\u8f93\u5165\u5730\u5740 http://localhost:5000/swagger/index.html\uff0c\u53ef\u4ee5\u8bbf\u95ee\u540e\uff0c\u8bf4\u660e\u540e\u53f0\u542f\u52a8\u6210\u529f\u4e86\u3002\r\n\r\n\t    *\u6ce8\u610f\uff1a\u540e\u7aef\u542f\u52a8\u6210\u529f\u540e\u4e0d\u8981\u5173\u95ed\uff0c\u5728\u4f7f\u7528SmartKG\u7684\u6574\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u524d\u540e\u7aef\u90fd\u8981\u4fdd\u6301\u6253\u5f00\u72b6\u6001\u3002*\r\n\r\n\t(6) \u3010\u542f\u52a8\u524d\u7aef\u3011\r\n\t    \u8fdb\u5165temp/smartkgui\u76ee\u5f55\u4e0b\uff0c\u8f93\u5165\u547d\u4ee4\uff1a\r\n\t\tnpm i\r\n\t    \u8fd9\u4e2a\u547d\u4ee4\u53ea\u9700\u8981\u7b2c\u4e00\u6b21\u4f7f\u7528\u65f6\u8fd0\u884c\uff0c\u5982\u679c\u5df2\u7ecf\u8fd0\u884c\u8fc7\uff0c\u5c31\u53ef\u4ee5\u8df3\u8fc7\u4e86\u3002\r\n\r\n\t    \u6b64\u547d\u4ee4\u8fd0\u884c\u6210\u529f\u540e\uff0c\u518d\u8f93\u5165\u547d\u4ee4\uff1a\r\n\t\tnpm run serve\r\n\r\n\t    \u8fd0\u884c\u6210\u529f\u540e\uff0c\u4f1a\u7ed9\u4e00\u4e2a\u8bbf\u95ee\u5730\u5740\uff0c\u4f8b\u5982\uff1ahttp://localhost:8080/\r\n            \u7528\u8fd9\u4e2a\u5730\u5740\u5c31\u53ef\u4ee5\u76f4\u63a5\u5728\u6d4f\u89c8\u5668\u4e2d\u8bbf\u95ee SmartKG \u7684\u4e3b\u754c\u9762\u4e86\uff0c\u8fd9\u4e2a\u5730\u5740\u52a0\u4e0a \"/upload\" \u662f SmartKG \u7684\u4e0a\u4f20\u9875\u9762\u3002\r\n\r\n\r\n### 2.2 Linux \u4e0a\u8fd0\u884c SmartKG\r\n\r\n\t(0) \u5728Linux\u73af\u5883\u90e8\u7f72\u524d\uff0c\u9700\u8981\u63d0\u524d\u5b89\u88c5\u597d docker \u548c docker-compose\u3002\r\n\r\n\t(1) \u6253\u5f00 Repo \u4e2d\u7684 dockers \u76ee\u5f55\uff0c\u5c06\u91cc\u9762\u7684 smartkg_services \u76ee\u5f55\u6574\u4f53\u538b\u7f29\uff0c\u5e76\u62f7\u8d1d\u5230Linux\u673a\u5668\u4e0a\uff0c\u4e00\u822c\u653e\u5728\u7528\u6237\u76ee\u5f55\u4e0b\u3002\r\n\r\n\t(2) \u5728 Linux \u7cfb\u7edf\u8fdb\u5165\u7528\u6237\u76ee\u5f55\uff0c\u5e76\u89e3\u538b\u7f29 smartkg_services.zip\u3002\r\n\t\r\n\t(3) \u8fdb\u5165 smartkg_services/ \u76ee\u5f55\uff0c\u8fd0\u884c\u4e0b\u5217\u547d\u4ee4\u542f\u52a8 SmartKG docker-compose OneBox:\r\n\r\n\t\t1) sudo docker-compose build --build-arg DOCKER_HOST=${docker_host_ip}\r\n\t\t2) sudo docker-compose up\r\n\r\n\t     \u8bbf\u95ee\u540e\u7aef\uff1ahttp://${docker_host_ip}:8082/swagger/index.html \u80fd\u591f\u83b7\u5f97 API \u5217\u8868\r\n\r\n             \u8bbf\u95ee\u524d\u7aef\uff1ahttp://${docker_host_ip}:8083 \u4e3b\u9875\u9762\r\n                       http://${docker_host_ip}:8083/upload \u4e0a\u4f20\u9875\u9762\r\n\r\n## 3. \u751f\u6210\u81ea\u5df1\u7684\u56fe\u8c31\r\n\r\n### 3.1 \u586b\u5199\u6a21\u677f\r\n\r\n\t(1) \u6a21\u677f\u4f4d\u4e8e ${SourceCode_Base_Path}/SmartKG/Resources/_Template/SmartKG_KGDesc_Template.xlsx\r\n\t(2) \u6a21\u677f\u5206\u4e3a\u4e24\u9875\uff1a\u9876\u70b9\u9875\u548c\u8fb9\u9875\u3002\u524d\u8005\u4e3a\u56fe\u8c31\u4e2d\u7684\u5b9e\u4f53\uff0c\u540e\u8005\u4e3a\u5b9e\u4f53\u95f4\u7684\u5173\u7cfb\u3002\u6839\u636e\u6a21\u677f\u6837\u4f8b\u586b\u5199\u4f60\u81ea\u5df1\u7684\u9876\u70b9\u548c\u8fb9\u6570\u636e\u3002\t\r\n\t(3) \u505a\u6d4b\u8bd5\uff0c\u5efa\u8bae\u4f7f\u7528 ${SourceCode_Base_Path}/SmartKG/Resources/Data/Excel/input/XYJ/SmartKG_Xiyouji_relations_new.xlsx\r\n\r\n### 3.2 \u5c06\u586b\u5199\u597d\u7684 excel \u6587\u4ef6\u901a\u8fc7 SmartKG \u7684\u524d\u7aef upload \u9875\u9762\u4e0a\u4f20\r\n\r\n## 4. \u7f16\u8bd1 SmartKG\r\n\r\n### 4.1 \u7528 Visual Studio 2019 \u7f16\u8bd1 SmartKG\r\n\r\n\t\u56de\u5230Repo\u76ee\u5f55\uff0c\u8fdb\u5165src\u6587\u4ef6\u5939\uff0c\u542f\u52a8SmartKG.sln\u3002\r\n\t\u8fdb\u5165\u5230VS\u540e\uff0c\u70b9\u51fbBuild\u7684Bulid Solution\uff0c\u7f16\u8bd1\u6e90\u4ee3\u7801\u3002\r\n\r\n### 4.2 Publish SmartKG\r\n\r\n\t\u5728 Visual Studio \u4e2d\u6253\u5f00 SmartKG solution \u540e\uff0c\u53f3\u952e\u70b9\u51fb SmartKG.KGBot project\uff0c\u9009\u62e9\u70b9\u51fb Publish\uff0c\u63a5\u7740\u70b9\u51fb Folder\uff0c\u4ee5\u53ca Next\u3002\r\n\t\r\n\t\u914d\u7f6e Publish \u9009\u9879\uff1a\r\n\r\n\t\t\u914d\u7f6e\uff1aRelease\r\n\t\t\u76ee\u6807\u6846\u67b6\uff1anetcoreapp2.1.16\r\n\t\t\u76ee\u6807\u8fd0\u884c\u65f6\uff1a\u53ef\u79fb\u690d\u7684\r\n\r\n\t\u4fdd\u5b58\u8bbe\u7f6e\u540e\u76f4\u63a5 Publish\uff01\r\n\r\n\r\n\r\n"
 },
 {
  "repo": "microsoft/electionguard-ballot-marking-device",
  "language": "TypeScript",
  "readme_contents": "![Microsoft Defending Democracy Program: ElectionGuard](images/electionguard-banner.svg)\n\n# \ud83d\uddf3 ElectionGuard Ballot Marking Device \n[![license](https://img.shields.io/github/license/microsoft/electionguard-admin-device)](License)\n\nThe ElectionGuard Reference Ballot Marking Device (BMD) is a fully functional\nimplementation of a BMD built in ReactJS. It uses the\n[Gamepad API](https://developer.mozilla.org/en-US/docs/Web/API/Gamepad_API) to\nsupport a physically-connected\n[Xbox Adaptive Controller](https://www.xbox.com/en-US/xbox-one/accessories/controllers/xbox-adaptive-controller)\nfor navigating ballots with the A/B buttons, D-pad, or other devices plugged\ninto the XAC's connection ports.\n\nThe BMD was designed under the supervision of the\n[Center for Civic Design](https://civicdesign.org) as an update of the\n[Anywhere Ballot](https://civicdesign.org/projects/anywhere-ballot/) and built\nby the team at [VotingWorks](https://voting.works). It runs locally in a web\nbrowser (Chrome or Edge Beta). A sample set of ballots (in json format) is\navailable in both the /public/data/ and /src/data directories that showcases a\nvariety of contests and referenda use cases.\n\nBy default, when a ballot is printed, the BMD also generates a static tracking\nID. End-to-end verifiable elections create tracking IDs generated when the\nballot is encrypted. It's used by voters to check that their vote was included\nin the final tally when all the artifacts of an end-to-end verifiable election\nare published. When you have built working encryption capability (using the\n[C Implementation](https://github.com/microsoft/ElectionGuard-SDK-C-Implementation)),\nthe election.json configuration file can be modified to retrieve the tracking ID\nby updating\n[this code block](https://github.com/microsoft/ElectionGuard-SDK-Ballot-Marking-Device-Reference-Implementation/blob/edee95d90fc5a4ce17a6cd9d537f9200b189e05d/src/endToEnd.ts#L14).\n\n## Install and Run App Locally\n\nThis assumes you have `git` and `yarn` installed.\n\n1. Clone the repo:\n\n   ```\n   git clone git@github.com:microsoft/ElectionGuard-SDK-Ballot-Marking-Device-Reference-Implementation.git\n   ```\n\n1. Navigate to the top level of the cloned directory\n\n   ```\n   cd ElectionGuard-SDK-Ballot-Marking-Device-Reference-Implementation\n   ```\n\n1. Install dependencies:\n\n   ```\n   yarn install\n   ```\n\n1. Run the app in your local browser:\n\n   ```\n   yarn start\n   ```\n\n## Local Development Scripts\n\n- `yarn install` - Install the dependencies.\n- `yarn start` - Run the app locally.\n- `yarn test`- Run tests in interactive mode.\n- `yarn test:coverage` - Run all tests and update test coverage report.\n\nSee `package.json` for all available scripts.\n\n## Technical Implementation\n\nThis project was bootstrapped with\n[Create React App](https://github.com/facebook/create-react-app) for TypeScript.\nIt uses [Styled Components](https://www.styled-components.com/docs/) for styles\n(and some `css` files too). [ESLint](https://eslint.org/) is configured to lint\nJavascript and TypeScript files, and format code using\n[Prettier](https://prettier.io/). [stylelint](https://stylelint.io/) is used to\nlint modern css. [Jest](https://jestjs.io/),\n[dom-testing-library](https://testing-library.com),\n[react-testing-library](https://github.com/kentcdodds/react-testing-library),\nand [Cypress](https://www.cypress.io/) are used to test components and\nend-to-end user flows.\n\n## Contributing\n\nHelp defend democracy and [contribute to the project](CONTRIBUTING.md).\n"
 },
 {
  "repo": "microsoft/SubscribableEvent",
  "language": "TypeScript",
  "readme_contents": "# SubscribableEvent\n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](https://github.com/Microsoft/SubscribableEvent/blob/master/LICENSE) [![npm version](https://img.shields.io/npm/v/subscribableevent.svg?style=flat-square)](https://www.npmjs.com/package/subscribableevent) [![Build Status](https://img.shields.io/travis/Microsoft/SubscribableEvent/master.svg?style=flat-square)](https://travis-ci.org/Microsoft/SubscribableEvent) [![npm downloads](https://img.shields.io/npm/dm/subscribableevent.svg?style=flat-square)](https://www.npmjs.com/package/subscribableevent) ![npm bundle size (minified)](https://img.shields.io/bundlephobia/min/subscribableevent.svg?style=flat-square) ![npm bundle size (minified + gzip)](https://img.shields.io/bundlephobia/minzip/subscribableevent.svg?style=flat-square)\n\n> A simple strongly-typed pub/sub/fire eventing system\n\n## Installation\n\n```shell\nnpm install --save subscribableevent\n```\n\n## Basic Example\n\n```typescript\nconst event = new SubscribableEvent<(payload: string) => void>();\n\nevent.subscribe((payload: string) => {\n    console.log(payload);\n});\n\nevent.fire('Payload Params');\n```\n\n## Contributing\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n"
 },
 {
  "repo": "microsoft/reactxp",
  "language": "TypeScript",
  "readme_contents": "# ReactXP\r\n\r\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](https://github.com/Microsoft/reactxp/blob/master/LICENSE) [![npm version](https://img.shields.io/npm/v/reactxp.svg?style=flat-square)](https://www.npmjs.com/package/reactxp) [![Build Status](https://dev.azure.com/ms/reactxp/_apis/build/status/Microsoft.reactxp?)](https://dev.azure.com/ms/reactxp/_build/latest?definitionId=16) [![Build Status](https://img.shields.io/travis/Microsoft/reactxp/master.svg?style=flat-square)](https://travis-ci.org/Microsoft/reactxp) [![npm downloads](https://img.shields.io/npm/dm/reactxp.svg?style=flat-square)](https://www.npmjs.com/package/reactxp) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](https://github.com/Microsoft/reactxp#contributing) [![Gitter](https://img.shields.io/gitter/room/nwjs/nw.js.svg?style=flat-square)](https://gitter.im/msreactxp/Lobby)\r\n\r\n\r\nReactXP is a library for cross-platform app development using React and React Native.\r\n\r\n## Why ReactXP\r\nWith React and React Native, your web app can share most of its logic with your iOS and Android apps, but the view layer needs to be implemented separately for each platform. We have taken this a step further and developed a thin cross-platform layer we call ReactXP. If you write your app to this abstraction, you can share your view definitions, styles and animations across multiple target platforms. Of course, you can still provide platform-specific UI variants, but this can be done selectively where desired.\r\n\r\n## Getting Started\r\nThe [samples](/samples) directory contains a minimal \u201cHello World\u201d app that demonstrates some basic ReactXP functionality. You can use this as a starting point. Just follow the build instructions in the README file.\r\n\r\nAlso included in the samples directory is the [RXPTest app](/samples/RXPTest) which attempts to exercise all of the functionality of ReactXP. It is a good source to consult for sample usage of APIs, components, and props.\r\n\r\nYou can read more about ReactXP and its APIs from the [ReactXP official Documentation](https://microsoft.github.io/reactxp/docs/getting-started.html).\r\n\r\nUse the command-line tool called [create-rx-app](https://github.com/a-tarasyuk/create-rx-app) to create a starter project.\r\n\r\n```sh\r\nnpm install create-rx-app -g\r\ncreate-rx-app AppName\r\n```\r\n\r\nor\r\n\r\n```sh\r\nnpx create-rx-app AppName\r\n```\r\n\r\nBy default the project will be created in TypeScript. However if you prefer JavaScript instead, add `--javascript` when creating the project.\r\n\r\nThis will create a directory called **AppName** inside the current working directory. Inside **AppName**, this will generate the initial project structure and install all of its dependencies. Once this installation is done, there are some commands you can run in the project directory:\r\n\r\n- `npm run start:web` - runs the Web version of the app in the development mode\r\n- `npm run build:web` - builds the Web version of the app for production to the **dist-web** folder\r\n- `npm run start:ios` - runs the iOS version of the app and attempts to open in the iOS Simulator if you're on a Mac and have it installed\r\n- `npm run start:android` - runs the Android version of the app and attempts to open your app on a connected Android device or emulator\r\n- `npm run start:windows` - runs the Windows version of the app\r\n- `npm start:rn-dev-server` - runs react native (RN) development server\r\n\r\n### Prerequisites\r\n* [Node.Js](https://nodejs.org/) ([Setup Instructions](https://nodejs.org/en/download/package-manager/))\r\n* [React Native](https://facebook.github.io/react-native/) ([Setup Instructions](https://facebook.github.io/react-native/docs/getting-started))\r\n\r\n## ESLint rules\r\n\r\n> [TSLint will be deprecated some time in 2019](https://github.com/palantir/tslint)\r\n\r\nIf you plan to migrate your projects from TSLint to ESlint and want to continue using the [_rules_](https://github.com/microsoft/reactxp/tree/master/src/tslint) to automate search common problems in *ReactXP* usage, you can use [eslint-plugin-reactxp](https://github.com/a-tarasyuk/eslint-plugin-reactxp).\r\n\r\n## Contributing\r\n\r\nWe welcome contributions to ReactXP. See the [CONTRIBUTING](./CONTRIBUTING.md) file for how to help out.\r\n\r\n## License\r\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details\r\n"
 },
 {
  "repo": "microsoft/onnxruntime",
  "language": "C++",
  "readme_contents": "<p align=\"center\"><img width=\"50%\" src=\"docs/images/ONNX_Runtime_logo_dark.png\" /></p>\n\n**ONNX Runtime** is a cross-platform **inference and training machine-learning accelerator** compatible with deep learning frameworks, PyTorch and TensorFlow/Keras, as well as classical machine learning libraries such as scikit-learn, and more.\n\nONNX Runtime uses the portable [ONNX](https://onnx.ai) computation graph format, backed by execution providers optimized for operating systems, drivers and hardware.\n\nCommon use cases for ONNX Runtime:\n\n* Improve inference performance for a wide variety of ML models\n* Reduce time and cost of training large models\n* Train in Python but deploy into a C#/C++/Java app\n* Run with optimized performance on different hardware and operating systems\n* Support models created in several different frameworks\n\n[ONNX Runtime inference](https://www.onnxruntime.ai/docs/get-started/inference.html) APIs are stable and production-ready since the [1.0 release](https://github.com/microsoft/onnxruntime/releases/tag/v1.0.0) in October 2019 and can enable faster customer experiences and lower costs.\n\n[ONNX Runtime training](https://www.onnxruntime.ai/docs/get-started/training.html) feature was introduced in May 2020 in preview. This feature supports acceleration of PyTorch training on multi-node NVIDIA GPUs for transformer models. Additional updates for this feature are coming soon.\n\n\n## Get Started\n\n**http://onnxruntime.ai/**\n* [Install](https://www.onnxruntime.ai/docs/get-started/install.html)\n* [Inference](https://www.onnxruntime.ai/docs/get-started/inference.html)\n* [Training](https://www.onnxruntime.ai/docs/get-started/training.html)\n* [Documentation](https://www.onnxruntime.ai/docs/)\n* [Samples and Tutorials](https://www.onnxruntime.ai/docs/tutorials/)\n* [Build Instructions](https://www.onnxruntime.ai/docs/how-to/build.html)\n* [Frequently Asked Questions](./docs/FAQ.md)\n\n## Build Pipeline Status\n|System|CPU|GPU|EPs|\n|---|---|---|---|\n|Windows|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Windows%20CPU%20CI%20Pipeline?label=Windows+CPU)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=9)|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Windows%20GPU%20CI%20Pipeline?label=Windows+GPU)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=10)|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Windows%20GPU%20TensorRT%20CI%20Pipeline?label=Windows+GPU+TensorRT)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=47)|\n|Linux|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20CPU%20CI%20Pipeline?label=Linux+CPU)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=11)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20CPU%20Minimal%20Build%20E2E%20CI%20Pipeline?label=Linux+CPU+Minimal+Build)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=64)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20CPU%20x64%20NoContribops%20CI%20Pipeline?label=Linux+CPU+x64+No+Contrib+Ops)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=110)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/centos7_cpu?label=Linux+CentOS7)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=78)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/orttraining-linux-ci-pipeline?label=Linux+CPU+Training)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=86)|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20GPU%20CI%20Pipeline?label=Linux+GPU)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=12)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20GPU%20TensorRT%20CI%20Pipeline?label=Linux+GPU+TensorRT)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=45)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/orttraining-distributed?label=Distributed+Training)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=140)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/orttraining-linux-gpu-ci-pipeline?label=Linux+GPU+Training)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=84)|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20NUPHAR%20CI%20Pipeline?label=Linux+NUPHAR)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=110)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Linux%20OpenVINO%20CI%20Pipeline%20v2?label=Linux+OpenVINO)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=108)|\n|Mac|[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/MacOS%20CI%20Pipeline?label=MacOS+CPU)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=13)<br>[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/MacOS%20NoContribops%20CI%20Pipeline?label=MacOS+NoContribops)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=65)|||\n|Android|||[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Android%20CI%20Pipeline?label=Android)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=53)|\n|iOS|||[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/iOS%20CI%20Pipeline?label=iOS)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=134)|\n|WebAssembly|||[![Build Status](https://dev.azure.com/onnxruntime/onnxruntime/_apis/build/status/Windows%20WebAssembly%20CI%20Pipeline?label=WASM)](https://dev.azure.com/onnxruntime/onnxruntime/_build/latest?definitionId=161)|\n\n\n## Data/Telemetry\n\nThis project may collect usage data and send it to Microsoft to help improve our products and services. See the [privacy statement](docs/Privacy.md) for more details.\n\n## Contributions and Feedback\n\nWe welcome contributions! Please see the [contribution guidelines](CONTRIBUTING.md).\n\nFor feature requests or bug reports, please file a [GitHub Issue](https://github.com/Microsoft/onnxruntime/issues).\n\nFor general discussion or questions, please use [Github Discussions](https://github.com/microsoft/onnxruntime/discussions).\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nThis project is licensed under the [MIT License](LICENSE).\n"
 },
 {
  "repo": "microsoft/charticulator-extensions",
  "language": "TypeScript",
  "readme_contents": "# Charticulator Extensions\n\nThis repository contains a collection of charticulator extensions.\n\n* [PowerBI Visual Builder](powerbi-visual-builder) - An extension that adds PowerBI visual export functionality to charticulator.\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/vcpkg",
  "language": "CMake",
  "readme_contents": "# Vcpkg: Overview\n\n[\u4e2d\u6587\u603b\u89c8](README_zh_CN.md)\n[Espa\u00f1ol](README_es.md)\n[\ud55c\uad6d\uc5b4](README_ko_KR.md)\n[Fran\u00e7ais](README_fr.md)\n\nVcpkg helps you manage C and C++ libraries on Windows, Linux and MacOS.\nThis tool and ecosystem are constantly evolving, and we always appreciate contributions!\n\nIf you've never used vcpkg before, or if you're trying to figure out how to use vcpkg,\ncheck out our [Getting Started](#getting-started) section for how to start using vcpkg.\n\nFor short description of available commands, once you've installed vcpkg,\nyou can run `vcpkg help`, or `vcpkg help [command]` for command-specific help.\n\n* Github: [https://github.com/microsoft/vcpkg](https://github.com/microsoft/vcpkg)\n* Slack: [https://cppalliance.org/slack/](https://cppalliance.org/slack/), the #vcpkg channel\n* Discord: [\\#include \\<C++\\>](https://www.includecpp.org), the #\ud83c\udf0fvcpkg channel\n* Docs: [Documentation](docs/README.md)\n\n[![Build Status](https://dev.azure.com/vcpkg/public/_apis/build/status/microsoft.vcpkg.ci?branchName=master)](https://dev.azure.com/vcpkg/public/_build/latest?definitionId=29&branchName=master)\n\n# Table of Contents\n\n- [Vcpkg: Overview](#vcpkg-overview)\n- [Table of Contents](#table-of-contents)\n- [Getting Started](#getting-started)\n  - [Quick Start: Windows](#quick-start-windows)\n  - [Quick Start: Unix](#quick-start-unix)\n  - [Installing Linux Developer Tools](#installing-linux-developer-tools)\n  - [Installing macOS Developer Tools](#installing-macos-developer-tools)\n    - [Installing GCC for macOS before 10.15](#installing-gcc-for-macos-before-1015)\n  - [Using vcpkg with CMake](#using-vcpkg-with-cmake)\n    - [Visual Studio Code with CMake Tools](#visual-studio-code-with-cmake-tools)\n    - [Vcpkg with Visual Studio CMake Projects](#vcpkg-with-visual-studio-cmake-projects)\n    - [Vcpkg with CLion](#vcpkg-with-clion)\n    - [Vcpkg as a Submodule](#vcpkg-as-a-submodule)\n- [Tab-Completion/Auto-Completion](#tab-completionauto-completion)\n- [Examples](#examples)\n- [Contributing](#contributing)\n- [License](#license)\n- [Telemetry](#telemetry)\n\n# Getting Started\n\nFirst, follow the quick start guide for either\n[Windows](#quick-start-windows), or [macOS and Linux](#quick-start-unix),\ndepending on what you're using.\n\nFor more information, see [Installing and Using Packages][getting-started:using-a-package].\nIf a library you need is not present in the vcpkg catalog,\nyou can [open an issue on the GitHub repo][contributing:submit-issue]\nwhere the vcpkg team and community can see it,\nand potentially add the port to vcpkg.\n\nAfter you've gotten vcpkg installed and working,\nyou may wish to add [tab completion](#tab-completionauto-completion) to your shell.\n\nFinally, if you're interested in the future of vcpkg,\ncheck out the [manifest][getting-started:manifest-spec] guide!\nThis is an experimental feature and will likely have bugs,\nso try it out and [open all the issues][contributing:submit-issue]!\n\n## Quick Start: Windows\n\nPrerequisites:\n- Windows 7 or newer\n- [Git][getting-started:git]\n- [Visual Studio][getting-started:visual-studio] 2015 Update 3 or greater with the English language pack\n\nFirst, download and bootstrap vcpkg itself; it can be installed anywhere,\nbut generally we recommend using vcpkg as a submodule for CMake projects,\nand installing it globally for Visual Studio projects.\nWe recommend somewhere like `C:\\src\\vcpkg` or `C:\\dev\\vcpkg`,\nsince otherwise you may run into path issues for some port build systems.\n\n```cmd\n> git clone https://github.com/microsoft/vcpkg\n> .\\vcpkg\\bootstrap-vcpkg.bat\n```\n\nTo install the libraries for your project, run:\n\n```cmd\n> .\\vcpkg\\vcpkg install [packages to install]\n```\n\nNote: This will install x86 libraries by default. To install x64, run:\n\n```cmd\n> .\\vcpkg\\vcpkg install package:x64-windows\n```\n\nOr\n\n```cmd\n> .\\vcpkg\\vcpkg install [packages to install] --triplet=x64-windows\n```\n\nYou can also search for the libraries you need with the `search` subcommand:\n\n```cmd\n> .\\vcpkg\\vcpkg search [search term]\n```\n\nIn order to use vcpkg with Visual Studio,\nrun the following command (may require administrator elevation):\n\n```cmd\n> .\\vcpkg\\vcpkg integrate install\n```\n\nAfter this, you can now create a New non-CMake Project (or open an existing one).\nAll installed libraries are immediately ready to be `#include`'d and used\nin your project without additional configuration.\n\nIf you're using CMake with Visual Studio,\ncontinue [here](#vcpkg-with-visual-studio-cmake-projects).\n\nIn order to use vcpkg with CMake outside of an IDE,\nyou can use the toolchain file:\n\n```cmd\n> cmake -B [build directory] -S . -DCMAKE_TOOLCHAIN_FILE=[path to vcpkg]/scripts/buildsystems/vcpkg.cmake\n> cmake --build [build directory]\n```\n\nWith CMake, you will still need to `find_package` and the like to use the libraries.\nCheck out the [CMake section](#using-vcpkg-with-cmake) for more information,\nincluding on using CMake with an IDE.\n\nFor any other tools, including Visual Studio Code,\ncheck out the [integration guide][getting-started:integration].\n\n## Quick Start: Unix\n\nPrerequisites for Linux:\n- [Git][getting-started:git]\n- [g++][getting-started:linux-gcc] >= 6\n\nPrerequisites for macOS:\n- [Apple Developer Tools][getting-started:macos-dev-tools]\n- On macOS 10.14 or below, you will also need:\n  - [Homebrew][getting-started:macos-brew]\n  - [g++][getting-started:macos-gcc] >= 6 from Homebrew\n\nFirst, download and bootstrap vcpkg itself; it can be installed anywhere,\nbut generally we recommend using vcpkg as a submodule for CMake projects.\n\n```sh\n$ git clone https://github.com/microsoft/vcpkg\n$ ./vcpkg/bootstrap-vcpkg.sh\n```\n\nTo install the libraries for your project, run:\n\n```sh\n$ ./vcpkg/vcpkg install [packages to install]\n```\n\nYou can also search for the libraries you need with the `search` subcommand:\n\n```sh\n$ ./vcpkg/vcpkg search [search term]\n```\n\nIn order to use vcpkg with CMake, you can use the toolchain file:\n\n```sh\n$ cmake -B [build directory] -S . -DCMAKE_TOOLCHAIN_FILE=[path to vcpkg]/scripts/buildsystems/vcpkg.cmake\n$ cmake --build [build directory]\n```\n\nWith CMake, you will still need to `find_package` and the like to use the libraries.\nCheck out the [CMake section](#using-vcpkg-with-cmake)\nfor more information on how best to use vcpkg with CMake,\nand CMake Tools for VSCode.\n\nFor any other tools, check out the [integration guide][getting-started:integration].\n\n## Installing Linux Developer Tools\n\nAcross the different distros of Linux, there are different packages you'll\nneed to install:\n\n- Debian, Ubuntu, popOS, and other Debian-based distributions:\n\n```sh\n$ sudo apt-get update\n$ sudo apt-get install build-essential tar curl zip unzip\n```\n\n- CentOS\n\n```sh\n$ sudo yum install centos-release-scl\n$ sudo yum install devtoolset-7\n$ scl enable devtoolset-7 bash\n```\n\nFor any other distributions, make sure you're installing g++ 6 or above.\nIf you want to add instructions for your specific distro,\n[please open a PR][contributing:submit-pr]!\n\n## Installing macOS Developer Tools\n\nOn macOS 10.15, the only thing you should need to do is run the following in your terminal:\n\n```sh\n$ xcode-select --install\n```\n\nThen follow along with the prompts in the windows that comes up.\n\nOn macOS 10.14 and previous, you'll also need to install g++ from homebrew;\nfollow the instructions in the following section.\n\n### Installing GCC for macOS before 10.15\n\nThis will _only_ be necessary if you're using a macOS version from before 10.15.\nInstalling homebrew should be very easy; check out <brew.sh> for more information,\nbut at its simplest, run the following command:\n\n```sh\n$ /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"\n```\n\nThen, in order to grab an up-to-date version of gcc, run the following:\n\n```sh\n$ brew install gcc\n```\n\nYou'll then be able to bootstrap vcpkg along with the [quick start guide](#quick-start-unix)\n\n## Using vcpkg with CMake\n\nIf you're using vcpkg with CMake, the following may help!\n\n### Visual Studio Code with CMake Tools\n\nAdding the following to your workspace `settings.json` will make\nCMake Tools automatically use vcpkg for libraries:\n\n```json\n{\n  \"cmake.configureSettings\": {\n    \"CMAKE_TOOLCHAIN_FILE\": \"[vcpkg root]/scripts/buildsystems/vcpkg.cmake\"\n  }\n}\n```\n\n### Vcpkg with Visual Studio CMake Projects\n\nOpen the CMake Settings Editor, and under `CMake toolchain file`,\nadd the path to the vcpkg toolchain file:\n\n```\n[vcpkg root]/scripts/buildsystems/vcpkg.cmake\n```\n\n### Vcpkg with CLion\n\nOpen the Toolchains settings\n(File > Settings on Windows and Linux, CLion > Preferences on macOS),\nand go to the CMake settings (Build, Execution, Deployment > CMake).\nFinally, in `CMake options`, add the following line:\n\n```\n-DCMAKE_TOOLCHAIN_FILE=[vcpkg root]/scripts/buildsystems/vcpkg.cmake\n```\n\nUnfortunately, you'll have to add this to each profile.\n\n### Vcpkg as a Submodule\n\nWhen using vcpkg as a submodule of your project,\nyou can add the following to your CMakeLists.txt before the first `project()` call,\ninstead of passing `CMAKE_TOOLCHAIN_FILE` to the cmake invocation.\n\n```cmake\nset(CMAKE_TOOLCHAIN_FILE ${CMAKE_CURRENT_SOURCE_DIR}/vcpkg/scripts/buildsystems/vcpkg.cmake\n  CACHE STRING \"Vcpkg toolchain file\")\n```\n\nThis will still allow people to not use vcpkg,\nby passing the `CMAKE_TOOLCHAIN_FILE` directly,\nbut it will make the configure-build step slightly easier.\n\n[getting-started:using-a-package]: docs/examples/installing-and-using-packages.md\n[getting-started:integration]: docs/users/integration.md\n[getting-started:git]: https://git-scm.com/downloads\n[getting-started:cmake-tools]: https://marketplace.visualstudio.com/items?itemName=ms-vscode.cmake-tools\n[getting-started:linux-gcc]: #installing-linux-developer-tools\n[getting-started:macos-dev-tools]: #installing-macos-developer-tools\n[getting-started:macos-brew]: #installing-gcc-on-macos\n[getting-started:macos-gcc]: #installing-gcc-on-macos\n[getting-started:visual-studio]: https://visualstudio.microsoft.com/\n[getting-started:manifest-spec]: docs/specifications/manifests.md\n\n# Tab-Completion/Auto-Completion\n\n`vcpkg` supports auto-completion of commands, package names,\nand options in both powershell and bash.\nTo enable tab-completion in the shell of your choice, run:\n\n```pwsh\n> .\\vcpkg integrate powershell\n```\n\nor\n\n```sh\n$ ./vcpkg integrate bash\n```\n\ndepending on the shell you use, then restart your console.\n\n# Examples\n\nSee the [documentation](docs/README.md) for specific walkthroughs,\nincluding [installing and using a package](docs/examples/installing-and-using-packages.md),\n[adding a new package from a zipfile](docs/examples/packaging-zipfiles.md),\nand [adding a new package from a GitHub repo](docs/examples/packaging-github-repos.md).\n\nOur docs are now also available online at ReadTheDocs: <https://vcpkg.readthedocs.io/>!\n\nSee a 4 minute [video demo](https://www.youtube.com/watch?v=y41WFKbQFTw).\n\n# Contributing\n\nVcpkg is an open source project, and is thus built with your contributions.\nHere are some ways you can contribute:\n\n* [Submit Issues][contributing:submit-issue] in vcpkg or existing packages\n* [Submit Fixes and New Packages][contributing:submit-pr]\n\nPlease refer to our [Contributing Guide](CONTRIBUTING.md) for more details.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct][contributing:coc].\nFor more information see the [Code of Conduct FAQ][contributing:coc-faq]\nor email [opencode@microsoft.com](mailto:opencode@microsoft.com)\nwith any additional questions or comments.\n\n[contributing:submit-issue]: https://github.com/microsoft/vcpkg/issues/new/choose\n[contributing:submit-pr]: https://github.com/microsoft/vcpkg/pulls\n[contributing:coc]: https://opensource.microsoft.com/codeofconduct/\n[contributing:coc-faq]: https://opensource.microsoft.com/codeofconduct/\n\n# License\n\nThe code in this repository is licensed under the [MIT License](LICENSE.txt).\n\n# Telemetry\n\nvcpkg collects usage data in order to help us improve your experience.\nThe data collected by Microsoft is anonymous.\nYou can opt-out of telemetry by re-running the bootstrap-vcpkg script with -disableMetrics,\npassing --disable-metrics to vcpkg on the command line,\nor by setting the VCPKG_DISABLE_METRICS environment variable.\n\nRead more about vcpkg telemetry at docs/about/privacy.md\n"
 },
 {
  "repo": "microsoft/vscode",
  "language": "TypeScript",
  "readme_contents": "# Visual Studio Code - Open Source (\"Code - OSS\")\n[![Feature Requests](https://img.shields.io/github/issues/microsoft/vscode/feature-request.svg)](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\n[![Bugs](https://img.shields.io/github/issues/microsoft/vscode/bug.svg)](https://github.com/microsoft/vscode/issues?utf8=\u2713&q=is%3Aissue+is%3Aopen+label%3Abug)\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-yellow.svg)](https://gitter.im/Microsoft/vscode)\n\n## The Repository\n\nThis repository (\"`Code - OSS`\") is where we (Microsoft) develop the [Visual Studio Code](https://code.visualstudio.com) product together with the community. Not only do we work on code and issues here, we also publish our [roadmap](https://github.com/microsoft/vscode/wiki/Roadmap), [monthly iteration plans](https://github.com/microsoft/vscode/wiki/Iteration-Plans), and our [endgame plans](https://github.com/microsoft/vscode/wiki/Running-the-Endgame). This source code is available to everyone under the standard [MIT license](https://github.com/microsoft/vscode/blob/main/LICENSE.txt).\n\n## Visual Studio Code\n\n<p align=\"center\">\n  <img alt=\"VS Code in action\" src=\"https://user-images.githubusercontent.com/1487073/58344409-70473b80-7e0a-11e9-8570-b2efc6f8fa44.png\">\n</p>\n\n[Visual Studio Code](https://code.visualstudio.com) is a distribution of the `Code - OSS` repository with Microsoft specific customizations released under a traditional [Microsoft product license](https://code.visualstudio.com/License/).\n\n[Visual Studio Code](https://code.visualstudio.com) combines the simplicity of a code editor with what developers need for their core edit-build-debug cycle. It provides comprehensive code editing, navigation, and understanding support along with lightweight debugging, a rich extensibility model, and lightweight integration with existing tools.\n\nVisual Studio Code is updated monthly with new features and bug fixes. You can download it for Windows, macOS, and Linux on [Visual Studio Code's website](https://code.visualstudio.com/Download). To get the latest releases every day, install the [Insiders build](https://code.visualstudio.com/insiders).\n\n## Contributing\n\nThere are many ways in which you can participate in the project, for example:\n\n* [Submit bugs and feature requests](https://github.com/microsoft/vscode/issues), and help us verify as they are checked in\n* Review [source code changes](https://github.com/microsoft/vscode/pulls)\n* Review the [documentation](https://github.com/microsoft/vscode-docs) and make pull requests for anything from typos to new content\n\nIf you are interested in fixing issues and contributing directly to the code base,\nplease see the document [How to Contribute](https://github.com/microsoft/vscode/wiki/How-to-Contribute), which covers the following:\n\n* [How to build and run from source](https://github.com/microsoft/vscode/wiki/How-to-Contribute)\n* [The development workflow, including debugging and running tests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#debugging)\n* [Coding guidelines](https://github.com/microsoft/vscode/wiki/Coding-Guidelines)\n* [Submitting pull requests](https://github.com/microsoft/vscode/wiki/How-to-Contribute#pull-requests)\n* [Finding an issue to work on](https://github.com/microsoft/vscode/wiki/How-to-Contribute#where-to-contribute)\n* [Contributing to translations](https://aka.ms/vscodeloc)\n\n## Feedback\n\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/vscode)\n* [Request a new feature](CONTRIBUTING.md)\n* Upvote [popular feature requests](https://github.com/microsoft/vscode/issues?q=is%3Aopen+is%3Aissue+label%3Afeature-request+sort%3Areactions-%2B1-desc)\n* [File an issue](https://github.com/microsoft/vscode/issues)\n* Follow [@code](https://twitter.com/code) and let us know what you think!\n\nSee our [wiki](https://github.com/microsoft/vscode/wiki/Feedback-Channels) for a description of each of these channels and information on some other available community-driven channels.\n\n## Related Projects\n\nMany of the core components and extensions to VS Code live in their own repositories on GitHub. For example, the [node debug adapter](https://github.com/microsoft/vscode-node-debug) and the [mono debug adapter](https://github.com/microsoft/vscode-mono-debug) have their own repositories. For a complete list, please visit the [Related Projects](https://github.com/microsoft/vscode/wiki/Related-Projects) page on our [wiki](https://github.com/microsoft/vscode/wiki).\n\n## Bundled Extensions\n\nVS Code includes a set of built-in extensions located in the [extensions](extensions) folder, including grammars and snippets for many languages. Extensions that provide rich language support (code completion, Go to Definition) for a language have the suffix `language-features`. For example, the `json` extension provides coloring for `JSON` and the `json-language-features` provides rich language support for `JSON`.\n\n## Development Container\n\nThis repository includes a Visual Studio Code Remote - Containers / Codespaces development container.\n\n- For [Remote - Containers](https://aka.ms/vscode-remote/download/containers), use the **Remote-Containers: Open Repository in Container...** command which creates a Docker volume for better disk I/O on macOS and Windows.\n- For Codespaces, install the [Visual Studio Codespaces](https://aka.ms/vscs-ext-vscode) extension in VS Code, and use the **Codespaces: Create New Codespace** command.\n\nDocker / the Codespace should have at least **4 Cores and 6 GB of RAM (8 GB recommended)** to run full build. See the [development container README](.devcontainer/README.md) for more information.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [MIT](LICENSE.txt) license.\n"
 },
 {
  "repo": "microsoft/spektate",
  "language": "TypeScript",
  "readme_contents": "[![Build Status](https://dev.azure.com/epicstuff/bedrock/_apis/build/status/microsoft.spektate?branchName=master)](https://dev.azure.com/epicstuff/bedrock/_build/latest?definitionId=124&branchName=master)\n![Azure DevOps coverage](https://img.shields.io/azure-devops/coverage/epicstuff/bedrock/124/master)\n\n# Spektate\n\nThis is an initiative to visualize [Project Bedrock](https://github.com/microsoft/bedrock). Spektate ties in information from the repositories API, the pipelines API and information stored in an Azure Table to display the dashboard with the following components:\n\n![](./images/spektate-pieces-diagram.png)\n\nHere's a detailed diagram describing the Spektate workflow. Each pipeline is responsible for sending a unique set of data to the storage, which is used to connect all the pieces together:\n\n![](./images/spektate-workflow.png)\n\nCurrently, Spektate consists of a command line interface and a simple dashboard prototype. The instructions to use both are below.\n\nNote: Spektate dashboard will delete deployments when their corresponding builds/releases have expired in Azure DevOps.\n\nOfficial docker images for this dashboard are located at `mcr.microsoft.com/k8s/bedrock/spektate`.\n\n## Onboard a Bedrock project to use Spektate\n\nFollow the steps in this [guide](https://github.com/microsoft/bedrock-cli/blob/master/guides/service-introspection-onboarding.md) to onboard a project to use Spektate.\n\n## Install on your cluster\n\nThe helm chart to use this dashboard is located [here](./chart). There's a Load Balancer provided in the helm chart but it's turned off in `values.yaml` with the setting `externalIP`. Set this to true if you would like to expose the dashboard via a public endpoint.\n\nSubstitute values for your configuration and install this dashboard via the command below:\n\n```bash\ncd ./chart\nhelm install . --name spektate --set storageAccessKey=<storageAccessKey> --set storageTableName=<storageTableName> --set storagePartitionKey=<storagePartitionKey> --set storageAccountName=<storageAccountName> --set pipelineProject=<pipelineProjectName> --set pipelineOrg=<pipelineOrg> --set pipelineAccessToken=<PipelinePAT> --set manifest=<manifestRepoName> --set manifestAccessToken=<manifestAccessToken> --set githubManifestUsername=<gitHubUserName>  --set sourceRepoAccessToken=<sourceRepoAccessToken>\n```\n\n- `storageAccessKey`: Access key for the storage account\n- `storageTableName`: Table name for the storage account\n- `storagePartitionKey`: Partition key for your configuration, you may want to use project name or some identifier that helps separate unrelated configurations for the purpose of introspection.\n- `storageAccountName`: Storage account name\n- `pipelineProject`: Project name for the pipelines in Azure DevOps\n- `pipelineOrg`: Org name for the pipelines in Azure DevOps\n- `pipelineAccessToken`: Access token for pipelines in Azure DevOps\n- `manifestRepoName`: Manifest repository name\n- `manifestAccessToken`: Access token for the manifest repository\n- `sourceRepoAccessToken`: Access token for the source repository\n- **Note**: If you're using GitHub, add `githubManifestUsername`: Account name or organization name under which the manifest repository resides.\n\nIf you're not using an external IP, use port-forwarding to access the dashboard:\n\n1. Copy pod name from `kubectl get pods`\n2. `kubectl port-forward pod/<pod-name> 2200:5000` or change `2200` to a port of your choice\n3. Navigate to http://localhost:2200 or change `2200` to a port of your choice\n\n## Dashboard dev mode\n\n1. Clone this repository.\n2. There is frontend and backend folders and each of them are separate yarn projects. `cd frontend` in one window and `cd backend` in another.\n3. Add the following env variables to your shell where you have changed directory to `backend`:\n\n   ```bash\n   export REACT_APP_STORAGE_ACCESS_KEY=\n   export REACT_APP_STORAGE_TABLE_NAME=\n   export REACT_APP_STORAGE_PARTITION_KEY=\n   export REACT_APP_STORAGE_ACCOUNT_NAME=\n   export REACT_APP_PIPELINE_PROJECT=\n   export REACT_APP_PIPELINE_ORG=\n   export REACT_APP_PIPELINE_ACCESS_TOKEN=\n   export REACT_APP_MANIFEST=\n   export REACT_APP_MANIFEST_ACCESS_TOKEN=\n   export REACT_APP_SOURCE_REPO_ACCESS_TOKEN=\n   ```\n\n   - `REACT_APP_STORAGE_ACCESS_KEY`: Access key for the storage account\n   - `REACT_APP_STORAGE_TABLE_NAME`: Table name for the storage account\n   - `REACT_APP_STORAGE_PARTITION_KEY`: Partition key for your configuration, you may want to use project name or some identifier that helps separate unrelated configurations for the purpose of introspection.\n   - `REACT_APP_STORAGE_ACCOUNT_NAME`: Storage account name\n   - `REACT_APP_PIPELINE_PROJECT`: Project name for the pipelines in Azure DevOps\n   - `REACT_APP_PIPELINE_ORG`: Org name for the pipelines in Azure DevOps\n   - `REACT_APP_PIPELINE_ACCESS_TOKEN`: Access token for pipelines in Azure DevOps\n   - `REACT_APP_MANIFEST`: Manifest repository name\n   - `REACT_APP_MANIFEST_ACCESS_TOKEN`: Access token for the manifest repository\n   - `REACT_APP_SOURCE_REPO_ACCESS_TOKEN`: Access token for the source repository\n   - **Note**: If you're using GitHub, add `REACT_APP_GITHUB_MANIFEST_USERNAME`: Account name or organization name under which the manifest repository resides.\n\n4. Run `yarn` in both to install dependencies\n5. Run `yarn start` in both to start the applications. You should be able to see the dashboard launch in one, and a Node.js server start in another! It should navigate you to the browser where dashboard is running.\n\n## Publish Docker image\n\nIn order to publish images to this repository, you will need access to `devcrewsacr.azurecr.io`\n\n1. Run `az acr login --name devcrewsacr`\n2. If you do not know credentials you will need to login, grab them from portal.azure.com or run `az acr credential show --name devcrewsacr`.\n3. Run `docker login devcrewsacr.azurecr.io` and you will be prompted to enter the credentials\n4. Run `docker push devcrewsacr.azurecr.io/public/k8s/bedrock/spektate:<tag>`\n\n## Azure Web App Hosting\n\nYou can provide an Azure Active Directory layer of authetication on top of Spektate. Follow instructions [here](./WebAppHosting.md).\n\n## Command Line Interface\n\nTo use the CLI for Spektate, head over to https://github.com/microsoft/bedrock-cli.\n\n# Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/BotFramework-Emulator",
  "language": "TypeScript",
  "readme_contents": "# ![Bot Framework Emulator](./docs/media/BotFrameworkEmulator_header.png)\n\n### [Find out what's new with Bot Framework](https://github.com/Microsoft/botframework/blob/main/whats-new.md#whats-new)\n\n# Bot Framework Emulator\n\n[![Build Status](https://fuselabs.visualstudio.com/BotFramework-Emulator/_apis/build/status/%5BV4-Nightly%5D-Main-Build?branchName=main)](https://fuselabs.visualstudio.com/BotFramework-Emulator/_build/latest?definitionId=419&branchName=main) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/BotFramework-Emulator/badge.svg?branch=main)](https://coveralls.io/github/Microsoft/BotFramework-Emulator?branch=main)\n\nThe Bot Framework Emulator is a desktop application that allows bot developers to test and debug bots built using the [Bot Framework SDK](https://github.com/microsoft/botbuilder). You can use the Bot Framework Emulator to test bots running either locally on your machine or connect to bots running remotely through a tunnel.\n\nThis repo is part the [Microsoft Bot Framework](https://github.com/microsoft/botframework-sdk) - a comprehensive framework for building enterprise-grade conversational AI experiences.\n\n## Download\n\n* Download the Bot Framework V4 Emulator for your platform from the [GitHub releases](https://github.com/Microsoft/BotFramework-Emulator/releases/latest) page.\n\n### Supported platforms\n\n* Windows\n* OS X\n* Linux\n\n  **Note for Linux users:**\n\n  The Emulator leverages a library that uses `libsecret` so you may need to install it before running `npm install`.\n\n  Depending on your distribution, you will need to run the following command:\n\n  Debian/Ubuntu: `sudo apt-get install libsecret-1-dev`\n\n  Red Hat-based: `sudo yum install libsecret-devel`\n\n  Arch Linux: `sudo pacman -S libsecret`\n\n## Documentation\n\nCheckout the [Wiki](https://github.com/Microsoft/BotFramework-Emulator/wiki) for docs.\n\n## Feedback\n\n* File a bug or suggestion in [GitHub Issues](https://github.com/Microsoft/BotFramework-Emulator/blob/v4/CONTRIBUTING.md#submitting-issues)\n* Ask a question on [Stack Overflow](https://stackoverflow.com/questions/tagged/botframework)\n\n## Related\n\n* [Microsoft Bot Framework](https://dev.botframework.com/)\n* [Bot Framework SDK](https://github.com/Microsoft/BotBuilder)\n* [Bot Framework CLI](https://github.com/microsoft/botframework-cli)\n* [Bot Framework Web Chat](https://github.com/Microsoft/BotFramework-WebChat)\n\n## Nightly builds\n\nNightly builds are generated using the latest code. Therefore, they may not be stable, and most likely lack up to date documentation. These builds are better suited for more experienced users, although everyone is welcome to use them and provide feedback. Nightly builds of the V4 Emulator are available [here](https://github.com/Microsoft/botframework-emulator-nightlies/releases).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Reporting Security Issues\n\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the [MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in the [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n"
 },
 {
  "repo": "microsoft/typed-rest-client",
  "language": "TypeScript",
  "readme_contents": "\n<a href=\"https://github.com/microsoft/typed-rest-client\"><img alt=\"GitHub Actions status\" src=\"https://github.com/microsoft/typed-rest-client/workflows/all-tests/badge.svg\"></a>\n\n[![Build Status](https://dev.azure.com/ms/typed-rest-client/_apis/build/status/Microsoft.typed-rest-client?branchName=master)](https://dev.azure.com/ms/typed-rest-client/_build/latest?definitionId=42&branchName=master)\n\n\n# Typed REST and HTTP Client with TypeScript Typings\n\nA lightweight REST and HTTP client optimized for use with TypeScript with generics and async await.\n\n## Features\n\n  - REST and HTTP client with TypeScript generics and async/await/Promises\n  - Typings included so no need to acquire separately (great for intellisense and no versioning drift)\n  - Basic, Bearer and NTLM Support out of the box.  Extensible handlers for others.\n  - Proxy support\n  - Certificate support (Self-signed server and client cert)\n  - Redirects supported\n\nIntellisense and compile support:\n\n![intellisense](./docs/intellisense.png)\n\n## Install\n\n```\nnpm install typed-rest-client --save\n```\n\nOr to install the latest preview:\n```\nnpm install typed-rest-client@preview --save\n```\n\n## Samples\n\nSee the [samples](./samples) for complete coding examples. Also see the [REST](./test/tests/resttests.ts) and [HTTP](./test/tests/httptests.ts) tests for detailed examples.\n\n## Errors\n\n### HTTP\n\nThe HTTP client does not throw unless truly exceptional.\n\n* A request that successfully executes resulting in a 404, 500 etc... will return a response object with a status code and a body.\n* Redirects (3xx) will be followed by default.\n\n\nSee [HTTP tests](./test/tests/httptests.ts) for detailed examples.\n\n### REST\n\nThe REST client is a high-level client which uses the HTTP client.  Its responsibility is to turn a body into a typed resource object.  \n\n* A 200 will be success.  \n* Redirects (3xx) will be followed.  \n* A 404 will not throw but the result object will be null and the result statusCode will be set.\n* Other 4xx and 5xx errors will throw.  The status code will be attached to the error object.  If a RESTful error object is returned (`{ message: xxx}`), then the error message will be that.  Otherwise, it will be a generic, `Failed Request: (xxx)`.\n\nSee [REST tests](./test/tests/resttests.ts) for detailed examples.\n\n## Debugging\n\nTo enable detailed console logging of all HTTP requests and responses, set the NODE_DEBUG environment varible:\n\n```\nexport NODE_DEBUG=http\n```\n\nor\n\n```\nset NODE_DEBUG=http\n```\n\n\n\n## Node support\n\nThe typed-rest-client is built using the latest LTS version of Node 8. We also support the latest LTS for Node 4 and Node 6.\n\n## Contributing\n\nTo contribute to this repository, see the [contribution guide](./CONTRIBUTING.md)\n\nTo build:\n\n```bash\n$ npm run build\n```\n\nTo run all tests:\n```bash\n$ npm test\n```\n\nTo just run unit tests:\n```bash\n$ npm run units\n```\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Security Issues\n\nDo you think there might be a security issue?\nHave you been phished or identified a security vulnerability?\nPlease don't report it here - let us know by sending an email to secure@microsoft.com.\n"
 },
 {
  "repo": "microsoft/azuredatastudio",
  "language": "TypeScript",
  "readme_contents": "# Azure Data Studio\n\n[![Join the chat at https://gitter.im/Microsoft/sqlopsstudio](https://badges.gitter.im/Microsoft/sqlopsstudio.svg)](https://gitter.im/Microsoft/sqlopsstudio?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Build Status](https://dev.azure.com/azuredatastudio/azuredatastudio/_apis/build/status/Azure%20Data%20Studio%20CI?branchName=main)](https://dev.azure.com/azuredatastudio/azuredatastudio/_build/latest?definitionId=4&branchName=main)\n[![Twitter Follow](https://img.shields.io/twitter/follow/azuredatastudio?style=social)](https://twitter.com/azuredatastudio)\n\nAzure Data Studio is a data management tool that enables you to work with SQL Server, Azure SQL DB and SQL DW from Windows, macOS and Linux.\n\n## **Download the latest Azure Data Studio release**\n\n| Platform\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t|\n| ---------------------------------------\t|\n| [Windows User Installer][win-user]\t\t\t|\n| [Windows System Installer][win-system]\t|\n| [Windows ZIP][win-zip]\t\t\t\t\t\t\t\t\t|\n| [macOS ZIP][osx-zip]\t\t\t\t\t\t\t\t\t\t|\n| [Linux TAR.GZ][linux-zip]\t\t\t\t\t\t\t\t|\n| [Linux RPM][linux-rpm]\t\t\t\t\t\t\t\t\t|\n| [Linux DEB][linux-deb]\t\t\t\t\t\t\t\t\t|\n\n\nGo to our [download page](https://aka.ms/getazuredatastudio) for more specific instructions.\n\n## Try out the latest insiders build from `main`:\n- [Windows User Installer - **Insiders build**](https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-user/insider)\n- [Windows System Installer - **Insiders build**](https://azuredatastudio-update.azurewebsites.net/latest/win32-x64/insider)\n- [Windows ZIP - **Insiders build**](https://azuredatastudio-update.azurewebsites.net/latest/win32-x64-archive/insider)\n- [macOS ZIP - **Insiders build**](https://azuredatastudio-update.azurewebsites.net/latest/darwin/insider)\n- [Linux TAR.GZ - **Insiders build**](https://azuredatastudio-update.azurewebsites.net/latest/linux-x64/insider)\n\nSee the [change log](https://github.com/Microsoft/azuredatastudio/blob/main/CHANGELOG.md) for additional details of what's in this release.\nGo to our [download page](https://aka.ms/getazuredatastudio) for more specific instructions.\n\n\n## **Feature Highlights**\n\n- Cross-Platform DB management for Windows, macOS and Linux with simple XCopy deployment\n- SQL Server Connection Management with Connection Dialog, Server Groups, Azure Integration and Registered Servers\n- Object Explorer supporting schema browsing and contextual command execution\n- T-SQL Query Editor with advanced coding features such as autosuggestions, error diagnostics, tooltips, formatting and peek definition\n- Query Results Viewer with advanced data grid supporting large result sets, export to JSON\\CSV\\Excel, query plan and charting\n- Management Dashboard supporting customizable widgets with drill-through actionable insights\n- Visual Data Editor that enables direct row insertion, update and deletion into tables\n- Backup and Restore dialogs that enables advanced customization and remote filesystem browsing, configured tasks can be executed or scripted\n- Task History window to view current task execution status, completion results with error messages and task T-SQL scripting\n- Scripting support to generate CREATE, SELECT, ALTER and DROP statements for database objects\n- Workspaces with full Git integration and Find In Files support to managing T-SQL script libraries\n- Modern light-weight shell with theming, user settings, full-screen support, integrated terminal and numerous other features\n\nHere are some of these features in action.\n\n<img src='https://github.com/Microsoft/azuredatastudio/blob/main/docs/overview_screen.jpg' width='800px'>\n\n## Contributing\nIf you are interested in fixing issues and contributing directly to the code base,\nplease see the document [How to Contribute](https://github.com/Microsoft/azuredatastudio/wiki/How-to-Contribute), which covers the following:\n\n* [How to build and run from source](https://github.com/Microsoft/azuredatastudio/wiki/How-to-Contribute#Build-and-Run-From-Source)\n* [The development workflow, including debugging and running tests](https://github.com/Microsoft/azuredatastudio/wiki/How-to-Contribute#development-workflow)\n* [Submitting pull requests](https://github.com/Microsoft/azuredatastudio/wiki/How-to-Contribute#pull-requests)\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Localization\nAzure Data Studio is localized into 10 languages: French, Italian, German, Spanish, Simplified Chinese, Traditional Chinese, Japanese, Korean, Russian, and Portuguese (Brazil). The language packs are available in the Extension Manager marketplace. Simply, search for the specific language using the extension marketplace and install. Once you install the selected language, Azure Data Studio will prompt you to restart with the new language.\n\n## Privacy Statement\nThe [Microsoft Enterprise and Developer Privacy Statement](https://privacy.microsoft.com/en-us/privacystatement) describes the privacy statement of this software.\n\n## Contributions and \"Thank You\"\nWe would like to thank all our users who raised issues, and in particular the following users who helped contribute fixes:\n\n* eulercamposbarros for `Prevent connections from moving on click (#7528)`\n* AlexFsmn for `Fixed issue where task icons got hidden if text was too long`\n* jamesrod817 for `Tempdb (#7022)`\n* dzsquared for `fix(snippets): ads parenthesis to sqlcreateindex snippet #7020`\n* devmattrick for `Update row count as updates are received #6642`\n* mottykohn for `In Message panel onclick scroll to line #6417`\n* Stevoni for `Corrected Keyboard Shortcut Execution Issue #5480`\n* yamatoya for `fix the format #4899`\n* GeoffYoung for `Fix sqlDropColumn description #4422`\n* AlexFsmn for `Added context menu for DBs in explorer view to backup & restore db. #2277`\n* sadedil for `Missing feature request: Save as XML #3729`\n* gbritton1 for `Removed reference to object explorer #3463`\n* Tarig0  for `Add Routine_Type to CreateStoredProc fixes #3257 (#3286)`\n* oltruong  for `typo fix #3025'`\n* Thomas-S-B for `Removed unnecessary IErrorDetectionStrategy #749`\n* Thomas-S-B for `Simplified code #750`\n* rdaniels6813  for `Add query plan theme support #3031`\n* Ruturaj123 for `Fixed some typos and grammatical errors #3027`\n* PromoFaux for `Use emoji shortcodes in CONTRIBUTING.md instead of \ufffd #3009`\n* ckaczor for `Fix: DATETIMEOFFSET data types should be ISO formatted #714`\n* hi-im-T0dd for `Fixed sync issue with my forked master so this commit is correct #2948`\n* hi-im-T0dd for `Fixed when right clicking and selecting Manage-correct name displays #2794`\n* philoushka  for `center the icon #2760`\n* anthonypants for `Typo #2775`\n* kstolte for `Fix Invalid Configuration in Launch.json #2789`\n* kstolte for `Fixing a reference to SQL Ops Studio #2788`\n* AlexFsmn `Feature: Ability to add connection name #2332`\n* AlexFsmn `Disabled connection name input when connecting to a server. #2566`\n* SebastianPfliegel `Added more saveAsCsv options #2099`\n* ianychoi `Fixes a typo: Mimunum -> Minimum #1994`\n* AlexFsmn `Fixed bug where proper file extension wasn't appended to the filename. #2151`\n* AlexFsmn `Added functionality for adding any file to import wizard #2329`\n* AlexFsmn `Fixed background issue when copying a chart to clipboard #2215`\n* AlexFsmn `Fixed problem where vertical charts didn't display labels correctly. #2263`\n* AlexFsmn `Fixed Initial values for charts to match visuals #2266`\n* AlexFsmn `Renamed chart option labels #2264`\n* AlexFsmn `Added feature for the opening file after exporting to CSV/XLS/JSON & query files #2216`\n* AlexFsmm `Get Connection String should copy to clipboard #2175`\n* lanceklinger `Fix for double-clicking column handle in results table #1504`\n* westerncj for `Removed duplicate contribution from README.md (#753)`\n* ntovas for `Fix for duplicate extensions shown in \"Save File\" dialog. (#779)`\n* SebastianPfliegel for `Add cursor snippet (#475)`\n* mikaoelitiana for the fix: `revert README and CONTRIBUTING after last VSCode merge (#574)`\n* alextercete for `Reinstate menu item to install from VSIX (#682)`\n* alextercete for `Fix \"No extension gallery service configured\" error (#427)`\n* mwiedemeyer for `Fix #58: Default sort order for DB size widget (#111)`\n* AlexTroshkin for `Show disconnect in context menu only when connectionProfile connected (#150)`\n* AlexTroshkin for `Fix #138: Invalid syntax color highlighting (identity not highlighting) (#140))`\n* stebet for `Fix #153: Fixing sql snippets that failed on a DB with a case-sensitive collation. (#152)`\n* SebastianPfliegel `Remove sqlExtensionHelp (#312)`\n* olljanat for `Implemented npm version check (#314)`\n* Adam Machanic for helping with the `whoisactive` extension\n\nAnd of course, we'd like to thank the authors of all upstream dependencies.  Please see a full list in the [ThirdPartyNotices.txt](https://raw.githubusercontent.com/Microsoft/azuredatastudio/main/ThirdPartyNotices.txt)\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the [Source EULA](LICENSE.txt).\n\n[win-user]: https://go.microsoft.com/fwlink/?linkid=2160781\n[win-system]: https://go.microsoft.com/fwlink/?linkid=2160780\n[win-zip]: https://go.microsoft.com/fwlink/?linkid=2160923\n[osx-zip]: https://go.microsoft.com/fwlink/?linkid=2160874\n[linux-zip]: https://go.microsoft.com/fwlink/?linkid=2160782\n[linux-rpm]: https://go.microsoft.com/fwlink/?linkid=2160875\n[linux-deb]: https://go.microsoft.com/fwlink/?linkid=2160876\n"
 },
 {
  "repo": "microsoft/jacdac-docs",
  "language": "TypeScript",
  "readme_contents": "# Jacdac Documentation\n\n**Jacdac** is a bus-based plug-and-play hardware and software stack for microcontrollers and their peripherals such as sensors and actuators. Jacdac is primarily designed for \u201cmodular electronics\u201d scenarios that support rapid prototyping, creative exploration, making and learning through physical computing. Jacdac is designed to be cheap, flexible and extensible.\n\nThis repository contains sources of [Jacdac](https://aka.ms/jacdac).\n\n* [User Documentation](https://aka.ms/jacdac/)\n* Discussions at https://github.com/microsoft/jacdac/discussions\n* Issues are tracked on https://github.com/microsoft/jacdac/issues\n\nThe rest of this page is for developers of the jacdac-ts library.\n\n## Developer setup\n### Codespaces\n\nEdit this project directly from your browser using GitHub Codespaces. If you have access to them,\n\n* open project in a new codespace\n* launch the docs server\n\n```\nyarn docs\n```\n\n* click on the generated URL in the terminal output and voila!\n\n### Local Setup\n\n* install node.js\n* install yarn\n\n```\nnpm install -g yarn\n```\n\n* setup repo\n\n```\nyarn setup\n```\n### VS Code\n\nYou are welcome to use any editor you want! Visual Studio Code\nprovides seamless support for git sub-modules and is our preferred editor.\n\n* open [Visual Studio Code](https://code.visualstudio.com/)\n\n```\ncode .\n```\n\n* install the recommended extensions (**MDX**, **ESLint** and **Prettier** extensions)\n* in the Git view, click on the ``jacdac`` branch and select ``main`` so that changes are automatically synched\n\n### Specs build\n\nTo regenerate the service definition JSON files from the ``.md`` files in jacdac-spec,\nrun\n\n```\nyarn buildspecs\n```\n### Docs build\n\n* run the docs web site locally\n\n```\nyarn develop\n```\n\n* browse to the local server\n\n```\nhttp://localhost:8000?dbg=1\n```\n\nTo analyze the webpack bundle size,\n\n```\ncd docs\ngatsby build\ngatsby serve\nnav to http://127.0.0.1:3001\n```\n\nIf the build fails after pulling, try\n\n```\nyarn clean\n```\n\n### Jacdac + MakeCode\n\n### Local build\n\nRun this command to rebuild the makecode packages\n\n```\nyarn buildpxt\n```\n\n#### Local debugging\n\nOpen the multi editor to test MakeCode devices with the Jacdac view. You can select to run Jacdac and/or MakeCode on localhost/web from the drop downs.\n\nhttps://makecode.com/multi?jacdac=1&localhost=1&beta=1\n\n### Adding a new MakeCode client\n\nCreate a new issue in https://github.com/microsoft/jacdac and select the ``MakeCode client`` template.\n\n### HTML tools\n\nYou can do ``yarn watch`` to watch/build bundles. Bundles are placed under the ``dist`` folder.\n\n```\nyarn watch\n```\n\nOn another terminal, launch a small web server and \ntry all the tools under ``docs/static/tools/*`` at http://localhost:8080/docs/static/tools/js/console.html . These tools load the files under ``dist`` so you'll want \nto also run ``yarn watch`` on the side.\n\n```\nyarn tools\n```\n\n* console http://localhost:8080/docs/static/tools/js/console.html\n* devices http://localhost:8080/docs/static/tools/js/devices.html\n* flashing http://localhost:8080/docs/static/tools/js/flashing.html\n* namer http://localhost:8080/docs/static/tools/js/namer.html\n* tfite http://localhost:8080/docs/static/tools/js/tflite.html\n* streaming http://localhost:8080/docs/static/tools/js/streaming.html\n* streaming-rickshaw: http://localhost:8080/docs/static/tools/js/streaming-rickshaw.html\n\n### Commits create releases\n\nThe releases are automatically created by the build system based on the title of the commit:\n\n* ``patch|fix:...``  patch\n* ``minor:feature:...`` minor\n\n### NPM scripts\n\n - `yarn watch`: Run `yarn build` in watch mode\n - `yarn lint`: Lints code\n - `yarn docs`: Launch docs web service\n\n## Microsoft Open Source Code of Conduct\n\nThis project is hosted at https://github.com/microsoft/jacdac-ts. \nThis project has adopted the \n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n\nResources:\n\n- [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)\n- [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\n- Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns\n"
 },
 {
  "repo": "microsoft/charticulator",
  "language": "TypeScript",
  "readme_contents": "\n[![Build Status](https://travis-ci.org/Microsoft/charticulator.svg?branch=master)](https://travis-ci.org/Microsoft/charticulator)\n\nCharticulator\n====\n\nCharticulator is a new charting tool that allows you to design charts by interactively specifying\nconstraints.\n\nProject Team\n----\n\n- [Donghao Ren](https://donghaoren.org/)\n- [Bongshin Lee](http://research.microsoft.com/en-us/um/people/bongshin/)\n- [Matthew Brehmer](https://www.microsoft.com/en-us/research/people/mabrehme/)\n- [Nathan Evans](https://github.com/natoverse)\n- [Kate Lytvynets](https://github.com/katua)\n- [David Tittsworth](https://github.com/stopyoukid)\n- [Chris Trevino](https://github.com/darthtrevino)\n\nBuild\n----\n\nFollow the following steps to prepare a development environment:\n\n- Install nodejs 8.0+: <https://nodejs.org/>\n- Install yarnjs 1.7+: <https://yarnpkg.com/>\n\nInstall node modules:\n\n```bash\nyarn\n```\n\nCopy the template configuration file and edit its contents:\n\n```bash\ncp config.template.yml config.yml\n# (on windows, use copy instead of cp)\n```\n\nRun the following command to build Charticulator, which will create a self contained bundle in the `dist` folder:\n\n```bash\nyarn build\n```\n\nRun a local web server to test Charticulator:\n\n```bash\n# Serve Charticulator at http://localhost:4000\nyarn server\n\n# Serve Charticulator publicly at http://0.0.0.0:4000\n# Use this if you want to enable access from another computer\nyarn public_server\n```\n\nDevelopment\n----\n\nFor a live development environment, keep the following command running:\n\n```bash\nyarn start\n```\n\nThis command watches for any change in `src/` and `sass/`, and recompiles Charticulator automatically.\nOnce this up, open <http://localhost:4000/>\nto launch Charticulator. Now when you change the source code, the app can be updated by simply\nrefreshing the browser page (you may need to disable browser cache).\n\nIn development mode, there is a test application for UI components, which can be accessed at <http://localhost:4000/test.html>.\n\nThe watch mode won't update when you change the following:\n\n- config.yml\n- THIRD_PARTY.yml\n- webpack.config.js\n\nWhen you update these, please do `yarn build` again.\n\n### Sample Datasets\nYou can add custom sample datasets that can be used with Charticulator.  To do so, create a `datasets` folder at the root of the repository(if it doesn't exist), add your `.csv` (or `.tsv`) to that folder, and finally create a `files.json` file in the folder with the following contents:\n\n```\n[\n    {\n        \"name\": \"<Your dataset display name>\",\n        \"description\": \"<Your dataset desription>\",\n        \"tables\": [\n            {\n                \"name\": \"<Your dataset file name without extension>\",\n                \"type\": \"<csv || tsv>\",\n                \"url\": \"<Your dataset file name with extension>\"\n            }\n        ]\n    }\n]\n```\n\nTesting\n----\n\nCharticulator currently include a rudimentary test code:\n\n```bash\nyarn test\n```\n\nMore test cases are needed.\n\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Documentation\n\nRun `yarn typedoc` to generate documentation pages.\nThe page will be awailable in [`./docs/charticulator`](./docs/charticulator/index.html)\n\nStart point of documentation is index page {@link \"index\"}"
 },
 {
  "repo": "microsoft/jacdac-ts",
  "language": "TypeScript",
  "readme_contents": "# Jacdac TypeScript\n\n**Jacdac** is a bus-based plug-and-play hardware/software stack \nfor **microcontrollers** and their peripherals (sensors/actuators), \nwith applications to rapid prototyping, making, and physical computing. \n\nThis repository contains a **TypeScript/JavaScript** client library for the [Jacdac](https://aka.ms/jacdac) protocol.\n\n* **[Jacdac Documentation](https://aka.ms/jacdac/)**\n* Discussions at https://github.com/microsoft/jacdac/discussions\n* Issues are tracked on https://github.com/microsoft/jacdac/issues\n\nThe rest of this page is for developers of the jacdac-ts library.\n\n## Developer setup\n\n* clone this repository and pull all submodules\n```\ngit clone https://github.com/microsoft/jacdac-ts\ngit submodule update --init --recursive\ngit pull\n```\n* install node.js\n* install yarn\n```\nnpm install -g yarn\n```\n* install dependencies\n```\nyarn install --frozen-lockfile\n```\n\n### Visual Studio Code\n\nYou are welcome to use any editor you want! Visual Studio Code\nprovides seamless support for git sub-modules and is our preferred editor.\n\n* open [Visual Studio Code](https://code.visualstudio.com/)\n```\ncode .\n```\n* install the recommended extensions (**MDX**, **ESLint** and **Prettier** extensions)\n* in the Git view, click on the ``jacdac`` branch and select ``main`` so that changes are automatically synched\n\n### Build\n\nTo have a watch developement,\n\n```\nyarn watch\n```\n\notherwise to build all libraries\n\n```\nyarn dist\n```\n\n### Specs build\n\nTo regenerate the service definition JSON files from the ``.md`` files in jacdac-spec,\nrun\n\n```\nyarn buildspecs\n```\n\n## Unit tests\n\nWe use [Mocha](https://mochajs.org/) to run the unit test suite from ``/tests``. To execute the tests,\n\n```\nyarn test\n```\n\n## Linting\n\nRun the following command to detect linting issues\n\n```\nyarn lint\n```\n\n### Jacdac + MakeCode\n\n### Local build\n\nRun this command to rebuild the makecode packages\n\n```\nyarn buildpxt\n```\n\n### HTML Tools\n\nLaunch a small web server and \ntry all the tools under ``/tools/*`` at [http://localhost:8080/tools](http://localhost:8080/tools) . These tools load the files under ``dist`` so you'll want \nto also run ``yarn watch`` on the side.\n\n```\nyarn tools\n```\n\nThese tools are also available on the [GitHub pages](https://microsoft.github.io/jacdac-ts/) of this repository:\n\n* [console](https://microsoft.github.io/jacdac-ts/tools/console.html)\n* [devices](https://microsoft.github.io/jacdac-ts/tools/devices.html)\n* [flashing](https://microsoft.github.io/jacdac-ts/tools/flashing.html)\n\nExperimental...\n\n* [namer](https://microsoft.github.io/jacdac-ts/tools/namer.html)\n* [tfite](https://microsoft.github.io/jacdac-ts/tools/tflite.html)\n* [streaming](https://microsoft.github.io/jacdac-ts/tools/streaming.html)\n* [streaming-rickshaw](https://microsoft.github.io/jacdac-ts/tools/streaming-rickshaw.html)\n* [peer.js](https://microsoft.github.io/jacdac-ts/tools/peerjs.html)\n\n### Commits create releases\n\nThe releases are automatically created by the build system based on the title of the commit:\n\n* ``patch:...`` or ``fix:...``  patch\n* ``minor:...`` or ``feature:...`` minor\n\n## Microsoft Open Source Code of Conduct\n\nThis project is hosted at https://github.com/microsoft/jacdac-ts. \nThis project has adopted the \n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n\nResources:\n\n- [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)\n- [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\n- Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns\n"
 },
 {
  "repo": "microsoft/google-play-vsts-extension",
  "language": "TypeScript",
  "readme_contents": "<table style=\"width: 100%; border-style: none;\"><tr>\n<td width=\"140px\" style=\"text-align: center;\"><img src=\"android_default.png\" style=\"max-width:100%\" /></td>\n<td><strong>Visual Studio Team Services Extension for Google Play</strong><br />\n<i>Provides build/release tasks that enable performing continuous delivery to the Google Play store from an automated VSTS build or release definition</i><br />\n<a href=\"https://marketplace.visualstudio.com/items/ms-vsclient.google-play\">Install now!</a>\n</td>\n</tr></table>\n\n# Visual Studio Team Services Extension for Google Play\n\n[![Build status](https://dev.azure.com/mseng/AzureDevOps/_apis/build/status/CrossPlatform.google-play-vsts-extension.GitHub.CI)](https://dev.azure.com/mseng/AzureDevOps/_build/latest?definitionId=5350)\n\nThis extension contains a set of deployment tasks which allow you to automate the release, promotion and rollout of app updates to the Google Play store from your CI environment. This can reduce the effort needed to keep your internal test, alpha, beta, rollout and production deployments up-to-date, since you can simply push changes to the configured source control branches, and let your automated build take care of the rest.\n\n## Prerequisites\n\nThis extension supports Visual Studio Team Services (VSTS) and Team Foundation Server (TFS) 2017 and later.\n\nIn order to automate the release of app updates to the Google Play store, you need to have manually released at least one version through the [Google Play Developer Console](https://play.google.com/apps/publish/). Additionally, you need to create a service account that is authorized to manage your app(s) releases on your behalf and can be used to authenticate \"headlessly\" from your VSTS build/release definitions. If you haven't already done so, then perform the following steps to create a service account:\n> For a more in depth guide [click this link](https://docs.microsoft.com/en-us/appcenter/distribution/stores/googleplay).\n\n1. Login to the [Google Play Developer Console](https://play.google.com/apps/publish/) and select **Settings** in the left-hand navigation menu (the gear icon)\n\n2. Select the **API access** setting and click the **Create Service Account** button underneath the **Service Accounts** section\n\n3. Follow the provided **Google Developers Console** hyperlink\n\n4. Click the **Create credentials** button in the displayed modal dialog, and select **Service account key** (with the role \"Owner\")\n\n5. Select **JSON** as the **Key type** and click the **Create** button\n\n6. Save the provided JSON file somewhere safe and memorable. You'll be using it later.\n\n7. Go to the **IAM** page and click on the **Add** button.\n\n8. Select the newly created service account in the **New members** box and assign it the  **Service Account User Role**, then click **Save**.\n\n9. Back in the **Google Play Developer Console**, click the **Done** button to close the modal\n\n10. Click the **Grant access** button in the row associated with the service account you just created.\n \n11. Ensure that the **Role** is set to **Release Manager** and then click the **Add user** button\n\nTo take advantage of the metadata updating capabilities, files need to be organized using fastlane\u2019s [supply tool](https://github.com/fastlane/fastlane/tree/master/supply#readme) format:\n\n1. Install the supply tool\n```\nsudo gem install supply\n```\n2. Navigate to your root folder \n```\ncd [your_project_folder]\n```\n3. Download metadata for an existing app to the  project folder\n```\nsupply init\n```\n\n## Quick Start\n\nOnce you have created or retrieved credentials for you Google Play service account, then perform the following steps to automate releasing updates from a VSTS build or release definition:\n\n1. Install the Google Play extension from the [VSTS Marketplace](https://marketplace.visualstudio.com/items/ms-vsclient.google-play)\n\n2. Go to your Visual Studio Team Services or TFS project, click on the **Build** tab, and create a new build definition (the \"+\" icon) that is hooked up to your project's appropriate source repo\n\n3. Click **Add build step...** and select the neccessary tasks to generate your release assets (e.g. **Gulp**, **Cordova Build**)\n\n4. Click **Add build step...** and select **Google Play - Release** from the **Deploy** category\n\n5. Configure the **Google Play - Release** task with the JSON private key file created above, the generated APK file, and the desired release track.\n\n6. Click the **Queue Build** button or push a change to your configured repo in order to run the newly defined build pipeline\n\n7. Your app changes will now be automatically published to the Google Play store!\n\n## Configuring Your Google Play Publisher Credentials\n\nIn addition to specifying your publisher credentials file directly within each build task, you can also configure your credentials globally and refer to them within each build or release definition as needed. To do this, perform the following steps:\n\n1. Setup a publishing manager (https://play.google.com/apps/publish/) and get the JSON key file from the [Google Developer API console](https://console.developers.google.com/apis)\n\n2. Go into your Visual Studio Team Services or TFS project and click on the gear icon in the lower left corner\n\n3. Click on the **Service Connections** tab\n\n4. Click on **New service connection** and select **Google Play**\n\n5. Give the new endpoint a name and enter the credentials for the publishing manager you generated in step#1. The credentials you need can be found in the JSON file and are the Email and the private key.\n\n6. Select this endpoint via the name you chose in #5 whenever you add either the **Google Play - Release** or **Google Play - Promote** tasks to a build or release definition\n\n## Task Reference\n\nIn addition to the custom service endpoint, this extension also contributes the following three build and release tasks:\n\n* [Google Play - Release](#google-play---release) - Allows automating the release of a new Android app version to the Google Play store.\n\n* [Google Play - Promote](#google-play---promote) - Allows automating the promotion of a previously released Android app update from one track to another (e.g. `alpha` -> `beta`).\n\n* [Google Play - Increase Rollout](#google-play---increase-rollout) - Allows automating increasing the rollout percentage of a previous release app update.\n\n* [Google Play - Release Bundle](#google-play---release-bundle) - Allows automating the release of a new Android bundle to the Google Play store.\n\n### Google Play - Release\n\nAllows you to release an update to your app on Google Play, and includes the following options:\n\n1. **JSON Key Path** *(File path)* or **Service Endpoint** - The credentials used to authenticate with Google Play. This can be acquired from the [Google Developer API console](https://console.developers.google.com/apis) and provided either directly to the task (via the `JSON Auth File` authentication method), \n\n    ![JSON Auth File](images/auth-with-json-file.png)\n\n    or configured within a service endpoint that you reference from the task (via the `Service Endpoint` authentication method). \n\n    ![Service Endpoint](images/auth-with-endpoint.png)\n\n    Note that in order to use the JSON Auth File method, the JSON file you get from the developer console needs to be checked into your source repo.\n\n\n2. **APK Path** *(File path, Required)* - Path to the APK file you want to publish to the specified track.\n\n    ![APK Path](images/apk-path.png)\n\n3. **Track** *(String, Required)* - Release track to publish the APK to.\n\n    ![Track](images/track.png)\n\n4. **Rollout Fraction** *(String, Required if visible)* - The percentage of users to roll the specified APK out to, specified as a number between 0 and 1 (e.g. `0.5` == `50%` of users). This option is only available when the **Track** input is set to **Rollout**.\n\n    ![Rollout Fraction](images/rollout-fraction.png)\n\n5. **Release Notes** *(File path)* - Path to the file specifying the release notes for the APK you are publishing.\n\n    ![Release Notes](images/release-notes.png)\n\n6. **Language Code** *(String, Optional)* - An IETF language tag identifying the language of the release notes as specified in the BCP-47 document. Default value is _en-US_.\n\n7. **Update Metadata** *(Boolean, Optional)* - Allows automating metadata updates to the Google Play store by leveraging the contents of the `Metadata Root Directory`.\n\n    ![Update Metadata](images/update-metadata.png)\n\n8. **Metadata Root Directory** *(String, Required if visible)* - Root directory for metadata related files. Becomes available after enabling the `Update Metadata` option. Expects a format similar to fastlane\u2019s [supply tool](https://github.com/fastlane/fastlane/tree/master/supply#readme) which is summarized below:\n \n```\n$(Specified Directory)\n   \u2514 $(languageCodes)\n     \u251c full_description.txt\n     \u251c short_description.txt\n     \u251c title.txt\n     \u251c video.txt\n     \u251c images\n     |  \u251c featureGraphic.png    || featureGraphic.jpg   || featureGraphic.jpeg\n     |  \u251c icon.png              || icon.jpg             || icon.jpeg\n     |  \u251c promoGraphic.png      || promoGraphic.jpg     || promoGraphic.jpeg\n     |  \u251c tvBanner.png          || tvBanner.jpg         || tvBanner.jpeg\n     |  \u251c phoneScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u251c sevenInchScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u251c tenInchScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u251c tvScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u2514 wearScreenshots\n     |     \u2514 *.png || *.jpg || *.jpeg\n     \u2514 changelogs\n       \u2514 $(versioncodes).txt\n```\n\n9. **Update only store listing**  *(Boolean, Optional)* - By default, the task will update the specified track and selected APK file(s) will be assigned to the related track. By selecting this option you can update only store listing. Default value is _false_. \n\n    ![Advanced Options](images//update-store-listing.png)\n\n10. **Update APK(s)** *(Boolean, Optional)* - By default, the task will update the specified binary APK file(s) on your app release. By unselecting this option you can update metadata keeping the APKs untouched. Default value is _true_.\n\n    ![Update APKs](images/update-apks.png)\n\n#### Advanced Options\n\n1. **Additional APK Path(s)** *(Text box)* - Paths to additional APK files you want to publish to the specified track (e.g. an x86 build) separated by new lines. This option allows the usage of wildcards and/or minimatch patterns. For example, **/*.apk to match the first APK file, in any directory.\n\n    ![Advanced Options](images/advanced-options.png)\n\n2. **Replace version codes** *(String, Required)* - You may specify which APK version codes should be replaced in the track with this deployment. Available options are: *All*, *List* - comma separated list of version codes, *Regular expression* - a regular expression pattern to select a list of APK version codes to be removed from the track with this deployment, e.g. _.\\\\*12?(3|4)?5_ \n\n### Google Play - Promote\n\nAllows you to promote a previously released APK from one track to another (e.g. `alpha` -> `beta`), and includes the following options:\n\n![Promote task](images/promote-task.png)\n\n1. **JSON Key Path** *(File path)* or **Service Endpoint** - The credentials used to authenticate with Google Play. This can be acquired from the [Google Developer API console](https://console.developers.google.com/apis) and provided either directly to the task (via the `JSON Auth File` authentication method), or configured within a service endpoint that you reference from the task (via the `Service Endpoint` authentication method). Note that in order to use the JSON Auth File method, the JSON file you get from the developer console needs to be checked into your source repo.\n\n2. **Package Name** *(String, Required)* - The unique package identifier (e.g. `com.foo.myapp`) that you wish to promote.\n\n3. **Source Track** *(Required, Required)* - The track you wish to promote your app from (e.g. `alpha`). This assumes that you previously released an update to this track, potentially using the [`Google Play - Release`](#google-play---release) task.\n\n4. **Destination Track** *(Required, Required)* - The track you wish to promote your app to (e.g. `production`).\n\n5. **Rollout Fraction** *(String, Required if visible)* - The percentage of users to roll the app out to, specified as a number between 0 and 1 (e.g. `0.5` == `50%` of users). This option is only available when the **Destination Track** option is set to `Rollout`. If you use rollout, and want to be able to automate the process of increasing the rollout over time, refer to the `Google Play - Increase Rollout` task.\n\n### Google Play - Increase Rollout\n\nAllows you to increase the rollout percentage of an app that was previously released to the **Rollout** track, and includes the following options:\n\n![Increase task](images/increase-task.png)\n\n1. **JSON Key Path** *(File path)* or **Service Endpoint** - The credentials used to authenticate with Google Play. This can be acquired from the [Google Developer API console](https://console.developers.google.com/apis) and provided either directly to the task (via the `JSON Auth File` authentication method), or configured within a service endpoint that you reference from the task (via the `Service Endpoint` authentication method). Note that in order to use the JSON Auth File method, the JSON file you get from the developer console needs to be checked into your source repo.\n\n2. **Package Name** *(String, Required)* - The unique package identifier (e.g. com.foo.myapp) of the app you wish to increase the rollout percentage for.\n\n3. **Rollout Fraction** *(String, Required)* - The new user fraction to increase the rollout to, specified as a number between 0 and 1 (e.g. `0.5` == `50%` of users)\n\n### Google Play - Release Bundle\n\nAllows you to release an app bundle to Google Play, and includes the following options:\n\n1. **JSON Key Path** *(File path)* or **Service Endpoint** - The credentials used to authenticate with Google Play. This can be acquired from the [Google Developer API console](https://console.developers.google.com/apis) and provided either directly to the task (via the `JSON Auth File` authentication method), \n\n    ![JSON Auth File](images/auth-with-json-file.png)\n\n    or configured within a service endpoint that you reference from the task (via the `Service Endpoint` authentication method). \n\n    ![Service Endpoint](images/auth-with-endpoint.png)\n\n    Note that in order to use the JSON Auth File method, the JSON file you get from the developer console needs to be checked into your source repo.\n    Please note that from the point of security it's preferrable to store it as [Secure file](https://docs.microsoft.com/azure/devops/pipelines/library/secure-files) and download using [Download Secure File task](https://docs.microsoft.com/azure/devops/pipelines/tasks/utility/download-secure-file).\n\n\n2. **Application Id** *(String, Required)* - The application id of the bundle you want to release, e.g. com.company.MyApp.\n\n    ![Application id](images/bundle-app-id.png)\n\n3. **Bundle Path** *(File path, Required)* - Path to the bundle (.aab) file you want to publish to the specified track. Wildcards can be used. For example, **/*.aab to match the first APK file, in any directory.\n\n4. **Track** *(String, Required)* - Track you want to publish the bundle to.\n\n5. **Roll out Release** *(Boolean, Optional)* - Roll out the release to a percentage of users.\n\n6. **Update Metadata** *(Boolean, Optional)* - Allows automating metadata updates to the Google Play store by leveraging the contents of the `Metadata Root Directory`.\n\n7. **Release Notes (file)** *(File path, Required if visible)* - Path to the file specifying the release notes (change log) for the APK you are publishing.\n\n    ![Release Notes](images/bundle-release-notes.png)\n\n8. **Language Code** *(String, Required if visible)* - An IETF language tag identifying the language of the release notes as specified in the BCP-47 document. Default value is _en-US_.\n\n9. **Deobfuscation Path** *(String, Optional)* - The path to the proguard mapping.txt file to upload.\n\n10. **Rollout Fraction** *(String, Optional)* - The percentage of users the specified APK will be released to for the specified 'Track'. It can be increased later with the 'Google Play - Increase Rollout' task.\n\n11. **Metadata Root Directory** *(String, Required)* - Root directory for metadata related files. Becomes available after enabling the `Update Metadata` option. Expects a format similar to fastlane\u2019s [supply tool](https://github.com/fastlane/fastlane/tree/master/supply#readme) which is summarized below:\n \n```\n$(Specified Directory)\n   \u2514 $(languageCodes)\n     \u251c full_description.txt\n     \u251c short_description.txt\n     \u251c title.txt\n     \u251c video.txt\n     \u251c images\n     |  \u251c featureGraphic.png    || featureGraphic.jpg   || featureGraphic.jpeg\n     |  \u251c icon.png              || icon.jpg             || icon.jpeg\n     |  \u251c promoGraphic.png      || promoGraphic.jpg     || promoGraphic.jpeg\n     |  \u251c tvBanner.png          || tvBanner.jpg         || tvBanner.jpeg\n     |  \u251c phoneScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u251c sevenInchScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u251c tenInchScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u251c tvScreenshots\n     |  |  \u2514 *.png || *.jpg || *.jpeg\n     |  \u2514 wearScreenshots\n     |     \u2514 *.png || *.jpg || *.jpeg\n     \u2514 changelogs\n       \u2514 $(versioncodes).txt\n```\n\n12. **Upload Deobfuscation File (mapping.txt)** *(Boolean, Optional)* - Select this option to attach your proguard mapping.txt file to the primary APK.\n\n#### Advanced Options\n\n1. **Replace Version Codes** *(String, Optional)* - Specify version codes to replace in the selected track with the new APKs: all, the comma separated list, or a regular expression pattern.\n\n    ![Advanced Options](images/bundle-advanced-options.png)\n\n2. **Version Code List** *(String, Required if visible)* - The comma separated list of APK version codes to be removed from the track with this deployment. Available options are: *All*, *List* - comma separated list of version codes, *Regular expression* - a regular expression pattern to select a list of APK version codes to be removed from the track with this deployment, e.g. _.\\\\*12?(3|4)?5_ \n\n3. **Version Code Pattern** *(String, Required if visible)* - The regular expression pattern to select a list of APK version codes to be removed from the track with this deployment, e.g. .*12?(3|4)?5\n\n\n#### Advanced Options\n\n1. **Replace version codes** *(String, Required)* - You may specify which APK version codes should be replaced in the track with this deployment. Available options are: *All*, *List* - comma separated list of version codes, *Regular expression* - a regular expression pattern to select a list of APK version codes to be removed from the track with this deployment, e.g. _.\\\\*12?(3|4)?5_ \n\n## Contact Us\n\n* [Report an issue](https://github.com/Microsoft/google-play-vsts-extension/issues)\n\nGoogle Play and the Google Play logo are trademarks of Google Inc.\n\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/Bing-Maps-Fleet-Tracker",
  "language": "C#",
  "readme_contents": "# Bing Maps Fleet Tracker\n\nBing Maps Fleet Tracker is a fleet management solution based on the Bing Maps APIs. It offers functionalities that enable tracking and managing a fleet of vehicles in real time. For more details, read this [blog post](https://aka.ms/bingmapsfleettrackerblog).\n\n## Getting Started\n\nThere are two parts to the set-up process:\n1. Set up the back-end services and administration portal;\n2. Set up the mobile client.\n\n#### Step 1: \nThe easiest way to set up the back-end services and administration portal is to use the [Bing Maps Fleet Tracker Deployment Portal](https://bingmapsfleettracker.azurewebsites.net), which one-click deploys the Bing Maps Fleet Tracker solution into your Azure subscription. For a step by step walk-through of how to deploy, use the deployment portal: see [out of the box deployment](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/DEPLOYMENT.md). **None** of the data entered on the deployment portal is stored by Bing Maps Fleet Tracker. It is only used to configure your deployment.\n\nAfter deploying the back-end services and administration portal successfully, you can find the walk-through of using the Bing Maps Fleet Tracker solution [here](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/WALKTHROUGH.md).\n\nYou can also build and run the back-end services and administration portal from source as detailed [here](#build-and-run).\n\n#### Step 2:\n##### Android client:\nThe easiest way to set up Android client is to download the prebuilt apk from [here](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/releases). You can also build and run the Android client from source as detailed [here](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/MobileClient/README.md#android).\n\n##### iOS client:\nYou will need to build and run the iOS client from source as detailed [here](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/MobileClient/README.md#ios).\n\n## Build and Run\n\nThe Bing Maps Fleet Tracker solution consist of 3 major components:\n\n* [The Backend Services](#backend-services)\n* [The Administration Portal](#administration-portal)\n* [The Mobile Client](#mobile-client)\n\nEach of these components can be built and run separately, and each can be replaced with implementations of your own.\n\n#### Backend Services\n\nThe backend services are responsible for the collection and processing of location information, the provisioning of tracking devices and assets, dispatching, and report generation. They are made up of an ASP.NET Core 2 service, and two Azure Functions. For more information on building an running the backend services see [Backend\\README.md](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/Backend/README.md).\n\n#### Administration Portal\n\nThe administration portal is an angular application that exposes the functionalities of the backend to the deployment administrators. It can be used to view reports, track and provision assets, and compare dispatching routes. For more information on building an running the administration portal see [Frontend\\README.md](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/Frontend/README.md).\n\n#### Mobile Client\n\nThe mobile client is an ionic mobile application responsible for collection of asset location information and the forwarding of this information to the backend. It is meant to provide an out of the box background tracking solution but it is not the only way to integrate with Bing Maps Fleet Tracker; any GPS device with an internet connection can be used to provide the background tracking (see [Using the Rest APIs](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/WALKTHROUGH.md#using-the-rest-apis)). For more information on building and running the mobile client see [MobileClient\\README.md](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/blob/master/MobileClient/README.md).\n\n## Telemetry collected by Bing Maps Fleet Tracker\n\nAfter deployment, on your first use of the application, you will be prompted to allow us to collect\nanonymous aggregate telemetry and error/warning log data. We use the telemetry data to get a feel for the\nusage of this project. Error log data are used to focus our efforts on fixing the issues you face.\n\nHere is a list of all the telemetry items we collect:\n\n* Deployment Id: this is a random GUID that is unique for each deployment.\n* Assets count: the total number of vehicles registered.\n* Locations count: the total number of locations stored.\n* Auto locations count: the number of automatically detected locations.\n* Tracking devices count: the total number of tracking devices.\n* Geo-fences count: the number of geo-fences setup.\n* Tracking points count: the number of tracking points stored on the system.\n\nError/warning log data collected consist of:\n\n* Deployment Id: this is a random GUID that is unique for each deployment.\n* Software version: the version of the software causing the error/warning.\n* Error/warning message: the error/warning message.\n\nYou can always enable/disable the data collection from the settings tab in your administration portal.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [https://cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## History\n\nSee [release history](https://github.com/Microsoft/Bing-Maps-Fleet-Tracker/releases).\n"
 },
 {
  "repo": "microsoft/redux-dynamic-modules",
  "language": "TypeScript",
  "readme_contents": "<div>\r\n<img src=\"docs/redux-dynamic-modules.png\" alt=\"logo\" width=\"100\">\r\n</img>\r\n<h1>Redux Dynamic Modules</h1<\r\n</div>\r\n\r\n[![Pipelines](https://dev.azure.com/redux-dynamic-modules/redux-dynamic-modules/_apis/build/status/Microsoft.redux-dynamic-modules?branchName=master)](https://dev.azure.com/redux-dynamic-modules/redux-dynamic-modules/redux-dynamic-modules%20Team/_build?definitionId=1&_a=summary) [![npm (scoped)](https://img.shields.io/npm/v/redux-dynamic-modules.svg)](https://npmjs.org/package/redux-dynamic-modules) [![Join the chat at https://gitter.im/redux-dynamic-modules/community](https://badges.gitter.im/redux-dynamic-modules/community.svg)](https://gitter.im/redux-dynamic-modules/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) ![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)\r\n\r\n## What is it?\r\n\r\n**redux-dynamic-modules** is a library that aims to make Redux Reducers and middleware easy to modular-ize and add/remove dynamically.\r\n\r\n## Motivation\r\n\r\nIn large Javascript applications, it is often desired to perform some kind of code-splitting, so that the initial script size is small. However, in Redux, you are required to define your reducers and middleware up-front; there is no good way to dynamically add/remove these constructs at runtime.\r\n\r\n**redux-dynamic-modules** is designed to make dynamically loading these constructs easier. You can define a **module**, which contains reducers and middleware, and add it to the Redux store at runtime. We also provide a React component `DynamicModuleLoader`, which can load/unload modules on mount/unmount.\r\n\r\nModules provide the following benefits:\r\n\r\n-   Modules can be easily re-used across the application, or between multiple similar applications.\r\n-   Components declare the modules needed by them and redux-dynamic-modules ensures that the module is loaded for the component.\r\n-   Modules can be added/removed from the store dynamically, ex. when a component mounts or when a user performs an action\r\n\r\n## Features\r\n\r\n-   Group together reducers, middleware, and state into a single, re-usable module.\r\n-   Add and remove modules from a Redux store at any time.\r\n-   Use the included `<DynamicModuleLoader />` component to automatically add a module when a component is rendered\r\n-   Extensions provide integration with popular libraries, including `redux-saga` and `redux-thunk`\r\n\r\n## Example Scenarios\r\n\r\n-   You don't want to load the code for all your reducers up front. Define a module for some reducers and use `DynamicModuleLoader` and a library like [react-loadable](https://github.com/jamiebuilds/react-loadable) to download and add your module at runtime.\r\n-   You have some common reducers/middleware that need to be re-used in different areas of your application. Define a module and easily include it in those areas.\r\n-   You have a mono-repo that contains multiple applications which share similar state. Create a package containing some modules and re-use them across your applications\r\n\r\n## Install\r\n\r\nRun\r\n\r\n```\r\nnpm install redux-dynamic-modules\r\n```\r\n\r\nor\r\n\r\n```\r\nyarn add redux-dynamic-modules\r\n```\r\n\r\n## Usage\r\n\r\n-   Create a module with the following format\r\n\r\n```typescript\r\nexport function getUsersModule(): IModule<IUserState> {\r\n    return {\r\n        id: \"users\",\r\n        reducerMap: {\r\n            users: usersReducer,\r\n        },\r\n        // Actions to fire when this module is added/removed\r\n        // initialActions: [],\r\n        // finalActions: []\r\n    };\r\n}\r\n```\r\n\r\n-   Create a `ModuleStore`\r\n\r\n```typescript\r\nimport { createStore, IModuleStore } from \"redux-dynamic-modules\";\r\nimport { getUsersModule } from \"./usersModule\";\r\n\r\nconst store: IModuleStore<IState> = createStore({\r\n      initialState: { /** initial state */ },\r\n      enhancers: [ /** enhancers to include */ ], \r\n      extensions: [/** extensions to include i.e. getSagaExtension(), getThunkExtension() */],\r\n},\r\n    getUsersModule()\r\n    /* ...any additional modules */\r\n);\r\n```\r\n\r\n-   Use like a standard Redux store\r\n-   Use the `DynamicModuleLoader` React component to add/remove modules when components mount/unmount\r\n\r\n```jsx\r\n<DynamicModuleLoader modules={[getHelloWorldModule()]}>\r\n    <div>Hello World!!</div>\r\n</DynamicModuleLoader>\r\n```\r\n\r\n## Extensions\r\n\r\n-   redux-saga - [redux-dynamic-modules-saga](https://www.npmjs.com/package/redux-dynamic-modules-saga)\r\n-   redux-thunk - [redux-dynamic-modules-thunk](https://www.npmjs.com/package/redux-dynamic-modules-thunk)\r\n\r\n## Examples\r\n\r\nSee the [Widgets](https://github.com/Microsoft/redux-dynamic-modules/tree/master/packages/widgets-example) for a quick of example of the library in practice.\r\n\r\nStep by step walthrough of start consuming `redux-dynamic-modules` in the widget app. [Youtube](https://www.youtube.com/watch?v=SktRbSZ-4Tk)\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/azure_arc",
  "language": "PowerShell",
  "readme_contents": "# Azure Arc Jumpstart documentation\n\nIf you are looking to explore the Jumpstart documentation, please go to the documentation website:\n\nhttps://azurearcjumpstart.io\n\nThis repository contains the markdown files which generate the above website. See below for guidance on running with a local environment to contribute to the docs.\n\n## Want to help and contribute?\n\nBefore making your first contribution, make sure to review the [contributing](https://azurearcjumpstart.io/contributing/) section in the docs.\n\n* Found a bug?! Use the [Bug Report](https://github.com/microsoft/azure_arc/issues/new?assignees=&labels=bug&template=bug_report.md&title=) issue template to let us know.\n\n* To ask for a Jumpstart scenario, create one yourself or submit an Azure Arc core product feature request, use the [Feature Request](https://github.com/microsoft/azure_arc/issues/new?assignees=&labels=&template=feature_request.md&title=) issue template.\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Jumpstart Roadmap\n\nUp-to-date roadmap for the Azure Arc Jumpstart scenarios can be found under [the repository GitHub Project](https://github.com/microsoft/azure_arc/projects/1).\n\n## Legal Notices\n\nMicrosoft and any contributors grant you a license to the Microsoft documentation and other content\nin this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),\nsee the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the\n[LICENSE-CODE](LICENSE-CODE) file.\n\nMicrosoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation\nmay be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\nThe licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\nMicrosoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n\nPrivacy information can be found at https://privacy.microsoft.com/\n\nMicrosoft and any contributors reserve all other rights, whether under their respective copyrights, patents,\nor trademarks, whether by implication, estoppel or otherwise.\n"
 },
 {
  "repo": "microsoft/Cloud-Native-In-a-Day",
  "language": "CSS",
  "readme_contents": "# Cloud Native In a Day\n\nThis workshop is designed for Microsoft partners to drive the adoption of cloud native technologies on Azure across customers. It includes whiteboard design session materials and hands-on lab. Content is based on Microsoft Cloud Workshops, that are widely used by Microsoft specialists and solution architects.\n\nApril 2020\n\n## Before you start\n\n- Take a look at a partner marketing materials for [Cloud Native In a Day](https://partner.microsoft.com/en-us/asset/collection/cloud-native-in-a-day)\n- Review [How to deliver Cloud Native In a Day workshop](https://note.microsoft.com/US-NOGEP-WBNR-FY20-05May-14-CloudNativeApps-SRDEM17754_Registration.html) session recording\n\n## Abstracts\n\n### Workshop\n\nFabrikam Medical Conferences provides conference web site services, tailored to the medical community. Their business has grown and the management of many instances of the code base and change cycle per tenant has gotten out of control.\n\nThe goal of this workshop is to help them build a proof of concept (POC) that will migrate their code to a more manageable process that involves containerization of tenant code, a better DevOps workflow, and a simple lift-and-shift story for their database backend.\n\nIn this workshop, you will build a proof of concept (POC) that will transform an existing on-premises application to a container-based application. This POC will deliver a multi-tenant web app hosting solution leveraging Azure Kubernetes Service (AKS), Docker containers on Linux nodes, and a migration from MongoDB to Cosmos DB.\n\nAt the end of this workshop, you will be better able to improve the reliability of and increase the release cadence of your container-based applications through time-tested DevOps practices.\n\n### Part I: Presentation\nStart from presenting Cloud Native applications on Azure story using the [included deck.](Presentation) Presentation should take 60-90 minutes and introduce the aspects of cloud native apps and value that they bring.\n\n### Part II: Whiteboard Design Session\n\nDuring [whiteboard design session](Whiteboard%20design%20session), you will discuss the choices related to building and deploying containerized applications in Azure, critical decisions around this, and other aspects of the solution, including ways to lift-and-shift parts of the application to reduce applications changes.\n\nBy the end of this design session, you will design solutions that target Azure Kubernetes Service (AKS) and define a DevOps workflow for containerized applications.\n\nPackage includes presenter deck, presenter guide and student guide.\n\nIf you are delivering the session remotely, we suggest to use [Microsoft Teams](https://products.office.com/microsoft-teams) and [Microsoft Whiteboard.](https://whiteboard.microsoft.com)\n\n### Part III: Hands-on Lab\n\n[Hands-on lab](Hands-on%20lab) is designed to guide attendees through the process of building and deploying Docker images to the Kubernetes platform hosted on Azure Kubernetes Services (AKS), in addition to learning how to work with dynamic service discovery, service scale-out, and high-availability.\n\nAt the end of this lab, attendees will be better able to build and deploy containerized applications to Azure Kubernetes Service and perform common DevOps procedures.\n\n## Azure services and related products\n\n- Azure Kubernetes Service (AKS)\n- Azure Container Registry\n- Azure DevOps\n- Docker\n- Cosmos DB (including MongoDB API)\n\n## Related references\n\n- [MCW](https://github.com/Microsoft/MCW)\n\n## Help & Support\n\nWe welcome feedback and comments from Microsoft SMEs & learning partners who deliver MCWs.  \n\n***Having trouble?***\n- First, verify you have followed all written lab instructions (including the Before the Hands-on lab document).\n- Next, create a new Issue in the repo with detailed description of the issue and any troubleshooting steps performed.\n\nIf you are planning to present a workshop, *review and test the materials early*! We recommend at least two weeks prior.\n\nLeave your comments by creating a new topic in Issues section or send an email to appinnovationinaday@microsoft.com with any questions.\n"
 },
 {
  "repo": "microsoft/vscode-java-pack",
  "language": "TypeScript",
  "readme_contents": "# Java Extension Pack\n\nJava Extension Pack is a collection of popular extensions that can help write, test and debug Java applications in Visual Studio Code. Check out [Java in VS Code](https://code.visualstudio.com/docs/languages/java) to get started.\n\n## Extensions Included\n\nBy installing Java Extension Pack, the following extensions are installed:\n\n- [\ud83d\udce6 Language Support for Java\u2122 by Red Hat ](https://marketplace.visualstudio.com/items?itemName=redhat.java)\n    - Code Navigation\n    - Auto Completion\n    - Refactoring\n    - Code Snippets\n- [\ud83d\udce6 Debugger for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-debug)\n    - Debugging\n- [\ud83d\udce6 Java Test Runner](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-test)\n    - Run & Debug JUnit/TestNG Test Cases\n- [\ud83d\udce6 Maven for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-maven)\n    - Project Scaffolding\n    - Custom Goals\n- [\ud83d\udce6 Project Manager for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-dependency)\n    - Manage Java projects, referenced libraries, resource files, packages, classes, and class members\n- [\ud83d\udce6 Visual Studio IntelliCode](https://marketplace.visualstudio.com/items?itemName=VisualStudioExptTeam.vscodeintellicode)\n    - AI-assisted development\n    - Completion list ranked by AI\n\n## Other Recommendations\n\nYou can do more with VS Code. Here are some more recommendations that could help.\n\n### Spring\n\nSpring Tools 4 (ST4) is also available in Visual Studio Code. It understands Spring so you can navigate Spring code at the level of beans, routes, etc. It can also show live information of the running Spring Boot applications. Check out [the ST4 website](https://spring.io/tools) to see a complete list of its features.\n\nTo use ST4, install [\ud83d\udce6 Spring Boot Extension Pack](https://marketplace.visualstudio.com/items?itemName=Pivotal.vscode-boot-dev-pack). Please also check out the [User Guide](https://github.com/spring-projects/sts4/wiki) to make the most of it.\n\n### Eclipse MicroProfile\n\nThe [\ud83d\udce6 Extension Pack for MicroProfile](https://marketplace.visualstudio.com/items?itemName=MicroProfile-Community.vscode-microprofile-pack) is a collection of extensions that can help develop your Java microservices using [Eclipse MicroProfile](https://microprofile.io/). You can quickly generate a MicroProfile project and utilize development tools for runtimes such as [Open Liberty](https://openliberty.io/) and [Quarkus](https://quarkus.io/).\n\n### Quarkus\n\n[\ud83d\udce6 Quarkus Tools for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=redhat.vscode-quarkus) is a feature-packed extension tailored for Quarkus application\ndevelopment within Visual Studio Code. You can quickly get started by using the extension's\nproject generation and project debugging feature. The extension also provides amazing\nlanguage features (completion, hover, validation etc.) for your project's application.properties file.\n\n### Containers and Microservices\n\nYou can use [\ud83d\udce6 Docker](https://marketplace.visualstudio.com/items?itemName=PeterJausovec.vscode-docker) extension to build docker images and work with image registries.\n\n[\ud83d\udce6 Kubernetes](https://marketplace.visualstudio.com/items?itemName=ms-kubernetes-tools.vscode-kubernetes-tools) extension provides an explorer view to manage clusters and the nodes inside. It also provides advanced syntax support for editing Kubernetes manifest files.\n\n### Tomcat and Jetty\n\nBoth [\ud83d\udce6 Tomcat](https://marketplace.visualstudio.com/items?itemName=adashen.vscode-tomcat) and [\ud83d\udce6 Jetty](https://marketplace.visualstudio.com/items?itemName=SummerSun.vscode-jetty) extension are available. They provide dedicated views to help work with your favorite web servers.\n\n### Linting\nThe [\ud83d\udce6 SonarLint](https://marketplace.visualstudio.com/items?itemName=SonarSource.sonarlint-vscode) extension lets you detect bugs and vulnerabilities as you write code in VS Code. The extension will simply run in the background and highlight code that poses a quality or security concern.\n\nAt the same time, [\ud83d\udce6 CheckStyle](https://marketplace.visualstudio.com/items?itemName=shengchen.vscode-checkstyle) is also available.\n\n## Questions & Issues\n\nEach extension mentioned above is a separate open-source project and has its own repository. To make things easier, simply [\ud83d\ude4b open an issue in this repository](https://github.com/Microsoft/vscode-java-pack/issues). The new issue will be triaged and redirected.\n\n## Telemetry\n\nThis extension collects telemetry data to help us build a better experience for building Java applications with VS Code. We only collect data on which commands are executed. We do not collect any information about names, addresses, paths, etc. The extension respects the `telemetry.enableTelemetry` setting which you can learn more about in our [FAQ](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting).\n\n## License\n\n[MIT](https://github.com/Microsoft/vscode-java-pack/blob/master/LICENSE.txt)\n\nHappy Coding!\n"
 },
 {
  "repo": "microsoft/tfs-cli",
  "language": "TypeScript",
  "readme_contents": "# Node CLI for Azure DevOps\n\n> NOTE: If you are looking for the new Azure DevOps CLI, see [vsts-cli](https://github.com/microsoft/vsts-cli)\n\n[![NPM version](https://badge.fury.io/js/tfx-cli.svg)](http://badge.fury.io/js/tfx-cli)\n\nCommand utility for interacting with Microsoft Team Foundation Server and Azure DevOps Services (formerly VSTS). It is cross platform and supported on Windows, OS X, and Linux.\n\n## Setup\n\nFirst, download and install [Node.js](http://nodejs.org) 4.0.x or later and NPM (included with the installer)\n\n### Linux/OSX\n```bash\nsudo npm install -g tfx-cli\n```\n\n### Windows\n```bash\nnpm install -g tfx-cli\n```\n\n## Commands\n\nTo see a list of commands:\n```\ntfx\n```\n\nFor help with an individual command:\n```\ntfx <command> --help\n```\n\n> Help info is dynamically generated, so it should always be the most up-to-date authority.\n\n### Command sets\n\n* `tfx build` ([builds](docs/builds.md)): Queue, view, and get details for builds\n* `tfx build tasks` ([build tasks](docs/buildtasks.md)): Create, list, upload and delete build tasks\n* `tfx extension` ([extensions](docs/extensions.md)): Package, manage, publish Team Foundation Server / Azure DevOps extensions\n* `tfx workitem` ([work items](docs/workitems.md)): Create, query and view work items.\n\n### Login\n\nTo avoid providing credentials with every command, you can login once. Currently supported credential types: Personal Access Tokens and basic auth credentials.\n\n> NTLM support is under consideration\n\n> Warning! Using this feature will store your login credentials on disk in plain text.\n\n#### Personal access token\n\nStart by [creating a personal access token](http://roadtoalm.com/2015/07/22/using-personal-access-tokens-to-access-visual-studio-online) and paste it into the login command.\n\n```bash\n~$ tfx login\nCopyright Microsoft Corporation\n\n> Service URL: {url}\n> Personal access token: xxxxxxxxxxxx\nLogged in successfully\n```\n\nExamples of valid URLs are:\n\n* `https://marketplace.visualstudio.com` \n* `https://youraccount.visualstudio.com/DefaultCollection`\n\n#### Basic auth\n\nYou can alternatively use basic auth by passing `--auth-type basic` (see [Configuring Basic Auth](docs/configureBasicAuth.md)).\n\n### Settings cache\n\nTo avoid providing other options in every command, you can save options out to a settings file by adding the `--save` flag.\n\n```bash\n~$ tfx build list --project MyProject --definition-name println --top 5 --save\n\n...\n\nid              : 1\ndefinition name : TestDefinition\nrequested by    : Teddy Ward\nstatus          : NotStarted\nqueue time      : Fri Aug 21 2015 15:07:49 GMT-0400 (Eastern Daylight Time)\n\n~$ tfx build list\nCopyright Microsoft Corporation\n\n...\n\nid              : 1\ndefinition name : TestDefinition\nrequested by    : Teddy Ward\nstatus          : NotStarted\nqueue time      : Fri Aug 21 2015 15:07:49 GMT-0400 (Eastern Daylight Time)\n```\n\nIf you used `--save` to set a default value for an option, you may need to override it by explicitly providing the option with a different value. You can clear any saved settings by running `tfx reset`. \n\n### Troubleshooting\n\nTo see detailed tracing output, you can set a value for the `TFX_TRACE` environment value and then run commands.  That may offer a clue into the problem (and will certainly help if logging an issue).\n\n### Linux/OSX\n```bash\nexport TFX_TRACE=1\n```\n\n### Windows\n```bash\nset TFX_TRACE=1\n```\n\n### PowerShell\n```bash\n$env:TFX_TRACE=1\n```\n\n## Contributing\n\nWe take contributions and fixes via Pull Request. [Read here](docs/contributions.md) for the details.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/vscode-edge-debug2",
  "language": "TypeScript",
  "readme_contents": "<h1 align=\"center\">\n  <br>\n  VS Code - Debugger for Microsoft Edge\n  <br>\n</h1>\n\n<h4 align=\"center\">Debug your JavaScript code running in Microsoft Edge from VS Code and Visual Studio.</h4>\n\nA VS Code extension to debug your JavaScript code in the Microsoft Edge browser. This is also used to enable JavaScript debugging inside the Microsoft Edge browser when launched from ASP.Net Projects in Visual Studio.\n\n**Note:** This extension currently supports both Microsoft Edge (Chromium) and Microsoft Edge (EdgeHTML). This extension can debug any version of Microsoft Edge (Chromium) but only some versions of Microsoft Edge (EdgeHTML). To see if your Windows version supports debugging Microsoft Edge (EdgeHTML) via Edge DevTools Protocol, please refer [here](https://docs.microsoft.com/en-us/microsoft-edge/devtools-protocol/).\n\n**Supported features**\n* Setting breakpoints, including in source files when source maps are enabled\n* Stepping through the code\n* The Locals pane\n* Debugging eval scripts, script tags, and scripts that are added dynamically\n* Watches\n\n**Unsupported scenarios**\n* Debugging web workers\n* Any features that aren't script debugging.\n\n## Getting Started\n\n### For debugging inside VS Code\n1. [Install the extension.](https://marketplace.visualstudio.com/items?itemName=msjsdiag.debugger-for-edge)\n2. Open the folder containing the project you want to work on.\n\n### For debugging Microsoft Edge (EdgeHTML or Chromium) inside Visual Studio\n1. Install a supported version of Windows.\n2. Install the latest version of Visual Studio. Debugging Microsoft Edge (EdgeHTML) is supported for VS versions >= 15.7. Debugging Microsoft Edge (Chromium) is supported for VS versions >= 15.9.19.\n3. Create an ASP.Net/ASP.Net Core Web Application.\n4. Set a breakpoint in your JavaScript/TypeScript file.\n5. Select 'Microsoft Edge' from the 'Web Browser' submenu in the debug target dropdown, and then press F5.\n\n### For enabling both Microsoft Edge (EdgeHTML) and Microsoft Edge (Chromium) in Visual Studio\nBy default, installing Microsoft Edge (Chromium) will overwrite Microsoft Edge (EdgeHTML). To enable both browsers:\n1. [Download Microsoft Edge group policy templates.](https://www.microsoftedgeinsider.com/en-us/enterprise)\n2. After extracting the template files above, copy the files as shown below:\n\nSource | Destination\n--- | ---\n<zip&#x2011;extract&#x2011;location>\\MicrosoftEdgePolicyTemplates\\windows\\admx\\\\*.admx | C:\\Windows\\PolicyDefinitions\n<zip&#x2011;extract&#x2011;location>\\MicrosoftEdgePolicyTemplates\\windows\\admx\\\\<your-locale\\>\\\\*.adml | C:\\Windows\\PolicyDefinitions\\\\<your-locale\\>\n\n3. Follow [these instructions](https://docs.microsoft.com/en-us/deployedge/microsoft-edge-sysupdate-access-old-edge) to enable side by side installations.\n\n## Using the debugger\nWhen your launch config is set up, you can debug your project. Pick a launch config from the dropdown on the Debug pane in Code. Press the play button or F5 to start.\n\n### Configuration\nThe extension operates in two modes - it can launch an instance of Microsoft Edge navigated to your app, or it can attach to a running instance of Edge. Both modes require you to be serving your web application from a local web server, which is started from either a VS Code task or from your command-line. Using the `url` parameter you simply tell VS Code which URL to either open or launch in Edge.\n\nYou can configure these modes with a `.vscode/launch.json` file in the root directory of your project. You can create this file manually, or Code will create one for you if you try to run your project, and it doesn't exist yet.\n\n### Launch\n\nBelow are two example `launch.json` configs with `\"request\": \"launch\"`. You must specify either `file` or `url` to launch Microsoft Edge against a local file or a url. If you use a url, set `webRoot` to the directory that files are served from. This can be either an absolute path or a path using `${workspaceFolder}` (the folder open in Code). Note that `webRoot` is used to resolve urls (like \"http://localhost/app.js\") to a file on disk (like `/Users/me/project/app.js`), so be careful that it's set correctly.\n```json\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Launch localhost in Microsoft Edge\",\n            \"type\": \"edge\",\n            \"request\": \"launch\",\n            \"url\": \"http://localhost/mypage.html\",\n            \"webRoot\": \"${workspaceFolder}/wwwroot\"\n        },\n        {\n            \"name\": \"Launch index.html in Microsoft Edge\",\n            \"type\": \"edge\",\n            \"request\": \"launch\",\n            \"file\": \"${workspaceFolder}/index.html\"\n        },\n    ]\n}\n```\n\n#### Microsoft Edge (Chromium)\nIf the stable release of Microsoft Edge (Chromium) is on your machine, this debug adapter will launch it by default. If you'd like to launch a different channel of Microsoft Edge (Chromium), simply add a `version` attribute to your existing configuration with the version you want to launch (`dev`, `beta`, or `canary`). The example configuration below will launch the Canary version of Microsoft Edge (Chromium):\n```json\n{\n    \"name\": \"Launch localhost in Microsoft Edge (Chromium) Canary\",\n    \"type\": \"edge\",\n    \"request\": \"launch\",\n    \"version\": \"canary\",\n    \"url\": \"http://localhost/mypage.html\",\n    \"webRoot\": \"${workspaceFolder}/wwwroot\"\n}\n```\n\nIf you want to use a different installation of a Chromium-based browser, you can also set the `runtimeExecutable` field with a path to the browser executable. Note that if you are using the `runtimeExecutable` flag, you should **not** be using `version`.\n\n#### Microsoft Edge (EdgeHTML)\nIf you do **not** have the stable release of Microsoft Edge (Chromium) on your machine, the debug adapter will launch Microsoft Edge (EdgeHTML) by default. You will have the same default configuration as above.\n\n### Attach\nWith `\"request\": \"attach\"`, you must launch Microsoft Edge with remote debugging enabled in order for the extension to attach to it. Here's how you can do that:\n\n__Windows__\n* Open the Command Prompt\n* Run `msedge.exe --remote-debugging-port=2015` for Microsoft Edge (Chromium) or `microsoftedge.exe --devtools-server-port=2015` for Microsoft Edge (EdgeHTML)\n\nThe example `launch.json` config below will attach to either Microsoft Edge (Chromium) or Microsoft Edge (EdgeHTML) depending on which one you launched on port `2015`.\n```json\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"type\": \"edge\",\n            \"request\": \"attach\",\n            \"name\": \"Attach to Microsoft Edge\",\n            \"port\": 2015,\n            \"webRoot\": \"${workspaceFolder}\"\n        }\n    ]\n}\n```\n\n### Other optional launch config fields\n* `trace`: When true, the adapter logs its own diagnostic info to a file. The file path will be printed in the Debug Console. This is often useful info to include when filing an issue on GitHub. If you set it to \"verbose\", it will log to a file and also log to the console.\n* `version`: When set to `canary`, `dev`, or `beta`, it will launch the matching version of Microsoft Edge (Chromium). If not specified, Microsoft Edge (EdgeHTML) will be launched.\n* `runtimeExecutable`: Workspace relative or absolute path to the runtime executable to be used. If not specified, Microsoft Edge (EdgeHTML) will be used from the default install location.\n* `runtimeArgs`: Optional arguments passed to the runtime executable.\n* `env`: Optional dictionary of environment key/value pairs.\n* `cwd`: Optional working directory for the runtime executable.\n* `userDataDir`: Normally, if Microsoft Edge is already running when you start debugging with a launch config, then the new instance won't start in remote debugging mode. So by default, the extension launches Microsoft Edge with a separate user profile in a temp folder. Use this option to set a different path to use, or set to false to launch with your default user profile. Note that this is only applicable to Microsoft Edge (Chromium) and will not work with Microsoft Edge (EdgeHTML).\n* `url`: On a 'launch' config, it will launch Microsoft Edge at this URL.\n* `urlFilter`: On an 'attach' config, or a 'launch' config with no 'url' set, search for a page with this url and attach to it. It can also contain wildcards, for example, `\"localhost:*/app\"` will match either `\"http://localhost:123/app\"` or `\"http://localhost:456/app\"`, but not `\"https://stackoverflow.com\"`.\n* `targetTypes`: On an 'attach' config, or a 'launch' config with no 'url' set, set a list of acceptable target types from the default `[\"page\"]`. For example, if you are attaching to an Electron app, you might want to set this to `[\"page\", \"webview\"]`. A value of `null` disables filtering by target type. Note that this is only applicable to Microsoft Edge (Chromium) and will not work with Microsoft Edge (EdgeHTML).\n* `sourceMaps`: By default, the adapter will use sourcemaps and your original sources whenever possible. You can disable this by setting `sourceMaps` to false.\n* `pathMapping`: This property takes a mapping of URL paths to local paths, to give you more flexibility in how URLs are resolved to local files. `\"webRoot\": \"${workspaceFolder}\"` is just shorthand for a pathMapping like `{ \"/\": \"${workspaceFolder}\" }`.\n* `smartStep`: Automatically steps over code that doesn't map to source files. Especially useful for debugging with async/await.\n* `disableNetworkCache`: If true, the network cache will be disabled.\n* `showAsyncStacks`: If true, callstacks across async calls (like `setTimeout`, `fetch`, resolved Promises, etc) will be shown.\n* `useWebView`: If true or `advanced`, the debugger will treat the `runtimeExecutable` as an application hosting a WebView. See: [Microsoft Edge (Chromium) WebView applications](#Microsoft-Edge-(Chromium)-WebView-applications)\n\n### Microsoft Edge (Chromium) WebView applications\nYou can also use the debugger to launch applications that are using an embedded [Microsoft Edge (Chromium) WebView](https://docs.microsoft.com/en-us/microsoft-edge/hosting/webview2). With the correct `launch.json` properties, the debugger will launch your host application and attach to the WebView allowing you to debug the running script content.\n\nTo use the debugger against a WebView application use the following properties in your launch config:\n* `runtimeExecutable`: Set this to the full path to your host application.\n* `useWebView`: Set this to be `true` or `advanced` depending on how your host application is using WebViews\n\nIn basic scenarios, your host application is using a single WebView that is loaded on launch of your application. If this is the case, you should set `useWebView` to be `true`. This will treat the host application just like it was another browser, attaching to the WebView on launch and failing with a timeout if it cannot find a matching `url` or `urlFilter` within the timeout.\n\nIn more advanced scenarios, your host appliation may be using a single WebView that doesn't load until later in your workflow. It may also be using multiple WebViews within the same application, or have a dependency on a specific `userDataDir` setting. In these cases you should set `useWebView` to be `advanced`. This will cause the debugger to treat your host application differently. When launching, the debugger will wait until it gets notified of a WebView that matches the `urlFilter` value without timing out. It will also not override the `userDataDir` internally and may attach on a different `port` value than what is specified in the config if several WebViews created in the host application.\n\n### Other targets\nYou can also theoretically attach to other targets that support the same [Chrome DevTools Protocol](https://chromedevtools.github.io/devtools-protocol/tot) as the Microsoft Edge (Chromium) browser, such as Electron or Cordova. These aren't officially supported, but should work with basically the same steps. You can use a launch config by setting `\"runtimeExecutable\"` to a program or script to launch, or an attach config to attach to a process that's already running. If Code can't find the target, you can always verify that it is actually available by navigating to `http://localhost:<port>/json` in a browser. If you get a response with a bunch of JSON, and can find your target page in that JSON, then the target should be available to this extension.\n\n## Skip files / Mark as Library code\nYou can use the `skipFiles` property to mark specific files as Library code while debugging. For example, if you set `\"skipFiles\": [\"jquery.js\"]`, then you will skip any file named 'jquery.js' when stepping through your code. You also won't break on exceptions thrown from 'jquery.js'. This works the same as \"Mark as Library code\" in the Microsoft Edge DevTools.\n\nThe supported formats are:\n  * The name of a file (like `jquery.js`)\n  * The name of a folder, under which to skip all scripts (like `node_modules`)\n  * A path glob, to skip all scripts that match (like `node_modules/react/*.min.js`)\n\n## Sourcemaps\nThe debugger uses sourcemaps to let you debug with your original sources, but sometimes the sourcemaps aren't generated properly and overrides are needed. In the config we support `sourceMapPathOverrides`, a mapping of source paths from the sourcemap, to the locations of these sources on disk. Useful when the sourcemap isn't accurate or can't be fixed in the build process.\n\nThe left hand side of the mapping is a pattern that can contain a wildcard, and will be tested against the `sourceRoot` + `sources` entry in the source map. If it matches, the source file will be resolved to the path on the right hand side, which should be an absolute path to the source file on disk.\n\nA few mappings are applied by default, corresponding to some common default configs for Webpack and Meteor:\n```javascript\n// Note: These are the mappings that are included by default out of the box, with examples of how they could be resolved in different scenarios. These are not mappings that would make sense together in one project.\n// webRoot = /Users/me/project\n\"sourceMapPathOverrides\": {\n    \"webpack:///./~/*\": \"${webRoot}/node_modules/*\",       // Example: \"webpack:///./~/querystring/index.js\" -> \"/Users/me/project/node_modules/querystring/index.js\"\n    \"webpack:///./*\":   \"${webRoot}/*\",                    // Example: \"webpack:///./src/app.js\" -> \"/Users/me/project/src/app.js\",\n    \"webpack:///*\":     \"*\",                               // Example: \"webpack:///project/app.ts\" -> \"/project/app.ts\"\n    \"webpack:///src/*\": \"${webRoot}/*\",                    // Example: \"webpack:///src/app.js\" -> \"/Users/me/project/app.js\"\n    \"meteor://\ud83d\udcbbapp/*\": \"${webRoot}/*\"                    // Example: \"meteor://\ud83d\udcbbapp/main.ts\" -> \"/Users/me/project/main.ts\"\n}\n```\nIf you set `sourceMapPathOverrides` in your launch config, that will override these defaults. `${workspaceFolder}` and `${webRoot}` can be used here. If you aren't sure what the left side should be, you can use the `trace` option to see the contents of the sourcemap, or look at the paths of the sources in the Microsoft Edge DevTools, or open your `.js.map` file and check the values manually.\n\n### Ionic/gulp-sourcemaps note\nIonic and gulp-sourcemaps output a sourceRoot of `\"/source/\"` by default. If you can't fix this via your build config, we suggest this setting:\n```json\n\"sourceMapPathOverrides\": {\n    \"/source/*\": \"${workspaceFolder}/*\"\n}\n```\n\n## Troubleshooting\n\n### My breakpoints aren't hit when debugging Microsoft Edge(EdgeHTML). What's wrong?\nIf your breakpoints weren't hit, it's most likely a sourcemapping issue or because you set breakpoints before launching Microsoft Edge (EdgeHTML) and were expecting them to hit while the browser loads. If that's the case, you will have to refresh the page in Microsoft Edge (EdgeHTML) after we have attached from VS Code/Visual Studio to hit your breakpoint.\n\nIf you are using sourcemaps, make sure they are configured right.\n\n### Cannot connect to the target: connect ECONNREFUSED 127.0.0.1:2015\nThis message means that the extension can't attach to Microsoft Edge, probably because Microsoft Edge wasn't launched in debug mode. Here are some things to try:\n* Ensure that the `port` property matches the port on which Microsoft Edge is listening for remote debugging connections. This is `2015` by default. Ensure nothing else is using this port, including your web server. If something else on your computer responds at `http://localhost:2015`, then set a different port.\n* If all else fails, try to navigate to `http://localhost:<port>/json/list` in a browser when you see this message - if there is no response, then something is wrong upstream of the extension. If there is a page of JSON returned, then ensure that the `port` in the launch config matches the port in that url.\n* If the above steps do not work, try closing all windows of Microsoft Edge and then relaunch.\n\n### General things to try if you're having issues:\n* Ensure `webRoot` is set correctly if needed\n* Look at your sourcemap config carefully. A sourcemap has a path to the source files, and this extension uses that path to find the original source files on disk. Check the `sourceRoot` and `sources` properties in your sourcemap and make sure that they can be combined with the `webRoot` property in your launch config to build the correct path to the original source files.\n* Check the console for warnings that this extension prints in some cases when it can't attach.\n* Ensure the code in your browser matches the code in Code. The browser may cache an old version of your code.\n* If your breakpoints bind, but aren't hit in Microsoft Edge (EdgeHTML), try refreshing the page. If you set a breakpoint in code that runs immediately when the page loads in Microsoft Edge (EdgeHTML), you won't hit that breakpoint until you refresh the page.\n\n## Feedback\nSend us your feedback by [filing an issue](https://github.com/Microsoft/vscode-edge-debug2/issues/new) against this extension's [GitHub repo](https://github.com/Microsoft/vscode-edge-debug2). Please include the debug adapter log file, which is created for each run in the %temp% directory with the name `vscode-edge-debug2.txt`. You can drag this file into an issue comment to upload it to GitHub.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/cordova-plugin-code-push",
  "language": "Objective-C",
  "readme_contents": "[![appcenterbanner](https://user-images.githubusercontent.com/31293287/32969262-3cc5d48a-cb99-11e7-91bf-fa57c67a371c.png)](http://microsoft.github.io/code-push/)\n\n#### [Sign up With App Center](https://appcenter.ms/signup?utm_source=CodePush&utm_medium=Azure) to use CodePush\n\n# Apache Cordova Plugin for CodePush\n\nThis plugin provides client-side integration for the [CodePush service](https://microsoft.github.io/code-push/), allowing you to easily add a dynamic update experience to your Cordova app(s).\n\n<!-- Cordova Catalog -->\n\n* [How does it work?](#how-does-it-work)\n* [Supported Cordova Platforms](#supported-cordova-platforms)\n* [Deprecating old versions](#deprecating-old-versions)\n* [Getting Started](#getting-started)\n* [Plugin Usage](#plugin-usage)\n* [Releasing Updates](#releasing-updates)\n* [API Reference](#api-reference)\n* [PhoneGap Build](#phonegap-build)\n* [Example Apps](#example-apps)\n\n<!-- Cordova Catalog -->\n\n## How does it work?\n\nA Cordova app is composed of HTML, CSS and JavaScript files and any accompanying images, which are bundled together by the Cordova CLI and distributed as part of a platform-specific binary (i.e. an .ipa or .apk file). Once the app is released, updating either the code (e.g. making bug fixes, adding new features) or image assets, requires you to recompile and redistribute the entire binary, which of course, includes any review time associated with the store(s) you are publishing to.\n\nThe CodePush plugin helps get product improvements in front of your end users instantly, by keeping your code and images synchronized with updates you release to the CodePush server. This way, your app gets the benefits of an offline mobile experience, as well as the \"web-like\" agility of side-loading updates as soon as they are available. It's a win-win!\n\nIn order to ensure that your end users always have a functioning version of your app, the CodePush plugin maintains a copy of the previous update, so that in the event that you accidentally push an update which includes a crash, it can automatically roll back. This way, you can rest assured that your newfound release agility won't result in users becoming blocked before you have a chance to roll back on the server. It's a win-win-win!\n\n*Note: Any product changes which touch native code (e.g. upgrading Cordova versions, adding a new plugin) cannot be distributed via CodePush, and therefore, must be updated via the appropriate store(s).*\n\n## Supported Cordova Platforms\n\nCordova 5.0.0+ is fully supported, along with the following associated platforms:\n\n* Android ([cordova-android](https://github.com/apache/cordova-android) 4.0.0+) - *Including CrossWalk!* *Note: Only on TLS 1.2 compatible devices*\n* iOS ([cordova-ios](https://github.com/apache/cordova-ios) 3.9.0+) - please see notes below.\n\n> Note: Starting with v2.0.0 `cordova-plugin-code-push` doesn't support apps using UIWebView due to [Apple officially deprecated it and discourage developers from using it](https://developer.apple.com/news/?id=12232019b). Prior versions of the plugin still support UIWebView but be aware that the App Store will no longer accept new apps using UIWebView as of April 2020 and app updates using UIWebView as of December 2020.\n\n> Note: In order to use CodePush along with the [`cordova-plugin-wkwebview-engine`](https://github.com/apache/cordova-plugin-wkwebview-engine) plugin, you need to install `v1.5.1-beta+` version of `cordova-plugin-code-push`, which includes full support for apps using either WebView. Please see [Using WKWebView](#using-wkwebview) section for more information of how to confiure your app to use `cordova-plugin-wkwebview-engine`.\n\nTo check which versions of each Cordova platform you are currently using, you can run the following command and inspect the `Installed platforms` list:\n\n```shell\ncordova platform ls\n```\n\nIf you're running an older Android and/or iOS platform than is mentioned above, and would be open to upgrading, you can easily do so by running the following commands (omitting a platform if it isn't necessary):\n\n```shell\ncordova platform update android\ncordova platform update ios\n```\n\n## Deprecating old versions\n\nSince CodePush is migrating to a new service all versions of cordova-plugin-code-push lower than **[1.12.0](https://github.com/microsoft/cordova-plugin-code-push/releases/tag/v1.12.0)** will not work in the nearest future.\n\nYou can find more information in our [documentation](https://github.com/microsoft/code-push/blob/master/migration-notice.md).\n\n## Getting Started\n\nOnce you've followed the general-purpose [\"getting started\"](https://docs.microsoft.com/en-us/appcenter/distribution/codepush/) instructions for setting up your CodePush account, you can start CodePush-ifying your Cordova app by running the following command from within your app's root directory:\n\n```shell\ncordova plugin add cordova-plugin-code-push@latest\n```\n\nWith the CodePush plugin installed, configure your app to use it via the following steps:\n\n1. Add your deployment keys to the `config.xml` file, making sure to include the right key for each Cordova platform:\n\n    ```xml\n    <platform name=\"android\">\n        <preference name=\"CodePushDeploymentKey\" value=\"YOUR-ANDROID-DEPLOYMENT-KEY\" />\n    </platform>\n    <platform name=\"ios\">\n        <preference name=\"CodePushDeploymentKey\" value=\"YOUR-IOS-DEPLOYMENT-KEY\" />\n    </platform>\n    ```\n\n    As a reminder, these keys are generated for you when you created your CodePush app via the CLI. If you need to retrieve them, you can simply run `appcenter codepush deployment list <ownerName>/<appName> --displayKeys`, and grab the key for the specific deployment you want to use (e.g. `Staging`, `Production`).\n\n    *NOTE: You [must](https://docs.microsoft.com/en-us/appcenter/distribution/codepush/cli#releasing-updates) create a separate CodePush app for iOS and Android, which is why the above sample illustrates declaring separate keys for Android and iOS. If you're only developing for a single platform, then you only need to specify the deployment key for either Android or iOS, so you don't need to add the additional `<platform>` element as illustrated above.*\n\n    Beginning from version **1.10.0** you can sign your update bundles (for more information about code signing please refer to relevant documentation [section](https://github.com/Microsoft/code-push/blob/master/cli/README.md#code-signing)). In order to enable code signing for Cordova application you should setup public key to verify bundles signature by providing following `preference` setting in `config.xml`:\n\n     ```xml\n    <platform name=\"android\">\n        ...\n        <preference name=\"CodePushPublicKey\" value=\"YOUR-PUBLIC-KEY\" />\n    </platform>\n    <platform name=\"ios\">\n        ...\n        <preference name=\"CodePushPublicKey\" value=\"YOUR-PUBLIC-KEY\" />\n    </platform>\n    ```\n    You can use the same private/public key pair for each platform.\n\n2. If you're using an `<access origin=\"*\" />` element in your `config.xml` file, then your app is already allowed to communicate with the CodePush servers and you can safely skip this step. Otherwise, add the following additional `<access />` elements:\n\n    ```xml\n    <access origin=\"https://codepush.appcenter.ms\" />\n    <access origin=\"https://codepush.blob.core.windows.net\" />\n    <access origin=\"https://codepushupdates.azureedge.net\" />\n    ```\n\n3. To ensure that your app can access the CodePush server on [CSP](https://developer.mozilla.org/en-US/docs/Web/Security/CSP/Introducing_Content_Security_Policy)-compliant platforms, add `https://codepush.appcenter.ms` to the `Content-Security-Policy` `meta` tag in your `index.html` file:\n\n    ```xml\n    <meta http-equiv=\"Content-Security-Policy\" content=\"default-src https://codepush.appcenter.ms 'self' data: gap: https://ssl.gstatic.com 'unsafe-eval'; style-src 'self' 'unsafe-inline'; media-src *\" />\n    ```\n\n4. Finally, double-check that you already have the [`cordova-plugin-whitelist`](https://github.com/apache/cordova-plugin-whitelist) plugin installed (most apps will). To check this, simply run the following command:\n\n    ```shell\n    cordova plugin ls\n    ```\n\n    If `cordova-plugin-whitelist` is in the list, then you are good to go. Otherwise, simply run the following command to add it:\n\n    ```shell\n    cordova plugin add cordova-plugin-whitelist\n    ```\n\nYou are now ready to use the plugin in the application code. See the [sample applications](/samples) for examples and the API documentation for more details.\n\n### Using WKWebView\n\nFor cordova-ios v4-v5 there is a possibility to specify WebView engine on the plugin build phase. By default UIWebView engine is used. To use WKWebView engine please do the following:\n\n* Install [cordova-plugin-wkwebview-engine](https://github.com/apache/cordova-plugin-wkwebview-engine#installation)\n* [Configure your app](https://github.com/apache/cordova-plugin-wkwebview-engine#required-permissions) to use WKWebView\n\n> Note: `cordova-plugin-wkwebview-engine` is just a workaround for cordova-ios v4-v5 users to be able to use WKWebView in their apps to avoid stop accepting updates via AppStore as of December 2020.\nCordova-ios v6+ has full support for native WKWebView and doesn't require `cordova-plugin-wkwebview-engine`.\n\n## Plugin Usage\n\nWith the CodePush plugin installed and configured, the only thing left is to add the necessary code to your app to control the following policies:\n\n1. When (and how often) to check for an update? (e.g. app start, in response to clicking a button in a settings page, periodically at some fixed interval)\n\n2. When an update is available, how to present it to the end user?\n\nThe simplest way to do this is to perform the following in your app's `deviceready` event handler:\n\n```javascript\ncodePush.sync();\n```\n\nIf an update is available, it will be silently downloaded, and installed the next time the app is restarted (either explicitly by the end user or by the OS), which ensures the least invasive experience for your end users. If an available update is mandatory, then it will be installed immediately, ensuring that the end user gets it as soon as possible.\n\nIf you would like your app to discover updates more quickly, you can also choose to call `sync` every time the app resumes from the background, by adding the following code (or something equivalent) as part of your app's startup behavior. You can call `sync` as frequently as you would like, so when and where you call it just depends on your personal preference.\n\n```javascript\ndocument.addEventListener(\"resume\", function () {\n    codePush.sync();\n});\n```\n\nAdditionally, if you would like to display an update confirmation dialog (an \"active install\"), configure when an available update is installed (e.g. force an immediate restart) or customize the update experience in any way, refer to the `sync` method's API reference for information on how to tweak this default behavior.\n\n*NOTE: While [Apple's developer agreement](https://developer.apple.com/programs/ios/information) fully allows performing over-the-air updates of JavaScript and assets (which is what enables CodePush!), it is against their policy for an app to display an update prompt. Because of this, we recommend that App Store-distributed apps don't enable the `updateDialog` option when calling `sync`, whereas Google Play and internally distributed apps (e.g. Enterprise, Fabric, HockeyApp) can choose to enable/customize it.*\n\n## Releasing Updates\n\nOnce your app has been configured and distributed to your users, and you've made some code and/or asset changes, it's time to instantly release them! The simplest (and recommended) way to do this is to use the `release-cordova` command in the App Center CLI, which will handle preparing and releasing your update to the CodePush server.\n\n*NOTE: Before you can start releasing updates, please log into App Center by running the `appcenter login` command*\n\nIn it's the most basic form, this command only requires one parameter: your owner name + \"/\" + app name.\n\n```shell\nappcenter codepush release-cordova -a <ownerName>/<appName>\n\nappcenter codepush release-cordova -a <ownerName>/MyApp-ios\nappcenter codepush release-cordova -a <ownerName>/MyApp-Android\n```\n\n*NOTE: When releasing updates to CodePush, you do not need to bump your app's version in the `config.xml` file, since you aren't modifying the binary version at all. You only need to bump this version when you upgrade Cordova and/or one of your plugins, at which point, you need to release an update to the native store(s). CodePush will automatically generate a \"label\" for each release you make (e.g. `v3`) in order to help identify it within your release history.*\n\nThe `release-cordova` command enables such a simple workflow because it understands the standard layout of a Cordova app, and therefore, can generate your update and know exactly which files to upload. Additionally, in order to support flexible release strategies, the `release-cordova` command exposes numerous optional parameters that let you customize how the update should be distributed to your end users (e.g. Which binary versions are compatible with it? Should the release be viewed as mandatory?).\n\n```shell\n# Release a mandatory update with a changelog\nappcenter codepush release-cordova -a <ownerName>/MyApp-ios -m --description \"Modified the header color\"\n\n# Release a dev Android build to just 1/4 of your end users\nappcenter codepush release-cordova -a <ownerName>/MyApp-android --rollout 25\n\n# Release an update that targets users running any 1.1.* binary, as opposed to\n# limiting the update to exact version name in the config.xml file\nappcenter codepush release-cordova -a <ownerName>/MyApp-android --target-binary-version \"~1.1.0\"\n\n# Release an update now but mark it as disabled\n# so that no users can download it yet\nappcenter codepush release-cordova -a <ownerName>/MyApp-ios -x\n\n# Release an update signed by private key (public key should be configured for application)\nappcenter codepush release-cordova -a <ownerName>/MyApp-android --private-key-path ~/rsa/private_key.pem\n```\n\nThe CodePush client supports differential updates, so even though you are releasing your app code on every update, your end users will only actually download the files they need. The service handles this automatically so that you can focus on creating awesome apps and we can worry about optimizing end user downloads.\n\n*NOTE: for **Ionic** apps you need to run `ionic build` before running `cordova-release` or `release` command in order to build web assets.*\n\nFor more details about how the `release-cordova` command works, as well as the various parameters it exposes, refer to the [CLI docs](https://docs.microsoft.com/en-us/appcenter/distribution/codepush/cli#releasing-updates-cordova). Additionally, if you would prefer to handle running the `cordova prepare` command yourself, and therefore, want an even more flexible solution than `release-cordova`, refer to the [`release` command](https://docs.microsoft.com/en-us/appcenter/distribution/codepush/cli#releasing-updates-general) for more details.\n\nIf you run into any issues, or have any questions/comments/feedback, you can [e-mail us](mailto:codepushfeed@microsoft.com) and/or open a new issue on this repo and we'll respond ASAP!\n\n## API Reference\n\nThe CodePush API is exposed to your app via the global `codePush` object, which is available after the `deviceready` event fires. This API exposes the following top-level methods:\n\n- __[checkForUpdate](#codepushcheckforupdate)__: Asks the CodePush service whether the configured app deployment has an update available.\n\n- __[getCurrentPackage](#codepushgetcurrentpackage)__: Retrieves the metadata about the currently installed update (e.g. description, installation time, size).\n\n- __[getPendingPackage](#codepushgetpendingpackage)__: Retrieves the metadata for an update (if one exists) that was downloaded and installed, but hasn't been applied yet via a restart.\n\n- __[notifyApplicationReady](#codepushnotifyapplicationready)__: Notifies the CodePush runtime that an installed update is considered successful. If you are manually checking for and installing updates (i.e. not using the sync method to handle it all for you), then this method **MUST** be called; otherwise CodePush will treat the update as failed and rollback to the previous version when the app next restarts.\n\n- __[restartApplication](#codepushrestartapplication)__: Immediately restarts the app. If there is an update pending, it will be immediately displayed to the end user.\n\n- __[sync](#codepushsync)__: Allows checking for an update, downloading it and installing it, all with a single call. Unless you need custom UI and/or behavior, we recommend most developers to use this method when integrating CodePush into their apps.\n\nAdditionally, the following objects and enums are also exposed globally as part of the CodePush API:\n\n- __[InstallMode](#installmode)__: Defines the available install modes for updates.\n\n- __[LocalPackage](#localpackage)__: Contains information about a locally installed package.\n\n- __[RemotePackage](#remotepackage)__: Contains information about an update package available for download.\n\n- __[SyncStatus](#syncstatus)__: Defines the possible intermediate and result statuses of the [sync](#codepushsync) operation.\n\n### codePush.checkForUpdate\n\n```javascript\ncodePush.checkForUpdate(onSuccess, onError?, deploymentKey?: String);\n```\n\nQueries the CodePush service to see whether the configured app deployment has an update available. By default, it will use the deployment key that is configured in your `config.xml` file, but you can override that by specifying a value via the optional `deploymentKey` parameter. This can be useful when you want to dynamically \"redirect\" a user to a specific deployment, such as allowing \"Early access\" via an easter egg or a user setting switch.\n\nWhen the update check completes, it will trigger the `onUpdateCheck` callback with one of two possible values:\n\n1. `null` if there is no update available. This occurs in the following scenarios:\n\n    1. The configured deployment doesn't contain any releases, and therefore, nothing to update.\n\n    2. The latest release within the configured deployment is targeting a different binary version than what you're currently running (either older or newer).\n\n    3. The currently running app already has the latest release from the configured deployment, and therefore, doesn't need it again.\n\n2. A `RemotePackage` instance which represents an available update that can be inspected and/or subsequently downloaded.\n\nParameters:\n\n- __onSuccess__: Callback that is invoked upon receiving a successful response from the server. The callback receives a single parameter, which is described above.\n\n- __onError__: Optional callback that is invoked in the event of an error. The callback takes one error parameter, containing the details of the error.\n\n- __deploymentKey__: Optional deployment key that overrides the `config.xml` setting.\n\nExample usage:\n\n```javascript\ncodePush.checkForUpdate(function (update) {\n    if (!update) {\n        console.log(\"The app is up to date.\");\n    } else {\n        console.log(\"An update is available! Should we download it?\");\n    }\n});\n```\n\n### codePush.getCurrentPackage\n\n```javascript\ncodePush.getCurrentPackage(onSuccess, onError?);\n```\n\nRetrieves the metadata about the currently installed \"package\" (e.g. description, installation time). This can be useful for scenarios such as displaying a \"what's new?\" dialog after an update has been applied or checking whether there is a pending update that is waiting to be applied via a resume or restart.\n\nWhen the update retrieval completes, it will trigger the `onSuccess` callback with one of two possible values:\n\n1. `null` if the app is currently running the HTML start page from the binary and not a CodePush update. This occurs in the following scenarios:\n\n    1. The end-user installed the app binary and has yet to install a CodePush update\n\n    2. The end-user installed an update of the binary (e.g. from the store), which cleared away the old CodePush updates, and gave precedence back to the binary.\n\n2. A `LocalPackage` instance which represents the metadata for the currently running CodePush update.\n\nParameters:\n\n- __onSuccess__: Callback that is invoked upon receiving the metadata about the currently running update. The callback receives a single parameter, which is described above.\n\n- __onError__: Optional callback that is invoked in the event of an error. The callback takes one error parameter, containing the details of the error.\n\nExample Usage:\n\n```javascript\ncodePush.getCurrentPackage(function (update) {\n    if (!update) {\n        console.log(\"No updates have been installed\");\n        return;\n    }\n\n    // If the current app \"session\" represents the first time\n    // this update has run, and it had a description provided\n    // with it upon release, let's show it to the end user\n    if (update.isFirstRun && update.description) {\n        // Display a \"what's new?\" modal\n    }\n});\n```\n\n### codePush.getPendingPackage\n\n```javascript\ncodePush.getPendingPackage(onSuccess, onError?);\n```\n\nGets the metadata for the currently pending update (if one exists). An update is considered \"pending\" if it has been downloaded and installed, but hasn't been applied yet via an app restart. An update could only ever be in this state if   `InstallMode.ON_NEXT_RESTART` or `InstallMode.ON_NEXT_RESUME` were specified upon calling `sync` or `LocalPackage.install`, and the app hasn't yet been restarted or resumed (respectively). This method can be useful if you'd like to determine whether there is a pending update and then prompt the user if they would like to restart now (via `codePush.restartApplication`) in order to apply it.\n\nWhen the update retrieval completes, it will trigger the `onSuccess` callback with one of two possible values:\n\n1. `null` if the app doesn't currently have a pending update (e.g. the app is already running the latest available version).\n\n2. A `LocalPackage` instance which represents the metadata for the currently pending CodePush update.\n\nParameters:\n\n- __onSuccess__: Callback that is invoked upon receiving the metadata about the currently pending update. The callback receives a single parameter, which is described above.\n\n- __onError__: Optional callback that is invoked in the event of an error. The callback takes one error parameter, containing the details of the error.\n\nExample Usage:\n\n```javascript\ncodePush.getPendingPackage(function (update) {\n    if (update) {\n        // An update is currently pending, ask the\n        // user if they would like to restart\n    }\n});\n```\n\n### codePush.notifyApplicationReady\n\n```javascript\ncodePush.notifyApplicationReady(notifySucceeded?, notifyFailed?);\n```\n\nNotifies the CodePush runtime that a freshly installed update should be considered successful, and therefore, an automatic client-side rollback isn't necessary. It is mandatory to call this function somewhere in the code of the updated bundle. Otherwise, when the app next restarts, the CodePush runtime will assume that the installed update has failed and roll back to the previous version. This behavior exists to help ensure that your end users aren't blocked by a broken update.\n\nIf you are using the `sync` function, and doing your update check on app start, then you don't need to manually call `notifyApplicationReady` since `sync` will call it for you. This behavior exists due to the assumption that the point at which `sync` is called in your app represents a good approximation of a successful startup.\n\nParameters:\n\n- __notifySucceeded__: Optional callback invoked if the plugin was successfully notified.\n\n- __notifyFailed__: Optional callback invoked in case of an error during notifying the plugin.\n\n### codePush.restartApplication\n\n```javascript\ncodePush.restartApplication();\n```\n\nImmediately restarts the app. This method is for advanced scenarios, and is primarily useful when the following conditions are true:\n\n1. Your app is specifying an install mode value of `ON_NEXT_RESTART` or `ON_NEXT_RESUME` when calling the `sync` or `LocalPackage.install` methods. This has the effect of not applying your update until the app has been restarted (by either the end user or OS) or resumed, and therefore, the update won't be immediately displayed to the end user.\n\n2. You have an app-specific user event (e.g. the end user navigated back to the app's home route) that allows you to apply the update in an unobtrusive way, and potentially gets the update in front of the end user sooner then waiting until the next restart or resume.\n\n### codePush.sync\n\n```javascript\ncodePush.sync(syncCallback?, syncOptions?, downloadProgress?, syncErrback?);\n```\n\nSynchronizes your app's code and images with the latest release to the configured deployment. Unlike the `checkForUpdate` method, which simply checks for the presence of an update, and let's you control what to do next, `sync` handles the update check, download and installation experience for you.\n\nThis method provides support for two different (but customizable) \"modes\" to easily enable apps with different requirements:\n\n1. **Silent mode** *(the default behavior)*, which automatically downloads available updates, and applies them the next time the app restarts (e.g. the OS or end user killed it, or the device was restarted). This way, the entire update experience is \"silent\" to the end user, since they don't see any update prompt and/or \"synthetic\" app restarts.\n\n2. **Active mode**, which when an update is available, prompts the end user for permission before downloading it, and then immediately applies the update. If an update was released using the mandatory flag, the end user would still be notified about the update, but they wouldn't have the choice to ignore it.\n\nExample Usage:\n\n```javascript\n// Fully silent update which keeps the app in\n// sync with the server, without ever\n// interrupting the end user\ncodePush.sync();\n\n// Active update, which lets the end user know\n// about each update, and displays it to them\n// immediately after downloading it\ncodePush.sync(null, { updateDialog: true, installMode: InstallMode.IMMEDIATE });\n```\n\n*Note: If you want to decide whether you check and/or download an available update based on the end user's device battery level, network conditions, etc. then simply wrap the call to sync in a condition that ensures you only call it when desired.*\n\nWhile the sync method tries to make it easy to perform silent and active updates with little configuration, it accepts the following optional parameters which allow you to customize numerous aspects of the default behavior mentioned above:\n\n- __syncCallback__: Called when the sync process moves from one stage to another in the overall update process. The method is called with a status code which represents the current state, and can be any of the [`SyncStatus`](#syncstatus) values.\n\n- __syncOptions__: Optional [`SyncOptions`](#syncoptions) parameter configuring the behavior of the sync operation.\n\n- __downloadProgress__: Called periodically when an available update is being downloaded from the CodePush server. The method is called with a `DownloadProgress` object, which contains the following two properties:\n\n    - __totalBytes__ *(Number)* - The total number of bytes expected to be received for this update (i.e. the size of the set of files which changed from the previous release).\n\n    - __receivedBytes__ *(Number)* - The number of bytes downloaded thus far, which can be used to track download progress.\n\n#### SyncOptions\n\nWhile the `sync` method tries to make it easy to perform silent and active updates with little configuration, it accepts an \"options\" object that allows you to customize numerous aspects of the default behavior mentioned above:\n\n- __deploymentKey__ *(String)* - Specifies the deployment key you want to query for an update against. By default, this value is derived from the `config.xml` file, but this option allows you to override it from the script-side if you need to dynamically use a different deployment for a specific call to `sync`.\n\n- __installMode__ *(InstallMode)* - Specifies when you would like to install optional updates (i.e. those that aren't marked as mandatory). Defaults to `InstallMode.ON_NEXT_RESTART`. Refer to the [`InstallMode`](#installmode) enum reference for a description of the available options and what they do.\n\n- __mandatoryInstallMode__ *(InstallMode)* - Specifies when you would like to install updates which are marked as mandatory. Defaults to `InstallMode.IMMEDIATE`. Refer to the [`InstallMode`](#installmode) enum reference for a description of the available options and what they do.\n\n- __minimumBackgroundDuration__ *(Number)* - Specifies the minimum number of seconds that the app needs to have been in the background before restarting the app. This property only applies to updates which are installed using `InstallMode.ON_NEXT_RESUME`, and can be useful for getting your update in front of end users sooner, without being too obtrusive. Defaults to `0`, which has the effect of applying the update immediately after a resume, regardless how long it was in the background.\n\n- __ignoreFailedUpdates__ *(Boolean)* - Specifies whether an available update should be ignored if it had been previously installed and rolled back on the client (because `notifyApplicationReady` wasn't successfully called). Defaults to `true`.\n\n- __updateDialog__ *(UpdateDialogOptions)* - An \"options\" object used to determine whether a confirmation dialog should be displayed to the end user when an update is available, and if so, what strings to use. Defaults to `null`, which has the effect of disabling the dialog completely. Setting this to any truthy value will enable the dialog with the default strings, and passing an object to this parameter allows enabling the dialog as well as overriding one or more of the default strings.\n\n    The following list represents the available options and their defaults:\n\n    - __appendReleaseDescription__ *(Boolean)* - Indicates whether you would like to append the description of an available release to the notification message which is displayed to the end user. Defaults to `false`.\n\n    - __descriptionPrefix__ *(String)* - Indicates the string you would like to prefix the release description with, if any, when displaying the update notification to the end user. Defaults to `\" Description: \"`.\n\n    - __mandatoryContinueButtonLabel__ *(String)*: The text to use for the button the end user must press in order to install a mandatory update. Defaults to `\"Continue\"`.\n\n    - __mandatoryUpdateMessage__ *(String)* - The text used as the body of an update notification, when the update is specified as mandatory. Defaults to `\"An update is available that must be installed.\"`.\n\n    - __optionalIgnoreButtonLabel__ *(String)* - The text to use for the button the end user can press in order to ignore an optional update that is available. Defaults to `\"Ignore\"`.\n\n    - __optionalInstallButtonLabel__ *(String)* - The text to use for the button the end user can press in order to install an optional update. Defaults to `\"Install\"`.\n\n    - __optionalUpdateMessage__ *(String)* - The text used as the body of an update notification, when the update is optional. Defaults to `\"An update is available. Would you like to install it?\"`.\n\n    - __updateTitle__ *(String)* - The text used as the header of an update notification that is displayed to the end user. Defaults to `\"Update available\"`.\n\nExample Usage:\n\n```javascript\n// Download the update silently, but install it on\n// the next resume, as long as at least 5 minutes\n// has passed since the app was put into the background.\ncodePush.sync(null, { installMode: InstallMode.ON_NEXT_RESUME, minimumBackgroundDuration: 60 * 5 });\n\n// Download the update silently, and install optional updates\n// on the next restart, but install mandatory updates on the next resume.\ncodePush.sync(null, { mandatoryInstallMode: InstallMode.ON_NEXT_RESUME });\n\n// Changing the title displayed in the\n// confirmation dialog of an \"active\" update\ncodePush.sync(null, { updateDialog: { updateTitle: \"An update is available!\" } });\n\n// Displaying an update prompt which includes the\n// description associated with the CodePush release\ncodePush.sync(null, {\n   updateDialog: {\n    appendReleaseDescription: true,\n    descriptionPrefix: \"\\n\\nChange log:\\n\"\n   },\n   installMode: InstallMode.IMMEDIATE\n});\n\n// Silently check for the update, but\n// display a custom downloading UI\n// via the SyncStatus and DownloadProgress callbacks\ncodePush.sync(syncStatus, null, downloadProgress);\n\nfunction syncStatus(status) {\n    switch (status) {\n        case SyncStatus.DOWNLOADING_PACKAGE:\n            // Show \"downloading\" modal\n            break;\n        case SyncStatus.INSTALLING_UPDATE:\n            // Hide \"downloading\" modal\n            break;\n    }\n}\n\nfunction downloadProgress(downloadProgress) {\n    if (downloadProgress) {\n    \t// Update \"downloading\" modal with current download %\n        //console.log(\"Downloading \" + downloadProgress.receivedBytes + \" of \" + downloadProgress.totalBytes);\n    }\n}\n```\n\nThe `sync` method can be called anywhere you'd like to check for an update. That could be in the `deviceready` event handler, the `click` event of a button, in the callback of a periodic timer, or whatever else makes sense for your needs. Just like the `checkForUpdate` method, it will perform the network request to check for an update in the background, so it won't impact your UI thread and/or JavaScript thread's responsiveness.\n\n### Package objects\n\nThe `checkForUpdate` and `getCurrentPackage` methods invoke success callbacks, that when triggered, provide access to \"package\" objects. The package represents your code update as well as any extra metadata (e.g. description, mandatory?). The CodePush API has the distinction between the following types of packages:\n\n1. `LocalPackage`: Represents a downloaded update that is either already running, or has been installed and is pending an app restart.\n\n2. `RemotePackage`: Represents an available update on the CodePush server that hasn't been downloaded yet.\n\n#### LocalPackage\n\nContains details about an update that has been downloaded locally or already installed. You can get a reference to an instance of this object either by calling the `codePush.getCurrentPackage` method, or as the value provided to the success callback of the `RemotePackage.download` method.\n\n##### Properties\n\n- __appVersion__: The native version of the application this package update is intended for. *(String)*\n- __deploymentKey__: Deployment key of the package. *(String)*\n- __description__: The description of the update. This is the same value that you specified in the CLI when you released the update. *(String)*\n- __failedInstall__: Indicates whether this update has been previously installed but was rolled back. The `sync` method will automatically ignore updates which have previously failed, so you only need to worry about this property if using `checkForUpdate`. *(Boolean)*\n- __isFirstRun__: Flag indicating if the current application run is the first one after the package was applied. *(Boolean)*\n- __isMandatory__: Indicates whether the update is considered mandatory. This is the value that was specified in the CLI when the update was released. *(Boolean)*\n- __label__: The internal label automatically given to the update by the CodePush server, such as `v5`. This value uniquely identifies the update within it's deployment. *(String)*\n- __packageHash__: The SHA hash value of the update. *(String)*\n- __packageSize__: The size of the code contained within the update, in bytes. *(Number)*\n\n##### Methods\n\n- __install(installSuccess, installError, installOptions)__: Installs this package to the application.\nThe install behavior is dependent on the provided `installOptions`. By default, the update package is silently installed and the application is reloaded with the new content on the next application start.\nOn the first run after the update, the application will wait for a `codePush.notifyApplicationReady()` call. Once this call is made, the install operation is considered a success.\nOtherwise, the install operation will be marked as failed, and the application is reverted to its previous version on the next run.\n\n    ###### InstallOptions\n\n    Interface defining several options for customizing install operation behavior.\n\n    - __installMode__: Used to specify the [InstallMode](#installmode) used for the install operation. Defaults to `InstallMode.ON_NEXT_RESTART`.\n\n    - __mandatoryInstallMode__: Used to specify the [InstallMode](#installmode) used for the install operation if the package is mandatory. Defaults to `InstallMode.IMMEDIATE`.\n\n    - __minimumBackgroundDuration__: If __installMode__ is `InstallMode.ON_NEXT_RESUME`, used to specify the amount of time the app must be in the background before the update is installed when it is resumed. Defaults to `0`.\n\nExample Usage:\n\n```javascript\n// App version 1 (current version)\n\nvar onError = function (error) {\n    console.log(\"An error occurred. \" + error);\n};\n\nvar onInstallSuccess = function () {\n    console.log(\"Installation succeeded.\");\n};\n\nvar onPackageDownloaded = function (localPackage) {\n    // Install regular updates after someone navigates away from the app for more than 2 minutes\n    // Install mandatory updates after someone restarts the app\n    localPackage.install(onInstallSuccess, onError, { installMode: InstallMode.ON_NEXT_RESUME, minimumBackgroundDuration: 120, mandatoryInstallMode: InstallMode.ON_NEXT_RESTART });\n};\n\nvar onUpdateCheck = function (remotePackage) {\n    if (!remotePackage) {\n        console.log(\"The application is up to date.\");\n    } else {\n        // The hash of each previously reverted package is stored for later use.\n        // This way, we avoid going into an infinite bad update/revert loop.\n        if (!remotePackage.failedInstall) {\n            console.log(\"A CodePush update is available. Package hash: \" + remotePackage.packageHash);\n            remotePackage.download(onPackageDownloaded, onError);\n        } else {\n            console.log(\"The available update was attempted before and failed.\");\n        }\n    }\n};\n\nwindow.codePush.checkForUpdate(onUpdateCheck, onError);\n\n//------------------------------------------------\n\n// App version 2 (updated version)\n\nvar app = {\n    onDeviceReady: function () {\n        // Calling this function is required during the first application run after an update.\n        // If not called, the application will be reverted to the previous version.\n        window.codePush.notifyApplicationReady();\n        // ...\n    }\n}\n```\n\nFor an example on how you are protected against a bad update, see the [notifyApplicationReady() documentation](#codepushnotifyapplicationready).\n\n#### RemotePackage\n\nContains details about an update that is available for download from the CodePush server. You get a reference to an instance of this object by calling the `codePush.checkForUpdate` method when an update is available. If you are using the sync API, you don't need to worry about the `RemotePackage`, since it will handle the download and installation process automatically for you.\n\n##### Properties\n\nThe `RemotePackage` inherits all of the same properties as the `LocalPackage`, but includes one additional one:\n\n- __downloadUrl__: The URL at which the package is available for download. This property is only needed for advanced usage, since the `download` method will automatically handle the acquisition of updates for you. *(String)*\n\n##### Methods\n\n- __abortDownload(abortSuccess, abortError)__: Aborts the current download session, if any.\n\n- __download(downloadSuccess, downloadError, downloadProgress)__: Downloads the package update from the CodePush service. The ```downloadSuccess``` callback is invoked with a [LocalPackage](#localpackage) argument, representing the downloaded package.\nThe optional `downloadProgress` callback is invoked several times during the download progress with one `DownloadProgress` parameter.\n\n    ###### DownloadProgress\n\n    Defines the format of the DownloadProgress object, used to send periodical update notifications on the progress of the update download.\n\n    Properties\n\n    - __totalBytes__: The size of the downloading update package, in bytes. (Number)\n    - __receivedBytes__: The number of bytes already downloaded. (Number)\n\nExample Usage:\n\n```javascript\nvar onError = function (error) {\n    console.log(\"An error occurred. \" + error);\n};\n\nvar onPackageDownloaded = function (localPackage) {\n    console.log(\"Package downloaded at: \" + localPackage.localPath);\n    // you can now update your application to the downloaded version by calling localPackage.install()\n};\n\nvar onProgress = function (downloadProgress) {\n    console.log(\"Downloading \" + downloadProgress.receivedBytes + \" of \" + downloadProgress.totalBytes + \" bytes.\");\n};\n\nvar onUpdateCheck = function (remotePackage) {\n    if (!remotePackage) {\n        console.log(\"The application is up to date.\");\n    } else {\n        console.log(\"A CodePush update is available. Package hash: \" + remotePackage.packageHash);\n        remotePackage.download(onPackageDownloaded, onError, onProgress);\n    }\n};\n\nwindow.codePush.checkForUpdate(onUpdateCheck, onError);\n```\n\n### Enums\n\nThe CodePush API includes the following \"enum\" objects which can be used to customize the update experience, and are available globally off of the `window` object:\n\n#### InstallMode\n\nThis enum specified when you would like an installed update to actually be applied, and can be passed to either the `sync` or `LocalPackage.install` methods. It includes the following values:\n\n- __IMMEDIATE__: The update will be applied to the running application immediately. The application will be reloaded with the new content immediately.\n\n- __ON_NEXT_RESTART__: Indicates that you want to install the update, but not forcibly restart the app. When the app is \"naturally\" restarted (due the OS or end user killing it), the update will be seamlessly picked up. This value is appropriate when performing silent updates, since it would likely be disruptive to the end user if the app suddenly restarted out of nowhere, since they wouldn't have realized an update was even downloaded. This is the default mode used for both the `sync` and `LocalPackage.install` methods.\n\n- __ON_NEXT_RESUME__: Indicates that you want to install the update, but don't want to restart the app until the next time the end user resumes it from the background. This way, you don't disrupt their current session, but you can get the update in front of them sooner then having to wait for the next natural restart. This value is appropriate for silent installs that can be applied on resume in a non-invasive way.\n\n#### SyncStatus\n\nDefines the possible statuses of the [sync](#codepushsync) operation. There are two categories of statuses: intermediate and result (final). The intermediate statuses represent progress statuses of the sync operation, and are not final. The result statuses represent final statuses of the sync operation. Every sync operation ends with only one result status, but can have zero or more intermediate statuses.\n\n- __UP_TO_DATE__: The app is fully up-to-date with the configured deployment.\n\n- __UPDATE_INSTALLED__: An available update has been installed and will be run either immediately after the callback function returns or the next time the app resumes/restarts, depending on the `InstallMode` specified in `SyncOptions`.\n\n- __UPDATE_IGNORED__: The app has an optional update, which the end user chose to ignore. *(This is only applicable when the `updateDialog` is used)*\n\n- __ERROR__: An error occurred during the `sync` operation. This might be an error while communicating with the server, downloading or unzipping the update. The console logs should contain more information about what happened. No update has been applied in this case.\n\n- __IN_PROGRESS__: Another sync is already running, so this attempt to sync has been aborted.\n\n- __CHECKING_FOR_UPDATE__: The CodePush server is being queried for an update.\n\n- __AWAITING_USER_ACTION__: An update is available, and a confirmation dialog was shown to the end user. *(This is only applicable when the `updateDialog` is used)*\n\n- __DOWNLOADING_PACKAGE__: An available update is being downloaded from the CodePush server.\n\n- __INSTALLING_UPDATE__: An available update was downloaded and is about to be installed.\n\n## PhoneGap Build\n\nThis plugin is compatible with [PhoneGap Build](https://build.phonegap.com), and supports creating Android and iOS builds out-of-the-box. However, in order for CodePush to calculate the hash of your binary contents on Android, PhoneGap Build needs to use Gradle to build your app, which isn't its default behavior (it uses Ant). To resolve this, simply add the following element to your app's `config.xml` file, as a child of the `<platform name=\"android\">` element:\n\n```xml\n<preference name=\"android-build-tool\" value=\"gradle\" />\n```\n\n## Example Apps\n\nThe Cordova community has graciously created some awesome open source apps that can serve as examples for developers that are getting started. The following is a list of OSS Cordova apps that are also using CodePush, and can therefore be used to see how others are using the service:\n\n* [PGDay CodePush Demo](https://github.com/rangle/pgdays-codepush-demo) - Demo app created by [Rangle.io](http://rangle.io) used for [PhoneGap Day Europe 2016](http://pgday.phonegap.com/eu2016/).\n\n*Note: If you've developed a Cordova app using CodePush, that is also open-source, please let us know. We would love to add it to this list!*\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-AsterPlot",
  "language": "HTML",
  "readme_contents": "# PowerBI-visuals-AsterPlot\n[![Build Status](https://travis-ci.org/Microsoft/PowerBI-visuals-AsterPlot.svg?branch=master)](https://travis-ci.org/Microsoft/PowerBI-visuals-AsterPlot) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/PowerBI-visuals-AsterPlot/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/PowerBI-visuals-AsterPlot?branch=master)\n\n> An Aster plot is a twist on a standard donut chart, using a second value to drive sweep angle.\n\n![Aster plot screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680537/Asset_a1b3a886-e716-453a-96d1-fc96890b4817/AsterPlotscreenshot1.png)\n# Overview\nThe Aster Plot allows a category that drives the chart and up to 2 measures:\n\nThe first measure controls the depth of each section\n\nThe second measure controls the width of each section\n\nSee also [Aster Plot chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380759&sourcecorrid=dd768b2b-0dc9-44e7-8c0e-01a6f95349d6&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)"
 },
 {
  "repo": "microsoft/azure-maven-plugins",
  "language": "Java",
  "readme_contents": "# Maven Plugins for Azure Services\n\nThis repository contains all Maven plugins for Microsoft Azure services. \n\n* [Plugins](#plugins)\n* [Authentication](#Authentication)\n* [Common Configurations](#Common-Configurations)\n* [CI/CD in Azure DevOps](#CI-CD-in-Azure-DevOps)\n* [Feedback and Questions](#Feedback-and-Questions)\n* [Contributing](#Contributing)\n* [Telemetry](#Telemetry)\n\nFor more information on authentication, common configurations, CI CD, and general plugin documentation, [see the Wiki](https://github.com/microsoft/azure-maven-plugins/wiki).\n\n## Plugins\n\nMaven Plugin | Maven Central Version | Build Status\n---|---|---\n[Maven Plugin for Azure Web Apps](./azure-webapp-maven-plugin/README.md) | [![Maven Central](https://img.shields.io/maven-central/v/com.microsoft.azure/azure-webapp-maven-plugin.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.microsoft.azure%22%20AND%20a%3A%22azure-webapp-maven-plugin%22) | [![AppVeyor Webapp Plugin](https://ci.appveyor.com/api/projects/status/0vr4svfgl9u3rcaw/branch/develop?svg=true)](https://ci.appveyor.com/project/xscript/azure-maven-plugins-xt3xm)\n[Maven Plugin for Azure Functions](https://github.com/microsoft/azure-maven-plugins/wiki/Azure-Functions) | [![Maven Central](https://img.shields.io/maven-central/v/com.microsoft.azure/azure-functions-maven-plugin.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.microsoft.azure%22%20AND%20a%3A%22azure-functions-maven-plugin%22) | [![AppVeyor Function Plugin](https://ci.appveyor.com/api/projects/status/5jti4qwh0j4ekh72/branch/develop?svg=true)](https://ci.appveyor.com/project/xscript/azure-maven-plugins-vvy0i)\n[Maven Plugin for Azure Spring Cloud](https://github.com/microsoft/azure-maven-plugins/wiki/Azure-Spring-Cloud) | [![Maven Central](https://img.shields.io/maven-central/v/com.microsoft.azure/azure-spring-cloud-maven-plugin.svg)](http://search.maven.org/#search%7Cga%7C1%7Cg%3A%22com.microsoft.azure%22%20AND%20a%3A%22azure-spring-cloud-maven-plugin%22) | \n\n\n## Authentication\n\nAll the Azure Maven plugins share the same authentication logic. There are 4 authentication methods by priority order:\n\n1. [Service Principles in plugin configuration](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication#service-principles-in-plugin-configuration)\n1. [Service Principles in settings.xml](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication#service-principles-in-settings.xml) (Recommended for production use)\n1. [Maven Plugin for Azure Account](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication#maven-plugin-for-azure-account) (Default if no other method are used)\n1. [Azure CLI](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication#azure-cli)\n\nFor example, if you have not only Service Principles configured in your plugin configuration, but also Azure CLI installed and logged in, the Azure Maven plugins will use the Service Principles in your plugin configuration.\n\nIf no credential found, Azure Maven plugins will automatically log you in with the third method like OAuth or DeviceLogin provided by Maven Plugin for Azure Account.\n\n### AuthType (since Web App 1.9.0)\nYou can specify which authentication method to use with <authType> in Maven configuration, the default value is auto, and here are all the valid values:\n\n* service_principal\n    * Will use credential specified in plugin configuration or Maven settings.xml, this is also the first priority authentication method in auto\n* azure_auth_maven_plugin\n    * Will use credential provided by Azure Auth Maven Plugin, it will first consume existing secret files, and will guide you auth with Oath or Device Login if you hadn't authenticated with Auth Maven Plugin before.\n* azure_cli\n    * Will use credential provided by Azure CLI, this could also be used in Azure Cloud Shell.\n* auto\n    * Will try all the auth methods in the following sequence: service_principal, azure_auth_maven_plugin(existing secret files), azure_cli, azure_auth_maven_plugin\n\n> Maven plugin will only try the specific authentication method (except auto) if <AuthType> is set in configuration.\n\nSee the [Authentication](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication) section in our wiki for more information.\n\n## Common Configurations\nThe three Maven Plugins for Azure Web App/Functions/Spring Cloud support below configuration properties.\n\n| Property | Required | Description | Version |\n| --- | --- | --- | --- | \n| \\<subscriptionId> | false\t| Specifies the target subscription.<br>Use this setting when you have multiple subscriptions in your authentication file. | WebApp: 0.1.0<br>Function: 0.1.0<br>Spring: 1.0.0 |\n| \\<allowTelemetry> | false | Specifies whether to allow this plugin to send telemetry data; default value is true. | \tWebApp: 0.1.0 <br> Function: 0.1.0 <br> Spring: 1.0.0 |\n| \\<auth> | false | Specifies auth configuration. For more info, please refer to [here.](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication#authentication) | WebApp:0.1.0 <br> Function:0.1.0 | \n | \\<authType> | false | Specifies which authentication method to use, default value is auto. For more infos, please refer to [here.](https://github.com/microsoft/azure-maven-plugins/wiki/Authentication#authtype) | WebApp:1.9.0 | \n | \\<skip> | false | Specifies whether to skip execution. Default value is false. | WebApp: 0.1.4 <br> Function: 0.1.0 | \n\n## Feedback and Questions\nTo report bugs or request new features, file issues on [Issues](https://github.com/microsoft/azure-maven-plugins/issues). Or, ask questions on [Stack Overflow with tag azure-java-tools](https://stackoverflow.com/questions/tagged/azure-java-tools).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once in all repositories using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Telemetry\nThis project collects usage data and sends it to Microsoft to help improve our products and services.\nRead Microsoft's [privacy statement](https://privacy.microsoft.com/en-us/privacystatement) to learn more.\nIf you would like to opt out of sending telemetry data to Microsoft, you can set `allowTelemetry` to false in the plugin configuration.\nPlease read our [documents](https://aka.ms/azure-maven-config) to find more details."
 },
 {
  "repo": "microsoft/tsiclient",
  "language": "TypeScript",
  "readme_contents": "# TSIClient: The Azure Time Series Insights JavaScript SDK\n\n<a href=\"https://tsiclientsample.azurewebsites.net\"><img src=\"https://insights.timeseries.azure.com/favicon.ico\" align=\"left\" hspace=\"10\" vspace=\"6\" height=\"100px\"></a>\n\nThe Azure Time Series Insights JavaScript SDK (aka **tsiclient**) is a JavaScript library for Microsoft Azure Time Series Insights, featuring components for data visualization and analytics, utilities for making calls directly to the TSI Platform API, and more.  **tsiclient** also ships with an associated CSS file (which you must include using your preferred css linking method), which makes the components look great out of the box.\n\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-red.svg)](https://opensource.org/licenses/MIT) [![npm version](https://badge.fury.io/js/tsiclient.svg)](https://badge.fury.io/js/tsiclient) \n\n## Resources\n\n* [API Reference documentation](docs/API.md)\n* [Product documentation](https://docs.microsoft.com/azure/time-series-insights/)\n* [Authorization and authentication](https://docs.microsoft.com/azure/time-series-insights/time-series-insights-authentication-and-authorization)\n* [Hosted tsiclient samples](https://tsiclientsample.azurewebsites.net)\n\n## Installing\n\nIf you use npm, `npm install tsiclient`. You can also load directly from [unpkg](https://unpkg.com/tsiclient/). For example:\n\n```html\n<script src=\"https://unpkg.com/tsiclient@latest/tsiclient.js\"></script>\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://unpkg.com/tsiclient@latest/tsiclient.css\"></link>\n```\n\nTo import all of **tsiclient** into an ES2015 application, import everything into a namespace, like so...\n\n```js\nimport TsiClient from \"tsiclient\";\n\n// later, when you want a line chart\nlet tsiClient = new TsiClient();\nlet lineChart = new tsiClient.ux.LineChart(document.getElementById('chart'));\n```\n\nYou can also import components individually.  If you only need the LineChart, you can import it like so...\n\n```js\nimport LineChart from 'tsiclient/LineChart'\n\n// later when you want a line chart\nlet lineChart = new LineChart(document.getElementById('chart'));\n```\nImporting individual components can help significantly reduce your bundle size as they work better with tree shaking. This is the recommended approach if your app only consumes specific components.\n\nTo import the tsiclient stylesheet into an ES2015 application, import either `tsiclient.css` or `tsiclient.min.css`, like so...\n\n```js\nimport 'tsiclient/tsiclient.css' // Standard styles\nimport 'tsiclient/tsiclient.min.css' // Minified styles\n```\n\n## Release Notes\n\nStarting with version 1.3.0, discrete events and state transitions will be represented just like numeric time series in the LineChart component.  This may be a breaking change for users representing non-numeric series in the line chart using the \"events\" and \"states\" Chart Options.  For usage instructions, consult [this example](https://tsiclientsample.azurewebsites.net/noauth/multipleseriestypes.html) and the associated [documentation](https://github.com/microsoft/tsiclient/blob/master/docs/UX.md#line-chart).\n\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments."
 },
 {
  "repo": "microsoft/kiota",
  "language": "C#",
  "readme_contents": "# Project\n\n[![Dotnet](https://github.com/microsoft/kiota/actions/workflows/dotnet.yml/badge.svg)](https://github.com/microsoft/kiota/actions/workflows/dotnet.yml) [![CodeQL](https://github.com/microsoft/kiota/actions/workflows/codeql-analysis.yml/badge.svg)](https://github.com/microsoft/kiota/actions/workflows/codeql-analysis.yml) [![Coverage](https://sonarcloud.io/api/project_badges/measure?project=microsoft_kiota&metric=coverage)](https://sonarcloud.io/dashboard?id=microsoft_kiota) [![Sonarcloud Status](https://sonarcloud.io/api/project_badges/measure?project=microsoft_kiota&metric=alert_status)](https://sonarcloud.io/dashboard?id=microsoft_kiota)\n\nKiota is a project to build an OpenAPI based code generator for creating SDKs for HTTP APIs. The goal is to produce a lightweight, low maintenance, code generator that is fast enough to run as part of the compile time tool-chain but scalable enough to handle the largest APIs. Kiota generates a lightweight set of strongly typed classes that layer over a core HTTP library and produce an intuitive and discoverable way of creating HTTP requests. A set of abstractions decouple the generated service library from the core allowing a variety of core libraries to be supported.\n\nThis library builds on top of the [Microsoft.OpenAPI.NET](https://github.com/microsoft/openapi.net) library to ensure comprehensive support for APIs that use OpenAPI descriptions. One of the goals of the project is to provide the best code generator support possible for OpenAPI and JSON Schema features.\n\n## Getting started\n\n### Required tools\n\n- [.NET SDK 5.0](https://dotnet.microsoft.com/download) *\n- [Visual Studio Code](https://code.visualstudio.com/)\n- [Microsoft Graph PowerShell SDK](https://github.com/microsoftgraph/msgraph-sdk-powershell), cloned into the same parent folder of this repository. This dependency is only required if you want to generate SDKs for Microsoft Graph.\n\n#### TypeScript tools\n\n- [NodeJS 14](https://nodejs.org/en/) *\n- [TypeScript](https://www.typescriptlang.org/) `npm i -g typescript` *\n\n#### Java tools\n\n- [JDK 16](https://adoptopenjdk.net/) *\n- [Gradle 7](https://gradle.org/install/) *\n\n#### Dotnet tools\n\nNo additional tools are required for dotnet projects.\n\n> Note: tools marked with * are required.\n\n### Generating SDKs\n\nYou can either clone the repository and build Kiota locally, download and run binaries or run the docker image.\n\n#### Running Kiota with Docker\n\n1. Navigate to [New personal access token](https://github.com/settings/tokens/new) and generate a new token. (permissions: read:package).\n1. Copy the token, you will need it later.\n1. Enable the SSO on the token if you are a Microsoft employee.\n1. Execute the following command to login to the registry.\n\n    ```Shell\n    echo \"<the personal access token>\" | docker login https://docker.pkg.github.com/microsoft/kiota/generator -u baywet --password-stdin\n    ```\n\n1. Execute the following command to start generating SDKs\n\n    ```Shell\n    docker run -v /some/output/path:/app/output -v /some/input/description.yml:/app/openapi.yml docker.pkg.github.com/microsoft/kiota/generator --language csharp -n samespaceprefix\n    ```\n\n    > Note: you can alternatively use the --openapi parameter with a URI instead of volume mapping.\n\n> Note: steps 1-4 only need to be done once per machine.\n\n#### Building Kiota\n\nFirst, clone the current repository. You can either use Visual Studio Code or Visual Studio or execute the following commands:\n\n```Shell\ndotnet publish ./src/kiota/kiota.csproj -c Release -p:PublishSingleFile=true -r win-x64\n```\n\n> Note: refer to [.NET runtime identifier catalog](https://docs.microsoft.com/en-us/dotnet/core/rid-catalog) so select the appropriate runtime for your platform.\n\nNavigate to the output directory (usually under `src/kiota/bin/Release/net5.0`) and start generating SDKs by running Kiota.\n\n#### Running Kiota from binaries\n\nIf you haven't built kiota locally, select the appropriate version from the [releases page](https://github.com/microsoft/kiota/releases).\n\n```Shell\nkiota.exe --openapi ../msgraph-sdk-powershell/openApiDocs/v1.0/mail.yml --language csharp -o ../somepath -n namespaceprefix\n```\n\n> Note: once your SDK is generated in your target project, you will need to add references to kiota abstractions and kiota core in your project. Refer to [Initializing target projects](#initializing-target-projects)\n\n#### Parameters reference\n\nKiota accepts the following parameters during the generation:\n\n| Name | Shorthand | Required | Description | Accepted values | Default Value |\n| ---- | --------- | -------- | ----------- | --------------- | ------------- |\n| class-name | c | no | The class name to use the for main entry point | A valid class name according to the target language specification. | GraphClient |\n| language | l | no | The programming language to generate the SDK in. | csharp, java, or typescript | csharp |\n| loglevel |  | no | The log level to use when logging events to the main output. | Microsoft.Extensions.Logging.LogLevel values | Warning |\n| namespace-name | n | no | The namespace name to use the for main entry point. | Valid namespace/module name according to target language specifications. | GraphClient |\n| openapi |  | no | URI or Path to the OpenAPI description (JSON or YAML) to use to generate the SDK. | A valid URI pointing to an HTTP document or a file on the local file-system. | ./openapi.yml |\n| output | o | no | The output path of the folder the code will be generated in. The folders will be created during the generation if they don't already exist. | A valid path to a folder. | ./output |\n\n### Debugging\n\nIf you are using Visual Studio Code as your IDE, the **launch.json** file already contains the configuration to run Kiota. By default this configuration will use the `openApiDocs/v1.0/Mail.yml` under the PowerShell repository as the OpenAPI to generate an SDK for. By default this configuration will output the generated files in a graphdotnetv4|graphjavav4|graphtypescriptv4 folder located in the parent folder this repository is cloned in.\n\nSelecting the language you want to generate an SDK for in the Visual Studio Debug tab and hitting **F5** will automatically build, start, and attach the debugging process to Kiota.\n\n### Initializing target projects\n\nBefore you can compile and run the target project, you will need to initialize it. After initializing the test project, you will need to add references to the [abstraction](./abstractions) and the [core](./core) package from the GitHub feed.\n\n#### TypeScript initialization\n\nClone a NodeJS/front end TypeScript starter like [this one](https://github.com/FreekMencke/node-typescript-starter).\n\n```Shell\nnpm i @azure/identity node-fetch\n```\n\n#### Java initialization\n\nExecute the following command in the directory you want to initialize the project in.\n\n```Shell\ngradle init\n# Select a console application\n```\n\nEdit `utilities/build.gradle` to add the following dependencies.\n\n```Groovy\napi 'com.google.code.findbugs:jsr305:3.0.2'\napi 'com.azure:azure-identity:1.2.5'\napi 'com.squareup.okhttp3:okhttp:4.9.1'\napi 'com.google.code.gson:gson:2.8.6'\n```\n\n#### Dotnet initialization\n\nExecute the following command in the directory you want to initialize the project in.\n\n```Shell\ndotnet new console\ndotnet new gitignore\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/botbuilder-tools",
  "language": "JavaScript",
  "readme_contents": "\n# ![Bot Framework Tools](./docs/media/BotFrameWorkTools-header.png)\n\n### [Click here to find out what's new for //build2019!](https://github.com/Microsoft/botframework/blob/master/whats-new.md#whats-new)\n\n## The new BF CLI replaces legacy standalone tools\n\nThe Bot Framework SDK team is happy to announce the General Availability of the consolidated bot framework CLI tool [bf-cli](https://aka.ms/bfcli). The new BF CLI tool will replace legacy standalone tools to manage Bot Framework bots and related services. The old tools will be ported over in phases and all new features, bug fixes, and further investments will focus on the new BF CLI.  Old tools will still work for the time being, but they are going to be deprecated in future releases.\n\nUpon the release of Bot Framework SDK version 4.6 the following legacy tools have been ported: Chatdown, QnAMaker, LuisGen, and LuDown.  Dispatch CLI is on the path to be deprecated and replaced with [Orchestrator](https://aka.ms/bf-orchestrator).\n\nTo learn more about the BF CLI please visit the [BF CLI github repository](https://aka.ms/bfcli).\n\n__The following page is about the legacy tools.__\n\n# Bot Framework Tools \n[![Build Status](https://fuselabs.visualstudio.com/SDK_v4/_apis/build/status/Tools/Botbuilder-tools-js-daily?branchName=master)](https://fuselabs.visualstudio.com/SDK_v4/_build/latest?definitionId=467&branchName=master) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/botbuilder-tools/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/botbuilder-tools?branch=master) [![lerna](https://img.shields.io/badge/maintained%20with-lerna-cc00ff.svg)](https://lernajs.io/)\n\nThe Bot Framework tools are a collection of cross-platform command line tools designed to cover end-to-end bot development workflow. This repo is part of the [Microsoft Bot Framework](https://github.com/Microsoft/botframework) -  a comprehensive framework for building enterprise-grade conversational AI experiences.\n\n| Stable release   | Tool | Description |\n|-----------------|------|--------------|\n| [![npm version](https://badge.fury.io/js/chatdown.svg)](https://badge.fury.io/js/chatdown) | [Chatdown](packages/Chatdown) | Prototype mock conversations in markdown and convert the markdown to transcripts you can load and view in the new V4 Bot Framework Emulator |\n| [![npm version](https://badge.fury.io/js/msbot.svg)](https://badge.fury.io/js/msbot) |[MSBot](packages/MSBot)| Create and manage connected services in your bot configuration file|\n| [![npm version](https://badge.fury.io/js/ludown.svg)](https://badge.fury.io/js/ludown) |[LUDown](packages/Ludown)| Build LUIS language understanding models using markdown files|\n| [![npm version](https://badge.fury.io/js/luis-apis.svg)](https://badge.fury.io/js/luis-apis) |[LUIS](packages/LUIS)| Create and manage your [LUIS.ai](http://luis.ai) applications |\n| [![npm version](https://badge.fury.io/js/qnamaker.svg)](https://badge.fury.io/js/qnamaker) |[QnAMaker](packages/QnAMaker) | Create and manage [QnAMaker.ai](http://qnamaker.ai) Knowledge Bases. |\n| [![npm version](https://badge.fury.io/js/botdispatch.svg)](https://badge.fury.io/js/botdispatch) | [Dispatch](packages/Dispatch) | Build language models allowing you to dispatch between disparate components (such as QnA, LUIS and custom code)|\n| [![npm version](https://badge.fury.io/js/luisgen.svg)](https://badge.fury.io/js/luisgen)| [LUISGen](packages/LUISGen) | Auto generate backing C#/Typescript classes for your LUIS intents and entities.|\n## Install CLI tools:\nPre-requisite:\n- [Node.js](https://nodejs.org/) version 10.14.1 or higher\n- [.NET Core SDK](https://www.microsoft.com/net/download) version 2.1.403 or higher\n\n```\nnpm install -g chatdown msbot ludown luis-apis qnamaker botdispatch luisgen\n```\n\n## Overview\n\n- Please see [here](https://aka.ms/BotBuilderOverview) for an overview of the end-to-end bot development workflow.\n- Please see [here](./tools-overview.md) for an overview of using Bot Builder tools throughout various phases of bot development.\n\nBot Builder tools are designed to work with\n- Bot Builder V4 SDK - [C# SDK](https://github.com/microsoft/botbuilder-dotnet), [JS SDK](https://github.com/microsoft/botbuilder-js)\n- [Bot Builder V3 SDK](https://github.com/microsoft/botbuilder-v3)\n- [Bot Framework Emulator V4](https://github.com/Microsoft/BotFramework-Emulator/releases)\n\nBefore writing code, review the [bot design\u202fguidelines](https://docs.microsoft.com/en-us/azure/bot-service/bot-service-design-principles)\u202ffor best practices and identify the needs for your bot: will a basic bot be enough or whether it should have more sophisticated capabilities, such as speech,\u202flanguage understanding,\u202fQnA, or the ability to extract knowledge from different sources and provide intelligent answers. This is also the phase where you might want to create mockup of conversations between the user and the bot for the specific scenarios your bot will support. [Chatdown](https://github.com/Microsoft/botbuilder-tools/tree/master/packages/Chatdown) is the tool built for this purpose. You can author .chat files that mockup the conversations and then use chatdown CLI to convert them into rich transcripts.\n\nAs you build your bot, you may also need to integrate AI services like [LUIS.ai](http://luis.ai) for language understanding, [QnAMaker.ai](http://qnamaker.ai) for your bot to respond to simple questions in a Q&A format, and more. You can bootstrap language understanding for your bot using [LUDown](https://github.com/Microsoft/botbuilder-tools/tree/master/packages/Ludown).\n\nThe tools are designed to work together. You can then use [LUIS](https://github.com/Microsoft/botbuilder-tools/tree/master/packages/LUIS) CLI and/or the [QnAMaker](https://github.com/Microsoft/botbuilder-tools/tree/master/packages/QnAMaker) CLI tools to create your LUIS.ai models and QnAMaker knowledge base.\n\nAs your bot grows in sophistication, [Dispatch](https://github.com/Microsoft/botbuilder-tools/tree/master/packages/Dispatch) CLI can help create and evaluate LUIS models used to dispatch intent across multiple bot modules such as LUIS models, QnA knowledge bases and others (added to dispatch as a file type).\n\nThroughout the Build phase, you can use [MSBot](https://github.com/Microsoft/botbuilder-tools/tree/master/packages/MSBot) CLI to create and keep your bot configuration file updated with all relevant service references.\n\nTo test and refine your bot, you can use the new [V4 Bot Framework Emulator](https://github.com/Microsoft/BotFramework-Emulator/releases). The Bot Framework Emulator is a cross-platform [Electron](https://electronjs.org/) application that enables you to test and debug your bots on local machine or in the cloud. The new emulator includes features like faster load times, an improved dynamic layout model, support for multiple bot configurations, simple bot components management, and the ability to inspect responses from connected services such as LUIS and QnA. The Bot Framework Emulator also deepens links to different parts used by the bot. The Bot Framework Emulator new functionality enables you to debug bots based on transcript logs and to view previous chat in presentation mode. The Bot Framework Emulator is available as open source on [Github](https://github.com/Microsoft/BotFramework-Emulator).\n\nWith the [Azure CLI Bot extension](./AzureCli), you can create, download, publish, configure channels with the [Azure Bot Service](https://azure.microsoft.com/en-us/services/bot-service/). Azure CLI Bot extension requires [Azure CLI](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli?view=azure-cli-latest) (version 2.0.45 or higher]\n\n## Building the tools\n\nIn order to build the SDK, ensure that you have [Git](https://git-scm.com/downloads) and [Node.js](https://nodejs.org/en/) installed.\n\nRun the following commands to build all tools.\n\n```\nnpm install\nnpm run build\n```\n\nRun the following command to verify your installation.\n\n```\nnpm run test\n```\n\nThis repository uses [lerna](https://github.com/lerna/lerna) to manage the packages included. This allows you to execute scripts for all packages or only for some packages. For instance, `lerna run test` will run all tests in each package, but `lerna run test --scope chatdown` will run the tests of chatdown.\n\nTo use lerna, install it as a global package with `npm install lerna --global`.\n\n\n\n## Nightly builds\n\nNightly builds are generated using the latest code. Therefore, they may not be stable, and most likely lack up to date documentation. These builds are better suited for more experienced users, although everyone is welcome to use them and provide feedback.\n\nYou can get the latest nightly build of MSBot from the [BotBuilder MyGet](https://botbuilder.myget.org/gallery) feed. To install the nightly -\n\n```shell\nnpm config set registry https://botbuilder.myget.org/F/botbuilder-tools-daily/npm/\n```\n\nInstall using npm:\n```shell\nnpm i -g chatdown msbot ludown luis-apis qnamaker botdispatch luisgen\n```\n\nTo reset registry:\n```shell\nnpm config set registry https://registry.npmjs.org/\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Reporting Security Issues\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the [MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in the [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n"
 },
 {
  "repo": "microsoft/azure-pipelines-extensions",
  "language": "PowerShell",
  "readme_contents": "# Azure Pipeline extensions for Azure DevOps\n\nThis repository is a common place for all the extensions that Azure DevOps team publishes as **Microsoft** or **Microsoft DevLabs** publisher.\n\n## How to Build \n\nEnsure you have installed Node.js. Clone the repository, and go to the root folder of the repository and run the following commands. \n\n- `npm install` will install all the node modules required to run gulp to package, build etc.\n- `gulp build`  will copy each task to \"_build\" folder, and install it's dependencies locally (wrt to the task) and copies the common modules required to run the task.\n- `gulp test` will run all pester or mocha tests written for each task, in the Tests folder. \n\n## How to package extensions\n\nYou'll have to run `gulp build` and `gulp test` before you start packaging.\n\n- `gulp package` will package all the extensions and stores them in \"_package\" folder.\n- `gulp package --publisher=<publisher_name>` will package all the extensions under a new publisher name that you specify in \"_package\" folder.\n- `gulp package --extension=<extension_name>` will package the single extension you mention, and stores it in \"_package\" folder.\n- PS: Tested the compatibility with node version 10.22.0 on a windows machine. \n\n## Updating Feed\n\nFeed with various nugets to consume resides at [this location](https://1essharedassets.visualstudio.com/1esPkgs/_packaging?_a=feed&feed=vsts_rm_extensions)\n\nFeed can be updated/republished by executing [this build definition](https://dev.azure.com/mseng/AzureDevOps/_build?definitionId=6226&_a=summary)\n"
 },
 {
  "repo": "microsoft/ShortStack",
  "language": "C#",
  "readme_contents": "# Introduction\r\nShortStack is a tool to transform the way you check in code so that you get more and better code reviews.  \r\n The typical developer will check in something large and painful at the end of a period of private feature\r\n development, but with ShortStack, it becomes easy to create small pull requests for each atomic piece of\r\n work you do to advance the feature.   This allows you to get feedback EARLY, because you won't have to wait for \r\n code reviews, and it will make code reviews MORE EFFECTIVE because you can isolate logic changes from \r\n each other and from trivial changes such as boiler plate code.\r\n\r\n# Getting Started\r\nTo get started with the powershell script:\r\n1. Clone short stack to you local drive:  ```git clone https://github.com/microsoft/ShortStack.git [local folder path]```\r\n2. Enable custom scripts on your machine with this powershell command:  ```Set-ExecutionPolicy Unrestricted```\r\n3. Install posh-git:  ```PowerShellGet\\Install-Module posh-git -Scope CurrentUser```\r\n4. Get a VSTS access token:\r\n    1. Visit https://mscodehub.visualstudio.com/ShortStack/_git/ShortStack\r\n    2. Click your user icon and click 'Security' \r\n    3. Click on 'Add' to add a new token (make it active for a year)\r\n    4. Click 'Create Token', then immediately copy the value displayed.\r\n5. Edit your powershell profile with this command: ```notepad $profile```. If prompted, create the file if it doesn't already exist and then add these lines:\r\n```\r\nImport-Module Posh-Git -Force\r\nImport-Module c:\\tools\\shortstack\\scripts\\ShortStack.psm1 -Force\r\n$VSTSPersonalAccessToken=\"(your VSTS personal access key)\"\r\n```\r\n6. Close and re-open powershell to make sure your profile works.  You should be able to type ```ss``` on the command line and see ShortStack Help.\r\n7. In each repository, Create a default reviewers file:\r\n    1. Create the file \"stackprefs.txt\" in your .git folder\r\n    2. run ```Get-VSTSUserGuids``` to see the user id's of users in your repository\r\n    3. for each reviewer you want to include, add this line: ```reviewerid=(vsts_guid_of_user)``` (lines starting with '#' are treated as comments)\r\n\r\n\r\n# Build and Test\r\nBuilding and running the cmdlets:\r\n\r\n1. Open .sln in Visual Studio 2019 or later\r\n\r\n# Contribute\r\nPlease feel free to fork your own repo and submit your work as a PR.  We will code review and bring in changes that meet a high quality bar.\r\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-heatmap",
  "language": "TypeScript",
  "readme_contents": "# Contributing\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n![HeatMap screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680662/Asset_12af7ce5-f2f7-4aad-9da8-8b00cb225b0d/TableHeatmapscreenshot2.png)\r\n# Overview\r\nUse this custom visual to build a table heat map that can be used to visualise and compare data values in an easy and intuitive way.\r\n\r\nYou have a built-in option within this visual to specify the number of buckets used for splitting your data.\r\n\r\nAdditionally, you can also customise it by choosing a colour scheme in line with your brand colours\r\n\r\nSee also [Table Heatmap at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380818&sourcecorrid=5eb141b8-0a43-4e89-a987-ca286076d449&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)"
 },
 {
  "repo": "microsoft/dotnet",
  "language": "HTML",
  "readme_contents": "# .NET Home\n\nThis repository is a starting point to learn about and engage in .NET and .NET open source projects.\n\nThis repository is not an official .NET Framework support location, however, we will respond to issues filed here as best we can. Please file .NET Core product issues at [dotnet/core](https://github.com/dotnet/core/issues) and ASP.NET Core product issues at [aspnet/home](https://github.com/aspnet/home/issues).\n\nYou can try out an early access release of the .NET Framework at the [.NET Framework Early Access](https://github.com/microsoft/dotnet-framework-early-access) website.\n\n## In this repository\n\n- [.NET Framework Release Notes](releases/README.md)\n- [.NET Framework Documentation](Documentation/README.md)\n- [.NET Open Source Developer Projects](dotnet-developer-projects.md)\n- [.NET Open Source Consumer Projects](dotnet-consumer-projects.md)\n- [Free Services & Tools for Open Source .NET Projects](dotnet-free-oss-services.md)\n\nPlease contribute to this repository via [pull requests](https://github.com/Microsoft/dotnet/pulls)\n\n## Finding .NET Open Source Projects\n\nHere are some excellent community-maintained lists of projects:\n\n- [Awesome .NET!](https://github.com/quozd/awesome-dotnet)\n- [ASP.NET Core Library and Framework Support](https://github.com/jpsingleton/ANCLAFS)\n\nThere are many projects that you can use and contribute to, some of which are listed below. Please do contribute to these projects!\n\n### .NET Core\n\n- [.NET Core (dotnet/core)](https://github.com/dotnet/core)\n- [.NET Core docs (dotnet/docs)](https://github.com/dotnet/docs)\n- [ASP.NET Core (dotnet/aspnetcore)](https://github.com/dotnet/aspnetcore)\n- [ASP.NET Core docs (dotnet/AspNetCore.Docs)](https://github.com/dotnet/AspNetCore.Docs)\n- [Roslyn Compiler Platform (dotnet/roslyn)](https://github.com/dotnet/roslyn)\n- [EntityFramework (dotnet/efcore)](https://github.com/dotnet/efcore)\n- [WPF (dotnet/wpf)](https://github.com/dotnet/wpf)\n- [Windows Forms (dotnet/winforms)](https://github.com/dotnet/winforms)\n\n### .NET Framework\n\n- [.NET Framework docs (dotnet/docs)](https://github.com/dotnet/docs)\n- [.NET Framework source code - read-only subset (microsoft/referencesource)](https://github.com/microsoft/referencesource)\n\n### Xamarin\n\n- [Xamarin iOS + macOS (xamarin-macios)](https://github.com/xamarin/xamarin-macios)\n- [Xamarin Android (xamarin/xamarin-android)](https://github.com/xamarin/xamarin-android)\n- [Xamarin Forms (xamarin/Xamarin.Forms)](https://github.com/xamarin/Xamarin.Forms)\n- [Mono Project](https://github.com/mono/)\n\n### Community\n\nHere is a short list of projects to check out:\n\n* [.NET for Apache Spark](https://github.com/dotnet/spark)\n* [Orleans](https://github.com/dotnet/orleans)\n* [Exceptionless](https://github.com/exceptionless/Exceptionless)\n* [Glimpse](https://github.com/Glimpse/Glimpse)\n* [JSON.NET](https://github.com/JamesNK/Newtonsoft.Json)\n* [MonoGame](https://github.com/MonoGame/MonoGame)\n* [MVVM Cross](https://github.com/MvvmCross/MvvmCross)\n* [ReactiveUI](https://github.com/reactiveui/ReactiveUI)\n\nThere are additional templates available for `dotnet new`. For more information, see [Available templates for dotnet new](https://github.com/dotnet/templating/wiki/Available-templates-for-dotnet-new)\n\n## .NET Foundation\n\nMany .NET open source projects are part of the\n[.NET Foundation](https://www.dotnetfoundation.org/projects). Microsoft has contributed many projects, including ASP.NET Core and\n.NET Core. You may want to consider [joining the .NET Foundation](https://dotnetfoundation.org/community/).\n\nCheck out the [.NET Foundation Forums](https://forums.dotnetfoundation.org/) to see what others are talking about, or start a new discussion to ask a question or make a point. \n\n## License\n\nThis repository is licensed with the [MIT](LICENSE) license.\n"
 },
 {
  "repo": "microsoft/regexp-i18n",
  "language": "TypeScript",
  "readme_contents": "# RegExpI18n library\n\n[![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](https://github.com/Microsoft/regexp-i18n/blob/master/LICENSE) [![npm version](https://img.shields.io/npm/v/regexp-i18n.svg?style=flat-square)](https://www.npmjs.com/package/regexp-i18n) [![npm downloads](https://img.shields.io/npm/dm/regexp-i18n.svg?style=flat-square)](https://www.npmjs.com/package/regexp-i18n) [![Build Status](https://img.shields.io/travis/Microsoft/regexp-i18n/master.svg?style=flat-square)](https://travis-ci.org/Microsoft/regexp-i18n) [![David](https://img.shields.io/david/Microsoft/regexp-i18n.svg?style=flat-square)](https://github.com/Microsoft/regexp-i18n) [![David](https://img.shields.io/david/dev/Microsoft/regexp-i18n.svg?style=flat-square)](https://github.com/Microsoft/regexp-i18n)\n\nLibrary provides range of the all letters in Unicode.\nThis ranges could be used in the RegExp as a part of the range. As ranges include astral symbols from astral pages you need to pass ~u~ flag to the regexp.\n\nLibrary tested on latest versons of Safari, Chrome, Firefox and Edge browsers.\n\n## Overview\n\nThe library designed to provide a way to match any i18n character in any alphabet.\n\nThe library exports following building blocks:\n\n### Constants / Ranges\n\nConstants & Ranges represent range of the symbols. You could use any of the constants provided as a part of the range regexp expression. Ranges could be used as an argument for the trim function.\n\n```typescript\nimport { Constants, Ranges, trim } from 'regexp-i18n';\n\nconst matchLetterPattern = '[' + Constants.LETTERS + ']';\nconst rx = new RegExp(matchLetterPattern, 'ug');\n\nlet data = '\u4ed6\u8d70\u904e\u57ce\u5e02\u7684\u72d7\u4ed6\u7684\u5144\u5f1f\u751f\u6c23\u4e86123';\nconsole.log(data.replace(rx, '')); // 123\nconsole.log(trim(data, Ranges.LETTERS)); // 123\n```\n\n1. `LETTERS` - all 18n letters\n1. `LETTERS_AND_DIACRITICS` - all i18n letters and diacritics\n1. `LETTERS_DIGITS_AND_DIACRITICS` - all i18n letters, digits and diacritics\n1. `DIACRITICS` - Special class of characters. Modifies previous character. Can't be stripped out without changing the text meaning.\n1. `DIGITS` - all i18n digits\n1. `IGNORABLE_SYMBOLS` - all ignorable unicode symbols.\n\n### Patterns\n\nThe patterns are regular expressions ranges well tested and reusable.\n\n1. `MATCH_LETTER` - Matches all 18n characters with diacritics. This is a strict pattern. All outstanding diacritics won't be matched.\n1. `MATCH_IGNORABLE_SYMBOLS` - Matches ignorable unicode symbols. These symbols are usually are not visible and could be ignored.\n\n```typescript\nimport { Patterns } from 'regexp-i18n';\n\nconst rx = new RegExp(Patterns.MATCH_LETTER, 'ug');\n\nlet data = '$\u0c95\u0ca8\u0ccd\u0ca8\u0ca1\u0cc8\u0c88123#';\nconsole.log(data.replace(rx, '')); // 123#\n```\n\n### Functions\n\n```typescript\nreplaceNotMatching(pattern: string, replaceValue: string, text: string): string;\n```\n\nAttempt to make a function replacing everything not matching to the pattern.\nThe motivation for it that it is impossible to make an inverse `MATCH_LETTER` pattern.\nNot very reliable in the complex cases yet.\n\n```typescript\ntrim(text: string, range: Range): string;\n```\n\nRemoves all leading and trailing characters in the given range from the text.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-gantt",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-gantt\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-gantt.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-gantt) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-gantt/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-gantt?branch=master)\n\n> A Gantt chart is a type of bar chart which illustrates a project timeline or schedule. The Gantt Chart visual shows the Tasks, Start Dates, Durations, % Complete, and Resources for a project. The Gantt Chart visual can be used to show current schedule status using percent-complete shadings and a vertical \"TODAY\" line. The Legend may be used to group or filter tasks based upon data values.\n\n![Gantt chart screenshot](https://github.com/microsoft/powerbi-visuals-gantt/blob/master/assets/screenshot.png?raw=true)\n\n# Overview\n\nGantt chart is a type of bar chart to illustrate a schedule with time axis. When you put Gantt chart along with other insightful charts in an interactive canvas, you can manage your project in whole new way. In Power BI as visuals interact with each other, you can look at your resource allocation, task completion, remaining tasks in different perspective and get a firm handle on the future.\nGantt charts are indispensable part of project management portfolio. Project Managers and executives love Gantt charts, since they visually show in a very effective at-a-glance way, the overall time line of the project, the current status & progress (or lack thereof) along with the assignment at considerable details.\nWith this custom visual, you can specify the Tasks, Start Date, Duration and %Completion for rendering them as Gantt. Please note that the %Completion expects a decimal value ( for example 0.85 means 85%) and Start Date , a date field and not a date hierarchy.\nYou can also control the color of the bar with a Legend. You can use any relevant field from your project as Legend for example task type for this purpose. Additionally, you can also specify the resource field, which would be listed next the bar in the Gantt.\n\nSee also [Gantt chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380765&sourcecorrid=968c5e90-8711-48fe-b9b4-a15ad9fe8dc4&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n"
 },
 {
  "repo": "microsoft/vscode-js-profile-visualizer",
  "language": "TypeScript",
  "readme_contents": "# vscode-js-profile-visualizer\n\nA custom editor for viewing `.cpuprofile` files in VS Code. Pairs well with out new [JavaScript debugger](https://github.com/microsoft/vscode-js-debug).\n\n![](./table.png)\n![](./flame.png)\n\n\n## Contributing\n\nThis is a Lerna monorepo, with a core package that shares data models and some UI between extensions.\n\n- You can use `npm run watch` to watch _everything_, or, for example, `npm run watch:flame`, to only watch changes to the flame graph extension.\n- There's a launch config that runs all extensions.\n- `npm run compile`, again with scopes like `compile:flame`, create static compilations of various packages.\n- If you need to install a dependency in one package, you can use `lerna add`, or add it to the package.json and then run `lerna bootstrap`.\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-Tornado",
  "language": "TypeScript",
  "readme_contents": "# PowerBI-visuals-Tornado\n![Node.js CI](https://github.com/microsoft/PowerBI-visuals-Tornado/workflows/Node.js%20CI/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/PowerBI-visuals-Tornado/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/PowerBI-visuals-Tornado?branch=master)\n\n\n> A bar chart with category values listed vertically. Use for comparing the relative importance of a variable between two distinct groups.\n\n![Tornado chart screenshot](https://github.com/microsoft/PowerBI-visuals-Tornado/blob/master/assets/screenshot.png?raw=true)\n# Overview\nTornado charts, are a special type of Bar chart, where the data categories are listed vertically instead of the standard horizontal presentation, and the categories are ordered so that the largest bar appears at the top of the chart, the second largest appears second from the top, and so on. They are so named because the final chart visually resembles either one half of or a complete tornado.\n\nA tornado chart is a common tool used to depict the sensitivity of a result to changes in selected variables. It shows the effect on the output of varying each input variable at a time, keeping all the other input variables at their initial (nominal) values. Typically, you choose a \u201clow\u201d and a \u201chigh\u201d value for each input.\n\nSee also [Tornado chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380768&sourcecorrid=dff81fda-dee7-4787-a5f6-1203b993fe0c&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n"
 },
 {
  "repo": "microsoft/PhoneticMatching",
  "language": "C#",
  "readme_contents": "[![Build status](https://dev.azure.com/maluuba/PhoneticMatching/_apis/build/status/PhoneticMatching-Build-Binaries-GitHub)](https://dev.azure.com/maluuba/PhoneticMatching/_build/latest?definitionId=96)\n\n# Introduction\nA phonetic matching library. Includes text utilities to do string comparisons on phonemes (the sound of the string), as opposed to characters.\n\nDocs can be found at: https://microsoft.github.io/PhoneticMatching/\n\nSupported API:\n* C++\n* Node.js (>=8.11.2)\n* C# .NET Core (>=2.1)\n\nSupported Languages\n* English\n\nCurrent pre-built binaries offered to save the trouble of compiling the source locally.\n* node-v{67,64,59,57}-{win32,linux,darwin}-{x64}\n\n(Run `node -p \"process.versions.modules\"` to see which Node-ABI in use.)\n# Getting Started\nThis repository consists of TypeScript and native dependencies built with `node-gyp`. See `package.json` for various scripts for the development process.\n\nFor first time building remember to `npm install`\n\nThis repository uses git submodules. If paths are outdated or non-existent run `git submodule update --init --recursive`\n\n## Install\nTo install from NPM\n```\nnpm install phoneticmatching\n```\n\n## Usage\nSee the typings for more details. <br> Classes prefixed with `En` make certain assumptions that are specific to the English language.\n```ts\nimport { EnPronouncer, EnPhoneticDistance, FuzzyMatcher, AcceleratedFuzzyMatcher, EnHybridDistance, StringDistance } from \"phoneticmatching\";\n```\n__Speech__ The namespace containing the type interfaces of the library objects.\n\n__EnPronouncer__ Pronounces a string, as a General English speaker, into its IPA string or array of Phones format.\n\n__matchers__ module:\n\n* __FuzzyMatcher__ Main use case for this library. Returns matches against a list of targets for a given query. The comparisons are not remembered and therefore better for one-off use cases.\n\n* __AcceleratedFuzzyMatcher__ Same interface as `FuzzyMatcher` but the list of targets are precomputed, so beneficial for multiple queries at the cost of a higher initialization time.\n\n* __EnContactMatcher__ A domain specialization of using the `AcceleratedFuzzyMatcher` for English speakers searching over a list of names. Does additional preprocessing and setups up the distance function for you.\n\n* __EnPlaceMatcher__ A domain specialization of using the `AcceleratedFuzzyMatcher` for English speakers searching over a list of places. Does additional preprocessing and setups up the distance function for you.\n\n__distance__ module:\n\n* __EnPhoneticDistance__ Returns a metric distance score between two English pronunciations.\n\n* __StringDistance__ Returns a metric distance score between two strings (edit distance).\n\n* __EnHybridDistance__ Returns a metric distance score based on a combination of the two above distance metrics (English pronunciations and strings).\n\n* __DistanceInput__ Input object for EnHybridDistance. Hold the text and the pronunciation of that text\n\n__nlp__ module:\n\n* __EnPreProcessor__ English Pre-processor.\n\n* __EnPlacesPreProcessor__ English Pre-processor with specific rules for places.\n\n* __SplittingTokenizer__ Tokenizing base-class that will split on the given RegExp.\n\nHere are some example of how to import modules and classes:\n\n```ts\nimport { EnContactMatcher, EnPlaceMatcher } from \"phoneticmatching\";\n```\n```ts\nimport * as Matchers from \"phoneticmatching/lib/matchers\";\n```\n\n## Example\nJavaScript\n```js\n// Import core functionality from the library.\nconst { EnPhoneticDistance, FuzzyMatcher } = require(\"phoneticmatching\");\n\n// A distance metric over pronunciations.\nconst metric = new EnPhoneticDistance();\n\n// The target list to match against.\nconst targets = [\n    \"Apple\",\n    \"Banana\",\n    \"Blackberry\",\n    \"Blueberry\",\n    \"Grapefruit\",\n    \"Pineapple\",\n    \"Raspberry\",\n    \"Strawberry\",\n];\n\n// Create the fuzzy matcher.\nconst matcher = new FuzzyMatcher(targets, metric);\n// Find the nearest match.\nconst result = matcher.nearest(\"blu airy\");\n/* The result should be:\n * {\n *     // The object from the targets list.\n *     element: 'Blueberry',\n *     // The distance score the from distance function.\n *     distance: 0.041666666666666664\n * }\n */\nconsole.log(result);\n```\nC#\n```csharp\nusing System;\n\n// Import core functionality from the library.\nusing Microsoft.PhoneticMatching.Matchers.FuzzyMatcher.Normalized;\n\npublic class Program\n{\n    public static void Main(string[] args)\n    {\n        // The target list to match against.\n        string[] targets = \n        {\n            \"Apple\",\n            \"Banana\",\n            \"Blackberry\",\n            \"Blueberry\",\n            \"Grapefruit\",\n            \"Pineapple\",\n            \"Raspberry\",\n            \"Strawberry\",\n        };\n\n        // Create the fuzzy matcher.\n        var matcher = new EnPhoneticFuzzyMatcher<string>(targets);\n\n        // Find the nearest match.\n        var result = matcher.FindNearest(\"blu airy\");\n\n        /* The result should be:\n         * {\n         *     // The object from the targets list.\n         *     element: 'Blueberry',\n         *     // The distance score the from distance function.\n         *     distance: 0.0416666666666667\n         * }\n         */\n        Console.WriteLine(\"element : [{0}] - distance : [{1}]\", result.Element, result.Distance);\n    }\n}\n```\n\n## Build\n### TypeScript Transpiling\n```\nnpm run tsc\n```\n### Native Compiling\n```py\n# X is the parallelization number, usually set to the number of cores of the machine.\n# This cleans and rebuilds everything.\nJOBS=X npm run rebuild\n# For incremental builds.\nJOBS=X npm run build\n```\n\n## Test\n```py\n# Requires native dependencies built, but TypeScript transpiling not required.\nnpm test\n```\n\n## Docs\n```py\n# Generate the doc files from the docstrings.\nnpm run build-docs\n```\n\n## Release\n```py\n# Builds everything, TypeScript & native & docs, as a release build.\nnpm run release\n```\n\n## Deployment/Upload\nNote that the .js library code and native dependencies will be deployed separately. Npm registries will be used for the .js code, `node-pre-gyp` will be used for prebuilt dependencies while falling back to building on the client.\n```py\n# Pushes pack to npmjs.com or a private registry if a .npmrc exists.\nnpm publish\n```\n```py\n# Packages a ./build/stage/{version}/maluubaspeech-{node_abi}-{platform}-{arch}.tar.gz.\n# See package.json:binary.host on where to put it.\nnpm run package\n```\n\n## NuGet Publish\nA .NET Core NuGet package is published for this project. The package is published by Microsoft. Hence, it must follow guidance at https://aka.ms/nuget and sign package content and package itself with an official Microsoft certificate. To ease signing and publishing process, we integrate ESRP signing to Azure DevOps build tasks.\nTo publish a new version of the package, create a release for the latest build (Pipelines->Releases->PublishNuget->Create a release).\n\n# Contributors\nThis project welcomes contributions and suggestions. Most contributions require you to\nagree to a Contributor License Agreement (CLA) declaring that you have the right to,\nand actually do, grant us the rights to use your contribution. For details, visit\nhttps://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need\nto provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the\ninstructions provided by the bot. You will only need to do this once across all repositories using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Reporting Security Issues\n\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security\nResponse Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should\nreceive a response within 24 hours. If for some reason you do not, please follow up via\nemail to ensure we received your original message. Further information, including the\n[MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in\nthe [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\n\n# License\nCopyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License.\n\nSee sources for licenses of dependencies.\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-StrippetsBrowser",
  "language": "JavaScript",
  "readme_contents": "[![CircleCI](https://circleci.com/gh/Microsoft/PowerBI-visuals-StrippetsBrowser/tree/master.svg?style=svg)](https://circleci.com/gh/Microsoft/PowerBI-visuals-StrippetsBrowser/tree/master)\n\n# Strippet Browser Custom Visual\n![Alt text](assets/screenshot.png?raw=true \"Strippets Browser\")\n\n## Debugging\n\n1. Install ssl certificate by running `npm run install-certificate` and following the steps from: [https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/CertificateSetup.md](https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/CertificateSetup.md)\n2. Enable Developer Tools in PowerBI: [https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/DebugVisualSetup.md](https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/DebugVisualSetup.md)\n3. Run `npm start` to start development.\n\n## Building\n\n1. Run `npm install` to download the dependencies.\n2. Run `npm run package` to package the visual.\n\nA `.pbiviz` file will be generated in the `dist` folder\n\n## Testing\n\nRun `npm test`\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-bulletchart",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-bulletchart\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-bulletchart.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-bulletchart) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-bulletchart/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-bulletchart?branch=master)\n\n> A bullet chart that includes four orientations and a few customization options. Use to feature a single measure against a qualitative range.\n\n![Bullet chart screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680538/Asset_5af45ce2-9b52-4aca-8c72-17e2a47b1c0b/BulletChartscreenshot3.png)\n# Overview\n\nBullet chart serves as a replacement for dashboard gauges and meters. Bullet charts were developed to overcome the fundamental issues of gauges and meters.\n\nThe bullet chart features a single, primary measure (for example, current year-to-date revenue), compares that measure to one or more other measures to enrich its meaning (for example, compared to a target), and displays it in the context of qualitative ranges of performance, such as poor, satisfactory, and good. The qualitative ranges are displayed as varying intensities of a single hue to make them discernible by those who are color blind and to restrict the use of colors on the dashboard to a minimum.\n\nBullet charts may be horizontal or vertical, and may be stacked to allow comparisons of several measures at once.\n\nThe Bullet chart consists of 5 primary components:\n* Text label: Your chart caption which defines what your chart is about and the unit of measurement.\n* Quantitative Scale: Measures the value of your metric on a linear axis.\n* The Featured Measure: The bar that displays the primary performance measure (eg: Revenue YTD).\n* Comparative Measure: The measure against which you want to compare your featured measure (eg: Target revenue).\n* Qualitative Scale: The background fill that encodes qualitative ranges like bad, satisfactory, and good.\n\nSee also [Bullet chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380755&sourcecorrid=69216a8c-bd11-4cd0-9e5b-9c4e0469b74b&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)"
 },
 {
  "repo": "microsoft/pxt",
  "language": "TypeScript",
  "readme_contents": "# Microsoft MakeCode\n\n* [Try out the editors in your browser...](https://makecode.com)\n\nMicrosoft MakeCode is based on the open source project [Microsoft Programming Experience Toolkit (PXT)](https://github.com/microsoft/pxt). ``Microsoft MakeCode`` is the name in the user-facing editors, ``PXT`` is used in all the GitHub sources.\n\nPXT is a framework for creating special-purpose programming experiences for\nbeginners, especially focused on computer science education. PXT's underlying\nprogramming language is a subset of TypeScript (leaving out JavaScript dynamic\nfeatures).\n\nThe main features of PXT are:\n* a Blockly-based code editor along with converter to the text format\n* a Monaco code editor that powers [VS Code](https://github.com/microsoft/vscode), editor's features are listed [here](https://code.visualstudio.com/docs/editor/editingevolved).\n* extensibility support to define new blocks in TypeScript\n* an ARM Thumb machine code emitter\n* a command-line package manager\n\nMore info:\n* [About](https://makecode.com/about)\n* [Documentation](https://makecode.com/docs)\n\nExamples of Editors built with MakeCode:\n\n* https://makecode.microbit.org\n* https://arcade.makecode.com\n* https://makecode.adafruit.com\n* https://minecraft.makecode.com\n* https://makecode.mindstorms.com\n* https://makecode.chibitronics.com\n* More editors at https://makecode.com/labs\n\n## Branches\n\n* ``master`` is the active development branch, currently ``v3.*`` builds\n* ``v*`` is the servicing branch for ``v*.*`` builds\n\n## Running a target from localhost\n\nPlease follow the [instructions here](https://makecode.com/cli).\n\n## Linking a target to PXT\n\nIf you are modifying your own instance of PXT and want a target (such as pxt-microbit) to use your local version, cd to the directory of the target (pxt-microbit, in our example, which should be a directory sibling of pxt) and perform\n\n```\npxt link ../pxt\n```\n\nIf you have multiple checkouts of pxt, you can do the following:\n* run `npm i` in pxt and the target\n* in the target, run `pxt link ..\\some-other-pxt` (you may need to update your CLI first by running `npm install -g pxt`)\n\nIf you run `npm i` afterwards (in either the target or pxt), you might need to repeat these steps.\n\n## Build\n\nFirst, install [Node](https://nodejs.org/en/): minimum version 8.\n\nTo build the PXT command line tools:\n\n```\nnpm install\nnpm run build\n```\n\nThen install the `pxt` command line tool (only need to do it once):\n\n```\nnpm install -g pxt\n```\n\nAfter this you can run `pxt` from anywhere within the build tree.\n\nTo start the local web server, run `pxt serve` from within the root\nof an app target (e.g. pxt-microbit). PXT will open the editor in your default web browser.\n\nIf you are developing against pxt, you can run `gulp watch` from within the root of the\npxt repository to watch for changes and rebuild.\n\n```\ngulp watch\n```\n\nIf you are working on the CLI exclusively,\n\n```\ngulp watchCli\n```\n\n### Icons\n\nThere are a number of custom icons (to use in addition\nto http://semantic-ui.com/elements/icon.html) in the `svgicons/` directory.\nThese need to be `1000x1000px`. Best start with an existing one. To see available icons go to\nhttp://localhost:3232/icons.html (this file, along with `icons.css` containing\nthe generated WOFF icon font, is created during build).\n\nIf you're having trouble with display of the icon you created, try:\n```\nnpm install -g svgo\nsvgo svgicons/myicon.svg\n```\n\n### Documentation Highlighting\n\nIn the documentation, highlighting of code snippets uses highlight.js (hljs).\nCurrently, the following languages are included:\n\n* TypeScript\n* Python\n* JavaScript\n* HTML,XML\n* Markdown\n\nIf you need to add other languages or update existing ones,\nyou can find the distribution at [https://highlightjs.org/download/](https://highlightjs.org/download/);\nselect all the languages you want to include (including the ones above!),\ndownload and unzip,\nand finally copy over `highlight.pack.js` into `webapp/public/highlight.js/`.\n\n## Tests\n\nThe tests are located in the `tests/` subdirectory and are a combination of node and\nbrowser tests. To execute them, run `npm run test:all` in the root directory.\n\n## License\n\n[MIT License](https://github.com/microsoft/pxt/blob/master/LICENSE)\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Contact Us\n\n[Get in touch](https://makecode.com/contact)\n\n## Trademarks\n\nMICROSOFT, the Microsoft Logo, and MAKECODE are registered trademarks of Microsoft Corporation. They can only be used for the purposes described in and in accordance with Microsoft\u2019s Trademark and Brand guidelines published at https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general.aspx. If the use is not covered in Microsoft\u2019s published guidelines or you are not sure, please consult your legal counsel or MakeCode team (makecode@microsoft.com).\n"
 },
 {
  "repo": "microsoft/arcade-machine-react",
  "language": "TypeScript",
  "readme_contents": "# @mixer/arcade-machine-react\n\n:video_game: Input abstraction layer for gamepads, keyboards, and UWP apps in React.\n\nSee [the docs](https://arcademachinedocs.z13.web.core.windows.net/) for more information and interactive examples!\n"
 },
 {
  "repo": "microsoft/LightGBM",
  "language": "C++",
  "readme_contents": "<img src=https://github.com/microsoft/LightGBM/blob/master/docs/logo/LightGBM_logo_black_text.svg width=300 />\n\nLight Gradient Boosting Machine\n===============================\n\n[![Python-package GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/Python-package/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![R-package GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/R-package/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![CUDA Version GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/CUDA%20Version/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![Static Analysis GitHub Actions Build Status](https://github.com/microsoft/LightGBM/workflows/Static%20Analysis/badge.svg?branch=master)](https://github.com/microsoft/LightGBM/actions)\n[![Azure Pipelines Build Status](https://lightgbm-ci.visualstudio.com/lightgbm-ci/_apis/build/status/Microsoft.LightGBM?branchName=master)](https://lightgbm-ci.visualstudio.com/lightgbm-ci/_build/latest?definitionId=1)\n[![Appveyor Build Status](https://ci.appveyor.com/api/projects/status/1ys5ot401m0fep6l/branch/master?svg=true)](https://ci.appveyor.com/project/guolinke/lightgbm/branch/master)\n[![Documentation Status](https://readthedocs.org/projects/lightgbm/badge/?version=latest)](https://lightgbm.readthedocs.io/)\n[![Link checks](https://github.com/microsoft/LightGBM/workflows/Link%20checks/badge.svg)](https://github.com/microsoft/LightGBM/actions?query=workflow%3A%22Link+checks%22)\n[![License](https://img.shields.io/github/license/microsoft/lightgbm.svg)](https://github.com/microsoft/LightGBM/blob/master/LICENSE)\n[![Python Versions](https://img.shields.io/pypi/pyversions/lightgbm.svg?logo=python&logoColor=white)](https://pypi.org/project/lightgbm)\n[![PyPI Version](https://img.shields.io/pypi/v/lightgbm.svg?logo=pypi&logoColor=white)](https://pypi.org/project/lightgbm)\n[![CRAN Version](https://www.r-pkg.org/badges/version/lightgbm)](https://cran.r-project.org/package=lightgbm)\n\nLightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n- Faster training speed and higher efficiency.\n- Lower memory usage.\n- Better accuracy.\n- Support of parallel, distributed, and GPU learning.\n- Capable of handling large-scale data.\n\nFor further details, please refer to [Features](https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst).\n\nBenefiting from these advantages, LightGBM is being widely-used in many [winning solutions](https://github.com/microsoft/LightGBM/blob/master/examples/README.md#machine-learning-challenge-winning-solutions) of machine learning competitions.\n\n[Comparison experiments](https://github.com/microsoft/LightGBM/blob/master/docs/Experiments.rst#comparison-experiment) on public datasets show that LightGBM can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. What's more, [distributed learning experiments](https://github.com/microsoft/LightGBM/blob/master/docs/Experiments.rst#parallel-experiment) show that LightGBM can achieve a linear speed-up by using multiple machines for training in specific settings.\n\nGet Started and Documentation\n-----------------------------\n\nOur primary documentation is at https://lightgbm.readthedocs.io/ and is generated from this repository. If you are new to LightGBM, follow [the installation instructions](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html) on that site.\n\nNext you may want to read:\n\n- [**Examples**](https://github.com/microsoft/LightGBM/tree/master/examples) showing command line usage of common tasks.\n- [**Features**](https://github.com/microsoft/LightGBM/blob/master/docs/Features.rst) and algorithms supported by LightGBM.\n- [**Parameters**](https://github.com/microsoft/LightGBM/blob/master/docs/Parameters.rst) is an exhaustive list of customization you can make.\n- [**Distributed Learning**](https://github.com/microsoft/LightGBM/blob/master/docs/Parallel-Learning-Guide.rst) and [**GPU Learning**](https://github.com/microsoft/LightGBM/blob/master/docs/GPU-Tutorial.rst) can speed up computation.\n- [**Laurae++ interactive documentation**](https://sites.google.com/view/lauraepp/parameters) is a detailed guide for hyperparameters.\n- [**FLAML**](https://www.microsoft.com/en-us/research/project/fast-and-lightweight-automl-for-large-scale-data/articles/flaml-a-fast-and-lightweight-automl-library/) provides automated tuning for LightGBM ([code examples](https://github.com/microsoft/FLAML/blob/main/notebook/flaml_lightgbm.ipynb)).\n- [**Optuna Hyperparameter Tuner**](https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258) provides automated tuning for LightGBM hyperparameters ([code examples](https://github.com/optuna/optuna/tree/master/examples/lightgbm)).\n\nDocumentation for contributors:\n\n- [**How we update readthedocs.io**](https://github.com/microsoft/LightGBM/blob/master/docs/README.rst).\n- Check out the [**Development Guide**](https://github.com/microsoft/LightGBM/blob/master/docs/Development-Guide.rst).\n\nNews\n----\n\nPlease refer to changelogs at [GitHub releases](https://github.com/microsoft/LightGBM/releases) page.\n\nSome old update logs are available at [Key Events](https://github.com/microsoft/LightGBM/blob/master/docs/Key-Events.md) page.\n\nExternal (Unofficial) Repositories\n----------------------------------\n\nFLAML (AutoML library for hyperparameter optimization): https://github.com/microsoft/FLAML\n\nOptuna (hyperparameter optimization framework): https://github.com/optuna/optuna\n\nJulia-package: https://github.com/IQVIA-ML/LightGBM.jl\n\nJPMML (Java PMML converter): https://github.com/jpmml/jpmml-lightgbm\n\nTreelite (model compiler for efficient deployment): https://github.com/dmlc/treelite\n\nHummingbird (model compiler into tensor computations): https://github.com/microsoft/hummingbird\n\ncuML Forest Inference Library (GPU-accelerated inference): https://github.com/rapidsai/cuml\n\ndaal4py (Intel CPU-accelerated inference): https://github.com/IntelPython/daal4py\n\nm2cgen (model appliers for various languages): https://github.com/BayesWitnesses/m2cgen\n\nleaves (Go model applier): https://github.com/dmitryikh/leaves\n\nONNXMLTools (ONNX converter): https://github.com/onnx/onnxmltools\n\nSHAP (model output explainer): https://github.com/slundberg/shap\n\ndtreeviz (decision tree visualization and model interpretation): https://github.com/parrt/dtreeviz\n\nMMLSpark (LightGBM on Spark): https://github.com/Azure/mmlspark\n\nKubeflow Fairing (LightGBM on Kubernetes): https://github.com/kubeflow/fairing\n\nKubeflow Operator (LightGBM on Kubernetes): https://github.com/kubeflow/xgboost-operator\n\nML.NET (.NET/C#-package): https://github.com/dotnet/machinelearning\n\nLightGBM.NET (.NET/C#-package): https://github.com/rca22/LightGBM.Net\n\nRuby gem: https://github.com/ankane/lightgbm\n\nLightGBM4j (Java high-level binding): https://github.com/metarank/lightgbm4j\n\nlightgbm-rs (Rust binding): https://github.com/vaaaaanquish/lightgbm-rs\n\nMLflow (experiment tracking, model monitoring framework): https://github.com/mlflow/mlflow\n\n`{treesnip}` (R `{parsnip}`-compliant interface): https://github.com/curso-r/treesnip\n\n`{mlr3learners.lightgbm}` (R `{mlr3}`-compliant interface): https://github.com/mlr3learners/mlr3learners.lightgbm\n\nSupport\n-------\n\n- Ask a question [on Stack Overflow with the `lightgbm` tag](https://stackoverflow.com/questions/ask?tags=lightgbm), we monitor this for new questions.\n- Open **bug reports** and **feature requests** (not questions) on [GitHub issues](https://github.com/microsoft/LightGBM/issues).\n\nHow to Contribute\n-----------------\n\nCheck [CONTRIBUTING](https://github.com/microsoft/LightGBM/blob/master/CONTRIBUTING.md) page.\n\nMicrosoft Open Source Code of Conduct\n-------------------------------------\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nReference Papers\n----------------\n\nGuolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma, Qiwei Ye, Tie-Yan Liu. \"[LightGBM: A Highly Efficient Gradient Boosting Decision Tree](https://papers.nips.cc/paper/6907-lightgbm-a-highly-efficient-gradient-boosting-decision-tree)\". Advances in Neural Information Processing Systems 30 (NIPS 2017), pp. 3149-3157.\n\nQi Meng, Guolin Ke, Taifeng Wang, Wei Chen, Qiwei Ye, Zhi-Ming Ma, Tie-Yan Liu. \"[A Communication-Efficient Parallel Algorithm for Decision Tree](http://papers.nips.cc/paper/6380-a-communication-efficient-parallel-algorithm-for-decision-tree)\". Advances in Neural Information Processing Systems 29 (NIPS 2016), pp. 1279-1287.\n\nHuan Zhang, Si Si and Cho-Jui Hsieh. \"[GPU Acceleration for Large-scale Tree Boosting](https://arxiv.org/abs/1706.08359)\". SysML Conference, 2018.\n\n**Note**: If you use LightGBM in your GitHub projects, please add `lightgbm` in the `requirements.txt`.\n\nLicense\n-------\n\nThis project is licensed under the terms of the MIT license. See [LICENSE](https://github.com/microsoft/LightGBM/blob/master/LICENSE) for additional details.\n"
 },
 {
  "repo": "microsoft/react-native-windows",
  "language": "C++",
  "readme_contents": "<h1 align=\"center\"> React Native for Windows </h1>\n\n<p align=\"center\">\n  Build native Windows apps with React.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/microsoft/react-native-windows/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-blue.svg\" alt=\"React Native for Windows is released under the MIT license.\" />\n  </a>\n  <a href=\"https://www.npmjs.org/package/react-native-windows\">\n    <img src=\"https://img.shields.io/npm/v/react-native-windows?color=e80441&label=react-native-windows\" alt=\"Current npm package version.\" />\n  </a>\n  <a href=\"https://github.com/microsoft/react-native-windows#contributing\">\n    <img src=\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg\" alt=\"PRs welcome!\" />\n  </a>\n</p>\n\n![Hero Image with Logo](https://github.com/microsoft/react-native-windows/raw/master/.github/hero2.png)\n\n> See the official [React Native website](https://reactnative.dev/) for an introduction to React Native.\n\n[React Native](https://reactnative.dev) is a framework developed by Facebook that enables you to build world-class application experiences on native platforms using a consistent developer experience based on JavaScript and [React](https://reactjs.org/). The focus of React Native is on developer efficiency across all the platforms you care about - learn once, write anywhere.\n\nThis repository adds support for the [Windows 10 SDK](https://developer.microsoft.com/en-us/windows/downloads), which allows you to build apps for [all devices supported by Windows 10](https://developer.microsoft.com/en-us/windows/get-started-windows-10) including PCs, tablets, 2-in-1s, Xbox, Mixed reality devices etc.\n\nVisit the official [React Native for Windows + macOS website](https://microsoft.github.io/react-native-windows) to learn more.\n\n## Contents\n\n- [Requirements](#requirements)\n- [Getting Started](#getting-started)\n- [Contributing](#contributing)\n- [Documentation](#documentation)\n- [License](#license)\n- [Code of Conduct](#code-of-conduct)\n\n### Status and roadmap\n[Check out our blog](https://microsoft.github.io/react-native-windows/blog/) if you'd like to stay up to date on the status of React Native for Windows and check out current and past roadmaps. We will post all new releases, updates and general news about the project there.\n\n## Requirements\nYou can run React Native Windows apps only on devices supported by the [Windows 10 SDK](https://developer.microsoft.com/en-us/windows/downloads).\n\nFor a full and detailed list of the system requirements and how to set up your development platform, see our [System Requirements](https://microsoft.github.io/react-native-windows/docs/rnw-dependencies) documentation on our website.\n\n## Getting Started\nSee the [Getting Started Guide](https://microsoft.github.io/react-native-windows/docs/getting-started) on our React Native for Windows + macOS website to build your first React Native for Windows app.\n\n### Logging Issues\nSearch the [existing issues](https://github.com/microsoft/react-native-windows/issues) and try to make sure your problem doesn\u2019t already exist before opening a new issue. If your issue doesn't exist yet, try to make sure you provide as much information as possible to us so we can help you sooner. It\u2019s helpful if you include information like:\n\n- The version of Windows, React Native, React Native Windows extension, and device family (i.e., mobile, desktop, Xbox, etc.) where you ran into the issue.\n- A stack trace and reduced repro case when possible.\n- Ensure the [appropriate template](https://github.com/microsoft/react-native-windows/issues/new/choose) is used when filing your issue(s).\n\n## Contributing\nSee [Contributing guidelines](https://github.com/microsoft/react-native-windows/blob/master/docs/contributing.md) for how to setup your fork of the repo and start a PR to contribute to React Native for Windows.\n\n[good first issue](https://github.com/microsoft/react-native-windows/labels/good%20first%20issue) and [help wanted](https://github.com/microsoft/react-native-windows/labels/help%20wanted) are great starting points for PRs.\n\n## Documentation\n[React Native already has great documentation](https://reactnative.dev/docs/getting-started) and we're working to ensure the React Native Windows is part of that documentation story.\n\n[React Native for Windows](https://microsoft.github.io/react-native-windows/) has it's own separate documentation site where Windows and macOS specific information, like API docs and blog updates live.\n\n### Examples\n- Using the CLI in the [Getting Started](https://microsoft.github.io/react-native-windows/docs/getting-started) guide will set you up with a sample React Native for Windows app that you can begin editing right away.\n- If you're looking for sample code, just browse the RNTester folder in the GitHub web UI\n\n## License\nThe React Native Windows extension, including modifications to the original Facebook source code, and all newly contributed code is provided under the [MIT License](LICENSE). Portions of the React Native Windows extension derived from React Native are copyright Facebook.\n\n## Code of Conduct\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/PSRule-vscode",
  "language": "PowerShell",
  "readme_contents": "# PSRule\n\nValidate infrastructure as code (IaC) and DevOps repositories using the PSRule PowerShell module.\nPSRule is powerful, feature rich, and highly customizable to meet your needs.\n\n![ext-stable-version-badge] ![ext-stable-installs-badge] ![module-version-badge]\n\nThis extension is available in two release channels:\n\nChannel | Description | Version/ downloads\n------- | ----------- | ---\n[Preview][ext-preview] | More frequent releases but more likely to contain bugs. | [![Preview][ext-preview-version-badge]][ext-preview] ![ext-preview-installs-badge]\n[Stable][ext-stable] | Less frequent releases, with more user testing, experimental features are disabled. | [![Stable][ext-stable-version-badge]][ext-stable] ![ext-stable-installs-badge]\n\n## Features\n\n### IntelliSense\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/microsoft/PSRule-vscode/main/docs/images/options-schema-flyout.png\" alt=\"Options suggestion context menu\" />\n</p>\n\n- Adds IntelliSense and validation support for configuring options and resources.\n  - **Workspace options** &mdash; use IntelliSense to configure options for the workspace.\n    - Type or trigger IntelliSense with `Ctrl+Space` from `ps-rule.yaml`.\n  - **Create resources** &mdash; define _baselines_ and _selectors_ by using pre-built snippets and IntelliSense.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/microsoft/PSRule-vscode/main/docs/images/snippet-rule-type.png\" alt=\"Rule definition snippet\" />\n</p>\n\n- Adds snippets for defining new rules.\n  - **Define rules** with snippets and IntelliSense support.\n    - Trigger IntelliSense by typing `rule` in a `.Rule.ps1` file.\n    IntelliSense can also be triggered by using the shortcut `Ctrl+Space`.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/microsoft/PSRule-vscode/main/docs/images/snippet-markdown.png\" alt=\"Rule markdown documentation snippet\" />\n</p>\n\n- Adds snippets for creating markdown documentation.\n  - **Quick documentation**  &mdash; create rule documentation to provide rule recommendations and examples.\n    - Trigger IntelliSense by typing `rule` in a `.md` file.\n    IntelliSense can also be triggered by using the shortcut `Ctrl+Space`.\n\n## Support\n\nThis project uses GitHub Issues to track bugs and feature requests.\nPlease search the existing issues before filing new issues to avoid duplicates.\n\n- For new issues, file your bug or feature request as a new [issue].\n- For help, discussion, and support questions about using this project, join or start a [discussion].\n\nSupport for this project/ product is limited to the resources listed above.\n\n## Installing PSRule module\n\nPSRule is available from the PowerShell Gallery and is required for this extension to work.\n\nTo install the module use the following command from a PowerShell prompt.\n\n```powershell\nInstall-Module -Name PSRule -Scope CurrentUser;\n```\n\n## Installing the extension\n\nYou can install the latest release of the extension by following the steps in the [Visual Studio Code documentation][vscode-ext-gallery].\nIn the Extensions pane, search for _PSRule_ extension and install it there.\nYou will get notified automatically about any future extension updates.\n\n```text\ncode --install-extension bewhite.psrule-vscode-preview\n```\n\n> NOTE: If you are using VS Code Insiders, the command will be `code-insiders`.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.\nIf you are ready to contribute, please visit the [contribution guide].\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Maintainers\n\n- [Bernie White](https://github.com/BernieWhite)\n\n## License\n\nThis project is [licensed under the MIT License][license].\n\n[issue]: https://github.com/Microsoft/PSRule-vscode/issues\n[discussion]: https://github.com/microsoft/PSRule-vscode/discussions\n[ci-badge]: https://dev.azure.com/bewhite/PSRule-vscode/_apis/build/status/PSRule-vscode-CI?branchName=main\n[vscode-ext-gallery]: https://code.visualstudio.com/docs/editor/extension-gallery\n[ext-preview]: https://marketplace.visualstudio.com/items?itemName=bewhite.psrule-vscode-preview\n[ext-preview-version-badge]: https://vsmarketplacebadge.apphb.com/version/bewhite.psrule-vscode-preview.svg\n[ext-preview-installs-badge]: https://vsmarketplacebadge.apphb.com/installs-short/bewhite.psrule-vscode-preview.svg\n[ext-stable]: https://marketplace.visualstudio.com/items?itemName=bewhite.psrule-vscode\n[ext-stable-version-badge]: https://vsmarketplacebadge.apphb.com/version/bewhite.psrule-vscode.svg\n[ext-stable-installs-badge]: https://vsmarketplacebadge.apphb.com/installs-short/bewhite.psrule-vscode.svg\n[module-version-badge]: https://img.shields.io/powershellgallery/v/PSRule.svg?label=PowerShell%20Gallery&color=brightgreen\n[contribution guide]: https://github.com/Microsoft/PSRule-vscode/blob/main/CONTRIBUTING.md\n[change log]: https://github.com/Microsoft/PSRule-vscode/blob/main/CHANGELOG.md\n[license]: https://github.com/Microsoft/PSRule-vscode/blob/main/LICENSE\n[chat]: https://gitter.im/PSRule/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge\n[chat-badge]: https://img.shields.io/static/v1.svg?label=chat&message=on%20gitter&color=informational&logo=gitter\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-chord",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-chord\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-chord.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-chord) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-chord/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-chord?branch=master)\n[![Build Status](https://dev.azure.com/customvisuals/public/_apis/build/status/Microsoft.powerbi-visuals-chord)](https://dev.azure.com/customvisuals/public/_build/latest?definitionId=2) [![Known Vulnerabilities](https://snyk.io/test/github/Microsoft/powerbi-visuals-chord/badge.svg)](https://snyk.io/test/github/Microsoft/powerbi-visuals-chord)\n\n> A chord diagram is a graphical method of displaying the inter-relationships between data in a matrix.\n\n![Chord diagramm screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680579/Asset_75a4e3dc-78d5-4a5d-b14b-d11cc0d3b730/Chordscreenshot1.png)\n# Overview\nThis type of diagram visualizes the inter-relationships between entities. The connections between entities are used to display that they share something in common. This makes Chord Diagrams ideal for comparing the similarities within a dataset or between different groups of data.\n\nNodes are arranged around a circle, with the relationships between points connected to each other either through the use of arcs or B\u00e9zier curves. Values are assigned to each connection, which is represented proportionally by the size of each arc.\n\nCustomize data colors, axis, labels and more.\n\nSee also [Chord chart at the Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380761&sourcecorrid=6ef257f3-686c-4b70-8b23-0dafd318e298&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-WordCloud",
  "language": "TypeScript",
  "readme_contents": "# PowerBI-visuals-WordCloud\n[![Build Status](https://travis-ci.org/Microsoft/PowerBI-visuals-WordCloud.svg?branch=master)](https://travis-ci.org/Microsoft/PowerBI-visuals-WordCloud)\n[![Coverage Status](https://coveralls.io/repos/github/Microsoft/PowerBI-visuals-WordCloud/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/PowerBI-visuals-WordCloud?branch=master)\n> Word Cloud is a visual representation of word frequency and value. Use it to get instant insight into the most important terms in a set.\n\n![Wordcloud chart screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680547/Asset_82e6791c-3970-4cd9-b687-1e9100c8ef5a/WordCloudscreenshot1.png)\n# Overview\nWord Cloud is a visual representation of word frequency and value. Use it to get instant insight into the most important terms in your data.\n\nWith the interactive experience of Word Cloud in Power BI, you no longer have to tediously dig through large volumes of text to find out which terms are prominent or prevalent. You can simply visualize them as Word Cloud and get the big picture instantly and user Power BI\u2019s interactivity to slice and dice further to uncover the themes behind the text content.\n\nThis visual also puts you in control on the appearance of the work cloud, be it the size or usage of space and how to treat the data. You can choose to break the words in the text to look for the frequency word or keep word break off to project a measure as a value of the text. You can also enable stop words to remove the common terms from the word cloud to avoid the clutter. By enabling rotation and playing with the angles allowed, you can become very creative with this visual.\n\nOptionally you can also use a measure to provide weightage to the text. If none provided, it will simply use the frequency. Check out the formatting pane for more options.\n\nSee also [Word Cloud at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380752&sourcecorrid=037b6fba-5738-4e90-a8ff-c4f1575a0b05&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)"
 },
 {
  "repo": "microsoft/azure-devops-extension-tasks",
  "language": "TypeScript",
  "readme_contents": "# Azure DevOps Extension Tasks\nBuild: [![Build Status](https://dev.azure.com/jessehouwing/azure-devops-extensions/_apis/build/status/azure-devops-extension-tasks/microsoft.azure-devops-extension-tasks?branchName=main&stageName=Build)](https://dev.azure.com/jessehouwing/azure-devops-extensions/_build/latest?definitionId=77&branchName=main) \nRelease: [![Build Status](https://dev.azure.com/jessehouwing/azure-devops-extensions/_apis/build/status/azure-devops-extension-tasks/microsoft.azure-devops-extension-tasks?branchName=main&stageName=Publish%20publicly%20to%20MsDevLabs)](https://dev.azure.com/jessehouwing/azure-devops-extensions/_build/latest?definitionId=77&branchName=main)\n\nThis extension provides build and release tasks for packaging and publishing Azure Devops Extensions to the [Visual Studio Marketplace](https://marketplace.visualstudio.com). There are also tasks to share and install your extension to your Azure Devops organization or Team Foundation Server.\n\n## To use\n\n[Learn more](https://marketplace.visualstudio.com/items?itemName=ms-devlabs.vsts-developer-tools-build-tasks) about this extension about and install the extension into your Azure DevOps Organisation via the Visual Studio Marketplace.\n\n## Available tasks\n\nAzure DevOps\n\n* **Package**: package an Azure DevOps extension into an extension package (.VSIX) file\n* **Publish**: (optionally) package and publish an extension (either privately or publicly) to the Visual Studio Marketplace\n* **Unpublish**: unpublish an extension from the Visual Studio Marketplace\n* **Share**: share an extension with an Azure DevOps organisation\n* **Install**: install an extension to an Azure DevOps organisation\n* **Query version**: query an extension's version (to make it easy to increment on your next package or publish)\n* **Wait for validation**: waits for the Visual Studio Marketplace validation to come through.\n\nVisual Studio\n\n* **Publish**: Publish a Visual Studio extension to the Visual Studio Marketplace\n\n### Required scopes\n\n When creating a personal access token for use by your pipeline, make sure the token has at least the following scopes for the task(s) you are using:\n\n* **Publish**: `All accessible organisations`, `Marketplace (publish)`\n* **Unpublish**: `All accessible organisations`, `Marketplace (manage)`\n* **Share**: `All accessible organisations`, `Marketplace (publish)`\n* **Install**: `All accessible organisations` or a specific Organisation, `Extensions (read and manage)`, `Marketplace (acquire)`\n* **Query Version**: `All accessible organisations`, `Marketplace (read)`\n* **Is Valid**: `All accessible organisations`, `Marketplace (read)`\n\n![Permissions](permissions.png)\n\n## Contribute\n\n1. From the root of the repo run `npm run initdev`. This will pull down the necessary modules and TypeScript declare files.\n2. Run `npm run build` to compile the build tasks.\n3. Run `npm run package` to create a .vsix extension package that includes the build tasks.\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-dataviewutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals DataViewUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-dataviewutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-dataviewutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-dataviewutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-dataviewutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-dataviewutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-dataviewutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-dataviewutils)\n\n> DataViewUtils is a set of functions and classes in order to simplify parsing of the DataView object for Power BI custom visuals\n\n## Usage\nLearn how to install and use the DataViewUtils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-dataview)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-dataviewutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-tooltiputils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals TooltipUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-tooltiputils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-tooltiputils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-tooltiputils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-tooltiputils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-tooltiputils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-tooltiputils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-tooltiputils)\n\n> TooltipUtils is a set of functions and classes in order to simplify usage of the Tooltip API for Power BI custom visuals\n\n## Usage\nLearn how to install and use the TooltipUtils in your custom visuals:\n* [Installation Guide](./docs/usage/installation-guide.md)\n* [Usage Guide](./docs/usage/usage-guide.md)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-tooltiputils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/license-checker-webpack-plugin",
  "language": "JavaScript",
  "readme_contents": "# license-checker-webpack-plugin\n\nWebpack plugin that verifies licenses of all external dependencies in a compilation, and outputs all that information to a file.\n\n## Installation\n\n### npm\n\n```\nnpm install license-checker-webpack-plugin --save-dev\n```\n\n### yarn\n\n```\nyarn add license-checker-webpack-plugin --dev\n```\n\n## Usage\n\nRequire the plugin into your Webpack configuration, and pass it to the `plugins` array.\n\n```js\nconst LicenseCheckerWebpackPlugin = require(\"license-checker-webpack-plugin\");\n\nmodule.exports = {\n  // ...\n  plugins: [new LicenseCheckerWebpackPlugin({ outputFilename: \"ThirdPartyNotices.txt\" })]\n};\n```\n\n## Options\n\n| Property         | Type                   | Default                                                    | Description                                                                                                                                                       |\n| ---------------- | ---------------------- | ---------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| `allow`          | `string`               | `\"(Apache-2.0 OR BSD-2-Clause OR BSD-3-Clause OR MIT)\"`    | SPDX expression with allowed licenses.                                                                                                                            |\n| `ignore`         | `array`                | `[]`                                                       | Array of dependencies to ignore, in the format `[\"<dependency name>@<version range>\"]`. For example, `[\"assignment@^2.0.0\"]`.                                     |\n| `override`       | `object`               | `{}`                                                       | Object of dependencies to override, in the format `{\"<dependency name>@<version range>\": { ... }}`. For example, `{\"assignment@^2.0.0\": { licenseName: \"MIT\" }}`. |\n| `emitError`      | `boolean`              | `false`                                                    | Whether to emit errors instead of warnings.                                                                                                                       |\n| `outputWriter`   | `string` or `function` | See [`defaultOutputWriter`](./src/defaultOutputWriter.js). | Path to a `.ejs` template, or function that will generate the contents of the third-party notices file.                                                           |\n| `outputFilename` | `string`               | `\"ThirdPartyNotices.txt\"`                                  | Name of the third-party notices file with all licensing information.                                                                                              |\n\nThe data that gets passed to the `outputWriter` function looks like this:\n\n```json\n[\n  {\n    \"name\": \"react\",\n    \"version\": \"16.3.2\",\n    \"repository\": \"git+https://github.com/facebook/react.git\",\n    \"licenseName\": \"MIT\",\n    \"licenseText\": \"MIT License\\n\\nCopyright (c) 2013-present, Facebook, Inc. [...]\"\n  },\n  {\n    \"name\": \"webpack\",\n    \"version\": \"4.8.3\",\n    \"author\": \"Tobias Koppers @sokra\",\n    \"repository\": \"git+https://github.com/webpack/webpack.git\",\n    \"licenseName\": \"MIT\",\n    \"licenseText\": \"Copyright JS Foundation and other contributors [...]\"\n  },\n  {\n    \"name\": \"whatwg-fetch\",\n    \"version\": \"2.0.4\",\n    \"repository\": \"git+https://github.com/github/fetch.git\",\n    \"licenseName\": \"MIT\",\n    \"licenseText\": \"Copyright (c) 2014-2016 GitHub, Inc. [...]\"\n  }\n]\n```\n\nHere's an example `webpack.config.js` file that uses all options:\n\n```js\nconst path = require(\"path\");\nconst LicenseCheckerWebpackPlugin = require(\"license-checker-webpack-plugin\");\nconst template = require(\"lodash.template\");\n\nmodule.exports = {\n  // ...\n  plugins: [\n    new LicenseCheckerWebpackPlugin({\n      allow: \"(Apache-2.0 OR BSD-2-Clause OR BSD-3-Clause OR MIT)\",\n      ignore: [\"@microsoft/*\"],\n      override: {\n        \"assignment@2.0.0\": { licenseName: \"MIT\" },\n        \"intersection-observer@0.5.0\": { licenseName: \"MIT\" },\n        \"querystring-es3@0.2.1\": { licenseName: \"MIT\" }\n      },\n      emitError: true,\n      outputWriter: path.resolve(__dirname, \"customTemplate.ejs\"),\n      outputFilename: \"ThirdPartyNotices.txt\"\n    })\n  ]\n};\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit <https://cla.microsoft.com>.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Licensing\n\nAll files on this repository are subject to the MIT license. Please read the `LICENSE` file at the root of the project.\n"
 },
 {
  "repo": "microsoft/pxt-event-emitter",
  "language": "TypeScript",
  "readme_contents": "# Project\n\n> This repo has been populated by an initial template to help get you started. Please\n> make sure to update the content to build a great experience for community-building.\n\nAs the maintainer of this project, please make a few updates:\n\n- Improving this README.MD file to provide a great experience\n- Updating SUPPORT.MD with content about this project's support experience\n- Understanding the security reporting process in SECURITY.MD\n- Remove this section from the README\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-testutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals TestUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-testutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-testutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-testutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-testutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-testutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-testutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-testutils)\n\n> TestUtils is a set of mocks and fakes in order to simplify unit testing for Power BI custom visuals\n\n## Usage\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-test)\n\n## 2.3.0 Migration note\n\nFrom version 2.3.0 `testDom` function returns `HTMLElement` instead of `JQuery` object. If you are using JQuery in tests, wrap the `testDom` calls with `$(...)` for compatibility:\n\n```typescript\n    // 2.2.1 and below\n    let element: JQuery = testDom(\"100\", \"100\");\n    // 2.3.0 and above\n    let element: JQuery = $(testDom(\"100\", \"100\"));\n```\n\nThe motivation is not to force JQuery usage. It might be not necessary in tests. In lots of cases `element.get(0)` is the next operation after receiving an element with `testDom`. Now JQuery is not required to use powerbi-visuals-utils-testutils, so you can drop this dependency. If you keep it, you can easily migrate your code to 2.3.* version using the example above.\n\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-testutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-svgutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals SVGUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-svgutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-svgutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-svgutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-svgutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-svgutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-svgutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-svgutils)\n\n> SVGUtils is a set of functions and classes in order to simplify SVG manipulations for Power BI custom visuals\n\n## Usage\nLearn how to install and use the SVGUtils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-svg)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-svgutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-colorutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals ColorUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-colorutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-colorutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-colorutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-colorutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-colorutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-colorutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-colorutils)\n\n> ColorUtils is a set of functions and classes in order to simplify color manipulations for Power BI custom visuals\n\n## Usage\nLearn how to install and use the ColorUtils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-color)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-colorutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-interactivityutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals InteractivityUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-interactivityutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-interactivityutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-interactivityutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-interactivityutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-interactivityutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-interactivityutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-interactivityutils)\n\n> InteractivityUtils is a set of functions and classes in order to simplify implementation of cross-selection and cross-filtering for Power BI custom visuals\n\n## Usage\nLearn how to install and use the InteractivityUtils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-interactivity-selections)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-interactivityutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-typeutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals TypeUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-typeutils/workflows/Build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-typeutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-typeutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-typeutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-typeutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-typeutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-typeutils)\n\n> TypeUtils is a set of functions and classes in order to extend the basic types for Power BI custom visuals\n\n## Usage\nLearn how to install and use the TypeUtils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-type)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-typeutils/issues)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-histogram",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-histogram\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-histogram.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-histogram) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-histogram/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-histogram?branch=master)\n\n> A histogram chart plots data ranges into intervals. Useful for estimating density.\n\n![Histogram chart screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680587/Asset_941ab72a-2c82-405a-b258-6c8c01d13e68/Histogramscreenshot1.png)\n# Overview\nA Histogram shows history representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable (quantitative variable).\n\nThe data is grouped into bins, that is, divide the entire range of values into a series of intervals\u2014and then count how many values fall into each interval.\n\nCustomize the number of bins, whether to use frequency or density, and the data colors.\n\nSee also [Histogram chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380776&sourcecorrid=e26ecce9-0b9e-47f4-9c7a-a023465dafdc&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n"
 },
 {
  "repo": "microsoft/nni",
  "language": "Python",
  "readme_contents": "<p align=\"center\">\n<img src=\"docs/img/nni_logo.png\" width=\"300\"/>\n</p>\n\n-----------\n\n[![MIT licensed](https://img.shields.io/badge/license-MIT-brightgreen.svg)](LICENSE)\n[![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/full%20test%20-%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=62&branchName=master)\n[![Issues](https://img.shields.io/github/issues-raw/Microsoft/nni.svg)](https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen)\n[![Bugs](https://img.shields.io/github/issues/Microsoft/nni/bug.svg)](https://github.com/Microsoft/nni/issues?q=is%3Aissue+is%3Aopen+label%3Abug)\n[![Pull Requests](https://img.shields.io/github/issues-pr-raw/Microsoft/nni.svg)](https://github.com/Microsoft/nni/pulls?q=is%3Apr+is%3Aopen)\n[![Version](https://img.shields.io/github/release/Microsoft/nni.svg)](https://github.com/Microsoft/nni/releases) [![Join the chat at https://gitter.im/Microsoft/nni](https://badges.gitter.im/Microsoft/nni.svg)](https://gitter.im/Microsoft/nni?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Documentation Status](https://readthedocs.org/projects/nni/badge/?version=stable)](https://nni.readthedocs.io/en/stable/?badge=stable)\n\n[NNI Doc](https://nni.readthedocs.io/) | [\u7b80\u4f53\u4e2d\u6587](README_zh_CN.md)\n\n**NNI (Neural Network Intelligence)** is a lightweight but powerful toolkit to help users **automate** <a href=\"https://nni.readthedocs.io/en/stable/FeatureEngineering/Overview.html\">Feature Engineering</a>, <a href=\"https://nni.readthedocs.io/en/stable/NAS/Overview.html\">Neural Architecture Search</a>, <a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html\">Hyperparameter Tuning</a> and <a href=\"https://nni.readthedocs.io/en/stable/Compression/Overview.html\">Model Compression</a>.\n\nThe tool manages automated machine learning (AutoML) experiments, **dispatches and runs** experiments' trial jobs generated by tuning algorithms to search the best neural architecture and/or hyper-parameters in **different training environments** like <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/LocalMode.html\">Local Machine</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/RemoteMachineMode.html\">Remote Servers</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/PaiMode.html\">OpenPAI</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/KubeflowMode.html\">Kubeflow</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/FrameworkControllerMode.html\">FrameworkController on K8S (AKS etc.)</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/DLTSMode.html\">DLWorkspace (aka. DLTS)</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/AMLMode.html\">AML (Azure Machine Learning)</a>, <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/AdaptDLMode.html\">AdaptDL (aka. ADL)</a> , other cloud options and even <a href=\"https://nni.readthedocs.io/en/stable/TrainingService/HybridMode.html\">Hybrid mode</a>.\n\n## **Who should consider using NNI**\n\n* Those who want to **try different AutoML algorithms** in their training code/model.\n* Those who want to run AutoML trial jobs **in different environments** to speed up search.\n* Researchers and data scientists who want to easily **implement and experiment new AutoML algorithms**, may it be: hyperparameter tuning algorithm, neural architect search algorithm or model compression algorithm.\n* ML Platform owners who want to **support AutoML in their platform**.\n\n## **What's NEW!** &nbsp;<a href=\"#nni-released-reminder\"><img width=\"48\" src=\"docs/img/release_icon.png\"></a>\n* **New release**: [v2.2 is available](https://github.com/microsoft/nni/releases) - _released on April-26-2021_\n* **New demo available**: [Youtube entry](https://www.youtube.com/channel/UCKcafm6861B2mnYhPbZHavw) | [Bilibili \u5165\u53e3](https://space.bilibili.com/1649051673) - _last updated on Apr-21-2021_\n\n* **New use case sharing**: [Cost-effective Hyper-parameter Tuning using AdaptDL with NNI](https://medium.com/casl-project/cost-effective-hyper-parameter-tuning-using-adaptdl-with-nni-e55642888761) - _posted on Feb-23-2021_\n\n## **NNI capabilities in a glance**\n\nNNI provides CommandLine Tool as well as an user friendly WebUI to manage training experiments. With the extensible API, you can customize your own AutoML algorithms and training services. To make it easy for new users, NNI also provides a set of build-in state-of-the-art AutoML algorithms and out of box support for popular training platforms.\n\nWithin the following table, we summarized the current NNI capabilities, we are gradually adding new capabilities and we'd love to have your contribution.\n\n<p align=\"center\">\n  <a href=\"#nni-has-been-released\"><img src=\"docs/img/overview.svg\" /></a>\n</p>\n\n<table>\n  <tbody>\n    <tr align=\"center\" valign=\"bottom\">\n    <td>\n      </td>\n      <td>\n        <b>Frameworks & Libraries</b>\n        <img src=\"docs/img/bar.png\"/>\n      </td>\n      <td>\n        <b>Algorithms</b>\n        <img src=\"docs/img/bar.png\"/>\n      </td>\n      <td>\n        <b>Training Services</b>\n        <img src=\"docs/img/bar.png\"/>\n      </td>\n    </tr>\n    </tr>\n    <tr valign=\"top\">\n    <td align=\"center\" valign=\"middle\">\n    <b>Built-in</b>\n      </td>\n      <td>\n      <ul><li><b>Supported Frameworks</b></li>\n        <ul>\n          <li>PyTorch</li>\n          <li>Keras</li>\n          <li>TensorFlow</li>\n          <li>MXNet</li>\n          <li>Caffe2</li>\n          <a href=\"https://nni.readthedocs.io/en/stable/SupportedFramework_Library.html\">More...</a><br/>\n        </ul>\n        </ul>\n      <ul>\n        <li><b>Supported Libraries</b></li>\n          <ul>\n           <li>Scikit-learn</li>\n           <li>XGBoost</li>\n           <li>LightGBM</li>\n           <a href=\"https://nni.readthedocs.io/en/stable/SupportedFramework_Library.html\">More...</a><br/>\n          </ul>\n      </ul>\n        <ul>\n        <li><b>Examples</b></li>\n         <ul>\n           <li><a href=\"examples/trials/mnist-pytorch\">MNIST-pytorch</li></a>\n           <li><a href=\"examples/trials/mnist-tfv1\">MNIST-tensorflow</li></a>\n           <li><a href=\"examples/trials/mnist-keras\">MNIST-keras</li></a>\n           <li><a href=\"https://nni.readthedocs.io/en/stable/TrialExample/GbdtExample.html\">Auto-gbdt</a></li>\n           <li><a href=\"https://nni.readthedocs.io/en/stable/TrialExample/Cifar10Examples.html\">Cifar10-pytorch</li></a>\n           <li><a href=\"https://nni.readthedocs.io/en/stable/TrialExample/SklearnExamples.html\">Scikit-learn</a></li>\n           <li><a href=\"https://nni.readthedocs.io/en/stable/TrialExample/EfficientNet.html\">EfficientNet</a></li>\n           <li><a href=\"https://nni.readthedocs.io/en/stable/TrialExample/OpEvoExamples.html\">Kernel Tunning</li></a>\n              <a href=\"https://nni.readthedocs.io/en/stable/SupportedFramework_Library.html\">More...</a><br/>\n          </ul>\n        </ul>\n      </td>\n      <td align=\"left\" >\n        <a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html\">Hyperparameter Tuning</a>\n        <ul>\n          <b>Exhaustive search</b>\n          <ul>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#Random\">Random Search</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#GridSearch\">Grid Search</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#Batch\">Batch</a></li>\n            </ul>\n          <b>Heuristic search</b>\n          <ul>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#Evolution\">Na\u00efve Evolution</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#Anneal\">Anneal</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#Hyperband\">Hyperband</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#PBTTuner\">PBT</a></li>\n          </ul>\n          <b>Bayesian optimization</b>\n            <ul>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#BOHB\">BOHB</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#TPE\">TPE</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#SMAC\">SMAC</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#MetisTuner\">Metis Tuner</a></li>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#GPTuner\">GP Tuner</a></li>\n            </ul>\n          <b>RL Based</b>\n          <ul>\n            <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#PPOTuner\">PPO Tuner</a> </li>\n          </ul>\n        </ul>\n          <a href=\"https://nni.readthedocs.io/en/stable/NAS/Overview.html\">Neural Architecture Search</a>\n          <ul>\n            <ul>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/ENAS.html\">ENAS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/DARTS.html\">DARTS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/PDARTS.html\">P-DARTS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/CDARTS.html\">CDARTS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/SPOS.html\">SPOS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/Proxylessnas.html\">ProxylessNAS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html#NetworkMorphism\">Network Morphism</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/TextNAS.html\">TextNAS</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/NAS/Cream.html\">Cream</a></li>\n            </ul>\n          </ul>\n          <a href=\"https://nni.readthedocs.io/en/stable/Compression/Overview.html\">Model Compression</a>\n          <ul>\n            <b>Pruning</b>\n            <ul>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#agp-pruner\">AGP Pruner</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#slim-pruner\">Slim Pruner</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#fpgm-pruner\">FPGM Pruner</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#netadapt-pruner\">NetAdapt Pruner</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#simulatedannealing-pruner\">SimulatedAnnealing Pruner</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#admm-pruner\">ADMM Pruner</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Pruner.html#autocompress-pruner\">AutoCompress Pruner</a></li>\n            </ul>\n            <b>Quantization</b>\n            <ul>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Quantizer.html#qat-quantizer\">QAT Quantizer</a></li>\n              <li><a href=\"https://nni.readthedocs.io/en/stable/Compression/Quantizer.html#dorefa-quantizer\">DoReFa Quantizer</a></li>\n            </ul>\n          </ul>\n          <a href=\"https://nni.readthedocs.io/en/stable/FeatureEngineering/Overview.html\">Feature Engineering (Beta)</a>\n          <ul>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/FeatureEngineering/GradientFeatureSelector.html\">GradientFeatureSelector</a></li>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/FeatureEngineering/GBDTSelector.html\">GBDTSelector</a></li>\n          </ul>\n          <a href=\"https://nni.readthedocs.io/en/stable/Assessor/BuiltinAssessor.html\">Early Stop Algorithms</a>\n          <ul>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/Assessor/BuiltinAssessor.html#MedianStop\">Median Stop</a></li>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/Assessor/BuiltinAssessor.html#Curvefitting\">Curve Fitting</a></li>\n          </ul>\n      </td>\n      <td>\n      <ul>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/LocalMode.html\">Local Machine</a></li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/RemoteMachineMode.html\">Remote Servers</a></li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/HybridMode.html\">Hybrid mode</a></li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/AMLMode.html\">AML(Azure Machine Learning)</a></li>\n        <li><b>Kubernetes based services</b></li>\n        <ul>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/PaiMode.html\">OpenPAI</a></li>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/KubeflowMode.html\">Kubeflow</a></li>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/FrameworkControllerMode.html\">FrameworkController on K8S (AKS etc.)</a></li>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/DLTSMode.html\">DLWorkspace (aka. DLTS)</a></li>\n          <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/AdaptDLMode.html\">AdaptDL (aka. ADL)</a></li>\n        </ul>\n      </ul>\n      </td>\n    </tr>\n      <tr align=\"center\" valign=\"bottom\">\n      </td>\n      </tr>\n      <tr valign=\"top\">\n       <td valign=\"middle\">\n    <b>References</b>\n      </td>\n     <td style=\"border-top:#FF0000 solid 0px;\">\n      <ul>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/autotune_ref.html#trial\">Python API</a></li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/Tutorial/AnnotationSpec.html\">NNI Annotation</a></li>\n         <li><a href=\"https://nni.readthedocs.io/en/stable/installation.html\">Supported OS</a></li>\n      </ul>\n      </td>\n       <td style=\"border-top:#FF0000 solid 0px;\">\n      <ul>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/Tuner/CustomizeTuner.html\">CustomizeTuner</a></li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/Assessor/CustomizeAssessor.html\">CustomizeAssessor</a></li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/Tutorial/InstallCustomizedAlgos.html\">Install Customized Algorithms as Builtin Tuners/Assessors/Advisors</a></li>\n      </ul>\n      </td>\n        <td style=\"border-top:#FF0000 solid 0px;\">\n      <ul>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/Overview.html\">Support TrainingService</li>\n        <li><a href=\"https://nni.readthedocs.io/en/stable/TrainingService/HowToImplementTrainingService.html\">Implement TrainingService</a></li>\n      </ul>\n      </td>\n    </tr>\n  </tbody>\n</table>\n\n## **Installation**\n\n### **Install**\n\nNNI supports and is tested on Ubuntu >= 16.04, macOS >= 10.14.1, and Windows 10 >= 1809. Simply run the following `pip install` in an environment that has `python 64-bit >= 3.6`.\n\nLinux or macOS\n\n```bash\npython3 -m pip install --upgrade nni\n```\n\nWindows\n\n```bash\npython -m pip install --upgrade nni\n```\n\nIf you want to try latest code, please [install NNI](https://nni.readthedocs.io/en/stable/installation.html) from source code.\n\nFor detail system requirements of NNI, please refer to [here](https://nni.readthedocs.io/en/stable/Tutorial/InstallationLinux.html#system-requirements) for Linux & macOS, and [here](https://nni.readthedocs.io/en/stable/Tutorial/InstallationWin.html#system-requirements) for Windows.\n\nNote:\n\n* If there is any privilege issue, add `--user` to install NNI in the user directory.\n* Currently NNI on Windows supports local, remote and pai mode. Anaconda or Miniconda is highly recommended to install [NNI on Windows](https://nni.readthedocs.io/en/stable/Tutorial/InstallationWin.html).\n* If there is any error like `Segmentation fault`, please refer to [FAQ](https://nni.readthedocs.io/en/stable/Tutorial/FAQ.html). For FAQ on Windows, please refer to [NNI on Windows](https://nni.readthedocs.io/en/stable/Tutorial/InstallationWin.html#faq).\n\n### **Verify installation**\n\n* Download the examples via clone the source code.\n\n  ```bash\n  git clone -b v2.2 https://github.com/Microsoft/nni.git\n  ```\n\n* Run the MNIST example.\n\n  Linux or macOS\n\n  ```bash\n  nnictl create --config nni/examples/trials/mnist-pytorch/config.yml\n  ```\n\n  Windows\n\n  ```powershell\n  nnictl create --config nni\\examples\\trials\\mnist-pytorch\\config_windows.yml\n  ```\n\n* Wait for the message `INFO: Successfully started experiment!` in the command line. This message indicates that your experiment has been successfully started. You can explore the experiment using the `Web UI url`.\n\n```text\nINFO: Starting restful server...\nINFO: Successfully started Restful server!\nINFO: Setting local config...\nINFO: Successfully set local config!\nINFO: Starting experiment...\nINFO: Successfully started experiment!\n-----------------------------------------------------------------------\nThe experiment id is egchD4qy\nThe Web UI urls are: http://223.255.255.1:8080   http://127.0.0.1:8080\n-----------------------------------------------------------------------\n\nYou can use these commands to get more information about the experiment\n-----------------------------------------------------------------------\n         commands                       description\n1. nnictl experiment show        show the information of experiments\n2. nnictl trial ls               list all of trial jobs\n3. nnictl top                    monitor the status of running experiments\n4. nnictl log stderr             show stderr log content\n5. nnictl log stdout             show stdout log content\n6. nnictl stop                   stop an experiment\n7. nnictl trial kill             kill a trial job by id\n8. nnictl --help                 get help information about nnictl\n-----------------------------------------------------------------------\n```\n\n* Open the `Web UI url` in your browser, you can view detailed information of the experiment and all the submitted trial jobs as shown below. [Here](https://nni.readthedocs.io/en/stable/Tutorial/WebUI.html) are more Web UI pages.\n\n<table style=\"border: none\">\n    <th><img src=\"./docs/img/webui-img/full-oview.png\" alt=\"drawing\" width=\"395\" height=\"300\"/></th>\n    <th><img src=\"./docs/img/webui-img/full-detail.png\" alt=\"drawing\" width=\"410\" height=\"300\"/></th>\n</table>\n\n## **Releases and Contributing**\nNNI has a monthly release cycle (major releases). Please let us know if you encounter a bug by [filling an issue](https://github.com/microsoft/nni/issues/new/choose).\n\nWe appreciate all contributions. If you are planning to contribute any bug-fixes, please do so without further discussions.\n\nIf you plan to contribute new features, new tuners, new training services, etc. please first open an issue or reuse an exisiting issue, and discuss the feature with us. We will discuss with you on the issue timely or set up conference calls if needed.\n\nTo learn more about making a contribution to NNI, please refer to our [How-to contribution page](https://nni.readthedocs.io/en/stable/contribution.html). \n\nWe appreciate all contributions and thank all the contributors!\n\n<a href=\"https://github.com/microsoft/nni/graphs/contributors\"><img src=\"docs/img/contributors.png\" /></a>\n\n\n## **Feedback**\n* [File an issue](https://github.com/microsoft/nni/issues/new/choose) on GitHub.\n* Discuss on the NNI [Gitter](https://gitter.im/Microsoft/nni?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) in NNI.\n\nJoin IM discussion groups:\n|Gitter||WeChat|\n|----|----|----|\n|![image](https://user-images.githubusercontent.com/39592018/80665738-e0574a80-8acc-11ea-91bc-0836dc4cbf89.png)| OR |![image](https://github.com/scarlett2018/nniutil/raw/master/wechat.png)|\n\n\n## Test status\n\n### Essentials\n\n| Type | Status |\n| :---: | :---: |\n| Fast test | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/fast%20test?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=54&branchName=master) |\n| Full linux | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/full%20test%20-%20linux?repoName=microsoft%2Fnni&branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=62&repoName=microsoft%2Fnni&branchName=master) |\n| Full windows | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/full%20test%20-%20windows?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=63&branchName=master) |\n\n### Training services\n\n| Type | Status |\n| :---: | :---: |\n| Remote - linux to linux | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20remote%20-%20linux%20to%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=64&branchName=master) |\n| Remote - linux to windows | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20remote%20-%20linux%20to%20windows?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=67&branchName=master) |\n| Remote - windows to linux | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20remote%20-%20windows%20to%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=68&branchName=master) |\n| OpenPAI | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20openpai%20-%20linux?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=65&branchName=master) |\n| Frameworkcontroller | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20frameworkcontroller?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=70&branchName=master) |\n| Kubeflow | [![Build Status](https://msrasrg.visualstudio.com/NNIOpenSource/_apis/build/status/integration%20test%20-%20kubeflow?branchName=master)](https://msrasrg.visualstudio.com/NNIOpenSource/_build/latest?definitionId=69&branchName=master) |\n\n## Related Projects\n\nTargeting at openness and advancing state-of-art technology, [Microsoft Research (MSR)](https://www.microsoft.com/en-us/research/group/systems-and-networking-research-group-asia/) had also released few other open source projects.\n\n* [OpenPAI](https://github.com/Microsoft/pai) : an open source platform that provides complete AI model training and resource management capabilities, it is easy to extend and supports on-premise, cloud and hybrid environments in various scale.\n* [FrameworkController](https://github.com/Microsoft/frameworkcontroller) : an open source general-purpose Kubernetes Pod Controller that orchestrate all kinds of applications on Kubernetes by a single controller.\n* [MMdnn](https://github.com/Microsoft/MMdnn) : A comprehensive, cross-framework solution to convert, visualize and diagnose deep neural network models. The \"MM\" in MMdnn stands for model management and \"dnn\" is an acronym for deep neural network.\n* [SPTAG](https://github.com/Microsoft/SPTAG) : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.\n\nWe encourage researchers and students leverage these projects to accelerate the AI development and research.\n\n## **License**\n\nThe entire codebase is under [MIT license](LICENSE)\n"
 },
 {
  "repo": "microsoft/pxt-microbit",
  "language": "TypeScript",
  "readme_contents": "# micro:bit target for PXT\n\n[![Build Status](https://travis-ci.org/microsoft/pxt-microbit.svg?branch=master)](https://travis-ci.org/microsoft/pxt-microbit) ![pxt-testghpkgs](https://github.com/microsoft/pxt-microbit/workflows/pxt-testghpkgs/badge.svg)\n\npxt-microbit is a [Microsoft Programming Experience Toolkit (PXT)](https://github.com/Microsoft/pxt) target that allows you to program a [BBC micro:bit](https://microbit.org/). \n\n* pxt-microbit **beta**, ``v3.0.*`` requires \n  * [pxt-microbit#stable3.0](https://github.com/Microsoft/pxt-microbit/tree/stable3.0)\n  * [pxt#stable6.0](https://github.com/Microsoft/pxt/tree/stable6.0).\n  * [pxt-common-packages#stable6.0](https://github.com/Microsoft/pxt-common-packages/tree/stable7.0).\n* pxt-microbit ``v2.0.*``, branch ``stable2.0``, requires [pxt v5.15.\\*](https://github.com/microsoft/pxt/tree/stable5.15). It is the servicing branch for live editor.\n* pxt-microbit ``v1.*`` requires pxt v4.4, which is currently in the [stable4.4 branch of pxt](https://github.com/Microsoft/pxt/tree/stable4.4).\n* pxt-microbit ``v0.*`` is in the [v0 branch of this repository](https://github.com/microsoft/pxt-microbit/tree/v0)\n\n* [Try it live](https://makecode.microbit.org/)\n\n## Issue tracking\n\nPlease add an issue if you discover an (unreported) bug.\n\n## Developing new extensions\n\nAuthoring and testing of new extensions can be done directly from the web editor. See [our documentation](https://makecode.com/blog/github-packages) on how to get started. If you want to run the editor locally, keep reading.\n\n## Local server setup\n\nThe local server lets you to run the editor and serve the documentation from your own computer. It is meant for a single developer used and not designed to serve the editor to a large amount of users.\n\n1. Install [Node.js](https://nodejs.org/) 8.9.4 or higher.\n2. Clone this repository.\n```\ngit clone https://github.com/microsoft/pxt-microbit\ncd pxt-microbit\n```\n3. Install the PXT command line (add `sudo` for Mac/Linux shells).\n```\nnpm install -g pxt\n```\n4. Install the pxt-microbit dependencies.\n```\nnpm install\n```\n\nGo to the **Running** section.\n\n### Developer Setup\n\nThis is the typical setup used by the MakeCode team to work on the microbit.\n\n1. Install [Node.js](https://nodejs.org/) 8.9.4 or higher.\n2. Install [Docker](https://www.docker.com/get-started) if you plan to build ``.cpp`` files.\n3. Clone the pxt repository.\n```\ngit clone https://github.com/microsoft/pxt\ncd pxt\n```\n4. Install the dependencies of pxt and build it\n```\nnpm install\nnpm run build\ncd ..\n```\n5. Clone the pxt-common-packages repository\n```\ngit clone https://github.com/microsoft/pxt-common-packages\ncd pxt-common-packages\nnpm install\ncd ..\n```\n6. Clone this repository.\n```\ngit clone https://github.com/microsoft/pxt-microbit\ncd pxt-microbit\n```\n7. Install the PXT command line (add `sudo` for Mac/Linux shells).\n```\nnpm install -g pxt\n```\n8. Install the pxt-microbit dependencies.\n```\nnpm install\n```\n8. Link pxt-microbit back to base pxt repo (add `sudo` for Mac/Linux shells). \nThis step is only required if you intend to make changes to pxt and/or \npxt-common-packages repos. If all you want is serve a local Makecode, you can skip\nthis step.\n```\npxt link ../pxt\npxt link ../pxt-common-packages\n```\nNote the above command assumes the folder structure of   \n```\n       makecode\n          |\n  ----------------------------------\n  |       |                        |\n pxt      pxt-common-packages  pxt-microbit\n ```\n\n### Running\n\nRun this command from inside pxt-microbit to open a local web server\n```\npxt serve\n```\nIf the local server opens in the wrong browser, make sure to copy the URL containing the local token. \nOtherwise, the editor will not be able to load the projects.\n\nIf you need to modify the `.cpp` files (and have installed yotta), enable yotta compilation using the `--localbuild` flag:\n```\npxt serve --local\n```\n\nIf you want to speed up the build, you can use the ``rebundle`` option, which skips building and simply refreshes the target information\n```\npxt serve --rebundle\n```\n\n### Cleaning\n\nSometimes, your built folder might be in a bad state, clean it and try again.\n```\npxt clean\n```\n\n\n### Building with CODAL locally\n\nThe following commands force a local build using CODAL.\n\n```\npxt buildtarget --local\n```\n\nTo disable docker, run\n\n```\nexport PXT_NODOCKER=1\n```\n\nIf you are also modifiying CODAL, consider running ``pxt clean`` to ensure the proper branch is picked up.\n\n### Modifying DAL/CODAL locally\n\n* follow instructions above until `pxt serve`\n* open editor on localhost and create a project\n* do `export PXT_FORCE_LOCAL=1 PXT_RUNTIME_DEV=1 PXT_ASMDEBUG=1`; you can add `PXT_NODOCKER=1`; `pxt help` has help on these\n* find project folder under `pxt-microbit/projects`, typically `pxt-microbit/projects/Untitled-42`\n* if you're going to modify `.cpp` files in PXT, replace `\"core\": \"*\"` in `pxt.json` with `\"core\": \"file:../../libs/core\"`;\n  similarly `\"radio\": \"file:../../libs/radio\"` and `\"microphone\": \"file:../../libs/microphone\"`\n* you can edit `main.ts` to change the PXT side of the program; you can also edit it from the localhost editor;\n  note that `Download` in the localhost editor will produce different binary than command line, as it builds in the cloud\n  and uses tagged version of CODAL\n* in that folder run `pxt build` - this will clone codal somewhere under `built/` (depends on build engine and docker)\n* there can be an issue with exporting the variables i.e. PXT_FORCE, so including them in the build command can help solve issues `sudo PXT_NODOCKER=1 PXT_ASMDEBUG=1 PXT_RUNTIME_DEV=1 PXT_DEBUG=1 PXT_FORCE_LOCAL=1 PXT_COMPILE_SWITCHES=csv---mbcodal pxt build`\n* if the target is not building, delete files in `hexcache` found in `pxt-microbit/built/hexcache` to force local build\n* the built hex can be found in `pxt-microbit/projects/<your project name>/built` named `binary.hex`\n* similarly, you can run `pxt deploy` (or just `pxt` which is the same) - it will build and copy to `MICROBIT` drive\n* assuming the build folder is under `built/codal`, go to `built/codal/libraries` and run `code *`\n* in git tab, checkout appropriate branches (they are all in detached head state to the way we tag releases)\n* modify files, run `pxt`, see effects\n* you can also run `pxt gdb` to debug; this requires `openocd`\n* other commands using `openocd` are `pxt dmesg` which dumps `DMESG(...)` buffer and `pxt heap` which can be used to visualize PXT heap \n  (and CODAL's one to some extent)\n\n### Updating dal.d.ts\n\n```\ncd libs/blocksprj\nrm -rf built\nPXT_FORCE_LOCAL=1 PXT_COMPILE_SWITCHES=csv---mbcodal pxt build\nPXT_FORCE_LOCAL=1 PXT_COMPILE_SWITCHES=csv---mbcodal pxt builddaldts\nmv dal.d.ts ../core\n```\n\n### Updates\n\nMake sure to pull changes from all repos regularly. More instructions are at https://github.com/Microsoft/pxt#running-a-target-from-localhost\n\n## Update playlists in markdown\n\nTo add a new playlist, add an entry in ``/playlists.json``, and regenerate the markdown (see paragraph below). You'll now have a new markdown gallery file listing the videos which you can reference in ``/targetconfig.json``.\n\nGet a Google API key and store it in the ``GOOGLE_API_KEY`` environment variables (turn on data from the app).\n\n```\npxt downloadplaylists\n```\n\n## Repos \n\nThe pxt-microbit target depends on several other repos. The main ones are:\n- https://github.com/Microsoft/pxt, the PXT framework\n- https://github.com/Microsoft/pxt-common-packages, common APIs accross various MakeCode editors\n- https://github.com/lancaster-university/microbit, basic wrapper around the DAL\n- https://github.com/lancaster-university/microbit-dal\n\n## History\n\nSee the [MakeCode blog](https://makecode.com/blog).\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nMICROSOFT, the Microsoft Logo, and MAKECODE are registered trademarks of Microsoft Corporation. They can only be used for the purposes described in and in accordance with Microsoft\u2019s Trademark and Brand guidelines published at https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general.aspx. If the use is not covered in Microsoft\u2019s published guidelines or you are not sure, please consult your legal counsel or MakeCode team (makecode@microsoft.com).\n"
 },
 {
  "repo": "microsoft/pxt-common-packages",
  "language": "TypeScript",
  "readme_contents": "# MakeCode Common packages\n\nA set of packages used in various MakeCode editors such as https://makecode.adafruit.com, https://maker.makecode.com, https://makecode.microbit.org, https://makecode.mindstorms.com, etc...\n\n## Contributing\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/azure-tools-for-java",
  "language": "Java",
  "readme_contents": "# Azure Toolkits for Java [![Travis CI](https://travis-ci.org/Microsoft/azure-tools-for-java.svg?branch=develop)](https://travis-ci.org/Microsoft/azure-tools-for-java)\nAzure Toolkits for Java is an open-source project that helps Java developers easily create, develop, configure, test, and deploy highly available and scalable Java web apps to Azure from [Eclipse](https://docs.microsoft.com/en-us/java/azure/eclipse/azure-toolkit-for-eclipse) and [IntelliJ IDEA](https://docs.microsoft.com/en-us/java/azure/intellij/azure-toolkit-for-intellij) on all supported platforms. \n* [Azure Toolkit for IntelliJ IDEA](https://docs.microsoft.com/en-us/java/azure/intellij/azure-toolkit-for-intellij)\n* [Azure Toolkit for Eclipse](https://docs.microsoft.com/en-us/java/azure/eclipse/azure-toolkit-for-eclipse)\n* [Release Notes](https://github.com/Microsoft/azure-tools-for-java/releases)\n* [Issues](https://github.com/Microsoft/azure-tools-for-java/issues)\n\n## Azure Toolkit for IntelliJ IDEA\n\n### Installation\n* [Set up the toolkits for IntelliJ](https://docs.microsoft.com/en-us/java/azure/intellij/azure-toolkit-for-intellij-installation)\n* [IntelliJ IDEA Plugin Repository](https://plugins.jetbrains.com/plugin/8053?pr=idea)\n\n### Documentation \n* [Get Started Tutorial](https://docs.microsoft.com/en-us/azure/app-service-web/app-service-web-intellij-create-hello-world-web-app)\n* [Home Page of Azure Toolkit for IntelliJ](https://docs.microsoft.com/en-us/java/azure/intellij/azure-toolkit-for-intellij)\n* [Java Developer Center on Azure](https://docs.microsoft.com/en-us/java/azure/)\n* [Get Started for HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-intellij-tool-plugin)\n\n## Azure Toolkit for Eclipse\n\n### Installation\n\n* [Set up the toolkits for Eclipse](https://docs.microsoft.com/en-us/java/azure/eclipse/azure-toolkit-for-eclipse-installation)  \n* [Eclipse Marketplace](http://marketplace.eclipse.org/content/azure-toolkit-eclipse)\n* Update site: `http://dl.microsoft.com/eclipse/` \n\n### Documentation\n* [Get Started Tutorial](https://docs.microsoft.com/azure/app-service-web/app-service-web-eclipse-create-hello-world-web-app)\n* [Home Page of Azure Toolkit for Eclipse](https://docs.microsoft.com/en-us/java/azure/eclipse/azure-toolkit-for-eclipse)\n* [Java Developer Center on Azure](https://docs.microsoft.com/en-us/java/azure/)\n* [Get Started for HDInsight](https://docs.microsoft.com/en-us/azure/hdinsight/hdinsight-apache-spark-eclipse-tool-plugin)\n\n## Known issues\nFollow this [link](https://github.com/Microsoft/azure-tools-for-java/issues?q=is%3Aissue+label%3Aknown-issue) to track the known issues.\n\n## Data/Telemetry\nAzure Toolkits for Java collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://go.microsoft.com/fwlink/?LinkID=620956) to learn more. If you don't wish to send usage data to Microsoft, you can turn off it in the following places:\n* For **Eclipse**: Open `Window > Preferences > Azure`, and uncheck the checkbox.\n* For **IntelliJ IDEA**: Open `Settings/Preferences > Microsoft Tools > Azure`, and uncheck the checkbox.\n\n## Contribution\nPlease see the [contribution instructions](CONTRIBUTING.md) if you wish to build the plugins from source.\n\n## Disclaimer\n*azure-tools-for-java uses JxBrowser http://www.teamdev.com/jxbrowser, which is a proprietary software. The use of JxBrowser is governed by JxBrowser Product Licence Agreement http://www.teamdev.com/jxbrowser-licence-agreement. If you would like to use JxBrowser in your development, please contact TeamDev.*\n"
 },
 {
  "repo": "microsoft/service-fabric-explorer",
  "language": "TypeScript",
  "readme_contents": "# Service Fabric Explorer (SFX)\n\nNOTE: Sfx is currently in the process of migrating from angularjs(Sfx v1) to angular 10(Sfx v2). The Sfx folder holds the previous version and SfxWeb is the new version. While this migration is happening, Sfx v1 will still be available but once Sfx v2 is considered safe and has 100% parity with V1 will be removed and official deprecated. All new development is being focused on V2 and unless its a critical bug with V1, V1 will not be getting any continued support.\n\nService Fabric Explorer is an application for inspecting and managing cloud applications and nodes in a Microsoft Azure Service Fabric cluster.\n\n## Build Status\nWindows | Linux / macOS\n------------ | -------------\n![Image of Windows Build Badge](https://ci.appveyor.com/api/projects/status/ejfk6b0c3dlunkws/branch/master) | ![Image of Linux/macOS Build Badge](https://travis-ci.org/Microsoft/service-fabric-explorer.svg?branch=master) \n\n## Installation\n\nMicrosoft publishes the following installer packages for SFX:\n\n- Windows\n  - https://aka.ms/sfx-windows\n\n- Linux\n  - https://aka.ms/sfx-linux-x86\n  - https://aka.ms/sfx-linux-x64\n\n- macOS\n  - https://aka.ms/sfx-macos\n\nFor more information about the application and how to use it: https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-visualizing-your-cluster\n\n## Developer Help and Documentation\n\nService Fabric Explorer consists of two main components, an AngularJS based application (Sfx) and an Electron part to host the AngularJS application (Sfx-Standalone).\n\n### Preparing the development machine\n\nTo develop Service Fabric Explorer, the following components are required.\n\n* Git: https://git-scm.com/\n* Node.js (Latest is preferred): https://nodejs.org/\n\nThe recommended IDE for Service Fabric Explorer development is VSCode because VSCode is a cross-platform editor, which supports Windows, Linux and macOS. But you can use whatever editor to develop. \n\nHere's a list of common IDE used.\n* VSCode: https://code.visualstudio.com/ \n* Visual Studio: https://www.visualstudio.com/\n\n### Set up the development environment\n\n1. Clone the master branch.\n`git clone --recurse-submodules https://github.com/Microsoft/service-fabric-explorer.git <path to the local folder>`\n2. Install project dependencies: *This can be done inside VSCode or use a console window.*\n   1. [SFX] Navigate to `src/SfxWeb` and run the following scripts.\n   ```Shell\n   npm install   \n   ```\n   2. [SFX Standalone] Navigate to `src/Sfx-Standalone` and run the following scripts.\n   ```Shell\n   npm install\n   ```\n   3. [SFX Proxy] Navigate to `src/Sfx-Proxy` and run the following scripts.\n   ```Shell\n   npm install   \n   ```\n\n3. Build projects\n   * VSCode\n      1. Open `src/SfxWeb`, `src/Sfx-Standalone` and `src/Sfx-Proxy` in VSCode with multiple-root workspce.\n      2. Run following tasks orderly.\n         * `clean-build` for Sfx-Standalone\n   * Console\n      1. Install Gulp globally on the machine.\n      ```Shell\n      npm install gulp-cli -g\n      ```\n      2. [SFX] Navigate to `src/SfxWeb` and run the following scripts.\n      For a develop/quick build\n      ```Shell\n      npm run build\n      ```\n      For a production build\n      ```\n      npm run build:prod\n      ```\n      4. [SFX Standalone] Navigate to `src/Sfx-Standalone` and run the following scripts.\n      ```Shell\n      gulp clean-build\n      ```\n\n### Develop Locally and Run Local Proxy\nNavigate to `src/SfxWeb`\n```Shell\nnpm start\n```\nNavigate to `src/Sfx-Proxy`\n```Shell\nnpm start\n```\n\nThere are 2 optional flags\n-r which would record every request to a folder(by default called playbackRecordings) and overwriting if the same request is made again\n-p every request will be checked for a saved response and if one exists get served instead\n```Shell\nnpm start -- -r -p\n```\n\nIf proxying requests to a secure cluster adding a file called localsettings.json to src/Sfx-Proxy can take a cert pfx location like below.\n```\n{\n  \"TargetCluster\": {\n    \"Url\": \"https://test.eastus.cloudapp.azure.com:19080\",\n    \"PFXLocation\": \"C:/some_cert.pfx\",\n    \"PFXPassPhrase\": \"password\"\n  },\n  \"recordFileBase\": \"playbackRecordings/\"\n}\n```\n\n\n## Testing\n\n### Run unit tests\nNavigate to  `sfx/SfxWeb` folder and run \n```\nnpm test\n```\n\n### Run E2E tests\nNavigate to sfx/SfxWeb folder and run\n```\nnpm run cypress:local\n```\nThis assumes that the angular local dev server is running\n\n### CI overview\nThe CI will run the following\n\n* production build\n* unit tests\n* E2E tests\n\n## Issues and questions\n\nFor questions related to Azure Service Fabric clusters, take a look at the [tag on StackOverflow](https://stackoverflow.com/questions/tagged/azure-service-fabric)\nand [official documentation](https://docs.microsoft.com/en-us/azure/service-fabric/).\n\n### General Service Fabric issues\n\nIf your issue is not specific to the Service Fabric Explorer, please use the [Service Fabric issues repository](https://github.com/Azure/service-fabric-issues/issues) to report an issue.\n\n### Service Fabric Explorer specific issues\n\nIf your issue is relevant to the Service Fabric Explorer, please use this repositories issue tracker.\n\nBe sure to search for similar previously reported issues prior to creating a new one.\nIn addition, here are some good practices to follow when reporting issues:\n\n- Add a `+1` reaction to existing issues that are affecting you\n- Include detailed output or screenshots when reporting unexpected error messages\n- Include the version of SFX installed\n- Include the version of Service Fabric runtime for the cluster you have selected\n\n## New ideas and improvements\n\nWe encourage everyone to contribute to this project, following the contribution guidelines below. If you have ideas and want to share these with the community before taking on implementing the change, feel free to suggest these using issues.\n\n# Contribution guidelines\n\nFor general contribution guidelines, plese see here: https://github.com/Microsoft/service-fabric/blob/master/CONTRIBUTING.md\n"
 },
 {
  "repo": "microsoft/pxt-jacdac",
  "language": "TypeScript",
  "readme_contents": "# Jacdac Services for MakeCode\n\nThis project contains [Jacdac](https://aka.ms/jacdac) host and client services for MakeCode editors.\n\n**This project is still under construction.**\n\n## Using this extensions\n\n* Open your MakeCode editor (see supported editors)\n* Go to the extension dialog and search for https://github.com/microsoft/pxt-jacdac\n* Import the extension.\n\n### Supported editors\n\n* Maker, https://maker.makecode.com\n* Arcade BETA, https://arcade.makecoe.com/beta\n* micro:bit Beta, https://makecode.microbit.org/beta\n\n## Developer section\n\nIssues are tracked at https://github.com/microsoft/jacdac/issues .\n\nTo build all projects\n```\nsh mk.sh\n```\n\nTo refresh the ``constants.ts`` files, build jacdac-spec (``yarn buildspecs`` from jacdac-ts) from https://github.com/microsoft/jacdac-ts .\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/SpareNet",
  "language": "Python",
  "readme_contents": "# Style-based Point Generator with Adversarial Rendering for Point Cloud Completion (CVPR 2021)\n\nAn efficient PyTorch library for Point Cloud Completion. \n\n<!-- ![image](./teaser.png) -->\n<div  align=\"center\">    \n<img src=\"./teaser.png\" width = \"800\"   align=center />\n</div>\n\n### [Project page](https://alphapav.github.io/SpareNet/) |   [Paper](https://arxiv.org/abs/2103.02535) | [Video]()\n\n[Chulin Xie*](https://github.com/AlphaPav), [Chuxin Wang*](https://chuxwa.github.io/), [Bo Zhang](https://bo-zhang.me/), [Hao Yang](https://www.microsoft.com/en-us/research/people/haya/), [Dong Chen](https://www.microsoft.com/en-us/research/people/doch/), and [Fang Wen](https://www.microsoft.com/en-us/research/people/fangwen/). (\\*Equal contribution)\n\n## Abstract\n>We proposed a novel Style-based Point Generator with Adversarial Rendering (SpareNet) for point cloud completion. Firstly, we present the channel-attentive EdgeConv to fully exploit the local structures as well as the global shape in point features. Secondly, we observe that the concatenation manner used by vanilla foldings limits its potential of generating a complex and faithful shape. Enlightened by the success of StyleGAN, we regard the shape feature as style code that modulates the normalization layers during the folding, which considerably enhances its capability. Thirdly, we realize that existing point supervisions, e.g., Chamfer Distance or Earth Mover\u2019s Distance, cannot faithfully re\ufb02ect the perceptual quality of the reconstructed points. To address this, we propose to project the completed points to depth maps with a differentiable renderer and apply adversarial training to advocate the perceptual realism under different viewpoints. Comprehensive experiments on ShapeNet and KITTI prove the effectiveness of our method, which achieves state-of-the-art quantitative performance while offering superior visual quality.\n\n\n## Installation\n\n1. Create a virtual environment via `conda`.\n\n   ```shell\n   conda create -n sparenet python=3.7\n   conda activate sparenet\n   ```\n\n2. Install `torch` and `torchvision`.\n\n   ```shell\n   conda install pytorch cudatoolkit=10.1 torchvision -c pytorch\n   ```\n\n3. Install requirements.\n\n   ```shell\n   pip install -r requirements.txt\n   ```\n\n4. Install cuda\n   ```shell\n   sh setup_env.sh\n   ```\n\n\n## Dataset\n* Download [the processed ShapeNet dataset](https://gateway.infinitescript.com/?fileName=ShapeNetCompletion) generated by [GRNet](https://github.com/hzxie/GRNet), and the [KITTI dataset](https://drive.google.com/drive/folders/1fSu0_huWhticAlzLh3Ejpg8zxzqO1z-F). \n\n* Update the file path of the datasets in `configs/base_config.py`:\n\n   ```\n   __C.DATASETS.shapenet.partial_points_path = \"/path/to/datasets/ShapeNetCompletion/%s/partial/%s/%s/%02d.pcd\"\n   __C.DATASETS.shapenet.complete_points_path = \"/path/to/datasets/ShapeNetCompletion/%s/complete/%s/%s.pcd\"\n   __C.DATASETS.kitti.partial_points_path = \"/path/to/datasets/KITTI/cars/%s.pcd\"\n   __C.DATASETS.kitti.bounding_box_file_path = \"/path/to/datasets/KITTI/bboxes/%s.txt\"\n\n   # Dataset Options: ShapeNet, ShapeNetCars, KITTI\n   __C.DATASET.train_dataset = \"ShapeNet\"\n   __C.DATASET.test_dataset = \"ShapeNet\"\n   ```\n\n\n## Get Started\n\n### Inference Using Pretrained Model\n\nThe pretrained models:\n\n- [SpareNet for ShapeNet](https://drive.google.com/file/d/15PiH-bRlSlK4AUUnVwREzuAlMVJ9TfQG) (316 MB)\n- [PCN for ShapeNet](https://drive.google.com/drive/folders/1ruN16MlJm4OeRMd41C19HyWqYOIrNrNh)\n- [GRNet for ShapeNet](https://gateway.infinitescript.com/?fileName=GRNet-ShapeNet.pth) (307 MB)\n- [GRNet for KITTI](https://gateway.infinitescript.com/?fileName=GRNet-KITTI.pth) (307 MB)\n- [MSN for ShapeNet](https://drive.google.com/drive/folders/14UZXKqXIZ0gL3hhrV2ySll_pH2eLGFL5) (8192 points)\n\n\n-  run\n\n   ```shell\n   python   --gpu ${GPUS}\\\n            --work_dir ${WORK_DIR} \\\n            --model ${network} \\\n            --weights ${path to checkpoint} \\\n            --test_mode ${mode}\n   ```\n\n-  example\n   ```shell\n   python  test.py --gpu 0 --work_dir /path/to/logfiles --model sparenet --weights /path/to/cheakpoint --test_mode default\n   ```\n\n### Train\n\nAll log files in the training process, such as log message, checkpoints, etc, will be saved to the work directory.\n\n-  run\n\n   ```shell\n   python   --gpu ${GPUS}\\\n            --work_dir ${WORK_DIR} \\\n            --model ${network} \\\n            --weights ${path to checkpoint}\n   ```\n-  example\n   ```shell\n   python  train.py --gpu 0,1,2,3 --work_dir /path/to/logfiles --model sparenet --weights /path/to/cheakpoint\n   ```\n\n<!-- ## Contributors -->\n\n## Differentiable Renderer\nA fully differentiable point renderer that enables end-to-end rendering from 3D point cloud to 2D depth maps. See the paper for details.\n\n<!-- ![image](./renderer.png) -->\n<div  align=\"center\">    \n<img src=\"./renderer.png\" width = \"600\"   align=center />\n</div>\n\n### Test FPD on ShapeNet Dataset\n* Run your model and save your results of test dataset\n\n* Update the file path of the results in `test_fpd.py` and run it:\n   ```\n   parser.add_argument('--log_dir', default='/path/to/save/logs')\n   parser.add_argument('--data_dir', default='/path/to/test/dataset/pcds')\n   parser.add_argument('--fake_dir', default='/path/to/methods/pcds',\n                              help='/path/to/results/shapenet_fc/pcds/')\n   ```\n\n### Usage of Renderer\n\nThe inputs of renderer are pcd, views and radius, and the outputs of renderer are depth_maps.\n-  example\n   ```shell\n   # `projection_mode`: a str with value \"perspective\" or \"orthorgonal\"\n   # `eyepos_scale`: a float that defines the distance of eyes to (0, 0, 0)\n   # `image_size`: an int defining the output image size\n   renderer = ComputeDepthMaps(projection_mode, eyepos_scale, image_size)\n\n   # `data`: a tensor with shape [batch_size, num_points, 3]\n   # `view_id`: the index of selected view satisfying 0 <= view_id < 8\n   # `radius_list`: a list of floats, defining the kernel radius to render each point\n   depthmaps = renderer(data, view_id, radius_list)\n   ```\n\n## License\n\nThe codes and the pretrained model in this repository are under the MIT license as specified by the LICENSE file. \n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n\n## BibTex\n\nIf you like our work and use the codebase or models for your research, please cite our work as follows.\n\n```bibtex\n@inproceedings{xie2021stylebased,\n      title={Style-based Point Generator with Adversarial Rendering for Point Cloud Completion}, \n      author={Chulin Xie and Chuxin Wang and Bo Zhang and Hao Yang and Dong Chen and Fang Wen},\n      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},\n      year={2021},\n}\n``` \n\n<!-- ## Acknowledgement\nWe thank for the inspiration from [MSN]() and [GRNet]() -->\n"
 },
 {
  "repo": "microsoft/ads-kerberos",
  "language": "C++",
  "readme_contents": "Kerberos\n========\n[![Build Status](https://travis-ci.org/mongodb-js/kerberos.svg?branch=master)](https://travis-ci.org/mongodb-js/kerberos)\n\nThe `kerberos` package is a C++ extension for Node.js that provides cross-platform support for kerberos authentication using GSSAPI on linux/osx, and SSPI on windows. Much of the code in this module is adapted from [ccs-kerberos](https://github.com/apple/ccs-pykerberos) and [winkerberos](https://github.com/mongodb-labs/winkerberos).\n\n### Requirements\n\n**Linux**\n- `python` v2.7\n- `make`\n- A proper C/C++ compiler toolchain, like [GCC](https://gcc.gnu.org/)\n- Distribution-specific kerberos packages (e.g. `krb5-dev` on Ubuntu)\n\n**macOS**\n- `Xcode Command Line Tools`: Can be installed with `xcode-select --install`\n- Distribution-specific kerberos packages (e.g. `krb5` on Homebrew)\n\n**Windows**\n- **Option 1:** Install all the required tools and configurations using Microsoft's [windows-build-tools](https://github.com/felixrieseberg/windows-build-tools) by running `npm install -g windows-build-tools` from an elevated PowerShell (run as Administrator).\n- **Option 2:** Install dependencies and configuration manually\n   1. Visual C++ Build Environment:\n     * **Option 1:** Install [Visual C++ Build Tools](http://go.microsoft.com/fwlink/?LinkId=691126) using the *Default Install* option.\n     * **Option 2:** Install [Visual Studio 2015](https://www.visualstudio.com/products/visual-studio-community-vs) (or modify an existing installation) and select *Common Tools for Visual C++* during setup.\n\n  > :bulb: [Windows Vista / 7 only] requires [.NET Framework 4.5.1](http://www.microsoft.com/en-us/download/details.aspx?id=40773)\n\n  2. Install [Python 2.7](https://www.python.org/downloads/) or [Miniconda 2.7](http://conda.pydata.org/miniconda.html) (`v3.x.x` is not supported), and run `npm config set python python2.7`\n  3. Launch cmd, `npm config set msvs_version 2015`\n\n### Installation\n\nNow you can install `kerberos` with the following:\n\n```bash\nnpm install kerberos\n```\n\n### Testing\n\nRun the test suite using:\n\n```bash\nnpm test\n```\n\nNOTE: The test suite requires an active kerberos deployment, see `test/scripts/travis.sh` to better understand these requirements.\n\n### Releasing\n\nRelease a new version of the extension by:\n\n1. Run `npm run release`\n2. Run `git push --follow-tags origin main`\n3. The release will be created in Github automatically by the CD pipeline, go to it and download the package artifact (tgz)\n4. Run `npm publish <path to tarball>`\n\n# Documentation\n\n## Classes\n\n<dl>\n<dt><a href=\"#KerberosClient\">KerberosClient</a></dt>\n<dd></dd>\n<dt><a href=\"#KerberosServer\">KerberosServer</a></dt>\n<dd></dd>\n</dl>\n\n## Functions\n\n<dl>\n<dt><a href=\"#checkPassword\">checkPassword(username, password, service, [defaultRealm], [callback])</a> \u21d2 <code>Promise</code></dt>\n<dd><p>This function provides a simple way to verify that a user name and password\nmatch those normally used for Kerberos authentication.\nIt does this by checking that the supplied user name and password can be\nused to get a ticket for the supplied service.\nIf the user name does not contain a realm, then the default realm supplied\nis used.</p>\n<p>For this to work properly the Kerberos must be configured properly on this\nmachine.\nThat will likely mean ensuring that the edu.mit.Kerberos preference file\nhas the correct realms and KDCs listed.</p>\n<p>IMPORTANT: This method is vulnerable to KDC spoofing attacks and it should\nonly be used for testing. Do not use this in any production system - your\nsecurity could be compromised if you do.</p>\n</dd>\n<dt><a href=\"#principalDetails\">principalDetails(service, hostname, [callback])</a> \u21d2 <code>Promise</code></dt>\n<dd><p>This function returns the service principal for the server given a service type and hostname.</p>\n<p>Details are looked up via the <code>/etc/keytab</code> file.</p>\n</dd>\n<dt><a href=\"#initializeClient\">initializeClient(service, [options], [callback])</a> \u21d2 <code>Promise</code></dt>\n<dd><p>Initializes a context for client-side authentication with the given service principal.</p>\n</dd>\n<dt><a href=\"#initializeServer\">initializeServer(service, [callback])</a> \u21d2 <code>Promise</code></dt>\n<dd><p>Initializes a context for server-side authentication with the given service principal.</p>\n</dd>\n</dl>\n\n<a name=\"KerberosClient\"></a>\n\n## KerberosClient\n**Properties**\n\n| Name | Type | Description |\n| --- | --- | --- |\n| username | <code>string</code> | The username used for authentication |\n| response | <code>string</code> | The last response received during authentication steps |\n| responseConf | <code>string</code> | Indicates whether confidentiality was applied or not (GSSAPI only) |\n| contextComplete | <code>boolean</code> | Indicates that authentication has successfully completed or not |\n\n\n* [KerberosClient](#KerberosClient)\n\n    * [.step(challenge, [callback])](#KerberosClient+step)\n\n    * [.wrap(challenge, [options], [callback])](#KerberosClient+wrap)\n\n    * [.unwrap(challenge, [callback])](#KerberosClient+unwrap)\n\n\n<a name=\"KerberosClient+step\"></a>\n\n### *kerberosClient*.step(challenge, [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| challenge | <code>string</code> | A string containing the base64-encoded server data (which may be empty for the first step) |\n| [callback] | <code>function</code> |  |\n\nProcesses a single kerberos client-side step using the supplied server challenge.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"KerberosClient+wrap\"></a>\n\n### *kerberosClient*.wrap(challenge, [options], [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| challenge | <code>string</code> | The response returned after calling `unwrap` |\n| [options] | <code>object</code> | Optional settings |\n| [options.user] | <code>string</code> | The user to authorize |\n| [callback] | <code>function</code> |  |\n\nPerform the client side kerberos wrap step.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"KerberosClient+unwrap\"></a>\n\n### *kerberosClient*.unwrap(challenge, [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| challenge | <code>string</code> | A string containing the base64-encoded server data |\n| [callback] | <code>function</code> |  |\n\nPerform the client side kerberos unwrap step\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"KerberosServer\"></a>\n\n## KerberosServer\n**Properties**\n\n| Name | Type | Description |\n| --- | --- | --- |\n| username | <code>string</code> | The username used for authentication |\n| response | <code>string</code> | The last response received during authentication steps |\n| targetName | <code>string</code> | The target used for authentication |\n| contextComplete | <code>boolean</code> | Indicates that authentication has successfully completed or not |\n\n<a name=\"KerberosServer+step\"></a>\n\n### *kerberosServer*.step(challenge, [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| challenge | <code>string</code> | A string containing the base64-encoded client data |\n| [callback] | <code>function</code> |  |\n\nProcesses a single kerberos server-side step using the supplied client data.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"checkPassword\"></a>\n\n## checkPassword(username, password, service, [defaultRealm], [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| username | <code>string</code> | The Kerberos user name. If no realm is supplied, then the `defaultRealm` will be used. |\n| password | <code>string</code> | The password for the user. |\n| service | <code>string</code> | The Kerberos service to check access for. |\n| [defaultRealm] | <code>string</code> | The default realm to use if one is not supplied in the user argument. |\n| [callback] | <code>function</code> |  |\n\nThis function provides a simple way to verify that a user name and password\nmatch those normally used for Kerberos authentication.\nIt does this by checking that the supplied user name and password can be\nused to get a ticket for the supplied service.\nIf the user name does not contain a realm, then the default realm supplied\nis used.\n\nFor this to work properly the Kerberos must be configured properly on this\nmachine.\nThat will likely mean ensuring that the edu.mit.Kerberos preference file\nhas the correct realms and KDCs listed.\n\nIMPORTANT: This method is vulnerable to KDC spoofing attacks and it should\nonly be used for testing. Do not use this in any production system - your\nsecurity could be compromised if you do.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"principalDetails\"></a>\n\n## principalDetails(service, hostname, [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| service | <code>string</code> | The Kerberos service type for the server. |\n| hostname | <code>string</code> | The hostname of the server. |\n| [callback] | <code>function</code> |  |\n\nThis function returns the service principal for the server given a service type and hostname.\n\nDetails are looked up via the `/etc/keytab` file.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"initializeClient\"></a>\n\n## initializeClient(service, [options], [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| service | <code>string</code> | A string containing the service principal in the form 'type@fqdn' (e.g. 'imap@mail.apple.com'). |\n| [options] | <code>object</code> | Optional settings |\n| [options.principal] | <code>string</code> | Optional string containing the client principal in the form 'user@realm' (e.g. 'jdoe@example.com'). |\n| [options.gssFlags] | <code>number</code> | Optional integer used to set GSS flags. (e.g.  GSS_C_DELEG_FLAG|GSS_C_MUTUAL_FLAG|GSS_C_SEQUENCE_FLAG will allow for forwarding credentials to the remote host) |\n| [options.mechOID] | <code>number</code> | Optional GSS mech OID. Defaults to None (GSS_C_NO_OID). Other possible values are `GSS_MECH_OID_KRB5`, `GSS_MECH_OID_SPNEGO`. |\n| [callback] | <code>function</code> |  |\n\nInitializes a context for client-side authentication with the given service principal.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n<a name=\"initializeServer\"></a>\n\n## initializeServer(service, [callback])\n\n| Param | Type | Description |\n| --- | --- | --- |\n| service | <code>string</code> | A string containing the service principal in the form 'type@fqdn' (e.g. 'imap@mail.apple.com'). |\n| [callback] | <code>function</code> |  |\n\nInitializes a context for server-side authentication with the given service principal.\n\n**Returns**: <code>Promise</code> - returns Promise if no callback passed\n"
 },
 {
  "repo": "microsoft/coe-starter-kit",
  "language": null,
  "readme_contents": "# NOTE: THIS IS A REPO IN TRANSITION.  WE ARE IN THE PROCESS OF MOVING FROM https://github.com/microsoft/powerapps-tools/tree/master/Administration/CoEStarterKit TO HERE.  PLEASE CONSIDER THE TRANSITION INCOMPLETE UNTIL THIS NOTE IS REMOVED.  THANK YOU FOR YOUR PATIENCE.\n\n# Microsoft Power Platform Center of Excellence (CoE) Starter Kit\nThe Center of Excellence (CoE) Starter Kit is a set of templates that are designed to help develop a strategy for adopting, maintaining and supporting the Power Platform, with a focus on Power Apps and Power Automate. The kit includes multiple Power Apps and Power BI analytics reports to view and interact with the data collected.  The kit also provides several assets that provide templates and suggested patterns and practices for implementing CoE efforts. The assets part of the CoE Starter Kit should be seen as a template from which you inherit your individual solution or can serve as inspiration for implementing your own apps and flows.\n\n## Setup Instructions and Documentation\nPlease find all information on how to install and use the kit on https://docs.microsoft.com/power-platform/guidance/coe/starter-kit\n\n## Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\n\nResources:\n\n- [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/)\n- [Microsoft Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\n- Contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with questions or concerns\n\n## Trademarks \nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n\n## Security\n\nMicrosoft takes the security of our software products and services seriously, which includes all source code repositories managed through our GitHub organizations, which include [Microsoft](https://github.com/Microsoft), [Azure](https://github.com/Azure), [DotNet](https://github.com/dotnet), [AspNet](https://github.com/aspnet), [Xamarin](https://github.com/xamarin), and [our GitHub organizations](https://opensource.microsoft.com/).\n\nIf you believe you have found a security vulnerability in any Microsoft-owned repository that meets Microsoft's [Microsoft's definition of a security vulnerability](https://docs.microsoft.com/en-us/previous-versions/tn-archive/cc751383(v=technet.10)), please report it to us as described below.\n\n## Reporting Security Issues\n\n**Please do not report security vulnerabilities through public GitHub issues.**\n\nInstead, please report them to the Microsoft Security Response Center (MSRC) at [https://msrc.microsoft.com/create-report](https://msrc.microsoft.com/create-report).\n\nIf you prefer to submit without logging in, send email to [secure@microsoft.com](mailto:secure@microsoft.com).  If possible, encrypt your message with our PGP key; please download it from the the [Microsoft Security Response Center PGP Key page](https://www.microsoft.com/en-us/msrc/pgp-key-msrc).\n\nYou should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Additional information can be found at [microsoft.com/msrc](https://www.microsoft.com/msrc).\n\nPlease include the requested information listed below (as much as you can provide) to help us better understand the nature and scope of the possible issue:\n\n  * Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.)\n  * Full paths of source file(s) related to the manifestation of the issue\n  * The location of the affected source code (tag/branch/commit or direct URL)\n  * Any special configuration required to reproduce the issue\n  * Step-by-step instructions to reproduce the issue\n  * Proof-of-concept or exploit code (if possible)\n  * Impact of the issue, including how an attacker might exploit the issue\n\nThis information will help us triage your report more quickly.\n\nIf you are reporting for a bug bounty, more complete reports can contribute to a higher bounty award. Please visit our [Microsoft Bug Bounty Program](https://microsoft.com/msrc/bounty) page for more details about our active programs.\n\n## Preferred Languages\n\nWe prefer all communications to be in English.\n\n## Policy\n\nMicrosoft follows the principle of [Coordinated Vulnerability Disclosure](https://www.microsoft.com/en-us/msrc/cvd).\n\n## Contributing\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/clarity",
  "language": "TypeScript",
  "readme_contents": "# Clarity\nClarity is an open-source behavioral analytics library written in typescript, with two key goals: privacy & performance. \n\nIt helps you understand how users view and use your website across all modern devices and browsers. Understanding how users navigate, interact and browse your website can provide new insights about your users. Empathizing with your users and seeing where features fail or succeed can help improve your product, grow revenue and improve user retention.\n\nIt's the same code that powers Microsoft's hosted behavioral analytics solution: <a href=\"https://clarity.microsoft.com\">https://clarity.microsoft.com</a>. If you would like to see a demo of how it works, checkout <a href=\"https://clarity.microsoft.com/demo/projects/view/3t0wlogvdz/impressions?date=Last%203%20days\">live demo</a>. \n\nWe encourage the community to join us in building the best behavioral analytics library, that puts privacy first and prioritizes performance. \n\n## Project Structure\n1. **[clarity-js](https://github.com/microsoft/clarity/tree/master/packages/clarity-js)**: Instrumentation code that goes on the website and tracks user interactions as well as layout changes.\n\n2. **[clarity-decode](https://github.com/microsoft/clarity/tree/master/packages/clarity-decode)**: Code, which usually runs on the server, decodes incoming data back into its original format.\n\n3. **[clarity-visualize](https://github.com/microsoft/clarity/tree/master/packages/clarity-visualize)**: It takes the decoded data from clarity-decode and turns it back into pixel-perfect session replay.\n\n4. **[clarity-devtools](https://github.com/microsoft/clarity/tree/master/packages/clarity-devtools)**: Devtools extension for chromium based browsers to generate live captures against any website.\n\n## Examples\nHere are some example sessions on popular websites visualized to demonstrate the telemetry captured:\n1. CNN (Web)\n</br><a href=\"https://thumbs.gfycat.com/AggressiveLankyAbyssiniangroundhornbill-size_restricted.gif\"><img src=\"https://thumbs.gfycat.com/AggressiveLankyAbyssiniangroundhornbill-size_restricted.gif\" title=\"Clarity - CNN Example\"/></a>\n\n2. Cook with Manali (Mobile)\n</br><a href=\"https://thumbs.gfycat.com/CoolDependableAdamsstaghornedbeetle-size_restricted.gif\"><img src=\"https://thumbs.gfycat.com/CoolDependableAdamsstaghornedbeetle-size_restricted.gif\" title=\"Clarity - Cook With Manali Example\"/></a> \n\n## Privacy Notice\nClarity handles sensitive data with care. By default sensitive content on the page is masked before uploading to the server.\n\n## Improving Clarity\nIf you haven't already done so, start contributing by following instructions **[here](https://github.com/microsoft/clarity/blob/master/CONTRIBUTING.md)**.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nHappy coding!\n"
 },
 {
  "repo": "microsoft/AzureTrailblazerAcademy",
  "language": "CSS",
  "readme_contents": "# Azure Trailblazer Academy\r\n\r\n<!-- \r\nGuidelines on README format: https://review.docs.microsoft.com/help/onboard/admin/samples/concepts/readme-template?branch=master\r\n\r\nGuidance on onboarding samples to docs.microsoft.com/samples: https://review.docs.microsoft.com/help/onboard/admin/samples/process/onboarding?branch=master\r\n\r\nTaxonomies for products and languages: https://review.docs.microsoft.com/new-hope/information-architecture/metadata/taxonomies?branch=master\r\n-->\r\n\r\nWelcome Azure Trailblazers!\r\n\r\nIn this repository you will find the content and labs you will need to complete the Azure Trailblazers Academy.\r\n\r\n## Sessions\r\n\r\n### [**Month 1**: Azure Fundamentals, IaaS and WebApps](./month1/labs)\r\n\r\nLearn the basics of Azure, the difference between Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) and build a web application from scratch using Azure native services.\r\n\r\n### [**Month 2**: Azure Data Services](./month2/labs)\r\n\r\nLearn how to use CosmosDB to store data for modern applications. Understand the basics of Azure Synapse (formerly known as Azure Data Warehouse) and how to transform and integrate data from other data stores using Synapse Pipelines.\r\n\r\n\r\n### [**Month 3**: Azure Serverless Computing and Azure DevOps](./month3)\r\n\r\nLearn about the different Serverless services available in Azure such as Funtions, LogicApps and EventGrid. This month you will build an end-to-end solution using only serverless components and learn how to automate your deployments using Azure DevOps.\r\n\r\n\r\n<!---\r\n### [**Month 4**: Azure Serverless Services](./month4)\r\n\r\nLearn about the different Serverless services available in Azure such as Funtions, LogicApps and EventGrid. This month you will build an end-to-end solution using only serverless components.\r\n\r\nMonitor your Azure Infrastructure and learn how to configure/query logs in Log Analytics Workspace, intall Microsoft Monitoring Agent Extension and setup alerting to be notified under different conditions.\r\n\r\n--->\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-FacetKey",
  "language": "JavaScript",
  "readme_contents": "[![CircleCI](https://circleci.com/gh/Microsoft/PowerBI-visuals-FacetKey/tree/master.svg?style=svg)](https://circleci.com/gh/Microsoft/PowerBI-visuals-FacetKey/tree/master)\n\n# Facet Key Powerbi Custom Visual\n![Alt text](assets/screenshot.png?raw=true \"Facet Key\")\n\n## Install\n* Run `npm install`\n\n## Debugging\n\n* Install ssl certificate by running `npm run install-certificate` and following the steps from: [https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/CertificateSetup.md](https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/CertificateSetup.md)\n* Enable Developer Tools in PowerBI: [https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/DebugVisualSetup.md](https://github.com/Microsoft/PowerBI-visuals/blob/master/tools/DebugVisualSetup.md)\n* Run `npm start` to start development.\n\n## Building\n\n* Run `npm run package` to package the visual.\n* `.pbiviz` file will be generated in the `dist` folder\n\n## Testing\n\n* Run `npm test`"
 },
 {
  "repo": "microsoft/BotFramework-DirectLineJS",
  "language": "TypeScript",
  "readme_contents": "![Bot Framework DirectLineJS](./docs/media/FrameWorkDirectLineJS@1x.png)\n\n### [Click here to find out what's new in Bot Framework for //build2019!](https://github.com/Microsoft/botframework/blob/master/whats-new.md#whats-new)\n\n# Microsoft Bot Framework Direct Line JS Client\n\n[![Build Status](https://travis-ci.org/Microsoft/BotFramework-DirectLineJS.svg?branch=master)](https://travis-ci.org/Microsoft/BotFramework-DirectLineJS)\n\nClient library for the [Microsoft Bot Framework](http://www.botframework.com) *[Direct Line](https://docs.botframework.com/en-us/restapi/directline3/)* protocol.\n\nUsed by [WebChat](https://github.com/Microsoft/BotFramework-WebChat) and thus (by extension) [Emulator](https://github.com/Microsoft/BotFramework-Emulator), WebChat channel, and [Azure Bot Service](https://azure.microsoft.com/en-us/services/bot-service/).\n\n## FAQ\n\n### *Who is this for?*\n\nAnyone who is building a Bot Framework JavaScript client who does not want to use [WebChat](https://github.com/Microsoft/BotFramework-WebChat).\n\nIf you're currently using WebChat, you don't need to make any changes as it includes this package.\n\n### *What is that funny `subscribe()` method in the samples below?*\n\nInstead of callbacks or Promises, this library handles async operations using Observables. Try it, you'll like it! For more information, check out [RxJS](https://github.com/reactivex/rxjs/).\n\n### *Can I use [TypeScript](http://www.typescriptlang.com)?*\n\nYou bet.\n\n### How ready for prime time is this library?\n\nThis is an official Microsoft-supported library, and is considered largely complete. Future changes (aside from supporting future updates to the Direct Line protocol) will likely be limited to bug fixes, performance improvements, tutorials, and samples. The big missing piece here is unit tests.\n\nThat said, the public API is still subject to change.\n\n## How to build from source\n\n0. Clone this repo\n1. `npm install`\n2. `npm run build` (or `npm run watch` to rebuild on every change, or `npm run prepublishOnly` to build production)\n\n## How to include in your app\n\nThere are several ways:\n\n1. Build from scratch and include either `/directLine.js` (webpacked with rxjs) or `lib/directline.js` in your app\n2. `npm install botframework-directlinejs`\n\n## Using from within a Node environment\n\nThis library uses RxJs/AjaxObserverable which is meant for use in a DOM environment. That doesn't mean you can't also use it from Node though, you just need to do a couple of extra things:\n\n1. `npm install --save ws xhr2`\n2. Add the following towards the top of your main application file:\n\n```typescript\nglobal.XMLHttpRequest = require('xhr2');\nglobal.WebSocket = require('ws');\n```\n\n## How to create and use a directLine object\n\n### Obtain security credentials for your bot:\n\n1. If you haven't already, [register your bot](https://azure.microsoft.com/en-us/services/bot-service/).\n2. Add a DirectLine (**not WebChat**) channel, and generate a Direct Line Secret. Make sure Direct Line 3.0 is enabled.\n3. For testing you can use your Direct Line Secret as a security token, but for production you will likely want to exchange that Secret for a Token as detailed in the Direct Line [documentation](https://docs.microsoft.com/en-us/azure/bot-service/bot-service-channel-directline?view=azure-bot-service-4.0).\n\n### Create a DirectLine object:\n\n```typescript\nimport { DirectLine } from 'botframework-directlinejs';\n// For Node.js:\n// const { DirectLine } = require('botframework-directlinejs');\n\nvar directLine = new DirectLine({\n    secret: /* put your Direct Line secret here */,\n    token: /* or put your Direct Line token here (supply secret OR token, not both) */,\n    domain: /* optional: if you are not using the default Direct Line endpoint, e.g. if you are using a region-specific endpoint, put its full URL here */\n    webSocket: /* optional: false if you want to use polling GET to receive messages. Defaults to true (use WebSocket). */,\n    pollingInterval: /* optional: set polling interval in milliseconds. Defaults to 1000 */,\n    timeout: /* optional: a timeout in milliseconds for requests to the bot. Defaults to 20000 */,\n    conversationStartProperties: { /* optional: properties to send to the bot on conversation start */\n        locale: 'en-US'\n    }\n});\n```\n\n### Post activities to the bot:\n\n```typescript\ndirectLine.postActivity({\n    from: { id: 'myUserId', name: 'myUserName' }, // required (from.name is optional)\n    type: 'message',\n    text: 'a message for you, Rudy'\n}).subscribe(\n    id => console.log(\"Posted activity, assigned ID \", id),\n    error => console.log(\"Error posting activity\", error)\n);\n```\n\nYou can also post messages with attachments, and non-message activities such as events, by supplying the appropriate fields in the activity.\n\n### Listen to activities sent from the bot:\n\n```typescript\ndirectLine.activity$\n.subscribe(\n    activity => console.log(\"received activity \", activity)\n);\n```\n\nYou can use RxJS operators on incoming activities. To see only message activities:\n\n```typescript\ndirectLine.activity$\n.filter(activity => activity.type === 'message')\n.subscribe(\n    message => console.log(\"received message \", message)\n);\n```\n\nDirect Line will helpfully send your client a copy of every sent activity, so a common pattern is to filter incoming messages on `from`:\n\n```typescript\ndirectLine.activity$\n.filter(activity => activity.type === 'message' && activity.from.id === 'yourBotHandle')\n.subscribe(\n    message => console.log(\"received message \", message)\n);\n```\n\n### Monitor connection status\n\nSubscribing to either `postActivity` or `activity$` will start the process of connecting to the bot. Your app can listen to the connection status and react appropriately :\n\n```typescript\n\nimport { ConnectionStatus } from 'botframework-directlinejs';\n\ndirectLine.connectionStatus$\n.subscribe(connectionStatus => {\n    switch(connectionStatus) {\n        case ConnectionStatus.Uninitialized:    // the status when the DirectLine object is first created/constructed\n        case ConnectionStatus.Connecting:       // currently trying to connect to the conversation\n        case ConnectionStatus.Online:           // successfully connected to the converstaion. Connection is healthy so far as we know.\n        case ConnectionStatus.ExpiredToken:     // last operation errored out with an expired token. Your app should supply a new one.\n        case ConnectionStatus.FailedToConnect:  // the initial attempt to connect to the conversation failed. No recovery possible.\n        case ConnectionStatus.Ended:            // the bot ended the conversation\n    }\n});\n```\n\n### Reconnect to a conversation\n\nIf your app created your DirectLine object by passing a token, DirectLine will refresh that token every 15 minutes.\nShould your client lose connectivity (e.g. close laptop, fail to pay Internet access bill, go under a tunnel), `connectionStatus$`\nwill change to `ConnectionStatus.ExpiredToken`. Your app can request a new token from its server, which should call\nthe [Reconnect](https://docs.microsoft.com/en-us/azure/bot-service/rest-api/bot-framework-rest-direct-line-3-0-reconnect-to-conversation?view=azure-bot-service-4.0) API.\nThe resultant Conversation object can then be passed by the app to DirectLine.\n\n```typescript\nvar conversation = /* a Conversation object obtained from your app's server */;\ndirectLine.reconnect(conversation);\n```\n\n### Resume an existing conversation\n\nWhen using DirectLine with WebChat, closing the current tab or refreshing the page will create a new conversation in most cases. You can resume an existing conversation to keep the user in the same context.\n\n**When using a secret** you can resume a conversation by:\n- Storing the conversationid (in a *permanent* place, like local storage)\n- Giving this value back while creating the DirectLine object along with the secret\n\n```typescript\nimport { DirectLine } from 'botframework-directlinejs';\n\nconst dl = new DirectLine({\n    secret: /* SECRET */,\n    conversationId: /* the conversationid you stored from previous conversation */\n});\n```\n\n**When using a token** you can resume a conversation by:\n- Storing the conversationid and your token (in a *permanent* place, like local storage)\n- Calling the DirectLine reconnect API yourself to get a refreshed token and a streamurl\n- Creating the DirectLine object using the ConversationId, Token, and StreamUrl\n\n```typescript\nimport { DirectLine } from 'botframework-directlinejs';\n\nconst dl = new DirectLine({\n    token: /* the token you retrieved while reconnecting */,\n    streamUrl: /* the streamUrl you retrieved while reconnecting */,\n    conversationId: /* the conversationid you stored from previous conversation */\n});\n```\n\n**Getting any history that Direct Line has cached** : you can retrieve history using watermarks:\nYou can see the watermark as an *activity 'bookmark'*. The resuming scenario will replay all the conversation activities from the watermark you specify.\n\n```typescript\nimport { DirectLine } from 'botframework-directlinejs';\n\nconst dl = new DirectLine({\n    token: /* the token you retrieved while reconnecting */,\n    streamUrl: /* the streamUrl you retrieved while reconnecting */,\n    conversationId: /* the conversationid you stored from previous conversation */,\n    watermark: /* a watermark you saved from a previous conversation */,\n    webSocket: false\n});\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Reporting Security Issues\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the [MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in the [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\n\nCopyright (c) Microsoft Corporation. All rights reserved.\n"
 },
 {
  "repo": "microsoft/dicom-server",
  "language": "C#",
  "readme_contents": "# Medical Imaging Server for DICOM\n\n [![Build Status](https://microsofthealthoss.visualstudio.com/DicomServer/_apis/build/status/CI-Build-OSS?branchName=main)](https://microsofthealthoss.visualstudio.com/DicomServer/_build/latest?definitionId=34&branchName=main)\n\nThe Medical Imaging Server for DICOM is an open source DICOM server that is easily deployed on Azure. It allows standards-based communication with any DICOMweb&trade; enabled systems, and injects DICOM metadata into a FHIR server to create a holistic view of patient data. The Medical Imaging Server for DICOM integrates tightly with the [FHIR Server for Azure](https://github.com/microsoft/fhir-server) enabling healthcare professionals, ISVs, and medical device vendors to create new and innovative solutions. FHIR is becoming an important standard for clinical data and provides extensibility to support integration of other types of data directly, or through references. By using the Medical Imaging Server for DICOM, organizations can store references to imaging data in FHIR and enable queries across clinical and imaging datasets.\n\n![Architecture](docs/images/DICOM-arch.png)\n\nThe Medical Imaging Server for DICOM is a .NET Core implementation of DICOMweb&trade;. [DICOMweb&trade;](https://www.dicomstandard.org/dicomweb) is the DICOM Standard for web-based medical imaging. Details of our conformance to the standard can be found in our [Conformance Statement](docs/resources/conformance-statement.md).\n\n## Deploy the Medical Imaging Server for DICOM\n\nThe Medical Imaging Server for DICOM is designed to run on Azure. However, for development and test environments it can be deployed locally as a set of Docker containers to speed up development.\n\n### Deploy to Azure\n\nIf you already have an Azure subscription, deploy the Medical Imaging Server for DICOM directly to Azure: <br/>\n    <a href=\"https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmicrosoft%2Fdicom-server%2Fmain%2Fsamples%2Ftemplates%2Fdefault-azuredeploy.json\" target=\"_blank\"><img src=\"https://azuredeploy.net/deploybutton.png\"/></a>\n\nTo sync your Medical Imaging Server for DICOM metadata directly into a FHIR server, deploy **DICOM Cast** (alongside a FHIR OSS Server and Medical Imaging Server for DICOM) via: <br/>\n    <a href=\"https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fmicrosoft%2Fdicom-server%2Fmain%2Fconverter%2Fdicom-cast%2Fsamples%2Ftemplates%2Fdefault-azuredeploy.json\" target=\"_blank\"><img src=\"https://azuredeploy.net/deploybutton.png\"/>\n    </a> \n\nFor a complete set of instructions for how to deploy the Medical Imaging Server for DICOM to Azure, refer to the Quickstart [Deploy to Azure ](docs/quickstarts/deploy-via-azure.md).\n\n### Deploy locally\n\nFollow the [Development Setup Instructions](docs/development/setup.md) to deploy a local copy of the Medical Imaging Server for DICOM. Be aware that this deployment leverages the [Azurite container](https://github.com/Azure/Azurite) which emulates the Azure Storage API, and should not be used in production.\n\nNote that the webapp library, ARM templates and Web.Zip package are for testing purposes only, they are not recommended for production scenarios. These will not be versioned. You can find the artifact feed generated by the Medical Imaging Server for DICOM at the [Azure Devops Public Feed](https://microsofthealthoss.visualstudio.com/FhirServer/_packaging?_a=feed&feed=Public), including the versioned packages.\n\n## Quickstarts\n\n- [Deploy Medical Imaging Server for DICOM via Azure](docs/quickstarts/deploy-via-azure.md)\n- [Deploy Medical Imaging Server for DICOM via Docker](docs/quickstarts/deploy-via-docker.md)\n- [Set up DICOM Cast](docs/quickstarts/deploy-dicom-cast.md)\n\n## Tutorials\n\n- [Use the Medical Imaging Server for DICOM APIs](docs/tutorials/use-the-medical-imaging-server-apis.md)\n- [Use DICOMweb&trade; Standard APIs with C#](docs/tutorials/use-dicom-web-standard-apis-with-c%23.md)\n- [Use DICOMweb&trade; Standard APIs with Python](docs/tutorials/use-dicom-web-standard-apis-with-python.md)\n- [Use DICOMweb&trade; Standard APIs with cURL](docs/tutorials/use-dicom-web-standard-apis-with-curl.md)\n\n## How-to guides\n\n- [Configure Medical Imaging Server for DICOM server settings](docs/how-to-guides/configure-dicom-server-settings.md)\n- [Enable Authentication and retrieve an OAuth token](docs/how-to-guides/enable-authentication-with-tokens.md)\n- [Enable Authorization](docs/how-to-guides/enable-authorization.md)\n- [Pull Changes from Medical Imaging Server for DICOM with Change Feed](docs/how-to-guides/pull-changes-from-change-feed.md)\n- [Sync DICOM metadata to FHIR](docs/how-to-guides/sync-dicom-metadata-to-fhir.md)\n- [Extended Query Tags](docs/how-to-guides/extended-query-tags.md)\n\n## Concepts\n\n- [DICOM](docs/concepts/dicom.md)\n- [Change Feed](docs/concepts/change-feed.md)\n- [DICOM Cast](docs/concepts/dicom-cast.md)\n\n## Resources\n\n- [FAQ](docs/resources/faq.md)\n- [Conformance Statement](docs/resources/conformance-statement.md)\n- [Health Check API](docs/resources/health-check-api.md)\n- [Performance Guidance](docs/resources/performance-guidance.md)\n\n## Development\n\n- [Setup](docs/development/setup.md)\n- [Code Organization](docs/development/code-organization.md)\n- [Naming Guidelines](docs/development/naming-guidelines.md)\n- [Exception handling](docs/development/exception-handling.md)\n- [Tests](docs/development/tests.md)\n- [Identity Server Authentication](docs/development/identity-server-authentication.md)\n- [Roles](docs/development/roles.md)\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repositories using our CLA.\n\nThere are many other ways to contribute to Medical Imaging Server for DICOM.\n* [Submit bugs](https://github.com/Microsoft/dicom-server/issues) and help us verify fixes as they are checked in.\n* Review the [source code changes](https://github.com/Microsoft/dicom-server/pulls).\n* Engage with Medical Imaging Server for DICOM users and developers on [StackOverflow](https://stackoverflow.com/questions/tagged/medical-imaging-server-for-dicom).\n* Join the [#dicomonazure](https://twitter.com/hashtag/dicomonazure?f=tweets&vertical=default) discussion on Twitter.\n* [Contribute bug fixes](CONTRIBUTING.md).\n\nSee [Contributing to Medical Imaging Server for DICOM](CONTRIBUTING.md) for more information.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-HeatStreams",
  "language": "TypeScript",
  "readme_contents": "![Node.js CI](https://github.com/microsoft/PowerBI-visuals-HeatStreams/workflows/Node.js%20CI/badge.svg)\n\n# Heat Streams PowerBI Visual\n\n# About\nThe HeatStreams Visual is a categorical heat-map encoding of a metric over a time or numeric domain. Users can pick from a variety of color schemes (all provided by d3), and basic selection of categories is provided. Categories may be multi-selected with ctrl+click. \n\n# Development\nThis visualization is a Lerna monorepo split into two main components: a React-based data visualization, and a PowerBI wrapper around the visual. The Essex build system is used to construct the visual.\n\n> yarn --ignore-engines # PowerBI insists on a Node 6.x engine, which isn't really necessary\n> yarn build            # Transpiles react components, bundles the PowerBI visual under `packages/powerbi-heat-streams/dist`\n> yarn start            # Starts up the local PowerBI visual development server\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/exp-extension",
  "language": "TypeScript",
  "readme_contents": ""
 },
 {
  "repo": "microsoft/vcpkg-tool",
  "language": "C++",
  "readme_contents": "# Vcpkg: Overview\r\n\r\n[\u4e2d\u6587\u603b\u89c8](https://github.com/microsoft/vcpkg/blob/master/README_zh_CN.md)\r\n[Espa\u00f1ol](https://github.com/microsoft/vcpkg/blob/master/README_es.md)\r\n[\ud55c\uad6d\uc5b4](https://github.com/microsoft/vcpkg/blob/master/README_ko_KR.md)\r\n[Fran\u00e7ais](https://github.com/microsoft/vcpkg/blob/master/README_fr.md)\r\n\r\nVcpkg helps you manage C and C++ libraries on Windows, Linux and MacOS.\r\nThis tool and ecosystem are constantly evolving, and we always appreciate contributions!\r\n\r\nPlease see the main repository https://github.com/microsoft/vcpkg for all feature discussion, issue\r\ntracking, and edits to which libraries are available.\r\n\r\n# Vcpkg-tool: Overview\r\n\r\nThis repository contains the contents formerly at https://github.com/microsoft/vcpkg in the\r\n\"toolsrc\" tree, and build support.\r\n\r\n# Contributing\r\n\r\nPlease refer to the \"contributing\" section of the\r\n[main `README.md`](https://github.com/microsoft/vcpkg/blob/master/README.md).\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct][contributing:coc].\r\nFor more information see the [Code of Conduct FAQ][contributing:coc-faq]\r\nor email [opencode@microsoft.com](mailto:opencode@microsoft.com)\r\nwith any additional questions or comments.\r\n\r\n[contributing:submit-issue]: https://github.com/microsoft/vcpkg/issues/new/choose\r\n[contributing:submit-pr]: https://github.com/microsoft/vcpkg/pulls\r\n[contributing:coc]: https://opensource.microsoft.com/codeofconduct/\r\n[contributing:coc-faq]: https://opensource.microsoft.com/codeofconduct/\r\n\r\n# License\r\n\r\nThe product code in this repository is licensed under the [MIT License](LICENSE.txt). The tests\r\ncontain 3rd party code as documented in `NOTICE.txt`.\r\n\r\n# Telemetry\r\n\r\nvcpkg collects usage data in order to help us improve your experience.\r\nThe data collected by Microsoft is anonymous.\r\nYou can opt-out of telemetry by re-running the bootstrap-vcpkg script with -disableMetrics,\r\npassing --disable-metrics to vcpkg on the command line,\r\nor by setting the VCPKG_DISABLE_METRICS environment variable.\r\n\r\nRead more about vcpkg telemetry at docs/about/privacy.md\r\n"
 },
 {
  "repo": "microsoft/Application-Insights-Workbooks",
  "language": "JSON",
  "readme_contents": "# Azure Monitor Workbook Templates [![Build Status](https://github.com/microsoft/Application-Insights-Workbooks/workflows/Template%20Validation/badge.svg)](https://travis-ci.org/microsoft/Application-Insights-Workbooks)\n\n\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a \nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us \nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments. \n\n## What is this repository for?\nThis repository contains the templates shown in the workbook galleries of [Azure Monitor Workbooks](https://docs.microsoft.com/azure/application-insights/app-insights-usage-workbooks). Templates added to this repository will show up in the various Workbook Galleries for users of Azure Monitor Workbooks. By contributing templates, you can help others solve interesting problems using the workbooks you've found helpful on your own team.\n\n## Azure Monitor Workbooks\n\nWorkbooks allow Azure Monitor users to create customizable interactive reports and analytic narratives by providing a flexible canvas that allows them to:\n\n1.\tCreate rich visual reports and analytics experiences within the Azure portal.\n2.\tUse metric, log and Azure Resource Graph data\n3.\tBuild interactive experiences based on user input\n4.\tCustomize their analysis and persist for later use.\n5.\tUse templates for curated analysis from a public gallery\n6.\tLeverage ARM programmability to create and manage their workbook assets.\n\nThese capabilities of workbooks can be used to create curated and customized reports, analytic narratives, dashboards, etc. \n\nUse these links to learn more about workbooks:\n\n* [Data Sources](Documentation/DataSources/DataSources.md)\n* [Visualizations](Documentation/Visualizations/Visualizations.md)\n* [Parameters](Documentation/Parameters/Parameters.md)\n* [Groups](Documentation/Groups/Groups.md)\n* [Interactivity](Documentation/Interactivity.md)\n* [Manage programmatically](Documentation/Programmatically.md)\n* [Sample Gallery](Documentation/Samples/Samples.md)\n* [Contributing](Documentation/Contributing.md) \n* [Testing](Documentation/Contributing.md#how-to-test-your-changes)\n* [Previews](Documentation/Contributing.md#testing-preview-workbook-templates)\n* [Auto-Refresh](Documentation/AutoRefresh.md)\n* [New Gallery](Documentation/Gallery.md)\n\n### Sample Workbook \n![Image of a sample workbook](Documentation/Images/WorkbookExample.png)\n\n## How to contribute?\n\nFor more details about getting started, see the [Contributing guidelines](CONTRIBUTING.md).\n\nNote that templates in this repo will show up for all users of Azure who open the specified gallery. For this reason, the templates gallery is curated by Microsoft. If the submitted template is useful to the community and it does not place undue stress on the underlying infrastructure, it will be accepted to be part of the gallery.\n\n## Status\nThis repo is [supported by Microsoft](https://docs.microsoft.com/en-us/azure/azure-monitor).\n* [File an issue](new-issue) or submit a pull request on GitHub\n* Request or upvote features on [UserVoice](https://feedback.azure.com/forums/913690-azure-monitor)\n* File a [support](https://docs.microsoft.com/en-us/azure/azure-supportability/how-to-create-azure-support-request) ticket with Azure\n\nWe are constantly working to improve, and we value your feedback.\n"
 },
 {
  "repo": "microsoft/PowerPlatformConnectors",
  "language": "Python",
  "readme_contents": "# Microsoft Power Platform Connectors\n\nWelcome to the Microsoft Power Platform Connectors open source repository. This repository contains custom connectors, certified connectors, and related tools to facilitate connector development for Azure Logic Apps, Microsoft Power Apps, and Microsoft Power Automate.\n\n## Custom Connectors\n\nThe ```custom-connectors``` folder contains fully functional connector samples which can be deployed to the Power Platform for extension and use. These samples may not be certified connectors, but should be maintained by the open source community to offer useful scenarios or examples of connector concepts.\n\n## Certified Connectors\n\nThe ```certified-connectors``` folder contains certified connectors which are already deployed and available out-of-box within the Power Platform for use. \nA requirement of our [connector certification program](https://docs.microsoft.com/connectors/custom-connectors/submit-certification) is that new certified connectors be open sourced for community contributions. \nThe ```certified-connectors``` folder is managed by the Microsoft Connector Certification Team to ensure that within the ```master``` branch, the connector version is identical to that deployed in the Power Platform. \nThe ```dev``` branch is maintained by the connector owner and the Microsoft Connector Certification Team to allow community development of the connector prior to certification and deployment of a version. \n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\n### Creating a Fork\n\nTo contibute to this open source repository, start by creating a fork on this repository. To do so, select the \"fork\" button on the upper right corner, and create your own copy of the repository. Next, sync your fork with the remote repository and clone your forked repository to your local machine.\n\n```git clone https://github.com/YOUR-USERNAME/PowerPlatformConnectors.git```\n\nCheck your remote URL.\n\n```git remote -v```\n\n```\n> origin  https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (fetch)\n> origin  https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (push)\n```\n\nAdd an upstream repository for your clone.\n\n```git remote add upstream https://github.com/microsoft/PowerPlatformConnectors.git```\n\nVerify the upstream links.\n\n```git remote -v```\n\n```\n> origin    https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (fetch) \n> origin    https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (push)\n> upstream  https://github.com/microsoft/PowerPlatformConnectors.git (fetch)\n> upstream  https://github.com/microsoft/PowerPlatformConnectors.git (push)\n```\n\nTo keep your fork up to date with this repository's updates, run these commands:\n\n```git fetch upstream```\n\n```git checkout master```\n\n```git merge upstream/master```\n\nYou are now ready to develop your connector in your own branch.\n\n### Submitting to the Open Source Repository\n\nContributions to the open source repository are made through pull requests. \nPrior to submitting a pull request, ensure that your pull request does not contain any sensitive or specific information, for example Client IDs or Client Secrets. \nAny sensitive values can be replaced with fake or dummy values for the purposes of submission as long as it is clearly indicated. \nAlso, ensure that the readme.md of the connector is updated with the latest information, or created for new connector submissions. \nAn example of a clear, structured, readme.md can be found in the [Azure Key Vault](https://github.com/microsoft/PowerPlatformConnectors/tree/master/custom-connectors/AzureKeyVault) connector repository. \nInclude this completed `readme.md` in same connector directory which contains the artifacts. \n\n#### Custom Connectors\n\nUpdates to an existing custom connector can be made through a simple pull request to update the custom connector files.\n\nFor new custom connectors, create a directory under the ```custom-connectors``` directory and place the connector files in the sub-folder. Ensure that a clear, structured, readme.md is included. \n\n#### Certified Connectors\n\nUpdates to certified connectors must first be made through a pull request to the ```dev``` branch for review by the connector owner. \nOnce a pull request has been merged to the ```dev``` branch, the connector owner can submit the connector for certification through the Connector certification tab in [ISV Studio](https://isvstudio.powerapps.com). Once certified, the Microsoft Certification team will handle merging the updates from ```dev``` to ```master```. \n\nUpdates to an existing custom connector can be made through a simple pull request to the ```dev``` branch to update the custom connector files.\n\nFor new connectors which will be submitted for certification, create a directory under the ```certified-connectors``` directory, place the connector files in the sub-folder, and submit a pull request to the ```dev``` branch. Ensure that a clear, structured, readme.md is included. \n\n### Tooling and Validation\n\n#### CLA\n\nWhen a pull request is submitted, a CLA-bot will automatically determine whether you need to provide\na CLA and annotate the PR appropriately. Simply follow the instructions\nprovided by the bot to ensure your pull request can be properly reviewed.\nYou will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n#### Swagger Validation\n\nA submitted pull request will also be validated against our Swagger Validator tool, which checks the connector files to ensure it is a proper Swagger file and adheres to our connector requirements and guidelines. Any errors or warnings will be added to the PR for both the submitter and the reviewer to understand. We do not accept pull requests with outstanding unresolved Swagger Validator issues. \n\n#### Breaking Change Detector\n\nAnother validation which runs on a submitted pull request is the breaking changes validator. This is to catch any inadvertent, non-backwards-compatible (i.e. breaking) changes which may break a current user experience, for example, deleting a published operation. The Breaking Change Detector compares the previous version of the Swagger with the new submission and raises awareness of any breaking change. The submitter and reviewer must both acknowledge any breaking changes submitted and ensure that no end users are inadvertently negatively affected. \n\n## Legal Notices\n\nMicrosoft and any contributors grant you a license to the Microsoft documentation and other content\nin this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),\nsee the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the\n[LICENSE-CODE](LICENSE-CODE) file.\n\nMicrosoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation\nmay be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\nThe licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\nMicrosoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n\nPrivacy information can be found at https://privacy.microsoft.com/en-us/\n\nMicrosoft and any contributors reserve all others rights, whether under their respective copyrights, patents,\nor trademarks, whether by implication, estoppel or otherwise.\n"
 },
 {
  "repo": "microsoft/Application-Insights-Workbooks",
  "language": "JSON",
  "readme_contents": "# Azure Monitor Workbook Templates [![Build Status](https://github.com/microsoft/Application-Insights-Workbooks/workflows/Template%20Validation/badge.svg)](https://travis-ci.org/microsoft/Application-Insights-Workbooks)\n\n\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a \nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us \nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments. \n\n## What is this repository for?\nThis repository contains the templates shown in the workbook galleries of [Azure Monitor Workbooks](https://docs.microsoft.com/azure/application-insights/app-insights-usage-workbooks). Templates added to this repository will show up in the various Workbook Galleries for users of Azure Monitor Workbooks. By contributing templates, you can help others solve interesting problems using the workbooks you've found helpful on your own team.\n\n## Azure Monitor Workbooks\n\nWorkbooks allow Azure Monitor users to create customizable interactive reports and analytic narratives by providing a flexible canvas that allows them to:\n\n1.\tCreate rich visual reports and analytics experiences within the Azure portal.\n2.\tUse metric, log and Azure Resource Graph data\n3.\tBuild interactive experiences based on user input\n4.\tCustomize their analysis and persist for later use.\n5.\tUse templates for curated analysis from a public gallery\n6.\tLeverage ARM programmability to create and manage their workbook assets.\n\nThese capabilities of workbooks can be used to create curated and customized reports, analytic narratives, dashboards, etc. \n\nUse these links to learn more about workbooks:\n\n* [Data Sources](Documentation/DataSources/DataSources.md)\n* [Visualizations](Documentation/Visualizations/Visualizations.md)\n* [Parameters](Documentation/Parameters/Parameters.md)\n* [Groups](Documentation/Groups/Groups.md)\n* [Interactivity](Documentation/Interactivity.md)\n* [Manage programmatically](Documentation/Programmatically.md)\n* [Sample Gallery](Documentation/Samples/Samples.md)\n* [Contributing](Documentation/Contributing.md) \n* [Testing](Documentation/Contributing.md#how-to-test-your-changes)\n* [Previews](Documentation/Contributing.md#testing-preview-workbook-templates)\n* [Auto-Refresh](Documentation/AutoRefresh.md)\n* [New Gallery](Documentation/Gallery.md)\n\n### Sample Workbook \n![Image of a sample workbook](Documentation/Images/WorkbookExample.png)\n\n## How to contribute?\n\nFor more details about getting started, see the [Contributing guidelines](CONTRIBUTING.md).\n\nNote that templates in this repo will show up for all users of Azure who open the specified gallery. For this reason, the templates gallery is curated by Microsoft. If the submitted template is useful to the community and it does not place undue stress on the underlying infrastructure, it will be accepted to be part of the gallery.\n\n## Status\nThis repo is [supported by Microsoft](https://docs.microsoft.com/en-us/azure/azure-monitor).\n* [File an issue](new-issue) or submit a pull request on GitHub\n* Request or upvote features on [UserVoice](https://feedback.azure.com/forums/913690-azure-monitor)\n* File a [support](https://docs.microsoft.com/en-us/azure/azure-supportability/how-to-create-azure-support-request) ticket with Azure\n\nWe are constantly working to improve, and we value your feedback.\n"
 },
 {
  "repo": "microsoft/PowerPlatformConnectors",
  "language": "Python",
  "readme_contents": "# Microsoft Power Platform Connectors\n\nWelcome to the Microsoft Power Platform Connectors open source repository. This repository contains custom connectors, certified connectors, and related tools to facilitate connector development for Azure Logic Apps, Microsoft Power Apps, and Microsoft Power Automate.\n\n## Custom Connectors\n\nThe ```custom-connectors``` folder contains fully functional connector samples which can be deployed to the Power Platform for extension and use. These samples may not be certified connectors, but should be maintained by the open source community to offer useful scenarios or examples of connector concepts.\n\n## Certified Connectors\n\nThe ```certified-connectors``` folder contains certified connectors which are already deployed and available out-of-box within the Power Platform for use. \nA requirement of our [connector certification program](https://docs.microsoft.com/connectors/custom-connectors/submit-certification) is that new certified connectors be open sourced for community contributions. \nThe ```certified-connectors``` folder is managed by the Microsoft Connector Certification Team to ensure that within the ```master``` branch, the connector version is identical to that deployed in the Power Platform. \nThe ```dev``` branch is maintained by the connector owner and the Microsoft Connector Certification Team to allow community development of the connector prior to certification and deployment of a version. \n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\n### Creating a Fork\n\nTo contibute to this open source repository, start by creating a fork on this repository. To do so, select the \"fork\" button on the upper right corner, and create your own copy of the repository. Next, sync your fork with the remote repository and clone your forked repository to your local machine.\n\n```git clone https://github.com/YOUR-USERNAME/PowerPlatformConnectors.git```\n\nCheck your remote URL.\n\n```git remote -v```\n\n```\n> origin  https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (fetch)\n> origin  https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (push)\n```\n\nAdd an upstream repository for your clone.\n\n```git remote add upstream https://github.com/microsoft/PowerPlatformConnectors.git```\n\nVerify the upstream links.\n\n```git remote -v```\n\n```\n> origin    https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (fetch) \n> origin    https://github.com/YOUR_USERNAME/PowerPlatformConnectors.git (push)\n> upstream  https://github.com/microsoft/PowerPlatformConnectors.git (fetch)\n> upstream  https://github.com/microsoft/PowerPlatformConnectors.git (push)\n```\n\nTo keep your fork up to date with this repository's updates, run these commands:\n\n```git fetch upstream```\n\n```git checkout master```\n\n```git merge upstream/master```\n\nYou are now ready to develop your connector in your own branch.\n\n### Submitting to the Open Source Repository\n\nContributions to the open source repository are made through pull requests. \nPrior to submitting a pull request, ensure that your pull request does not contain any sensitive or specific information, for example Client IDs or Client Secrets. \nAny sensitive values can be replaced with fake or dummy values for the purposes of submission as long as it is clearly indicated. \nAlso, ensure that the readme.md of the connector is updated with the latest information, or created for new connector submissions. \nAn example of a clear, structured, readme.md can be found in the [Azure Key Vault](https://github.com/microsoft/PowerPlatformConnectors/tree/master/custom-connectors/AzureKeyVault) connector repository. \nInclude this completed `readme.md` in same connector directory which contains the artifacts. \n\n#### Custom Connectors\n\nUpdates to an existing custom connector can be made through a simple pull request to update the custom connector files.\n\nFor new custom connectors, create a directory under the ```custom-connectors``` directory and place the connector files in the sub-folder. Ensure that a clear, structured, readme.md is included. \n\n#### Certified Connectors\n\nUpdates to certified connectors must first be made through a pull request to the ```dev``` branch for review by the connector owner. \nOnce a pull request has been merged to the ```dev``` branch, the connector owner can submit the connector for certification through the Connector certification tab in [ISV Studio](https://isvstudio.powerapps.com). Once certified, the Microsoft Certification team will handle merging the updates from ```dev``` to ```master```. \n\nUpdates to an existing custom connector can be made through a simple pull request to the ```dev``` branch to update the custom connector files.\n\nFor new connectors which will be submitted for certification, create a directory under the ```certified-connectors``` directory, place the connector files in the sub-folder, and submit a pull request to the ```dev``` branch. Ensure that a clear, structured, readme.md is included. \n\n### Tooling and Validation\n\n#### CLA\n\nWhen a pull request is submitted, a CLA-bot will automatically determine whether you need to provide\na CLA and annotate the PR appropriately. Simply follow the instructions\nprovided by the bot to ensure your pull request can be properly reviewed.\nYou will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n#### Swagger Validation\n\nA submitted pull request will also be validated against our Swagger Validator tool, which checks the connector files to ensure it is a proper Swagger file and adheres to our connector requirements and guidelines. Any errors or warnings will be added to the PR for both the submitter and the reviewer to understand. We do not accept pull requests with outstanding unresolved Swagger Validator issues. \n\n#### Breaking Change Detector\n\nAnother validation which runs on a submitted pull request is the breaking changes validator. This is to catch any inadvertent, non-backwards-compatible (i.e. breaking) changes which may break a current user experience, for example, deleting a published operation. The Breaking Change Detector compares the previous version of the Swagger with the new submission and raises awareness of any breaking change. The submitter and reviewer must both acknowledge any breaking changes submitted and ensure that no end users are inadvertently negatively affected. \n\n## Legal Notices\n\nMicrosoft and any contributors grant you a license to the Microsoft documentation and other content\nin this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),\nsee the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the\n[LICENSE-CODE](LICENSE-CODE) file.\n\nMicrosoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation\nmay be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\nThe licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\nMicrosoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n\nPrivacy information can be found at https://privacy.microsoft.com/en-us/\n\nMicrosoft and any contributors reserve all others rights, whether under their respective copyrights, patents,\nor trademarks, whether by implication, estoppel or otherwise.\n"
 },
 {
  "repo": "microsoft/qlib",
  "language": "Python",
  "readme_contents": "[![Python Versions](https://img.shields.io/pypi/pyversions/pyqlib.svg?logo=python&logoColor=white)](https://pypi.org/project/pyqlib/#files)\n[![Platform](https://img.shields.io/badge/platform-linux%20%7C%20windows%20%7C%20macos-lightgrey)](https://pypi.org/project/pyqlib/#files)\n[![PypI Versions](https://img.shields.io/pypi/v/pyqlib)](https://pypi.org/project/pyqlib/#history)\n[![Upload Python Package](https://github.com/microsoft/qlib/workflows/Upload%20Python%20Package/badge.svg)](https://pypi.org/project/pyqlib/)\n[![Github Actions Test Status](https://github.com/microsoft/qlib/workflows/Test/badge.svg?branch=main)](https://github.com/microsoft/qlib/actions)\n[![Documentation Status](https://readthedocs.org/projects/qlib/badge/?version=latest)](https://qlib.readthedocs.io/en/latest/?badge=latest)\n[![License](https://img.shields.io/pypi/l/pyqlib)](LICENSE)\n[![Join the chat at https://gitter.im/Microsoft/qlib](https://badges.gitter.im/Microsoft/qlib.svg)](https://gitter.im/Microsoft/qlib?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n\n\n<p align=\"center\">\n  <img src=\"http://fintech.msra.cn/images_v060/logo/1.png\" />\n</p>\n\n\nQlib is an AI-oriented quantitative investment platform, which aims to realize the potential, empower the research, and create the value of AI technologies in quantitative investment.\n\nIt contains the full ML pipeline of data processing, model training, back-testing; and covers the entire chain of quantitative investment: alpha seeking, risk modeling, portfolio optimization, and order execution. \n\nWith Qlib, users can easily try ideas to create better Quant investment strategies.\n\nFor more details, please refer to our paper [\"Qlib: An AI-oriented Quantitative Investment Platform\"](https://arxiv.org/abs/2009.11189).\n\n- [**News and Plans**](#news-and-plans)\n- [Framework of Qlib](#framework-of-qlib)\n- [Quick Start](#quick-start)\n  - [Installation](#installation)\n  - [Data Preparation](#data-preparation)\n  - [Auto Quant Research Workflow](#auto-quant-research-workflow)\n  - [Building Customized Quant Research Workflow by Code](#building-customized-quant-research-workflow-by-code)\n- [**Quant Model Zoo**](#quant-model-zoo)\n  - [Run a single model](#run-a-single-model)\n  - [Run multiple models](#run-multiple-models)\n- [**Quant Dataset Zoo**](#quant-dataset-zoo)\n- [More About Qlib](#more-about-qlib)\n- [Offline Mode and Online Mode](#offline-mode-and-online-mode)\n  - [Performance of Qlib Data Server](#performance-of-qlib-data-server)\n- [Related Reports](#related-reports)\n- [Contact Us](#contact-us)\n- [Contributing](#contributing)\n\n\n# News And Plans\nNew features under development(order by estimated release time).\nYour feedbacks about the features are very important.\n| Feature                        | Status      |\n| --                      | ------    |\n| Online serving and automatic model rolling | Under review: https://github.com/microsoft/qlib/pull/290 | \n| Planning-based portfolio optimization | Under review:  https://github.com/microsoft/qlib/pull/280 | \n| Fund data supporting and analysis  |  Under review: https://github.com/microsoft/qlib/pull/292 |\n| Point-in-Time database | Under review: https://github.com/microsoft/qlib/pull/343 |\n| High-frequency trading | Under review: https://github.com/microsoft/qlib/pull/408 | \n| Meta-Learning-based data selection | Initial opensource version under development |\n\nRecent released features\n| Feature | Status |\n| --                      | ------    |\n| DoubleEnsemble Model | Released https://github.com/microsoft/qlib/pull/286 | \n| High-frequency data processing example | Released https://github.com/microsoft/qlib/pull/257 |\n| High-frequency trading example | Part of code released https://github.com/microsoft/qlib/pull/227 | \n| High-frequency data(1min) | Released https://github.com/microsoft/qlib/pull/221 |\n| Tabnet Model | Released https://github.com/microsoft/qlib/pull/205 | \n\nFeatures released before 2021 are not listed here.\n\n# Framework of Qlib\n\n<div style=\"align: center\">\n<img src=\"http://fintech.msra.cn/images_v060/framework.png?v=0.1\" />\n</div>\n\n\nAt the module level, Qlib is a platform that consists of the above components. The components are designed as loose-coupled modules, and each component could be used stand-alone.\n\n| Name                   | Description                                                                                                                                                                                                                                                                                                                                                             |\n| ------                 | -----                                                                                                                                                                                                                                                                                                                                                                   |\n| `Infrastructure` layer | `Infrastructure` layer provides underlying support for Quant research. `DataServer` provides a high-performance infrastructure for users to manage and retrieve raw data. `Trainer` provides a flexible interface to control the training process of models, which enable algorithms to control the training process.                                                       |\n| `Workflow` layer       | `Workflow` layer covers the whole workflow of quantitative investment. `Information Extractor` extracts data for models. `Forecast Model` focuses on producing all kinds of forecast signals (e.g. _alpha_, risk) for other modules. With these signals `Portfolio Generator` will generate the target portfolio and produce orders to be executed by `Order Executor`. |\n| `Interface` layer      | `Interface` layer tries to present a user-friendly interface for the underlying system. `Analyser` module will provide users detailed analysis reports of forecasting signals, portfolios and execution results                                                                                                                                                                 |\n\n* The modules with hand-drawn style are under development and will be released in the future.\n* The modules with dashed borders are highly user-customizable and extendible.\n\n\n# Quick Start\n\nThis quick start guide tries to demonstrate\n1. It's very easy to build a complete Quant research workflow and try your ideas with _Qlib_.\n2. Though with *public data* and *simple models*, machine learning technologies **work very well** in practical Quant investment.\n\nHere is a quick **[demo](https://terminalizer.com/view/3f24561a4470)** shows how to install ``Qlib``, and run LightGBM with ``qrun``. **But**, please make sure you have already prepared the data following the [instruction](#data-preparation).\n\n\n## Installation\n\nThis table demonstrates the supported Python version of `Qlib`:\n|               | install with pip           | install from source  | plot |\n| ------------- |:---------------------:|:--------------------:|:----:|\n| Python 3.6    | :heavy_check_mark:    | :heavy_check_mark: (only with `Anaconda`)                  | :heavy_check_mark: |\n| Python 3.7    | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n| Python 3.8    | :heavy_check_mark:    | :heavy_check_mark:   | :heavy_check_mark: |\n| Python 3.9    | :x:                   | :heavy_check_mark:   | :x: |\n\n**Note**: \n1. Please pay attention that installing cython in Python 3.6 will raise some error when installing ``Qlib`` from source. If users use Python 3.6 on their machines, it is recommended to *upgrade* Python to version 3.7 or use `conda`'s Python to install ``Qlib`` from source.\n2. For Python 3.9, `Qlib` supports running workflows such as training models, doing backtest and plot most of the related figures (those included in [notebook](examples/workflow_by_code.ipynb)). However, plotting for the *model performance* is not supported for now and we will fix this when the dependent packages are upgraded in the future.\n\n### Install with pip\nUsers can easily install ``Qlib`` by pip according to the following command.\n\n```bash\n  pip install pyqlib\n```\n\n**Note**: pip will install the latest stable qlib. However, the main branch of qlib is in active development. If you want to test the latest scripts or functions in the main branch. Please install qlib with the methods below.\n\n### Install from source\nAlso, users can install the latest dev version ``Qlib`` by the source code according to the following steps:\n\n* Before installing ``Qlib`` from source, users need to install some dependencies:\n\n  ```bash\n  pip install numpy\n  pip install --upgrade  cython\n  ```\n\n* Clone the repository and install ``Qlib`` as follows.\n  * If you haven't installed qlib by the command ``pip install pyqlib`` before:\n    ```bash\n    git clone https://github.com/microsoft/qlib.git && cd qlib\n    python setup.py install\n    ```\n  * If you have already installed the stable version by the command ``pip install pyqlib``:\n    ```bash\n    git clone https://github.com/microsoft/qlib.git && cd qlib\n    pip install .\n    ```\n  **Note**: **Only** the command ``pip install .`` **can** overwrite the stable version installed by ``pip install pyqlib``, while the command ``python setup.py install`` **can't**.\n\n**Tips**: If you fail to install `Qlib` or run the examples in your environment,  comparing your steps and the [CI workflow](.github/workflows/test.yml) may help you find the problem.\n\n## Data Preparation\nLoad and prepare data by running the following code:\n  ```bash\n  # get 1d data\n  python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data --region cn\n\n  # get 1min data\n  python scripts/get_data.py qlib_data --target_dir ~/.qlib/qlib_data/cn_data_1min --region cn --interval 1min\n\n  ```\n\nThis dataset is created by public data collected by [crawler scripts](scripts/data_collector/), which have been released in\nthe same repository.\nUsers could create the same dataset with it. \n\n*Please pay **ATTENTION** that the data is collected from [Yahoo Finance](https://finance.yahoo.com/lookup), and the data might not be perfect.\nWe recommend users to prepare their own data if they have a high-quality dataset. For more information, users can refer to the [related document](https://qlib.readthedocs.io/en/latest/component/data.html#converting-csv-format-into-qlib-format)*.\n\n<!-- \n- Run the initialization code and get stock data:\n\n  ```python\n  import qlib\n  from qlib.data import D\n  from qlib.config import REG_CN\n\n  # Initialization\n  mount_path = \"~/.qlib/qlib_data/cn_data\"  # target_dir\n  qlib.init(mount_path=mount_path, region=REG_CN)\n\n  # Get stock data by Qlib\n  # Load trading calendar with the given time range and frequency\n  print(D.calendar(start_time='2010-01-01', end_time='2017-12-31', freq='day')[:2])\n\n  # Parse a given market name into a stockpool config\n  instruments = D.instruments('csi500')\n  print(D.list_instruments(instruments=instruments, start_time='2010-01-01', end_time='2017-12-31', as_list=True)[:6])\n\n  # Load features of certain instruments in given time range\n  instruments = ['SH600000']\n  fields = ['$close', '$volume', 'Ref($close, 1)', 'Mean($close, 3)', '$high-$low']\n  print(D.features(instruments, fields, start_time='2010-01-01', end_time='2017-12-31', freq='day').head())\n  ```\n -->\n\n## Auto Quant Research Workflow\nQlib provides a tool named `qrun` to run the whole workflow automatically (including building dataset, training models, backtest and evaluation). You can start an auto quant research workflow and have a graphical reports analysis according to the following steps: \n\n1. Quant Research Workflow: Run  `qrun` with lightgbm workflow config ([workflow_config_lightgbm_Alpha158.yaml](examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml) as following.\n    ```bash\n      cd examples  # Avoid running program under the directory contains `qlib`\n      qrun benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n    ```\n    If users want to use `qrun` under debug mode, please use the following command:\n    ```bash\n    python -m pdb qlib/workflow/cli.py examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml\n    ```\n    The result of `qrun` is as follows, please refer to [Intraday Trading](https://qlib.readthedocs.io/en/latest/component/backtest.html) for more details about the result. \n\n    ```bash\n\n    'The following are analysis results of the excess return without cost.'\n                           risk\n    mean               0.000708\n    std                0.005626\n    annualized_return  0.178316\n    information_ratio  1.996555\n    max_drawdown      -0.081806\n    'The following are analysis results of the excess return with cost.'\n                           risk\n    mean               0.000512\n    std                0.005626\n    annualized_return  0.128982\n    information_ratio  1.444287\n    max_drawdown      -0.091078\n    ```\n    Here are detailed documents for `qrun` and [workflow](https://qlib.readthedocs.io/en/latest/component/workflow.html).\n\n2. Graphical Reports Analysis: Run `examples/workflow_by_code.ipynb` with `jupyter notebook` to get graphical reports\n    - Forecasting signal (model prediction) analysis\n      - Cumulative Return of groups\n      ![Cumulative Return](http://fintech.msra.cn/images_v060/analysis/analysis_model_cumulative_return.png?v=0.1)\n      - Return distribution\n      ![long_short](http://fintech.msra.cn/images_v060/analysis/analysis_model_long_short.png?v=0.1)\n      - Information Coefficient (IC)\n      ![Information Coefficient](http://fintech.msra.cn/images_v060/analysis/analysis_model_IC.png?v=0.1)        \n      ![Monthly IC](http://fintech.msra.cn/images_v060/analysis/analysis_model_monthly_IC.png?v=0.1)\n      ![IC](http://fintech.msra.cn/images_v060/analysis/analysis_model_NDQ.png?v=0.1)\n      - Auto Correlation of forecasting signal (model prediction)\n      ![Auto Correlation](http://fintech.msra.cn/images_v060/analysis/analysis_model_auto_correlation.png?v=0.1)\n\n    - Portfolio analysis\n      - Backtest return\n      ![Report](http://fintech.msra.cn/images_v060/analysis/report.png?v=0.1)\n      <!-- \n      - Score IC\n      ![Score IC](docs/_static/img/score_ic.png)\n      - Cumulative Return\n      ![Cumulative Return](docs/_static/img/cumulative_return.png)\n      - Risk Analysis\n      ![Risk Analysis](docs/_static/img/risk_analysis.png)\n      - Rank Label\n      ![Rank Label](docs/_static/img/rank_label.png)\n      -->\n   - [Explanation](https://qlib.readthedocs.io/en/latest/component/report.html) of above results\n\n## Building Customized Quant Research Workflow by Code\nThe automatic workflow may not suit the research workflow of all Quant researchers. To support a flexible Quant research workflow, Qlib also provides a modularized interface to allow researchers to build their own workflow by code. [Here](examples/workflow_by_code.ipynb) is a demo for customized Quant research workflow by code.\n\n\n# [Quant Model Zoo](examples/benchmarks)\n\nHere is a list of models built on `Qlib`.\n- [GBDT based on XGBoost (Tianqi Chen, et al. 2016)](qlib/contrib/model/xgboost.py)\n- [GBDT based on LightGBM (Guolin Ke, et al. 2017)](qlib/contrib/model/gbdt.py)\n- [GBDT based on Catboost (Liudmila Prokhorenkova, et al. 2017)](qlib/contrib/model/catboost_model.py)\n- [MLP based on pytorch](qlib/contrib/model/pytorch_nn.py)\n- [LSTM based on pytorch (Sepp Hochreiter, et al. 1997)](qlib/contrib/model/pytorch_lstm.py)\n- [GRU based on pytorch (Kyunghyun Cho, et al. 2014)](qlib/contrib/model/pytorch_gru.py)\n- [ALSTM based on pytorch (Yao Qin, et al. 2017)](qlib/contrib/model/pytorch_alstm.py)\n- [GATs based on pytorch (Petar Velickovic, et al. 2017)](qlib/contrib/model/pytorch_gats.py)\n- [SFM based on pytorch (Liheng Zhang, et al. 2017)](qlib/contrib/model/pytorch_sfm.py)\n- [TFT based on tensorflow (Bryan Lim, et al. 2019)](examples/benchmarks/TFT/tft.py)\n- [TabNet based on pytorch (Sercan O. Arik, et al. 2019)](qlib/contrib/model/pytorch_tabnet.py)\n- [DoubleEnsemble based on LightGBM (Chuheng Zhang, et al. 2020)](qlib/contrib/model/double_ensemble.py)\n\nYour PR of new Quant models is highly welcomed.\n\nThe performance of each model on the `Alpha158` and `Alpha360` dataset can be found [here](examples/benchmarks/README.md).\n\n## Run a single model\nAll the models listed above are runnable with ``Qlib``. Users can find the config files we provide and some details about the model through the [benchmarks](examples/benchmarks) folder. More information can be retrieved at the model files listed above.\n\n`Qlib` provides three different ways to run a single model, users can pick the one that fits their cases best:\n- Users can use the tool `qrun` mentioned above to run a model's workflow based from a config file.\n- Users can create a `workflow_by_code` python script based on the [one](examples/workflow_by_code.py) listed in the `examples` folder.\n\n- Users can use the script [`run_all_model.py`](examples/run_all_model.py) listed in the `examples` folder to run a model. Here is an example of the specific shell command to be used: `python run_all_model.py --models=lightgbm`, where the `--models` arguments can take any number of models listed above(the available models can be found  in [benchmarks](examples/benchmarks/)). For more use cases, please refer to the file's [docstrings](examples/run_all_model.py).\n\n## Run multiple models\n`Qlib` also provides a script [`run_all_model.py`](examples/run_all_model.py) which can run multiple models for several iterations. (**Note**: the script only support *Linux* for now. Other OS will be supported in the future. Besides, it doesn't support parrallel running the same model for multiple times as well, and this will be fixed in the future development too.)\n\nThe script will create a unique virtual environment for each model, and delete the environments after training. Thus, only experiment results such as `IC` and `backtest` results will be generated and stored.\n\nHere is an example of running all the models for 10 iterations:\n```python\npython run_all_model.py 10\n```\n\nIt also provides the API to run specific models at once. For more use cases, please refer to the file's [docstrings](examples/run_all_model.py). \n\n\n# Quant Dataset Zoo\nDataset plays a very important role in Quant. Here is a list of the datasets built on `Qlib`:\n\n| Dataset                                    | US Market | China Market |\n| --                                         | --        | --           |\n| [Alpha360](./qlib/contrib/data/handler.py) |  \u221a        |  \u221a           |\n| [Alpha158](./qlib/contrib/data/handler.py) |  \u221a        |  \u221a           |\n\n[Here](https://qlib.readthedocs.io/en/latest/advanced/alpha.html) is a tutorial to build dataset with `Qlib`.\nYour PR to build new Quant dataset is highly welcomed.\n\n# More About Qlib\nThe detailed documents are organized in [docs](docs/).\n[Sphinx](http://www.sphinx-doc.org) and the readthedocs theme is required to build the documentation in html formats. \n```bash\ncd docs/\nconda install sphinx sphinx_rtd_theme -y\n# Otherwise, you can install them with pip\n# pip install sphinx sphinx_rtd_theme\nmake html\n```\nYou can also view the [latest document](http://qlib.readthedocs.io/) online directly.\n\nQlib is in active and continuing development. Our plan is in the roadmap, which is managed as a [github project](https://github.com/microsoft/qlib/projects/1).\n\n\n\n# Offline Mode and Online Mode\nThe data server of Qlib can either deployed as `Offline` mode or `Online` mode. The default mode is offline mode.\n\nUnder `Offline` mode, the data will be deployed locally. \n\nUnder `Online` mode, the data will be deployed as a shared data service. The data and their cache will be shared by all the clients. The data retrieval performance is expected to be improved due to a higher rate of cache hits. It will consume less disk space, too. The documents of the online mode can be found in [Qlib-Server](https://qlib-server.readthedocs.io/). The online mode can be deployed automatically with [Azure CLI based scripts](https://qlib-server.readthedocs.io/en/latest/build.html#one-click-deployment-in-azure). The source code of online data server can be found in [Qlib-Server repository](https://github.com/microsoft/qlib-server).\n\n## Performance of Qlib Data Server\nThe performance of data processing is important to data-driven methods like AI technologies. As an AI-oriented platform, Qlib provides a solution for data storage and data processing. To demonstrate the performance of Qlib data server, we\ncompare it with several other data storage solutions. \n\nWe evaluate the performance of several storage solutions by finishing the same task,\nwhich creates a dataset (14 features/factors) from the basic OHLCV daily data of a stock market (800 stocks each day from 2007 to 2020). The task involves data queries and processing.\n\n|                         | HDF5      | MySQL     | MongoDB   | InfluxDB  | Qlib -E -D  | Qlib +E -D   | Qlib +E +D  |\n| --                      | ------    | ------    | --------  | --------- | ----------- | ------------ | ----------- |\n| Total (1CPU) (seconds)  | 184.4\u00b13.7 | 365.3\u00b17.5 | 253.6\u00b16.7 | 368.2\u00b13.6 | 147.0\u00b18.8   | 47.6\u00b11.0     | **7.4\u00b10.3** |\n| Total (64CPU) (seconds) |           |           |           |           | 8.8\u00b10.6     | **4.2\u00b10.2**  |             |\n* `+(-)E` indicates with (out) `ExpressionCache`\n* `+(-)D` indicates with (out) `DatasetCache`\n\nMost general-purpose databases take too much time to load data. After looking into the underlying implementation, we find that data go through too many layers of interfaces and unnecessary format transformations in general-purpose database solutions.\nSuch overheads greatly slow down the data loading process.\nQlib data are stored in a compact format, which is efficient to be combined into arrays for scientific computation.\n\n# Related Reports\n- [\u3010\u534e\u6cf0\u91d1\u5de5\u6797\u6653\u660e\u56e2\u961f\u3011\u56fe\u795e\u7ecf\u7f51\u7edc\u9009\u80a1\u4e0eQlib\u5b9e\u8df5\u2014\u2014\u534e\u6cf0\u4eba\u5de5\u667a\u80fd\u7cfb\u5217\u4e4b\u56db\u5341\u4e8c](https://mp.weixin.qq.com/s/w5fDB6oAv9dO6vlhf1kmhA)\n- [Guide To Qlib: Microsoft\u2019s AI Investment Platform](https://analyticsindiamag.com/qlib/)\n- [\u3010\u534e\u6cf0\u91d1\u5de5\u6797\u6653\u660e\u56e2\u961f\u3011\u5fae\u8f6fAI\u91cf\u5316\u6295\u8d44\u5e73\u53f0Qlib\u4f53\u9a8c\u2014\u2014\u534e\u6cf0\u4eba\u5de5\u667a\u80fd\u7cfb\u5217\u4e4b\u56db\u5341](https://mp.weixin.qq.com/s/Brcd7im4NibJOJzZfMn6tQ)\n- [\u5fae\u8f6f\u4e5f\u641eAI\u91cf\u5316\u5e73\u53f0\uff1f\u8fd8\u662f\u5f00\u6e90\u7684\uff01](https://mp.weixin.qq.com/s/47bP5YwxfTp2uTHjUBzJQQ)\n- [\u5fae\u77ffQlib\uff1a\u4e1a\u5185\u9996\u4e2aAI\u91cf\u5316\u6295\u8d44\u5f00\u6e90\u5e73\u53f0](https://mp.weixin.qq.com/s/vsJv7lsgjEi-ALYUz4CvtQ)\n\n# Contact Us\n- If you have any issues, please create issue [here](https://github.com/microsoft/qlib/issues/new/choose) or send messages in [gitter](https://gitter.im/Microsoft/qlib).\n- If you want to make contributions to `Qlib`, please [create pull requests](https://github.com/microsoft/qlib/compare). \n- For other reasons, you are welcome to contact us by email([qlib@microsoft.com](mailto:qlib@microsoft.com)).\n  - We are recruiting new members(both FTEs and interns), your resumes are welcome!\n\nJoin IM discussion groups:\n|[Gitter](https://gitter.im/Microsoft/qlib)|\n|----|\n|![image](http://fintech.msra.cn/images_v060/qrcode/gitter_qr.png)|\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe right to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/vscode-powerquery",
  "language": "TypeScript",
  "readme_contents": "# Power Query language service for VS Code\r\n\r\nProvides a language service for the [Power Query / M formula language](https://powerquery.microsoft.com/) with the following capabilities:\r\n\r\n-   Suggestions / Auto complete (Based on M standard library functions, and keywords)\r\n-   Parameter hints\r\n-   Hover\r\n-   Code formatting\r\n-   Syntax validation\r\n\r\nNow available in the [Visual Studio Code Marketplace](https://marketplace.visualstudio.com/items?itemName=PowerQuery.vscode-powerquery).\r\n\r\n## How to build\r\n\r\n1. install dependencies:\r\n\r\n```cmd\r\nnpm install\r\n```\r\n\r\n2. build all packages:\r\n\r\n```cmd\r\nnpm run build\r\n```\r\n\r\n## How to run command line tests\r\n\r\n```cmd\r\ncd server\r\nnpm run test\r\n```\r\n\r\nThere is also a UI test suite that can be run from VS Code.\r\n\r\n## Generate vscode extension\r\n\r\nInstall the [vsce](https://code.visualstudio.com/api/working-with-extensions/publishing-extension) CLI utility.\r\n\r\n```cmd\r\nnpm install --global vsce\r\n```\r\n\r\nGenerate vsix package:\r\n\r\n```cmd\r\nvsce package\r\n```\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/PowerToys",
  "language": "C#",
  "readme_contents": "# Microsoft PowerToys\n\n<img src=\"./doc/images/overview/PT%20hero%20image.png\"/>\n\n[Downloads & Release notes][github-release-link] | [Contributing to PowerToys](#contributing) | [What's Happening](#whats-happening) | [Roadmap](#powertoys-roadmap)\n\n## Build status\n\n| Architecture | Master | Stable | Installer |\n|--------------|--------|--------|-----------|\n| x64 | [![Build Status for Master](https://dev.azure.com/ms/PowerToys/_apis/build/status/microsoft.PowerToys?branchName=master)](https://dev.azure.com/ms/PowerToys/_build/latest?definitionId=219&branchName=master) | [![Build Status for Stable](https://dev.azure.com/ms/PowerToys/_apis/build/status/microsoft.PowerToys?branchName=stable)](https://dev.azure.com/ms/PowerToys/_build/latest?definitionId=219&branchName=stable) | [![Build Status for Installer](https://github-private.visualstudio.com/microsoft/_apis/build/status/CDPX/powertoys/powertoys-Windows-Official-master-Test?branchName=master)](https://github-private.visualstudio.com/microsoft/_build/latest?definitionId=61&branchName=master) |\n\n## About\n\nMicrosoft PowerToys is a set of utilities for power users to tune and streamline their Windows 10 experience for greater productivity. For more info on [PowerToys overviews and guides][usingPowerToys-docs-link], or any other tools and resources for [Windows development environments](https://docs.microsoft.com/windows/dev-environment/overview), head over to [docs.microsoft.com][usingPowerToys-docs-link]! \n\n|              | Current utilities: |              |\n|--------------|--------------------|--------------|\n| [Color Picker](https://aka.ms/PowerToysOverview_ColorPicker) |  [FancyZones](https://aka.ms/PowerToysOverview_FancyZones) | [File Explorer Add-ons](https://aka.ms/PowerToysOverview_FileExplorerAddOns) |\n| [Image Resizer](https://aka.ms/PowerToysOverview_ImageResizer) | [Keyboard Manager](https://aka.ms/PowerToysOverview_KeyboardManager) | [PowerRename](https://aka.ms/PowerToysOverview_PowerRename) |\n| [PowerToys Run](https://aka.ms/PowerToysOverview_PowerToysRun) | [Shortcut Guide](https://aka.ms/PowerToysOverview_ShortcutGuide) | [Video Conference Mute (Experimental)](https://aka.ms/PowerToysOverview_VideoConference) |\n\n## Installing and running Microsoft PowerToys\n\n### Requirements\n\n- Windows 10 v1903 (build 18362) or newer.\n   - \u26a0\ufe0f PowerToys minimum version of Windows 10 is v1903 starting with the 0.37 release\n- Have [.NET Core 3.1.14 Desktop Runtime](https://dotnet.microsoft.com/download/dotnet/thank-you/runtime-desktop-3.1.14-windows-x64-installer). The installer should handle this but we want to directly make people aware.\n\n### Via GitHub with EXE [Recommended]\n\n#### Stable version\n\nInstall from the [Microsoft PowerToys GitHub releases page][github-release-link]. Click on `Assets` to show the files available in the release and then click on `PowerToysSetup-0.37.0-x64.exe` to download the PowerToys installer.\n\nThis is our preferred method.\n\n#### Experimental version\nTo install the Video Conference mute, please use the [v0.36 experimental version of PowerToys][github-prerelease-link] to try out this version. It includes all improvements from v0.35 in addition to the Video conference utility. Click on `Assets` to show the files available in the release and then download the .exe installer.\n\n### Via WinGet (Preview)\nDownload PowerToys from [WinGet](https://github.com/microsoft/winget-cli#installing-the-client). To install PowerToys, run the following command from the command line / PowerShell:\n\n```powershell\nWinGet install powertoys\n```\n\n### Other install methods\n\nThere are [community driven install methods](./doc/unofficialInstallMethods.md) such as Chocolatey and Scoop.  If these are your preferred install solutions, this will have the install instructions.\n\n### Processor support\n\nWe currently support the matrix below.\n\n| x64 | x86 | ARM64 |\n|:---:|:---:|:---:|\n| [Supported][github-release-link] | [Issue #602](https://github.com/microsoft/PowerToys/issues/602) | [Issue #490](https://github.com/microsoft/PowerToys/issues/490) |\n\n## Contributing\n\nThis project welcomes contributions of all types. Help spec'ing, design, documentation, finding bugs are ways everyone can help on top of coding features / bug fixes. We are excited to work with the power user community to build a set of tools for helping you get the most out of Windows.\n\nWe ask that **before you start work on a feature that you would like to contribute**, please read our [Contributor's Guide](CONTRIBUTING.md). We will be happy to work with you to figure out the best approach, provide guidance and mentorship throughout feature development, and help avoid any wasted or duplicate effort.\n\nMost contributions require you to agree to a [Contributor License Agreement (CLA)][oss-CLA] declaring that you have the right to, and actually do, grant us the rights to use your contribution.\n\nFor guidance on developing for PowerToys, please read the [developer docs](/doc/devdocs) for a detailed breakdown. This includes how to setup your computer to compile.\n\n## What's Happening\n\n### PowerToys Roadmap\n\nOur [prioritized roadmap][roadmap] of features and utilities that the core team is focusing on.\n\n### 0.37 - April 2021 Update\n\nOur goals for [v0.37 release cycle](https://github.com/microsoft/PowerToys/issues?q=is%3Aopen+is%3Aissue+project%3Amicrosoft%2FPowerToys%2F19) Video Conference Mute work so we can bring it into the stable branch, general bug fixes, moving Keyboard manager out, and removing the legacy settings app.\n\nThe 0.36 experimental release was released this month as well which includes Video Conference Mute which is based off the 0.35 code base.\n\nOur [prioritized roadmap][roadmap] of features and utilities will dictate what the core team is focusing on for the near future. \n\n#### Highlights from v0.37\n\n**General**\n\n- PowerToys now requires Windows 10, version 1903 or higher\n- FancyZones editor default launching key is <kbd>Win</kbd>+<kbd>Shift</kbd>+<kbd>`</kbd>\n   - Windows Terminal's new Quake mode will use <kbd>Win</kbd>+<kbd>`</kbd>.  We feel this is a far better use of the keystroke. \n   - Current PowerToys users can update this in our settings in the FancyZone section.\n- Removed our v1 HTML based settings system\n\n## New Spec - Feedback please!\n\n- What is new in PowerToys (SCOOBE) - [Pull Request](https://github.com/microsoft/PowerToys/pull/10978)\n\n### FancyZones\n- Editor UX bug fixes. Thanks [@niels9001](https://github.com/niels9001)\n- Monitor resolution is added to the top to directly infer the boxes on top are your monitors\n- Fix for editor crash when editing a custom layout\n\n### PowerRename\n- Option added for capitalization.  \n- Improved loading responsiveness with large sums of files.\n\n### PowerToys Run\n- Changed XAML to improve rendering. Thanks [@niels9001](https://github.com/niels9001)\n- Disabled plugins are no longer loaded\n- VS Code plugin workspaces showing up now.  Thanks [@ricardosantos9521](https://github.com/ricardosantos9521)\n\n### Keyboard manager \n- Now an independent exe.  This now runs high priority in its own process.  When your CPU is under load, this should allow the process to continue to be prioritized\n\n### Color Picker \n- uses a centralized keyhook.  This should improve activation\n- Esc for closing will no longer bubble through.  Thanks [@DoctorNefario](https://github.com/DoctorNefario)\n\n### Settings / Welcome to PowerToys\n- Shortcuts will stand out more\n- Few accessability bugs fixed. Thanks [@niels9001](https://github.com/niels9001)\n\n### Shortcut Guide\n- Excluded apps for Shortcut Guide.  Thanks [@davidegiacometti ](https://github.com/davidegiacometti)\n\n### Installer\n- new arg for starting PT after silent install\n\n### Developer quality of life\n- Ability to directly debug against Settings\n\n## Community contributions\n\nWe'd like to directly mention (in alphabetical order) for their continued community support this month and helping directly make PowerToys a better piece of software.  \n\n[@Aaron-Junker](https://github.com/Aaron-Junker), [@addrum](https://github.com/addrum), [@davidegiacometti ](https://github.com/davidegiacometti), [@DoctorNefario](https://github.com/DoctorNefario), [@htcfreek](https://github.com/htcfreek), [@Jay-o-Way](https://github.com/Jay-o-Way), [@niels9001](https://github.com/niels9001), and [@ricardosantos9521](https://github.com/ricardosantos9521)\n\n#### What is being planned for v0.39 - May 2021\n\nFor [v0.39][github-next-release-work], we are planning to work on:\n\n- Stability and bug fixes\n- Improving VCM\n- Moving Shortcutguide out of the main exe\n\n## PowerToys Community\n\nThe PowerToys team is extremely grateful to have the [support of an amazing active community][community-link]. The work you do is incredibly important. PowerToys wouldn\u2019t be nearly what it is today without your help filing bugs, updating documentation, guiding the design, or writing features. We want to say thank you and take time to recognize your work.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct][oss-conduct-code].\n\n## Privacy Statement\n\nThe application logs basic telemetry. Our Telemetry Data page (Coming Soon) has the trends from the telemetry. Please read the [Microsoft privacy statement][privacy-link] for more information.\n\n[oss-CLA]: https://cla.opensource.microsoft.com\n[oss-conduct-code]: CODE_OF_CONDUCT.md\n[community-link]: COMMUNITY.md\n[github-release-link]: https://github.com/microsoft/PowerToys/releases/\n[roadmap]: https://github.com/microsoft/PowerToys/wiki/Roadmap\n[privacy-link]: http://go.microsoft.com/fwlink/?LinkId=521839\n[vidConfOverview]: https://aka.ms/PowerToysOverview_VideoConference\n[loc-bug]: https://github.com/microsoft/PowerToys/issues/new?assignees=&labels=&template=translation_issue.md&title=\n[usingPowerToys-docs-link]: https://docs.microsoft.com/windows/powertoys/\n\n<!-- items that need to be updated release to release -->\n[github-next-release-work]: https://github.com/microsoft/PowerToys/issues?q=is%3Aopen+is%3Aissue+project%3Amicrosoft%2FPowerToys%2F20\n[github-prerelease-link]: https://github.com/microsoft/PowerToys/releases/tag/v0.36.0\n"
 },
 {
  "repo": "microsoft/fuse-webui",
  "language": "TypeScript",
  "readme_contents": "\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-sampleslicer",
  "language": "TypeScript",
  "readme_contents": "# PowerBI Slicer custom visual sample\r\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-sampleslicer.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-sampleslicer)\r\n\r\nDemonstrates the use of the Advanced Filtering API introduced in the version 1.7 of [PowerBI Visuals Tools](https://github.com/Microsoft/PowerBI-visuals-tools). \r\n\r\nThis PowerBI Custom Visual relies on the Advanced Filter API for bulk data-point selection and [PowerBI Visuals Interactivity Utils](https://github.com/Microsoft/powerbi-visuals-utils-interactivityutils) for discrete data-point selection.\r\n\r\n### Understanding the visual\r\nThe visual lets the user select numeric data inputs to be displayed in all other visuals in the same report sheet. The user can either select discrete values or a range by adjusting the sliders. \r\n\r\nSee a [demo PowerBI report](doc/SampleSlicer.pbix) to get an idea about the visual's functionality.\r\n\r\n![](doc/images/SampleSlicer.PNG)\r\n\r\n### Setting up the environment\r\n\r\nYou will first need to set up your environment as detailed [here](https://github.com/Microsoft/PowerBI-visuals/blob/master/Readme.md#setting-up-environment).\r\n\r\n### Installing dev dependencies\r\n\r\nOnce you have cloned this example, run these commands to install dependencies and to connect the visual into powerbi.\r\n\r\n```\r\nnpm install # This command will install all necessary modules\r\n```\r\n\r\n### Starting the dev app\r\n```\r\npbiviz start\r\n```\r\n\r\n### Understanding the code\r\n1. [Code structure](doc/CodeStructure.md)\r\n2. Discrete selection with the PowerBI Visuals Interactivity Utils\r\n  - [Adding the Interactivity Utils to the project](doc/AddingInteractivityUtils.md)\r\n  - [Using the Interactivity Utils](doc/UsingInteractivityUtils.md)\r\n3. Advanced selection with the Advanced Filter API\r\n  - [Adding the Advanced Filter API to the project](doc/AddingAdvancedFilterAPI.md)\r\n  - [Using the Advanced Filter API](doc/UsingAdvancedFilterAPI.md)\r\n4. Bookmarks support\r\n  - [Adding bookmarks support to the project](doc/AddingBookmarksSuppoprt.md)\r\n5. Slicer synchronization support\r\n  - [Enable Sync Slicers](doc/SlicerSynchronizationSupport.md)"
 },
 {
  "repo": "microsoft/electionguard-admin-device",
  "language": "TypeScript",
  "readme_contents": "![Microsoft Defending Democracy Program: ElectionGuard](images/electionguard-banner.svg)\r\n\r\n# ElectionGuard Admin Device\r\n\r\n![package](https://github.com/microsoft/electionguard-admin-device/workflows/Package/badge.svg)\r\n[![license](https://img.shields.io/github/license/microsoft/electionguard-admin-device)](License)\r\n\r\nThe ElectionGuard Admin Device is a fully functional\r\nimplementation built in ReactJS. It connects to an ElectionGuard SDK API to\r\ncomplete two main tasks.\r\n\r\n1. Start an Election\r\n2. Tally Voting Results\r\n\r\nThis reference implementation is meant to demonstrate a possible use case of the\r\nElectionGuard SDK.\r\n\r\n## Running the sample\r\n\r\nThis project was bootstrapped with\r\n[Create React App](https://github.com/facebook/create-react-app).\r\n\r\nThis project can be run in two configurations.\r\n\r\n1. Full Hardware Demo\r\n   - **OS:** Linux (Unbuntu)\r\n   - **Hardware:** Card reader, smart card, and usb stick\r\n   - **Reference Implementation APIs:**\r\n     - [Usb stick Api](https://github.com/InfernoRed/module-usbstick)\r\n     - [Smart Card Api](https://github.com/InfernoRed/module-smartcards)\r\n     - [ElectionGuard Api](https://github.com/microsoft/ElectionGuard-SDK-DotNetCore-Reference-Web-API)\r\n2. Mock Demo\r\n   - To demo, create a `.env.local` and enable the mocks shown in the `.env`\r\n     file.\r\n\r\n`yarn start`\r\n\r\nRuns the app in the development mode.<br /> Open\r\n[http://localhost:3000](http://localhost:3000) to view it in the browser.\r\n\r\nThe page will reload if you make edits.<br /> You will also see any lint errors\r\nin the console.\r\n\r\n`yarn test`\r\n\r\nLaunches the test runner in the interactive watch mode.<br /> See the section\r\nabout\r\n[running tests](https://facebook.github.io/create-react-app/docs/running-tests)\r\nfor more information.\r\n\r\n`yarn build`\r\n\r\nBuilds the app for production to the `build` folder.<br /> It correctly bundles\r\nReact in production mode and optimizes the build for the best performance.\r\n\r\nThe build is minified and the filenames include the hashes.<br /> Your app is\r\nready to be deployed!\r\n\r\nSee the section about\r\n[deployment](https://facebook.github.io/create-react-app/docs/deployment) for\r\nmore information.\r\n\r\n## Contributing\r\n\r\nHelp defend democracy and [contribute to the project](CONTRIBUTING).\r\n\r\n<!--\r\nGuidelines on README format: https://review.docs.microsoft.com/help/onboard/admin/samples/concepts/readme-template?branch=master\r\n\r\nGuidance on onboarding samples to docs.microsoft.com/samples: https://review.docs.microsoft.com/help/onboard/admin/samples/process/onboarding?branch=master\r\n\r\nTaxonomies for products and languages: https://review.docs.microsoft.com/new-hope/information-architecture/metadata/taxonomies?branch=master\r\n-->\r\n"
 },
 {
  "repo": "microsoft/code-with-engineering-playbook",
  "language": "Ruby",
  "readme_contents": "# CSE Code-With Customer/Partner Engineering Playbook\n\nAn engineer working for a [CSE](docs/CSE.md) project...\n\n* Has responsibilities to their team \u2013 mentor, coach, and lead.\n* Knows their **playbook**. Follows their playbook. Fixes their playbook if it is broken. If they find a better playbook, they copy it. If somebody could use your playbook, give them yours.\n* Leads by example. Models the behaviors we desire both interpersonally and technically.\n* Strives to understand how their work fits into a broader context and ensures the outcome.\n\nThis is our playbook. All contributions welcome! Please feel free to submit a [pull request](https://github.com/microsoft/code-with-engineering-playbook/pulls) to get involved.\n\n> **Note:** If you are reading this on github - head over to [https://microsoft.github.io/code-with-engineering-playbook/](https://microsoft.github.io/code-with-engineering-playbook/) for a better reading experience\n\n## Why Have A Playbook\n\n* To increase overall efficiency for team members and the whole team in general.\n* Reduce the number of mistakes and avoid common pitfalls.\n* Strive to be a better engineer and learn from other people's shared experience.\n\n## \"The\" Checklist\n\nIf you do nothing else follow the [Engineering Fundamentals Checklist](docs/ENG-FUNDAMENTALS-CHECKLIST.md)! It's here to help follow the Engineering Fundamentals.\n\n## Structure of a Sprint\n\nA [breakdown of sections](docs/SPRINT-STRUCTURE.md) according to the structure of an Agile sprint.\n\n## General Guidance\n\n* Keep the code quality bar high.\n* Value quality and precision over \u2018getting things done\u2019.\n* Work diligently on the one important thing.\n* As a distributed team take time to share context via wiki, teams and backlog items.\n* Make the simple thing work now. Build fewer features today, but ensure they work amazingly. Then add more features tomorrow.\n* Avoid adding scope to a backlog item, instead add a new backlog item.\n* Our goal is to ship incremental customer value.\n* Keep backlog item details up to date to communicate the state of things with the rest of your team.\n* Report product issues found and provide clear and repeatable engineering feedback!\n* We all own our code and each one of us has an obligation to make all parts of the solution great.\n\n## QuickLinks\n\n* [Engineering Fundamentals Checklist](docs/ENG-FUNDAMENTALS-CHECKLIST.md)\n* [Structure of a Sprint](docs/SPRINT-STRUCTURE.md)\n\n## Engineering Fundamentals\n\n* [Agile Development](docs/agile-development/README.md)\n* [Automated Testing](docs/automated-testing/README.md)\n* [Code Reviews](docs/code-reviews/README.md)\n* [Continuous Delivery (CD)](docs/continuous-delivery/README.md)\n* [Continuous Integration (CI)](docs/continuous-integration/README.md)\n* [Design Decision Logs](docs/design-reviews/decision-log/README.md)\n* [Design Reviews](docs/design-reviews/README.md)\n* [Developer Experience](docs/developer-experience/README.md)\n* [Engineering Feedback](docs/engineering-feedback/README.md)\n* [Observability](docs/observability/README.md)\n* [Security](docs/security/README.md)\n* [Source Control](docs/source-control/README.md)\n* [Reliability](docs/reliability/README.md)\n\n## Fundamentals for Specific Technology Areas\n\n* [Data and DataOps Fundamentals](docs/data-fundamentals/README.md)\n* [Machine Learning Fundamentals](docs/ml-fundamentals/README.md)\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for contribution guidelines.\n"
 },
 {
  "repo": "microsoft/vsts-extension-multivalue-control",
  "language": "TypeScript",
  "readme_contents": "> Currently only available on TFS 2017 or later and Visual Studio Team Services. \n\n![Work Item Form](img/form.png)\n\n# Select multiple values for your fields\n![Control](img/operatingSystem.png)\n\n# Expand the control only when needed\n![Control Collapsed](img/operatingSystemCollapsed.png)\n\n![Control Expanded](img/operatingSystemExpanded.png)\n\n# How to get started\n## Azure Devops Services\n\nNavigate to your work item form customization page and add a multivalue control.\n\n![Layout Customization](img/layoutCustomization.png)\n\nEdit the control so it can use the right field to store your selection and the right set of values to be displayed.\n\n![Options](img/options.png)\n\nBe sure to allow user inputed values if a picklisk (string) field is used to back the extension.\n\n![check the box to allow users to enter their own values](img/allowedValues.png)\n\n## Azure Devops Server\nWe recommend TFS 2017 RC2 or later when running this extension.\n\n[Learn more](https://github.com/Microsoft/vsts-extension-multivalue-control/blob/master/xmldetails.md) about how to customize the multivalue control directly on XML.\n\n# How to query\n\nThe selected values are stored in a semicolon separated format.  To search for items that have a specific value use the \"Contains Words\" operator.  If searching for multiple values, use multipe \"Contains Words\" clauses for that field.\n\n# Source code \n\nThe [source](https://github.com/Microsoft/vsts-extension-multivalue-control) for this extension can be found on Github - feel free to take, fork and extend. \n\nYou can also learn how to build your own custom control extension for the work item form [here](https://www.visualstudio.com/en-us/docs/integrate/extensions/develop/custom-control). \n\n# Feedback \n\nWe appreciate your feedback! Here are some ways to connect with us:\n\n* Add a review.\n* Report issues in [GitHub](https://github.com/Microsoft/vsts-extension-multivalue-control/issues).\n\n> Microsoft DevLabs is an outlet for experiments from Microsoft, experiments that represent some of the latest ideas around developer tools. Solutions in this category are designed for broad usage, and you are encouraged to use and provide feedback on them; however, these extensions are not supported nor are any commitments made as to their longevity.\n"
 },
 {
  "repo": "microsoft/openpaimarketplace",
  "language": "JavaScript",
  "readme_contents": "<p align=\"center\">\n  <img src=\"./docs/images/marketplace.svg\" width=\"160\" alt=\"Marketplace Logo\" /></a>\n</p>\n\n<h2 align=\"center\">Openpaimarketplace</h2>\n\n<p align=\"center\">\n  <a href=\"https://github.com/microsoft/openpaimarketplace/actions?query=workflow%3A%22Publish+Docker+Image%22\"><img src=\"https://github.com/microsoft/openpaimarketplace/workflows/Publish%20Docker%20Image/badge.svg\" alt=\"Publish Docker Image\"></a>\n  <a href=\"https://github.com/microsoft/openpaimarketplace/actions?query=workflow%3AWebportal\"><img src=\"https://github.com/microsoft/openpaimarketplace/workflows/Webportal/badge.svg?branch=master\" alt=\"Webportal CI\"></a>\n  <a href=\"https://github.com/microsoft/openpaimarketplace/actions?query=workflow%3A%22Rest+Server%22\"><img src=\"https://github.com/microsoft/openpaimarketplace/workflows/Rest%20Server/badge.svg?branch=master\" alt=\"Rest Server CI\"></a>\n  <a href=\"https://openpaimarketplace.readthedocs.io/en/latest/?badge=latest\"><img src=\"https://readthedocs.org/projects/openpaimarketplace/badge/?version=latest\" alt=\"Doc\"></a>\n  <a href=\"https://github.com/microsoft/openpaimarketplace/releases\"><img src=\"https://img.shields.io/github/v/release/Microsoft/openpaimarketplace\" alt=\"Release\"></a>\n</p>\n\n---\n\nA marketplace which stores data and job templates of openpai. Users could use openpaimarketplace to share their jobs or run-and-learn others' sharing job.\n\n## Components\n\nThere are two components of openpaimarketplace, [rest server](https://github.com/microsoft/openpaimarketplace/tree/master/rest_server) and [webportal](https://github.com/microsoft/openpaimarketplace/tree/master/webportal), which are responsible for backend service and frontend UI seperately.\n\n## Getting Started\n\n- For Admin\n  \n  To the admin user who is responsible for deploying and managing OpenPAI and openpaimarketplace, please check [admin manual](https://openpaimarketplace.readthedocs.io/en/latest/admin/README.html) for help.\n\n- For User\n\n  To the normal user who wants to use marketplace templates in OpenPAI, please check [user manual](https://openpaimarketplace.readthedocs.io/en/latest/user/README.html) for help.\n\n## Reference\n\n- [OpenPAI](https://github.com/microsoft/pai): A complete solution for AI platform. HiveD will be more user-friendly when working in tandem with OpenPAI.\n\n- [OpenPAI Protocol](https://github.com/microsoft/openpai-protocol): The protocol interface between marketplace and OpenPAI platform.\n\n## Developing Guide\n\nThis section is a guide for developers who are new to openpaimarketplace. Openpaimarketplace contains 2 sub projects, `rest_server` and `webportal`. For the detailed developing guide, you should refer to the readme doc of each sub project.\n\n### [rest_server](./rest_server)\n\nRest server uses nodejs as backend service framework. The api follows RESTful API specification.\n\n### [webportal](./webportal)\n\nCurrently openpaimarketplace webportal is used as a [pai webportal plugin](https://github.com/microsoft/pai/blob/master/docs/manual/cluster-admin/how-to-customize-cluster-by-plugins.md). It uses react as frontend framework, and builds with webpack bundler.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit <https://cla.opensource.microsoft.com>.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/Bing-COVID-19-Data",
  "language": null,
  "readme_contents": "# Bing COVID-19 data\r\n\r\n## FAQ\r\n\r\n### What data is available in the Bing COVID-19-Data GitHub repo?\r\nBing COVID-19 data includes confirmed, fatal, and recovered cases from all regions, updated daily in a .csv file. If there is an update or correction to already-published data, the data file will be updated accordingly. To ensure the stability of the data we share, it will be released with a 24-hour delay.\r\n\r\n### What are the sources of the data?\r\nWe collect data from multiple trusted, reliable sources, including the [World Health Organization (WHO)](https://www.who.int/emergencies/diseases/novel-coronavirus-2019), [Centers for Disease Control and Prevention (CDC)](https://www.cdc.gov/coronavirus/2019-ncov/index.html), national and state public health departments, [BNO News](https://bnonews.com/index.php/2020/04/the-latest-coronavirus-cases/), [24/7 Wall St.](https://247wallst.com/), and [Wikipedia](https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic).\r\n\r\n### How can I use this data?\r\nThis information is available strictly for educational and academic purposes, such as medical research, government agencies, and academic institutions. Data used or cited in publications should include an attribution to 'Bing COVID-19 Tracker' with a link to www.bing.com/covid.\r\n\r\n### Why is data missing or inconsistent for some regions\r\nSources don't always provide counts for all data points, especially recovered case counts. The '-' symbol indicates where data is unavailable. In the dataset published in GitHub, the data field will be blank where data is unavailable.\r\n\r\n### Where can I see the latest data?\r\nThe most current data available can be found on www.bing.com/covid and in the Bing COVID-19 widget. You can find more information about the Bing COVID-19 widget [here](https://www.bing.com/covid/dev#widget).\r\n \r\n### Why is COVID data different on every website?\r\nCOVID tracking data comes from a wide set of sources that update at different times and may not always align.\r\n\r\n### What about the Bing COVID-19 Widget?\r\nLearn more about the Bing COVID-19 widget [here](https://github.com/microsoft/COVID-19-Widget).\r\n\r\n#### Please reachout to BingCovid19DataReqs@microsoft.com for any questions or requests regarding the data. \r\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-sunburst",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-sunburst\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-sunburst.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-sunburst) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-sunburst/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-sunburst?branch=master)\n\nSunburst is a multilevel donut chart, used to visualize hierarchical data, depicted by concentric circles.\n\n![Sunburst chart screenshot](assets/screenshot.png)\n# Overview\nSunburst chart is used to visualize hierarchical data, depicted by concentric circles. The circle in the centre represents the root node, with the hierarchy moving outward from the center. A segment of the inner circle bears a hierarchical relationship to those segments of the outer circle which lie within the angular sweep of the parent segment.\n\nSee also [Sunburst chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380767&sourcecorrid=dfbfa3b3-75c3-497e-b2b9-ffd93aaca76f&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n\n\n### Sunburst has 2 bucket fields: Category, Values.\n1. Category - Field with a list of categories for each circle segment. It can accept many values.\n2. Values - Field with values for Category field. It can accept one value. Also this field is used for cross filtering with other visuals.\n\n![Sunburst screenshot 1](assets/Fields.png)\n\n# Selection\nYou can select any segment of the chart for data filtering. For cleaning of selection you should click outside to \"\u0421lear\" button on the right top corner of a visual.\n\n# Settings of Sunburst\n### Group\n- Font size: size of the label in the center of sunburst (see screenshot):\n![Sunburst screenshot 2](assets/settings1.png)\n\n- Show category label: show category label in the center of the visual\n![Sunburst screenshot 3](assets/settings2.png)\n- Show data labels: show text labels inside of arc segments of Sunburst\n![Sunburst screenshot 3](assets/settings3.png)\n- Category colors: to change colors of each category of the visual. Changing element color will also change its child elements color, but if you changed child element color before then it'll keep unchanged.\n![Sunburst screenshot 4](assets/settings4.png)\n\n### Tooltip\n- Display Units: tooltip numeric value format. Possible values: Auto, Thousands, Million, Billions, Trillions.\n- Decimal places: amount of decimal places to show.\n![Sunburst screenshot 5](assets/settings5.png)\n\n### Legend\n- Position: Legend location. Possible values: Top, Bottom, Left, Right, Top Center, Bottom Center, Left Center, Right Center. \n- Title: switch on/off the legend Title.\n- Legend Name: title caption.\n- Color: font color of the legend values.\n- Text Size: font size of legend values.\n![Sunburst screenshot 6](assets/settings6.png)"
 },
 {
  "repo": "microsoft/devops-project-samples",
  "language": "JavaScript",
  "readme_contents": "\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/FASTER",
  "language": "C#",
  "readme_contents": "<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/microsoft/FASTER/master/docs/assets/images/faster-logo.png\" alt=\"FASTER logo\" width=\"600px\" />\n</p>\n  \n[![NuGet](https://img.shields.io/nuget/v/Microsoft.FASTER.Core.svg)](https://www.nuget.org/packages/Microsoft.FASTER.Core/)\n[![Build Status](https://dev.azure.com/ms/FASTER/_apis/build/status/Microsoft.FASTER)](https://dev.azure.com/ms/FASTER/_build/latest?definitionId=8)\n[![Gitter](https://badges.gitter.im/Microsoft/FASTER.svg)](https://gitter.im/Microsoft/FASTER?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n# Introduction\n\nManaging large application state easily, resiliently, and with high performance is one of the hardest\nproblems in the cloud today. The FASTER project offers two artifacts to help tackle this problem.\n\n* **FASTER Log** is a high-performance concurrent persistent recoverable log, iterator, and random \nreader library in C#. It supports very frequent commit operations at low latency, and can quickly saturate \ndisk bandwidth. It supports both sync and async interfaces, handles disk errors, and supports checksums.\n\n* **FASTER KV** is a concurrent key-value store + cache (available in C# and C++) that is designed for point \nlookups and heavy updates. FASTER supports data larger than memory, by leveraging fast external \nstorage (local or cloud). It also supports consistent recovery using a fast non-blocking checkpointing technique \nthat lets applications trade-off performance for commit latency.\n\nBoth FASTER KV and FASTER Log offer orders-of-magnitude higher performance than comparable solutions, on standard\nworkloads. Start learning about FASTER, its unique capabilities, and how to get started at our official website:\n\n[aka.ms/FASTER](https://aka.ms/FASTER)\n\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/antares",
  "language": "C++",
  "readme_contents": "## What is Antares:\n\n**Antares** is an automatic engine to generate multi-platform kernels with optimization for ***DNN developers*** (targeting to backends like CUDA/ROCm/CPU/DirectX12/Graphcore/OneAPI/..). It is also a framework for ***Hardware developers*** to extend new backends/hareware quickly and easily. Antares provides IR that follows \"_One Language Syntax for All Platforms_\", and general-purpose device access APIs that hide the differences of not only DNN description but also device mapping.\n\n1. [Features](#about-antares-features)\n    - Backend Extension\n    - Effective Auto Tuning\n    - Einsum-based Antares IR\n    - Framework JIT Extension (Op Maker Plugin for Pytorch/Tensorflow/Tensorflow2)\n\n2. [How to Use Antares](#how-to-use-antares)\n    - **Senario-1:** Quick Start for Developers that Use Antares to Tune Operator/Sub-graph in Foreground Terminal\n    - **Senario-2:** Quick Start for Developers that Use Antares to Extend Operator/Sub-graph in Pytorch/Tensorflow\n\n3. [Antares Pre-dependencies for Different Backends](#antares-predependencies--for-different-backends)\n    - **Linux-based:** cuda, rocm, mcpu, scpu, gc, sycl_intel, sycl_cuda, ocl_amdgpu, ocl_nvidia, ocl_android, ..\n    - **Windows-based:** cuda_win64, rocm_win64, hlsl_win64, ..\n\n4. [About Microsft Open Source](#about-microsft-open-source)\n\n## About Antares Features:\n\n#### a. Backend Extension\n\nThe current version of Antares supports code generation for the following backends (in orange blocks) and devices (in black blocks):\n\n![](images/antares-backends.svg)\n\n#### b. Effective Auto Tuning\n\nAuto tuning by Antares contributes to not only much less tuning time, but also equivalent or better performance for Intra-op/Inter-op execution (against TVM Ansor).\n\n![](images/tuning-perf.svg)\n\n#### c. Einsum-based Antares IR\n\n- Antares IR is the frontend of both kernel generation and automatic optimization.\n- The syntax of Antares IR is slim to describe most MLP/CNN/RNN/LSTM/Transformer based models like MNIST/ResNet/BERT/GPT/..\n\n\u2003\u2003**E.g. The following computation logic describes a layer of standard BERT transformer:**\n\n``` sh\n  merged_layer_local[R, B, S1, N1, H1] +=! input_tensor[B, S1, N, H] * qkv_weight[R, N, H, N1, H1];\n  merged_layer_trans[R, B, N1, S1, H1] = merged_layer_local[R, B, S1, N1, H1] + qkv_bias[R, N1, H1];\n  attention_scores[B, N1, S1, S2] +=! merged_layer_trans[0, B, N1, S1, H1] * merged_layer_trans[1, B, N1, S2, H1] / const({H}).cast(`float32`);\n    softmax_1_temp0[B, N1] >=! attention_scores[B, N1, S1, S2];\n    softmax_1_temp1[B, N1] +=! (attention_scores[B, N1, S1, S2] - softmax_1_temp0[B, N1]).call(`exp`);\n  attention_probs[B, N1, S1, S2] = (attention_scores[B, N1, S1, S2] - softmax_1_temp0[B, N1]).call(`exp`) / softmax_1_temp1[B, N1];\n  ... ...\n  layer_norm_2_src[B, S1, N2, H2] = layer_output[B, S1, N2, H2] + attention_output_norm[B, S1, N2, H2];\n    layer_norm_2_temp0[B, S1] += layer_norm_2_src[B, S1, N2, H2];\n    layer_norm_2_temp1[B, S1] += layer_norm_2_src[B, S1, N2, H2] * layer_norm_2_src[B, S1, N2, H2];\n  layer_output_norm[B, S1, N2, H2] = (layer_norm_2_src[B, S1, N2, H2] * {N * H} - layer_norm_2_temp0[B, S1]) * (layer_norm_2_temp0[B, S1] * {N * H} - layer_norm_2_temp1[B, S1] * layer_norm_2_temp1[B, S1]).call(`max`, [1e-8]).call(`rsqrt`);\n```\nFor more IR usage or examples, please follow documentation here: [Antares IR & Examples](AntaresIR.md)\n\n#### d. Pytorch/Tensorflow/Tensorflow2 Op Maker (JIT Plugin)\n\u2003\u2003Antares provides JIT plugin for Pytorch/Tensorflow/Tensorflow2 to help frameworks to easily extend new operators, e.g.:\n\n```py\n# Tensorflow/Tensorflow2 Example:\nop = antares.make_op(ir='dot_0[N, M] +=! data[N, K] * weight[K, M]', feed_dict={'data': x, 'weight': y}).emit()\nresult_1 = sess.run(op)\nprint('The custom result_1 is:\\n%s' % result_1)\nresult_2 = sess.run(tf.add(op, op))\nprint('The custom result_2 is:\\n%s' % result_2)  \n\n# Pytorch Example:\ncustom_op = CustomOp(ir='dot_0[N, M] +=! data[N, K] * weight[K, M]', feed_dict={'data': x, 'weight': y}).to(device, dtype).emit()\nresult = custom_op()\nprint('The custom result is:', result)\n```\nFor complete programs, please follow examples here: [Antares Examples for Pytorch](frameworks/pytorch/examples) and [Antares Examples for TF/TF2](frameworks/tensorflow/examples)\n\n## How to Use Antares?\n\n### Senario-1: Quick Start for Developers that Use Antares to Tune Operator/Sub-graph in Foreground Terminal:\n\n- Step-1 (Recommend for User with Root): Prepare Environment for Docker Mode\n```sh\n# Setup Package dependencies\nsudo apt install docker.io\n\n# Get Antares\ngit clone https://github.com/microsoft/antares --branch v0.2.x\ncd antares/\n\n# Set default backend type:\necho 'c-cuda' > backend.default\n\n# Build the environment with sudo (if this step failed, please go to \"Pre-dependencies\" section to check which \"backend-related dependencies\" are missing):\nsudo make\n```\n- Step-1 (Recommend for Non-root Users): Prepare Environment for Host Mode\n```sh\n# Ensure Package dependencies (Please ensure the following root-required dependencies has been installed.)\nsudo apt install git python3-pip g++ make g++-mingw-w64-x86-64\n\n# Get Antares\ngit clone https://github.com/microsoft/antares --branch v0.2.x\ncd antares/\n\n# Set default backend type:\necho 'c-cuda' > backend.default\n\n# Build the environment without sudo (if this step failed, please go to \"Pre-dependencies\" section to check which \"backend-related dependencies\" are missing):\nmake\n```\n\u2003\u2003All valid backends are listed in directory [antares/backends](backends)\n\n- Step-2: Tune a Specific Workload in Foreground\n\n```sh\n# Example-1: Run the following command in bash to tune MatMul (4096, 4096) x (4096, 4096) using 2000 trials:\nCOMMIT=force STEP=2000 COMPUTE_V1='- S = 4096; einstein_v2(input_dict={\"input0\": {\"dtype\": \"float32\", \"shape\": [S, S]}, \"input1\": {\"dtype\": \"float32\", \"shape\": [S, S]}}, exprss=\"output0[N, M] +=! input0[N, K] * input1[K, M]\")' make\n\n# Example-2: Run the following command in bash to tune MNIST-inference using 5000 trials:\nCOMMIT=force STEP=5000 COMPUTE_V1='- einstein_v2(input_dict={\"data\": {\"dtype\": \"float32\", \"shape\": [64, 784]}, \"weight_0\": {\"dtype\": \"float32\", \"shape\": [784, 512]}, \"weight_1\": {\"dtype\": \"float32\", \"shape\": [512, 512]}, \"weight_2\": {\"dtype\": \"float32\", \"shape\": [512, 10]}, \"bias_0\": {\"dtype\": \"float32\", \"shape\": [512]}, \"bias_1\": {\"dtype\": \"float32\", \"shape\": [512]}, \"bias_2\": {\"dtype\": \"float32\", \"shape\": [10]}}, extra_outputs=[], exprss=\"data_0[N, M] +=!  data[N, K] * weight_0[K, M];   data_1[N, K] =   (data_0[N, K] + bias_0[K]).call(`max`, [0.0]);   data_2[N, M] +=!  data_1[N, K] * weight_1[K, M];   data_3[N, K] =   (data_2[N, K] + bias_1[K]).call(`max`, [0.0]);   data_4[N, M] +=!  data_3[N, K] * weight_2[K, M];   data_5[N, K] =   (data_4[N, K] + bias_2[K]);\")' make\n\n```\n\u2003\u2003Apart from detailed reporting logs during the tuning procedure, the best kernel record will be saved to directory [antares/codehub](codehub). If you don't want to create/overwrite existing kernel record in codehub, environment variable `COMMIT=force` in the tuning command can be removed.\n\n### Senario-2: Quick Start for Developers that Use Antares to Extend Operator/Sub-graph in Pytorch/Tensorflow (only for CUDA & ROCm backend currently):\n\n- Step-1: Prepare Environment\n\n  You need to follow `Step-1` from Senario-1 to finish environment preparation beforehand. This prevents many environmental issues when walking to the next step.\n\n- Step-2: Set up a corresponding TF/TF2/Pytorch version that matches your CUDA/ROCm driver version. (**If you have installed TF/TF2/Pytorch, please just ignore this step**)\n\n  Here we provide several prebuilt package sources that match different environment requirements:\n\n        For Tensorflow 1.x & 2.x: Recommended Packages (tested in Ubuntu 20.04):\n        #   Tensorflow-1 for NVIDIA CUDA 10.0:\n        python3 -m pip install --upgrade pip && python3 -m pip install tensorflow-gpu==1.15.4\n        #   Tensorflow-1 for NVIDIA CUDA 11.0:\n        python3 -m pip install --upgrade pip && python3 -m pip install https://github.com/ghostplant/tensorflow-wheel-collections/releases/download/cuda-11/tensorflow_gpu-1.15.4_cuda11+nv-cp38-cp38-linux_x86_64.whl\n        #   Tensorflow-1 for AMD ROCm 4.0:\n        python3 -m pip install tensorflow-rocm==1.15.9\n\n        #   Tensorflow-2 for NVIDIA CUDA 11.0:\n        python3 -m pip install --upgrade pip && python3 -m pip install tensorflow-gpu==2.4.0\n        #   Tensorflow-2 for AMD ROCm 4.0:\n        python3 -m pip install tensorflow-rocm==2.4.0\n\n        For Pytorch 1.x: Recommended Packages (tested in Ubuntu 20.04):\n        #   Pytorch for NVIDIA CUDA 10.0:\n        python3 -m pip install torch==1.5.0 torchvision==0.6.0 -f https://download.pytorch.org/whl/torch_stable.html\n        #   Pytorch for NVIDIA CUDA 11.0:\n        python3 -m pip install torch===1.7.1+cu110 torchvision===0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n        #   Pytorch for AMD ROCm 4.0:\n        python3 -m pip install torch torchvision -f https://download.pytorch.org/whl/rocm4.0.1/torch_stable.html\n\n- Step-4: Install JIT Plugin Client and Run Examples\n\n    ```sh\n    # If using Pytorch, set up JIT Plugin for Pytorch:\n    sudo python3 ./frameworks/pytorch/setup.py\n\n    # If using Tensorflow, set up JIT Plugin for Tensorflow/Tensorflow2:\n    sudo python3 ./frameworks/tensorflow/setup.py\n\n    # Set the path of Antares root directory:\n    export ANTARES_ROOT=\"(..clone path to antares..)/\"\n\n    # Test Examples for Pytorch:\n    cd ./frameworks/pytorch/examples\n    ./1_hello_world.py\n\n    # Test Examples for Tensorflow:\n    cd ./frameworks/tensorflow/examples\n    ./1_hello_world.py\n    ```\n\u2003\u2003More examples here: [Antares Examples for Pytorch](frameworks/pytorch/examples) and [Antares Examples for TF/TF2](frameworks/tensorflow/examples)\n\n## Antares Predependencies  for Different Backends:\n\nBefore running `make` command in antares root directory, you need to ensure the corresponding backend driver is installed correctly.\n\n- Predependencies for backend `c-cuda`, `c-sycl_cuda`:\n\n    `Requirement: Ubuntu >= 18.04`\n\n    `Requirement: Install NVIDIA CUDA toolkit (>= 10.0) on Host OS`\n\n    `Requirement: docker`\n\n- Predependencies for backend `c-ocl_nvidia`:\n\n    `Requirement: Ubuntu >= 18.04`\n\n    `Requirement: Install NVIDIA CUDA toolkit (>= 10.0) to Host OS`\n\n    `Requirement: run bash command \"make install_host\" in antares root directory beforehand`\n\n- Predependencies for backend `c-ocl_android`:\n\n    `Requirement: Ubuntu >= 18.04`\n\n    `Requirement: Install package \"adb\", connect to rooted Android device and ensure command \"adb shell su -c 'ls /sdcard'\" works`\n\n    `Requirement: run bash command \"make install_host\" in antares root directory beforehand`\n\n- Predependencies for backend `c-rocm`, `c-ocl_amdgpu`:\n\n    `Requirement: Ubuntu >= 18.04`\n\n    `Requirement: Install AMD ROCm (>= 4.0) package \"rock-dkms\" & \"rock-dkms-firmware\" from repo http://repo.radeon.com/rocm/apt/debian to Host OS`\n\n    `Requirement: docker`\n\n- Predependencies for backend `c-ipu`:\n\n    `Requirement: Ubuntu >= 18.04`\n\n    `Requirement: Install Poplar SDK to Host OS, ensure \"popc\" command exists in system PATH`\n\n    `Requirement: run bash command \"make install_host\" in antares root directory beforehand`\n\n- Predependencies for backend `c-scpu`, `c-mcpu`, `c-sycl_intel`:\n\n    `Requirement: Ubuntu >= 18.04`\n\n    `Requirement: docker`\n\n- Predependencies for backend `c-hlsl_win64`, `c-hlsl_xbox`:\n\n    `Requirement: Windows 10 64 bit (>= 2004), run \"dxdiag.exe\" to ensure Direct3D 12.0 Accleration is enabled`\n\n    `Requirement: Windows Subsystem Linux 1.0` [How to Install WSL 1.0](https://docs.microsoft.com/en-us/windows/wsl/install-win10)\n\n    `Requirement: GIT clones antares repo inside WSL environment, and the path of antares directory should be **visible to Windows**, (e.g. \"/../c/Users/me/Desktop/antares\" would be OK, but \"/home/me/antares\" won't).`\n\n    `Requirement: run bash command \"make install_host\" in antares root directory beforehand`\n\n- Predependencies for backend `c-rocm_win64`:\n\n    `Requirement: Windows 10 64 bit (>= 2004)`\n\n    `Requirement: Windows Subsystem Linux 1.0` [How to Install WSL 1.0](https://docs.microsoft.com/en-us/windows/wsl/install-win10)\n\n    `Requirement: Install Official AMD GPU driver (release version >= 2020.11).` Ensure `C:\\Windows\\System32\\amdhip64.dll` exists after installation.\n\n    `Requirement: GIT clones antares repo inside WSL environment, and the path of antares directory should be **visible to Windows**, (e.g. \"/../c/Users/me/Desktop/antares\" would be OK, but \"/home/me/antares\" won't).`\n\n    `Requirement: run bash command \"make install_host\" in antares root directory beforehand`\n\n- Predependencies for backend `c-cuda_win64`:\n\n    `Requirement: Windows 10 64 bit (>= 2004)`\n\n    `Requirement: Windows Subsystem Linux 1.0` [How to Install WSL 1.0](https://docs.microsoft.com/en-us/windows/wsl/install-win10)\n\n    `Requirement: Install Official NVIDIA CUDA driver (>= 10.0).` Ensure `C:\\Windows\\System32\\nvcuda.dll` exists after installation.\n\n    `Requirement: GIT clones antares repo inside WSL environment, and the path of antares directory should be **visible to Windows**, (e.g. \"/../c/Users/me/Desktop/antares\" would be OK, but \"/home/me/antares\" won't).`\n\n    `Requirement: run bash command \"make install_host\" in antares root directory beforehand`\n\n## Current Support Table:\n\n|       | HIP-C(c-rocm/c-rocm_win64) | CUDA(c-cuda/c-cuda_win64) | CPU(c-mcpu/c-scpu) | DirectX12(c-hlsl_win64) | Graphcore(c-ipu) | Intel OneAPI(c-sycl_intel) | Codeplay DPCPP (c-sycl_cuda) |\n|---|---|---|---|---|---|---|---|\n| Deploy Environment | Linux/WSL1 | Linux | Linux | WSL1 | Linux | Linux |   |\n| Target Device | AMDGPU | NVGPU | Generic CPU | Generic Graphic Card | IPU Device | Intel CPU/HD Graphic/FPGA |  NVGPU |\n| Global schedules  | Y | Y | Y | Y | Y | Y | Y |\n| Local schedules   | Y | Y | Y | Y |   | Y | Y |\n| Head fusion       | Y | Y | Y | Y | Y | Y | Y |\n| Tail fusion       | Y | Y |   | Y |   |   | Y |\n| Evaluator         | Y | Y | Y | Y | Y | Y | Y |\n| Tensorflow Plugin | Y | Y | Y (intel-tensorflow) |   |   |   |   |\n| Pytorch Plugin    | Y | Y | Y |   |   |   |   |\n| Multi Kernel Eval | Y | Y | Y | Y |   | Y | Y |\n\n## About Microsft Open Source\nFor more information about Microsoft Open Source Policy, please see [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct)\n\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-mekkochart",
  "language": "TypeScript",
  "readme_contents": "# powerbi-visuals-mekkochart\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-mekkochart.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-mekkochart) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-mekkochart/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-mekkochart?branch=master) \n[![Build Status](https://dev.azure.com/customvisuals/public/_apis/build/status/Microsoft.powerbi-visuals-chord)](https://dev.azure.com/customvisuals/public/_build/latest?definitionId=8)\n\n\nA mix of 100% stacked column chart and 100% stacked bar chart combined into one view\n\n![Mekko chart screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680589/Asset_694cc686-1c97-4063-b1e1-a67a2f57fab7/MekkoChartscreenshot1.png)\n\n# Overview\n\nSince it captures two dimensions in one chart, you can quickly spot the large segments as well the ones that are underrepresented in one quick glance. You can either use the same measure for the column height and width or use different ones depending on your need.\nSimilar to a treemap, the dimensional values are represented by the length and width of each rectangle. The width of a column is proportional to the total value of the column.\nSegmentation and Pattern analysis are a big part of business analysis and with traditional charts you need to piece multiple individual items together in your mental map to draw conclusions. For dealing with such complex business analysis involving multiple variables/dimensions, the iconic marimekko design is very appealing and the Mekko chart makes it super easy to achieve this in Power BI.\nThe Mekko chart visual also allows you to control the legends, data colors, and data labels for a truly customized presentation.\n\nSee also [Mekko chart at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380785&sourcecorrid=848a7fc8-787d-427c-9364-34c8c9204179&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)"
 },
 {
  "repo": "microsoft/data-protection-mapping-project",
  "language": "TypeScript",
  "readme_contents": "Copyright (c) Data Protection Mapping Project. All rights reserved.\nLicensed under the MIT License.\n\n## Data Protection/Privacy Mapping Project Mission\nThe Data Protection/Privacy Mapping Project (the \u201cProject\u201d) facilitates consistent global comprehension and implementation of data protection with an open source mapping between ISO/IEC 27701 and global data protection and/or privacy laws and regulations.\n### Principles\n* Neutral \u2013 The project is not for profit and carries no affiliation or company-driven focus. \n* Open \u2013 The data, infrastructure, and processes are available to all\n* Consensus \u2013 Mapping data can at times be subjective, but consensus can be achieved through engagements with stakeholders\n* Transparent \u2013 The operations and decision-making process for this project is transparent\n### Scope\nThe Project aims to make the link between ISO/IEC 27001 and data protection regulatory requirements comprehensible to privacy professionals. It seeks to continuously improve and expand the data map between ISO/IEC 27701 and data protection laws and regulations, especially that of regulatory requirements. Initial mapping data is based on existing mapping between ISO/IEC 27701 and GDPR, and additional mappings were prepared by outside counsel for Microsoft between ISO/IEC 27701 and regulations from Australia, California, Canada, Brazil, Hong Kong, Singapore, South Korea, and Turkey.\n### What?\nCrowdsourcing the mapping between ISO/IEC 27701 controls and various data protection requirements.\n### Why?\nData Protection regulatory requirements vary from jurisdiction to jurisdiction. With today\u2019s global economy and shifting technology landscape, it is becoming increasingly difficult for organizations to manage data protection accountability efficiently and effectively. This mapping project leverages the universal data protection controls outlined by ISO/IEC 27701 to help organizations reconcile various laws and regulations with the common controls. Certification bodies, internal auditors and other stakeholders can then review the implementation of these controls to confirm accountability for the mapped regulations. Establishing a common understanding of the relationship between the ISO/IEC 27701 and data protection laws and regulations enables consistent interpretations and shared accountability among organizations globally. This can help strengthen data protection, technological solutions, and commerce.\n### Microsoft's Role\nMicrosoft initiated the Project by donating the initial data visualization code and regulatory mappings with ISO/IEC 27701 except the mapping with GDPR. The intention of publishing the content to open source is to stimulate international cooperation within the global privacy community and to improve the reliability and consistency of privacy practice. Microsoft will initially act as one of the Data Curators and Code Committers while the Project takes shape. Microsoft plans to transition away from the initial role of Data Curator as the Project matures. As part of Microsoft's contribution to the privacy community, the app is freely deployed on Microsoft services.\n### How?\nThe Project encourages mapping contributions from data protection experts. The Data Curators will assess whether to accept, reject, or amend those contributions. Contributions that are accepted (with or without amendments) are then posted publicly with attribution for the public to review and consume. Contributions that are rejected are published separately with explanation from data curators within the site for future reference.\n### Future efforts could focus on further topics such as the following examples:\n*\tMapping Quality: Improve comprehensiveness, integrity and accuracy of the mapping\n*\tMapping Scope: Add new mappings\n*\tMultilingual Capability: Enable multi-language capability both for mapping and consumption of data\n*\tImprove User Interface: Include attribution of mapping source and time stamp\n*\tAdditional Data Visualization and Analytics\n*\tSimplify Data Export\nThe ordering and completion of this projected work and effort applied will depend entirely on the community and their interests.\n## Governance\n### Processes\nThe project undertakes four main operations in support of the stated goals and scope. Those processes are listed here in rough execution order:\n#### Consume\nThe general expectation is that most users for the Project will only consume the data without making contribution. Users may use and download all or part of the mapping data for their own analysis under MIT license. Please note that the mapping data does not expose the full content of ISO/IEC 27701, which is the heart of the Project. Proper consumption of the project content requires acquisition of the standard from ISO, IEC, national standard bodies, such as BSI, ANSI, JISC, or ABNT, or other authorized sellers.\n#### Value-added projects\nUsers are encouraged to create derivative, value-added projects from the mapping data for commercial purposes under the licensing terms of the Project. Users shall cite and acknowledge the Project. As the mapping data will evolve over time, time stamp or continuous data synchronization may be necessary. Commercial use of the mapping content shall respect the copyrights of ISO/IEC.\n#### Curate\nThe curation process is open and transparent. Data Curators work on data contributed by the data protection community to validate presented information. All deliberations, discoveries and discussions are recorded and made available for community inspection.\nInitially this workflow will happen in one or more GitHub repositories using standard Pull Request workflows on human-readable and diff-able curation artifacts. The project should develop additional tools to supplement or supplant this flow to better support users who are not technically savvy but will always ensure full transparency.\nAt least initially, all curated data must be signed off by two or more Data Curators after a due consideration of data quality. This is in the interest of working through thought and mechanical processes and developing a common understanding of the data and determining what is admissible. Disagreement in what is admissible should be resolved through consensus among Data Curators. While the voting process can be used to resolve such dispute, it is intended to be a procedure of last resort.\n#### Contribute\nContribution from the data protection community is the most important activity for this project. All contributions are welcomed. Contributions may include correction or improvement of existing mappings, new mappings, and code contribution. Due to the nature and spirit of open source projects, all contributors must be either individually identifiable or representing an organization.\n### Roles\n#### Data Curator\nA Data Curator is akin to a project maintainer or committer in typical open source projects. Data Curators have \u201cwrite\u201d permissions to the curation repository and are ultimately responsible for admitting data to the data repository. A Data Curator is responsible for data quality control, integrity and accuracy. The role requires reasonable domain context to enable issue identification and resolution. The role also requires technical expertise in running the necessary tools used to manage the project. Each curator must be, and be seen to be, neutral and impartial. \nNew Data Curators are nominated and approved by existing curators based on their merits and prior contributions. The role relates to an individual expert, an organization or a position in an organization. Under no circumstances, shall a Data Curator be held responsible for any errors or other flaws in the data merged into the service.\nThe current Data Curators are: Lanx Goh, Eric Lachaud, and Alex Li on behalf of Microsoft\n#### Data Contributor\nA Data Contributor for the Project is like a contributor on any other open source project \u2013 they identify bugs or improvements, fork the repo and contribute a pull request with their changes. For data contributors, this could be a small change (e.g., spelling correction or URL link submission), a substantive change (e.g., mapping correction), or wholesale data mapping (e.g., providing data mapping for additional regulations). Contributors should, as with any other open source project, expect to substantiate the changes with background information and adequate explanation of correctness. Since most Contributors are unlikely to be knowledgeable users of GitHub, data contribution in the form of spreadsheet sent to the Data Curators will be accepted.\nA serial contributor of quality data or code is a candidate to become a curator or code committer.\n#### Consumer\nA Data Consumer accesses the curated data. They understand that the data is provided \u201cas-is\u201d with no guarantees or warranties as to (a) the correctness of the data or (b) suitability for any particular purpose. All data is fully qualified as to its origin and any clarifications made and it is up to the consumer to decide whether to use the data at their own risk.\n#### Code Committer\nWhile the Project is focused on data, the project initially contains a modest amount of code to enable data import and data visualization. Upon the initial release of the project, code committership and data curatorship roles are integrated. But it is recognized that there is a distinct skill set that is required for a Code Committer and a Data Curator. Separation of roles may develop as the project evolve.\nThe current Code Committer is Alex Li on behalf of Microsoft\n#### Removal from role\nIn the unlikely event that a committer or curator becomes disruptive or falls inactive for an extended period of time, they may be removed from the role through an absolute majority vote of the remaining set of committers and curators. Committers and curators may resign at any time from the Project. Advance notice in case of resignation is encouraged to identify replacement. \n### Voting\nMost decisions within the project can be done through informal consensus and recorded in the appropriate public record. When a formal decision is required, for example, when electing committers/curators, a vote is held using the following process:\n\u2022\tA topic for voting is tabled by a Data Curator or Code Committer by notifying all other Curators and Committers.\n\u2022\tOnce tabled, Data Curators may vote during an open voting period lasting no less than one working week. Voting will occur on an agreed to, mutually convenient, and open medium (e.g., email, GitHub issue, etc.)\n\u2022\tA minimum of two positive (+1) votes and no negative (-1) votes carries the topic. Note that negative votes must be substantiated.\n\u2022\tAbstention (0) votes do not affect the outcome.\n\n### Running the app\n\nYou can access the app live at the following URL: https://dataprotectionmapping.z21.web.core.windows.net/ or https://aka.ms/dpmap.\n\n### Building the code\n\n#### Prerequisites\n\nPlease ensure that you have at least the **minimum** recommended versions\n\n-   Node >= 9.0.0 \n\n#### 1. Clone the repository\n\n-   Clone the repository using the following commands:\n    ```bash\n    git clone https://github.com/microsoft/data-protection-mapping-project\n    ```\n-   Select the created directory\n    ```bash\n    cd data-protection-mapping-project\n    ```\n\n#### 2. Install packages\n\n-   Install the Angular CLI and the project dependency packages:\n\n    ```bash\n    npm install -g @angular/cli\n    npm install\n    ```\n\n#### 3. Build and run\n\n-   Run the dev server\n    ```bash\n    ng serve\n    ```\n\n#### 4. Open app in web browser\n\n-   Navigate your browser to: \n\thttp://localhost:4200\n\n\n# MIT License\n\nCopyright <2020> Data Protection Mapping Project\n  \n  MIT License\n  \n  Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n  \n  The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n  \n  THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-ChicletSlicer",
  "language": "TypeScript",
  "readme_contents": "# PowerBI-visuals-ChicletSlicer\n[![Build Status](https://travis-ci.org/Microsoft/PowerBI-visuals-ChicletSlicer.svg?branch=master)](https://travis-ci.org/Microsoft/PowerBI-visuals-ChicletSlicer) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/PowerBI-visuals-ChicletSlicer/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/PowerBI-visuals-ChicletSlicer?branch=master)\n\n> Use this slicer to display image and/or text buttons that act as an in-canvas filter. Define additional properties for the layout & selection to customize this slicer to meet your specific needs\n\n![ChicletSlicer screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680551/Asset_95650974-8e44-40cf-b041-fe64ca49a6e0/ChicletSlicerscreenshot2.png)\n\n# Overview\n\nThe Chiclet Slicer was inspired by the great slicer control found in Excel since 2010, but with much greater customization options.\nChiclet are a slicers made of buttons, that can also be arranged horizontally for a very efficient real estate use, or arranged as a matrix for a super compact form.\nChiclet slicer also supports cross highlighting.\nThat's not all - they can even contain images!\n\nSee also [Chiclet Slicer at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380756&sourcecorrid=1094fb73-f014-4f7a-accf-65142c8316af&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n\nChicletSlicer has 3 bucket fields: Category, Values and Images.\n1. Category - Field with a list of categories for each \"chiclet\" item. String values\n2. Values - Field with values for Category field. This field use just for cross filtering with other visuals.\n3. Image - Field with a list of images for each \"chiclet\" item. Values of this field can be presented in \"base64 image\" format or it can be just external link to image.\n\n# Selection\nYou can select any chiclet item for data filtering and also you can use multi selection. For cleaning of selection you should click to \"\u0421lear\" button on the right top corner of a visual.\n\n# Search\nYou can filter a list of chiclets items by category using string search. For activation of search field you should click to \"search\" in options of the visual. After that you can input search string and data will be filtered immediately.\n\n# Settings of ChicletSlicer\n### General options\n- Orientation: An order of \"chiclets\" list building. Can be vertical or horizontal\n- Columns: Amount of ChicletSlicer columns.\n- Rows: Amount of ChicletSlicer rows.\n- Show disabled: Setting which regulate where will be displayed disabled chiclets items.\n  This setting has 3 selection values:\n  - Inplace: Disabled chiclets will be located in a their original positions.\n  - Bottom: Disabled chiclets will be located in a bottom of the list.\n  - Hide: Disabled chiclets will be hide from list.\n- Multiple selection:\n  - If this option is turned on you will be able to select chiclets without Ctrl button. (It will be usefull for multiple selection on mobile devices)\n  - If this option is turned off you have to use Ctrl button for multiple selection.\n- Forced selection: This setting forcibly select first item and doesn't allow to unselect any chiclet item\n\n### Chiclets options\n- Text size: Size of text for chiclet item.\n- Height: Height of chicklet item.\n- Width: Width of chiclet item.\n- Background: Background color of all ChicletSlicer.\n- Transparency: Transparency of ChicletSlicer background.\n- Selected Color: Background color of selected chiclet item.\n- Hover color: Text color when you hover to chiclet item.\n- Unselected color: Background color of unselected chicklet items.\n- Disabled color: Color of disabled chicklet item.\n- Outline color: Color for outline of chiclet item.\n- Outline weight: Thickness of chiclet item outline.\n- Text color: Color of chiclet item text.\n- Padding: Indent around chiclet item.\n- Outline style: Style of outline.\n  This settins has 3 selection values:\n  - Rounded: Round outline edges\n  - Cut: Semicircular outline edges\n  - Square: Square outline edges\n\n### Images options\n- Image split: Height of Image for chiclet item\n- Round: Shows image as rounded\n- Stretch image: Stretch image to full chiclet item width\n- Bottom image:\n  - If this option is turned on image will be in the bottom of chiclet item, under the text\n  - If this option is turned off image will be in the top of chiclet item, above the text"
 },
 {
  "repo": "microsoft/vscode-python-devicesimulator",
  "language": "TypeScript",
  "readme_contents": "# Device Simulator Express, a Microsoft Garage project\r\n\r\n<a href='https://www.python.org/downloads/'><img src='https://img.shields.io/badge/Python-3.7%2B-blue.svg' alt='Python versions: 3.7+' /></a> <img src='https://img.shields.io/badge/VS%20Code-v1.43+-blue' alt='VS Code version 1.43'> <img src='https://www.repostatus.org/badges/latest/active.svg' alt='Project Status: Active \u2013 The project has reached a stable, usable state and is being actively developed.' /> <a href='LICENSE'><img src='https://img.shields.io/badge/license-MIT-blue.svg' alt='License: We are using the MIT License'></a> <a href='CONTRIBUTING.md'><img src='https://img.shields.io/badge/PRs-Welcome-brightgreen.svg' alt='We are welcoming PRS!'></a> <img src='https://img.shields.io/badge/platform-win%20%7C%20osx-lightgrey.svg' alt='Platforms Supported: Windows, MacOSX'/>\r\n\r\n<a href='https://microsoftgarage.visualstudio.com/002806e2-ebaa-4672-9d2e-5fe5d29154ef/_boards/board/t/227906bb-31ac-4b07-8626-3d757754a616/Microsoft.RequirementCategory/'><img src='https://microsoftgarage.visualstudio.com/002806e2-ebaa-4672-9d2e-5fe5d29154ef/227906bb-31ac-4b07-8626-3d757754a616/_apis/work/boardbadge/73f82653-3da1-4a6f-bb79-c91c9eecec28' alt='Azure DevOps Board Badge' /></a>\r\n\r\nMake without limit! Device Simulator Express, a Microsoft Garage project, allows you to code microcontrollers without the hardware on hand! You can program your Adafruit Circuit Playground Express (CPX), your BBC micro:bit or the Adafruit CLUE! Test and debug your code on the device simulator and see the same\r\nresult when you plug in your actual microcontroller. Curious about the output of the device, the serial\r\nmonitor allows you to observe the device output.\r\n\r\n## Table of Contents\r\n  - [Devices we support](#devices-we-support)\r\n  - [Prerequisites](#prerequisites)\r\n  - [Adafruit Circuit Playground Express (CPX) Simulator](#adafruit-circuit-playground-express-cpx-simulator)\r\n    - [Features](#features)\r\n    - [Useful Links](#useful-links)\r\n    - [Keyboard Shortcuts](#keyboard-shortcuts)\r\n  - [BBC micro:bit Simulator](#bbc-microbit-simulator)\r\n    - [Features](#features-1)\r\n    - [Useful Links](#useful-links-1)\r\n    - [Keyboard Shortcuts](#keyboard-shortcuts-1)\r\n  - [Adafruit CLUE Simulator](#adafruit-clue-simulator)\r\n    - [Features](#features-2)\r\n    - [Useful Links](#useful-links-2)\r\n    - [Keyboard Shortcuts](#keyboard-shortcuts-2)\r\n  - [How to use](#how-to-use)\r\n    - [Commands](#commands)\r\n  - [Contribute](#contribute)\r\n  - [Provide feedback](#provide-feedback)\r\n  - [Privacy and Telemetry Notice](#privacy-and-telemetry-notice)\r\n  - [Third Party Notice](#third-party-notice)\r\n  - [Troubleshooting Tips](#troubleshooting-tips)\r\n  - [License](#license)\r\n  - [Notes](#notes)\r\n  \r\n## Devices we support\r\n\r\n-   [**Adafruit Circuit Playground Express (CPX)**](#adafruit-circuit-playground-express-cpx-simulator)\r\n\r\n    [<img alt='CircuitPlayground Express' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/cpx/cpx-img.png'>](#adafruit-circuit-playground-express-cpx-simulator)\r\n\r\n-   [**BBC micro:bit**](#bbc-microbit-simulator)\r\n\r\n    [<img alt='bbc micro:bit' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/microbit/microbit.png'>](#bbc-microbit-simulator)\r\n\r\n-   [**Adafruit CLUE**](#adafruit-clue-simulator)\r\n\r\n    [<img alt='Adafruit CLUE' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/clue/clue.png'>](#adafruit-clue-simulator)\r\n\r\n## Build Status\r\n\r\n| Branch  |                                                                                                                    Build Status                                                                                                                    |\r\n| :------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |\r\n| dev     |     [![Build Status](https://microsoftgarage.visualstudio.com/Intern%20GitHub/_apis/build/status/Adafruit/Pacifica-CI?branchName=dev)](https://microsoftgarage.visualstudio.com/Intern%20GitHub/_build/latest?definitionId=304&branchName=dev)     |\r\n| staging | [![Build Status](https://microsoftgarage.visualstudio.com/Intern%20GitHub/_apis/build/status/Adafruit/Pacifica-CI?branchName=staging)](https://microsoftgarage.visualstudio.com/Intern%20GitHub/_build/latest?definitionId=304&branchName=staging) |\r\n| master  |  [![Build Status](https://microsoftgarage.visualstudio.com/Intern%20GitHub/_apis/build/status/Adafruit/Pacifica-CI?branchName=master)](https://microsoftgarage.visualstudio.com/Intern%20GitHub/_build/latest?definitionId=304&branchName=master)  |\r\n\r\n## Prerequisites\r\n\r\nThe following dependencies are required to install before launching Device Simulator Express.  \r\nYou will be prompted to install the Python dependencies during the first use.\r\n\r\n-   _**[Visual Studio Code](https://code.visualstudio.com/)**_\r\n-   _**[Python 3.7+](https://www.python.org/downloads/)**_: Make sure you've added Python and pip to your PATH in your environment variables. (1)\r\n-   _**[Python VS Code extension](https://marketplace.visualstudio.com/items?itemName=ms-python.python)**_: This will be installed automatically from the marketplace when you install Device Simulator Express.\r\n\r\n## Adafruit Circuit Playground Express (CPX) Simulator\r\n\r\n### Features\r\n\r\n-   IntelliSense and syntax highlighting for CircuitPython code for the CPX library\r\n-   Template file generation\r\n-   Integrated Python Debugging for the Simulator\r\n-   Serial monitor (available on Windows and Mac only)\r\n-   Output panel for the simulator\r\n-   Deploy CircuitPython code to the physical device.\r\n-   Simulation of the CPX device, including:\r\n    -   Green LED\r\n    -   Red LED\r\n    -   Push Buttons A and B\r\n    -   Slider Switch\r\n    -   Speaker: Play .wav file\r\n    -   10 NeoPixels\r\n    -   Light sensor\r\n    -   Motion sensors\r\n    -   Acceleration detection\r\n    -   Device shake detection\r\n    -   Temperature sensor\r\n    -   7 Capacitive Touch sensors\r\n\r\nThe simulator supports most of the sensors on CPX except **IR transmitter & Receiver**, **Sound Sensor (microphone)**, **Speaker (Play Tone)** and the **\"tap\" on Motion Sensor**.\r\nThe code related to these sensors can still run on the actual CPX board and be deployed using Device Simulator Express.  \r\nAs we only support CPX library now, other libraries (i.e. simpleio) can\u2019t run on the simulator. But they will work on the actual device!\r\n\r\n### Useful Links\r\n\r\n-   Tutorials and Example Code for Adafruit CPX:\r\n    -   [Adafruit CPX library tutorial](https://learn.adafruit.com/circuitpython-made-easy-on-circuit-playground-express/circuit-playground-express-library)\r\n    -   [Adafruit CPX Examples on GitHub](https://github.com/adafruit/Adafruit_CircuitPython_CircuitPlayground/tree/master/examples)\r\n    -   [Adafruit CPX Guided Tour (Intro for the Hardware)](https://learn.adafruit.com/adafruit-circuit-playground-express/guided-tour)\r\n-   Format Adafruit CPX device:\r\n    -   [Tutorial for formatting Adafruit CPX for CircuitPython](https://learn.adafruit.com/welcome-to-circuitpython/installing-circuitpython)\r\n    -   [Download Firmware .uf2 file](https://learn.adafruit.com/adafruit-circuit-playground-express/circuitpython-quickstart)\r\n    -   [Download the latest version of the Adafruit CPX library](https://learn.adafruit.com/welcome-to-circuitpython/circuitpython-libraries)\r\n\r\n### Keyboard Shortcuts\r\n\r\nIn Device Simulator Express, you can use keyboard to interact with the device:\r\n\r\n-   Push Button: <kbd>A</kbd> for Button A, <kbd>B</kbd> for Button B, <kbd>C</kbd> for Buttons A & B\r\n-   Capacitive Touch Sensor: <kbd>Shift</kbd> + <kbd>1</kbd> ~ <kbd>7</kbd> for GPIO pins A1 - A7\r\n-   Slider Switch: <kbd>Shift</kbd> + <kbd>S</kbd>\r\n-   Refresh the simulator: <kbd>Shift</kbd> + <kbd>R</kbd>\r\n-   Run the simulator: <kbd>Shift</kbd> + <kbd>F</kbd>\r\n\r\n## BBC micro:bit Simulator\r\n\r\n### Features\r\n\r\n-   IntelliSense and syntax highlighting for MicroPython code for the micro:bit library\r\n-   Template file generation\r\n-   Integrated Python Debugging for the Simulator\r\n-   Deploy MicroPython code to the physical device\r\n-   Serial monitor (available on Windows and Mac only)\r\n-   Simulation of the micro:bit device, including:\r\n    -   25 LEDs\r\n    -   Push Buttons A and B\r\n    -   Light sensor\r\n    -   Motion sensors\r\n    -   Acceleration detection including gesture detection\r\n    -   Temperature sensor\r\n\r\n### Useful Links\r\n\r\n-   Tutorials and Example Code for BBC micro:bit:\r\n    -   [MicroPython documentation](https://microbit-micropython.readthedocs.io/en/latest/)\r\n    -   [BBC micro:bit examples on the official micro:bit website](https://microbit.org/projects/make-it-code-it/?filters=python)\r\n\r\n### Keyboard Shortcuts\r\n\r\n-   Push Button: <kbd>A</kbd> for Button A, <kbd>B</kbd> for Button B, <kbd>C</kbd> for Buttons A & B\r\n-   Refresh the simulator: <kbd>Shift</kbd> + <kbd>R</kbd>\r\n-   Run the simulator: <kbd>Shift</kbd> + <kbd>F</kbd>\r\n\r\n## Adafruit CLUE Simulator\r\n\r\n### Features\r\n\r\n-   IntelliSense and syntax highlighting for CircuitPython code for the following drivers and libraries:\r\n    -   `adafruit_clue`\r\n    -   `adafruit_slideshow`\r\n    -   `adafruit_display_shapes`\r\n    -   `adafruit_display_text`\r\n    -   `adafruit_bitmap_font`\r\n    -   `adafruit_fancyled`\r\n    -   `neopixel`\r\n    -   `displayio`\r\n-   Template file generation\r\n-   Integrated Python Debugging for the Simulator\r\n-   Deploy CircuitPython code to the physical device\r\n-   Serial monitor (available on Windows and Mac only)\r\n-   Simulation of the CLUE device, including:\r\n    -   240x240 color screen\r\n    -   Push Buttons A and B\r\n    -   Sensors for:\r\n        -   Temperature\r\n        -   Light\r\n        -   Color\r\n        -   Acceleration\r\n        -   Humidity\r\n        -   Pressure\r\n        -   Proximity\r\n        -   Gestures\r\n        -   Gyro\r\n        -   Magnetic Field\r\n\r\n### Useful Links\r\n\r\n-   Tutorials and Example Code for Adafruit CLUE:\r\n    -   [Adafruit CLUE Overview](https://learn.adafruit.com/adafruit-clue)\r\n    -   [Adafruit CLUE Examples on GitHub](https://github.com/adafruit/Adafruit_CircuitPython_CLUE/tree/master/examples)\r\n\r\n### Keyboard Shortcuts\r\n\r\n-   Push Button: <kbd>A</kbd> for Button A, <kbd>B</kbd> for Button B, <kbd>C</kbd> for Buttons A & B\r\n-   Refresh the simulator: <kbd>Shift</kbd> + <kbd>R</kbd>\r\n-   Run the simulator: <kbd>Shift</kbd> + <kbd>F</kbd>\r\n\r\n## How to use\r\n\r\nTo use Device Simulator Express, install the extension from the marketplace and reload VS Code.\r\n\r\nTo access many of the commands, you need to open the command palette. This can be done with <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> for Windows and Linux / <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> for Mac. It can also be accessed from the toolbar by going to `View -> Command Palette`.\r\n\r\n### I. Take a look at the \"Device Simulator Express: Getting Started\" Command.\r\n\r\n1. Type in `\"Device Simulator Express: Getting Started\"` in the command palette (<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> / <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> to open the command palette).\r\n2. Choose the the device you want to play with from the dropdown.\r\n3. Read, copy and learn some of the things you can do with the simulator!\r\n\r\n<img alt='Getting Started' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/getting_started.png'>\r\n\r\n### II. Start with the \"Device Simulator Express: New File\" Command.\r\n\r\n1. Type in `\"Device Simulator Express: New File\"` in the command palette (<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> / <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> to open the command palette).\r\n2. Select the device you want to use.\r\n3. Name and save your file somewhere, and we\u2019re good to go!\r\n4. Start with some examples: you can find examples files and tutorials inside the comments at the top of the file.\r\n\r\n<img alt='\"New File\" animation' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/new_file.gif'>\r\n\r\n### III. Start from an existing Python file.\r\n\r\n1. Open the folder or your .py file in Visual Studio Code.\r\n2. Run `Device Simulator Express: Open Simulator` from the command palette or icon in the editor toolbar.\r\n3. Select the device you want to use.\r\n\r\n### IV. Run your code on the simulator.\r\n\r\n1. Run `Run Simulator` from the command palette or use the `Play` button on the simulator webview.\r\n\r\n<img alt='How to run the simulator animation' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/run.gif'>\r\n\r\n### V. Deploy your code to the physical device\r\n\r\nBefore deploying the Python code to your CPX device, you need to format your device by following these tutorials:\r\n\r\n-   _For the CPX_:\r\n\r\n    -   Download the firmware with the .uf2 file (link: https://learn.adafruit.com/adafruit-circuit-playground-express/circuitpython-quickstart).\r\n    -   Download the lastest versions of the cpx libraries (link: https://learn.adafruit.com/welcome-to-circuitpython/circuitpython-libraries).\r\n\r\n-   _For the micro:bit_:\r\n\r\n    -   Download the firmware with the .hex file (link: https://microbit.org/get-started/user-guide/firmware/).\r\n\r\n-   _For the CLUE_:\r\n    -   Download the latest versions of the cpx libraries and follow the instructions here (link:https://learn.adafruit.com/adafruit-clue/circuitpython).\r\n\r\n1. Plug in your device (make sure it\u2019s formatted properly already).\r\n2. Run the command `\"Device Simulator Express: Deploy to Device\"`.\r\n\r\n<img alt='Deploy to Device' src='https://raw.githubusercontent.com/microsoft/vscode-python-devicesimulator/dev/assets/readmeFiles/deploy.png'>\r\n\r\n### VI. Use the Serial Monitor for your device (available on Windows and Mac only)\r\n\r\n1. Plug in your device (make sure it\u2019s formatted properly already).\r\n2. Run the command `\"Device Simulator Express: Open Serial Monitor\"`.\r\n3. Select your baud rate for the serial port.\r\n4. The `print()` statements in your code will show in the output console.\r\n\r\n### VII. Debug your project on the simulator\r\n\r\n1. Add breakpoints in your code\r\n2. Press F5 to enter the debugging mode, and you can start debugging line by line!\r\n\r\n### Commands\r\n\r\nDevice Simulator Express provides several commands in the Command Palette (<kbd>F1</kbd> or <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> / <kbd>Cmd</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> for Mac OS) for working with \\*.py files:\r\n\r\n-   `Device Simulator Express: Getting Started`: Opens a page in VS Code that helps users get started with the extension. Here, users can browse through code that they can use to play with the simulators.\r\n-   `Device Simulator Express: Run Simulator`: Runs Python code on the simulator.\r\n-   `Device Simulator Express: New File`: Opens an unsaved .py file with template code, also opens the simulator for the selected device.\r\n-   `Device Simulator Express: Open Simulator`: Opens the simulator in the simulator window for the selected device\r\n-   `Device Simulator Express: Deploy to Device`: Copies the current file to the selected device.\r\n-   `Device Simulator Express: Open Serial Monitor`: Opens the serial monitor in the integrated output window.\r\n-   `Device Simulator Express: Close Serial Monitor`: Stops the serial monitor and releases the serial port.\r\n-   `Device Simulator Express: Change Baud Rate`: Changes the baud rate of the selected serial port. For Adafruit CPX, the default baud rate is 115200.\r\n-   `Device Simulator Express: Select Serial Port`: Changes the current serial port.\r\n\r\n## Contribute\r\n\r\n[See here for steps to run the extension locally.](https://github.com/microsoft/vscode-python-devicesimulator/blob/dev/docs/developers-setup.md)\r\n\r\n## Provide feedback\r\n\r\nTo add a review for our extension, please do so on the [Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-python.devicesimulatorexpress)\r\n\r\nTo report issues, provide feedback or requests, please use this link: [Provide Feedback](https://github.com/microsoft/vscode-python-devicesimulator/issues).  \r\nWe would love to hear from you about your experience to keep improving our project.\r\n\r\n## Privacy and Telemetry Notice\r\n\r\n### Data Collection\r\n\r\nThe software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described in the repository. There are also some features in the software that may enable you and Microsoft to collect data from users of your applications. If you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together with a copy of Microsoft's privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. You can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.\r\n\r\n### Disable Telemetry\r\n\r\nThe Microsoft Device Simulator Express Extension for Visual Studio Code collects usage\r\ndata and sends it to Microsoft to help improve our products and\r\nservices. Read our\r\n[privacy statement](https://privacy.microsoft.com/privacystatement) to\r\nlearn more. This extension respects the `telemetry.enableTelemetry`\r\nsetting which you can learn more about at\r\nhttps://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting.\r\n\r\nTo disable telemetry, follow these steps:\r\n\r\n1. Open **File** (Open **Code** on macOS)\r\n2. Select **Preferences**\r\n3. Select **Settings**\r\n4. Search for `telemetry`\r\n5. Uncheck the **Telemetry: Enable Telemetry** setting\r\n\r\n## Third Party Notice\r\n\r\nA `ThirdPartyNotices.txt` file is provided in the extension's source code listing the appropriate third-party notices.\r\n\r\n## Troubleshooting Tips\r\n\r\n-   The first time you install the extension, you'll need to execute the `run` command at least once in order to access auto-completion.\r\n-   While running a code file, if you get an error saying it can't find the file, make sure you've clicked on a valid Python code file before running it.\r\n-   To open the output panel again after closing it go to VS Code menu: `View -> Output`.\r\n-   If you try to deploy to the CPX while it's plugged in but you still get an error saying it cannot find the board, make sure your device is formatted correctly and that its name matches `CIRCUITPY`.\r\n-   If you can't get the Simulator communication working while debugging, try to open your `Settings` and check the port used under `\"Device Simulator Express: Debugger Server Port\"`. You can either change it (usually ports above 5000 should work) or try to free it, then start debugging again.\r\n-   When you are using the serial monitor, if you get some unusual error messages, unplug the device and reload the VS Code windows.\r\n-   If you're using Ubuntu and having some problems with setting up the environment, try reviewing [this article's](https://www.digitalocean.com/community/tutorials/how-to-install-python-3-and-set-up-a-local-programming-environment-on-ubuntu-16-04) \"Step 1\" section on how to set up Python 3 on Ubuntu 16.04. Then, ensure that you've run `sudo apt-get install -y python3-venv` to allow for virtual environment creation.\r\n\r\n## License\r\n\r\n    Device Simulator Express, a Microsoft Garage project\r\n\r\n    Copyright (c) Microsoft Corporation. All rights reserved.\r\n\r\n    MIT License\r\n\r\n    Permission is hereby granted, free of charge, to any person obtaining a copy\r\n    of this software and associated documentation files (the \"Software\"), to deal\r\n    in the Software without restriction, including without limitation the rights\r\n    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\r\n    copies of the Software, and to permit persons to whom the Software is\r\n    furnished to do so, subject to the following conditions:\r\n\r\n    The above copyright notice and this permission notice shall be included in all\r\n    copies or substantial portions of the Software.\r\n\r\n    THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\r\n    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\r\n    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\r\n    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\r\n    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\r\n    SOFTWARE.\r\n\r\n## Notes\r\n\r\n1. Make sure that when you type _python_ in a terminal, the command is recognized and you have the correct version. The easiest way to do it is to select the \"Add to PATH\" option directly when you install Python. Otherwise you can search how to insert it manually.\r\n2. You can choose to see the prompt or not by changing the extension configurations.\r\n"
 },
 {
  "repo": "microsoft/vscode-arduino",
  "language": "TypeScript",
  "readme_contents": "# Visual Studio Code extension for Arduino\n\n[![Gitter](https://img.shields.io/badge/chat-on%20gitter-blue.svg)](https://gitter.im/Microsoft/vscode-arduino)\n[![Travis CI](https://travis-ci.org/Microsoft/vscode-arduino.svg?branch=master)](https://travis-ci.org/Microsoft/vscode-arduino)\n\nWelcome to the Visual Studio Code extension for **Arduino** <sup>preview</sup> ! The Arduino extension makes it easy to develop, build, deploy and debug your Arduino sketches in Visual Studio Code, with a rich set of functionalities. These include:\n\n* IntelliSense and syntax highlighting for Arduino sketches\n* Verify and upload your sketches in Visual Studio Code\n* Built-in board and library manager\n* Built-in example list\n* Built-in serial monitor\n* Snippets for sketches\n* Automatic Arduino project scaffolding\n* Command Palette (<kbd>F1</kbd>) integration of frequently used commands (e.g. Verify, Upload...)\n* Integrated Arduino Debugging <sup>New</sup>\n\n## Prerequisites\nEither the Arduino IDE or Arduino CLI are required.\n\n### Arduino IDE\nThe Arduino IDE can be installed the Arduino [download page](https://www.arduino.cc/en/main/software#download).\n- The supported Arduino IDE versions are `1.6.x` and later.\n- The Windows Store's version of the Arduino IDE is not supported because of the sandbox environment that the application runs in.\n- *Note:* Arduino IDE `1.8.7` had some breaking changes, causing board package and library installation failures.  These failures were corrected in `1.8.8` and later.\n\n### Arduino CLI\nThe Arduino CLI can be downloaded from the repository's [release page](https://github.com/arduino/arduino-cli/releases/tag/0.13.0)\n- The extension has only been tested with v0.13.0.\n- If you use the CLI you will have to set `arduino.path` since the CLI does not have a default path. \n\n## Installation\nOpen VS Code and press <kbd>F1</kbd> or <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd> to open command palette, select **Install Extension** and type `vscode-arduino`.\n\nOr launch VS Code Quick Open (<kbd>Ctrl</kbd> + <kbd>P</kbd>), paste the following command, and press enter.\n```bash\next install vscode-arduino\n```\n\nYou can also install directly from the Marketplace within Visual Studio Code, searching for `Arduino`.\n\n## Get Started\nYou can find code samples and tutorials each time that you connect a supported device. Alternatively you can visit our [IoT Developer Blog Space](https://devblogs.microsoft.com/iotdev/) or [Get Started Tutorials](https://docs.microsoft.com/azure/iot-hub/iot-hub-arduino-iot-devkit-az3166-get-started).\n\n## Commands\nThis extension provides several commands in the Command Palette (<kbd>F1</kbd> or <kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>P</kbd>) for working with `*.ino` files:\n\n- **Arduino: Board Manager**: Manage packages for boards. You can add 3rd party Arduino board by configuring `Additional Board Manager URLs` in the board manager.\n- **Arduino: Change Baud Rate**: Change the baud rate of the selected serial port.\n- **Arduino: Change Board Type**: Change board type or platform.\n- **Arduino: Close Serial Monitor**: Stop the serial monitor and release the serial port.\n- **Arduino: Examples**: Show list of examples.\n- **Arduino: Initialize**: Scaffold a VS Code project with an Arduino sketch.\n- **Arduino: Library Manager**: Explore and manage libraries.\n- **Arduino: Open Serial Monitor**: Open the serial monitor in the integrated output window.\n- **Arduino: Select Serial Port**: Change the current serial port.\n- **Arduino: Send Text to Serial Port**: Send a line of text via the current serial port.\n- **Arduino: Upload**: Build sketch and upload to Arduino board.\n- **Arduino: CLI Upload**: Upload complied code without building sketch (CLI only).\n- **Arduino: Upload Using Programmer**: Upload using an external programmer.\n- **Arduino: CLI Upload Using Programmer**: Upload using an external programmer without building sketch (CLI only).\n- **Arduino: Verify**: Build sketch.\n- **Arduino: Rebuild IntelliSense Configuration**: Forced/manual rebuild of the IntelliSense configuration. The extension analyzes Arduino's build output and sets the IntelliSense include paths, defines, compiler arguments accordingly.\n\n## Keybindings\n- **Arduino: Upload** <kbd>Alt</kbd> + <kbd>Cmd</kbd> + <kbd>U</kbd> *or* <kbd>Alt</kbd> + <kbd>Ctrl</kbd> + <kbd>U</kbd>\n- **Arduino: Verify** <kbd>Alt</kbd> + <kbd>Cmd</kbd> + <kbd>R</kbd> *or* <kbd>Alt</kbd> + <kbd>Ctrl</kbd> + <kbd>R</kbd>\n- **Arduino: Rebuild IntelliSense Configuration** <kbd>Alt</kbd> + <kbd>Cmd</kbd> + <kbd>I</kbd> *or* <kbd>Alt</kbd> + <kbd>Ctrl</kbd> + <kbd>I</kbd>\n\n## Options\n| Option | Description |\n| --- | --- |\n| `arduino.path`  | Path to Arduino, you can use a custom version of Arduino by modifying this setting to include the full path. Example: `C:\\\\Program Files\\\\Arduino` for Windows, `/Applications` for Mac, `/home/<username>/Downloads/arduino-1.8.1` for Linux. (Requires a restart after change). The default value is automatically detected from your Arduino IDE installation path. |\n| `arduino.commandPath` | Path to an executable (or script) relative to `arduino.path`. The default value is `arduino_debug.exe` for Windows, `Contents/MacOS/Arduino` for Mac and `arduino` for Linux, You also can use a custom launch script to run Arduino by modifying this setting. (Requires a restart after change) Example: `run-arduino.bat` for Windows, `Contents/MacOS/run-arduino.sh` for Mac and `bin/run-arduino.sh` for Linux. |\n| `arduino.additionalUrls` | Additional Boards Manager URLs for 3rd party packages. You can have multiple URLs in one string with a comma(`,`) as separator, or have a string array. The default value is empty. |\n| `arduino.logLevel` | CLI output log level. Could be info or verbose. The default value is `\"info\"`. |\n| `arduino.allowPDEFiletype` | Allow the VSCode Arduino extension to open .pde files from pre-1.0.0 versions of Arduino. Note that this will break Processing code. Default value is `false`. |\n| `arduino.enableUSBDetection` | Enable/disable USB detection from the VSCode Arduino extension. The default value is `true`. When your device is plugged in to your computer, it will pop up a message \"`Detected board ****, Would you like to switch to this board type`\". After clicking the `Yes` button, it will automatically detect which serial port (COM) is connected a USB device. If your device does not support this feature, please provide us with the PID/VID of your device; the code format is defined in `misc/usbmapping.json`.To learn more about how to list the vid/pid, use the following tools: https://github.com/EmergingTechnologyAdvisors/node-serialport `npm install -g serialport` `serialport-list -f jsonline`|\n| `arduino.disableTestingOpen` | Enable/disable automatic sending of a test message to the serial port for checking the open status. The default value is `false` (a test message will be sent). |\n| `arduino.skipHeaderProvider` | Enable/disable the extension providing completion items for headers. This functionality is included in newer versions of the C++ extension. The default value is `false`.|\n| `arduino.defaultBaudRate` | Default baud rate for the serial port monitor. The default value is 115200. Supported values are 300, 1200, 2400, 4800, 9600, 19200, 38400, 57600, 74880, 115200, 230400 and 250000 |\n| `arduino.disableIntelliSenseAutoGen` | When `true` vscode-arduino will not auto-generate an IntelliSense configuration (i.e. `.vscode/c_cpp_properties.json`) by analyzing Arduino's compiler output. |\n\nThe following Visual Studio Code settings are available for the Arduino extension. These can be set in global user preferences <kbd>Ctrl</kbd> + <kbd>,</kbd> or workspace settings (`.vscode/settings.json`). The latter overrides the former.\n\n```json\n{\n    \"arduino.path\": \"C:/Program Files (x86)/Arduino\",\n    \"arduino.commandPath\": \"arduino_debug.exe\",\n    \"arduino.logLevel\": \"info\",\n    \"arduino.allowPDEFiletype\": false,\n    \"arduino.enableUSBDetection\": true,\n    \"arduino.disableTestingOpen\": false,\n    \"arduino.skipHeaderProvider\": false,\n    \"arduino.additionalUrls\": [\n        \"https://raw.githubusercontent.com/VSChina/azureiotdevkit_tools/master/package_azureboard_index.json\",\n        \"http://arduino.esp8266.com/stable/package_esp8266com_index.json\"\n    ],\n    \"arduino.defaultBaudRate\": 115200\n}\n```\n*Note:* You only need to set `arduino.path` in Visual Studio Code settings, other options are not required.\n\nThe following settings are as per sketch settings of the Arduino extension. You can find them in\n`.vscode/arduino.json` under the workspace.\n\n```json\n{\n    \"sketch\": \"example.ino\",\n    \"port\": \"COM5\",\n    \"board\": \"adafruit:samd:adafruit_feather_m0\",\n    \"output\": \"../build\",\n    \"debugger\": \"jlink\",\n    \"prebuild\": \"./prebuild.sh\",\n    \"postbuild\": \"./postbuild.sh\",\n    \"intelliSenseGen\": \"global\"\n}\n```\n- `sketch` - The main sketch file name of Arduino.\n- `port` - Name of the serial port connected to the device. Can be set by the `Arduino: Select Serial Port` command. For Mac users could be \"/dev/cu.wchusbserial1420\".\n- `board` - Currently selected Arduino board alias. Can be set by the `Arduino: Change Board Type` command. Also, you can find the board list there.\n- `output` - Arduino build output path. If not set, Arduino will create a new temporary output folder each time, which means it cannot reuse the intermediate result of the previous build leading to long verify/upload time, so it is recommended to set the field. Arduino requires that the output path should not be the workspace itself or in a subfolder of the workspace, otherwise, it may not work correctly. By default, this option is not set. It's worth noting that the contents of this file could be deleted during the build process, so pick (or create) a directory that will not store files you want to keep.\n- `debugger` - The short name of the debugger that will be used when the board itself does not have a debugger and there is more than one debugger available. You can find the list of debuggers [here](https://github.com/Microsoft/vscode-arduino/blob/master/misc/debuggerUsbMapping.json). By default, this option is not set.\n- `prebuild` - External command which will be invoked before any sketch build (verify, upload, ...). For details see the [Pre- and Post-Build Commands](#Pre--and-Post-Build-Commands) section.\n- `postbuild` - External command to be run after the sketch has been built successfully. See the afore mentioned section for more details.\n- `intelliSenseGen` - Override the global setting for auto-generation of the IntelliSense configuration (i.e. `.vscode/c_cpp_properties.json`). Three options are available:\n  - `\"global\"`: Use the global settings (default)\n  - `\"disable\"`: Disable the auto-generation even if globally enabled\n  - `\"enable\"`: Enable the auto-generation even if globally disabled\n- `buildPreferences` - Set Arduino preferences which then are used during any build (verify, upload, ...). This allows for extra defines, compiler options or includes. The preference key-value pairs must be set as follows:\n```json\n    \"buildPreferences\": [\n        [\"build.extra_flags\", \"-DMY_DEFINE=666 -DANOTHER_DEFINE=3.14 -Wall\"],\n        [\"compiler.cpp.extra_flags\", \"-DYET_ANOTER=\\\"hello\\\"\"]\n    ]\n}\n```\n\n## Pre- and Post-Build Commands\nOn Windows the commands run within a `cmd`-, on Linux and OSX within a `bash`-instance. Therefore your command can be anything what you can run within those shells. Instead of running a command you can invoke a script. This makes writing more complex pre-/post-build mechanisms much easier and opens up the possibility to run python or other scripting languages.\nThe commands run within the workspace root directory and vscode-arduino sets the following environment variables:  \n**`VSCA_BUILD_MODE`** The current build mode, one of `Verifying`, `Uploading`, `Uploading (programmer)` or `Analyzing`. This allows you to run your script on certain build modes only.  \n**`VSCA_SKETCH`** The sketch file relative to your workspace root directory.  \n**`VSCA_BOARD`** Your board and configuration, e.g. `arduino:avr:nano:cpu=atmega328`.  \n**`VSCA_WORKSPACE_DIR`** The absolute path of your workspace root directory.  \n**`VSCA_LOG_LEVEL`** The current log level. This allows you to control the verbosity of your scripts.  \n**`VSCA_SERIAL`** The serial port used for uploading. Not set if you haven't set one in your `arduino.json`.  \n**`VSCA_BUILD_DIR`** The build directory. Not set if you haven't set one in your `arduino.json`.  \n\nFor example under Windows the following `arduino.json` setup\n```json\n{\n    \"board\": \"arduino:avr:nano\",\n    \"sketch\": \"test.ino\",\n    \"configuration\": \"cpu=atmega328\",\n    \"prebuild\": \"IF \\\"%VSCA_BUILD_MODE%\\\"==\\\"Verifying\\\" (echo VSCA_BUILD_MODE=%VSCA_BUILD_MODE% && echo VSCA_BOARD=%VSCA_BOARD%)\"\n}\n```\nwill produce\n```\n[Starting] Verifying sketch 'test.ino'\nRunning pre-build command: \"IF \"%VSCA_BUILD_MODE%\"==\"Verifying\" (echo VSCA_BUILD_MODE=%VSCA_BUILD_MODE% && echo VSCA_BOARD=%VSCA_BOARD%)\"\nVSCA_BUILD_MODE=Verifying \nVSCA_BOARD=arduino:avr:nano:cpu=atmega328\nLoading configuration...\n<...>\n```\nwhen verifying.\n\n## IntelliSense\nvscode-arduino auto-configures IntelliSense by default. vscode-arduino analyzes Arduino's compiler output by running a separate build and generates the corresponding configuration file at `.vscode/c_cpp_properties.json`. vscode-arduino tries as hard as possible to keep things up to date, e.g. it runs the analysis when switching the board or the sketch.\n\nIt doesn't makes sense though to run the analysis repeatedly. Therefore if the workspace reports problems (\"squiggles\") - for instance after adding new includes from a new library - run the analysis manually:\n\nManual rebuild: **Arduino: Rebuild IntelliSense Configuration**,\nKeybindings: <kbd>Alt</kbd> + <kbd>Cmd</kbd> + <kbd>I</kbd> *or* <kbd>Alt</kbd> + <kbd>Ctrl</kbd> + <kbd>I</kbd>\n\nWhen the analysis is invoked manually it ignores any global and project specific disable.\n\n### IntelliSense Configurations\nvscode-arduino's analysis stores the result as a dedicated IntelliSense-configuration named `Arduino`. You have to select it from the far right of the status bar when you're in one of your source files as shown here:\n\n![74001156-cfce8280-496a-11ea-9b9d-7d30c83765c1](https://user-images.githubusercontent.com/21954933/74351237-2696ea80-4db7-11ea-9f7a-1bfc652ad5f5.png)\n\nThis system allows you to setup and use own IntelliSense configurations in parallel to the automatically generated configurations provided through vscode-arduino. Just add your configuration to `c_cpp_properties.json` and name it differently from the default configuration (`Arduino`), e.g. `My awesome configuration` and select it from the status bar or via the command palette command **C/C++: Select a Configuration...**\n\n## Debugging Arduino Code <sup>preview</sup>\nBefore you start to debug your Arduino code, please read [this document](https://code.visualstudio.com/docs/editor/debugging) to learn about the basic mechanisms of debugging in Visual Studio Code. Also see [debugging for C++ in VSCode](https://code.visualstudio.com/docs/languages/cpp#_debugging) for further reference.\n\nMake sure that your Arduino board can work with [STLink](http://www.st.com/en/development-tools/st-link-v2.html), [Jlink](https://www.segger.com/jlink-debug-probes.html) or [EDBG](http://www.atmel.com/webdoc/protocoldocs/ch01s01.html). The debugging support is currently fully tested with the following boards:\n- [MXChip IoT Developer Kit - AZ3166](https://microsoft.github.io/azure-iot-developer-kit/)\n- [Arduino M0 PRO](https://www.arduino.cc/en/Main/ArduinoBoardM0PRO)\n- [Adafruit WICED WiFi Feather](https://www.adafruit.com/product/3056)\n- [Adafruit Feather M0](https://www.adafruit.com/product/3010)\n- Arduino Zero Pro\n\nSteps to start debugging:\n1. Plug in your board to your development machine properly. For those boards that do not have an on-board debugging chip, you need to use a STLink or JLink connector.\n2. Go to the **Debug View** (<kbd>Ctrl</kbd> + <kbd>Shift</kbd> + <kbd>D</kbd>). and set breakpoints in your source files.\n3. Press <kbd>F5</kbd> to select your debugging environment.\n4. When your breakpoint is hit, you can see variables and add expression(s) to watch on the Debug Side Bar.\n\n> To learn more about how to debug Arduino code, visit our [team blog](https://blogs.msdn.microsoft.com/iotdev/2017/05/27/debug-your-arduino-code-with-visual-studio-code/).\n\n## Change Log\nSee the [Change log](https://github.com/Microsoft/vscode-arduino/blob/master/CHANGELOG.md) for details about the changes in each version.\n\n## Supported Operating Systems\nCurrently this extension supports the following operating systems:\n\n- Windows 7 and later (32-bit and 64-bit)\n- macOS 10.10 and later\n- Ubuntu 16.04\n  - The extension might work on other Linux distributions, as reported by other users, but without guarantee.\n\n## Support\nYou can find the full list of issues on the [Issue Tracker](https://github.com/Microsoft/vscode-arduino/issues). You can submit a [bug or feature suggestion](https://github.com/Microsoft/vscode-arduino/issues/new), and participate in community driven [discussions](https://gitter.im/Microsoft/vscode-arduino).\n\n## Development\n\nInstallation prerequisites:\n\n- [Git](https://git-scm.com/)\n- [Node.js](https://nodejs.org/) (>= 6.5.0)\n- [Npm](https://www.npmjs.com/) (>= 3.10.3)\n\nTo *run and develop*, do the following:\n- `git clone https://github.com/microsoft/vscode-arduino`\n- `cd vscode-arduino`\n- Run `npm i`\n- Run `npm i -g gulp`\n- Open in Visual Studio Code (`code .`)\n- Press <kbd>F5</kbd> to debug.\n\nTo *test*, press <kbd>F5</kbd> in VS Code with the \"Launch Tests\" debug configuration.\n\n## Code of Conduct\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct). For more information please see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/#howadopt) or contact opencode@microsoft.com with any additional questions or comments.\n\n## Privacy Statement\nThe [Microsoft Enterprise and Developer Privacy Statement](https://www.microsoft.com/en-us/privacystatement/EnterpriseDev/default.aspx) describes the privacy statement of this software.\n\n## License\nThis extension is licensed under the [MIT License](https://github.com/Microsoft/vscode-arduino/blob/master/LICENSE.txt). Please see the [Third Party Notice](https://github.com/Microsoft/vscode-arduino/blob/master/ThirdPartyNotices.txt) file for additional copyright notices and terms.\n\n## Contact Us\nIf you would like to help build the best Arduino experience with VS Code, you can reach us directly at [gitter chat room](https://gitter.im/Microsoft/vscode-arduino).\n"
 },
 {
  "repo": "microsoft/FastTrack",
  "language": "PowerShell",
  "readme_contents": "# Microsoft FastTrack Open Source\nWelcome to the home for Microsoft FastTrack Open Source Software (FTOSS). Through this initiative we are collecting tools, scripts, and guidance from across the FastTrack program, our partners, and anyone who wants to contribute with the aim to make them easier to find, grow, and improve. Please let us know any questions or feedback you have using the [issues list](https://github.com/Microsoft/FastTrack/issues).\n\n## Scripts\n\nWe have a collection of [scripts](scripts) to help with migration related tasks. Each script folder has a readme describing what the script does and how to use it. If you have scripts you would like to add please submit a Pull Request.\n\n## Tools\n\n|Project|Description\n|----|--------------------------\n|[SMAT Workbook Generator](https://github.com/Microsoft/fasttrack-smat-workbook-generator)|Combines the output of SMAT into a single workbook|\n|[IdFix](https://github.com/Microsoft/idfix)|Fix on-premesis AD issues before migration|\n|[gscan](https://github.com/microsoft/FastTrack/tree/master/tools/gsuite-scanner)|Provides an inventory of v1 Google Sites|\n|[SimpleGraph](https://github.com/microsoft/FastTrack/tree/master/tools/SimpleGraph)|Use PowerShell to make simple requests against Graph API, with full support for complex requests|\n\n## Samples\n\n|Sample|Description\n|----|--------------------------\n|[teams-spfx-create-team](./samples/teams-spfx-create-team)|Demonstrates how to create a Microsoft Team from a SharePoint Framework Field customizer. Makes use of PnPjs libraries, Office UI Fabric & React Fabric Controls, and React.|\n|[Teams upgrade snippets](./samples/teams-upgrade-snippets)|Example PowerShell snippets for common automated tasks when performing an upgrade to Teams Only mode from Skype for Business|\n\n## Ideas Welcome!\n\nIf you have ideas for projects that would improve our delivery, experience, or process please [submit an issue](https://github.com/Microsoft/FastTrack/issues) and let us know. We can't promise every idea will be implemented, but we value your feedback. Please be sure to include sufficient information that we can understand your idea and respond.\n\nDo you have a script or tool you use that would be of value to the community? Please let us know so we can discuss potentially adding it to the catalog - or submit a Pull Request to get it added!\n\n## Contributing\n\nIf you have a script or sample you would like to contribute to the Microsoft FastTrack repository please review the [contributing](CONTRIBUTING.md) guidance. If you have any questions, please let us know using the issues list. We'd love to discuss how you'd like to contribute!\n\n## Support Statement\n\nThe scripts, samples, and tools made available through the FastTrack Open Source initiative are provided as-is. These resources are developed in partnership with the community and do not represent official Microsoft software. As such, support is not available through premier or other Microsoft support channels. If you find an issue or have questions please reach out through the issues list and we'll do our best to assist, however there is no associated SLA.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Legal Notices\n\nMicrosoft and any contributors grant you a license to the Microsoft documentation and other content in this repository under the [MIT License](https://opensource.org/licenses/MIT), see the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the [LICENSE-CODE](LICENSE-CODE) file.\n\nMicrosoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation may be either trademarks or registered trademarks of Microsoft in the United States and/or other countries. The licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks. Microsoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n\nPrivacy information can be found at https://privacy.microsoft.com/en-us/\n\nMicrosoft and any contributors reserve all others rights, whether under their respective copyrights, patents,\nor trademarks, whether by implication, estoppel or otherwise.\n"
 },
 {
  "repo": "microsoft/vscode-apimanagement",
  "language": "TypeScript",
  "readme_contents": "[![Version](https://vsmarketplacebadge.apphb.com/version/ms-azuretools.vscode-apimanagement.svg)](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-apimanagement) [![Installs](https://vsmarketplacebadge.apphb.com/installs-short/ms-azuretools.vscode-apimanagement.svg)](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-apimanagement)\r\n[![Build Status](https://dev.azure.com/ms-azuretools/AzCode/_apis/build/status/vscode-apimanagement?branchName=master)](https://dev.azure.com/ms-azuretools/AzCode/_build/latest?definitionId=20&branchName=master) [![GitHub](https://img.shields.io/github/license/mashape/apistatus.svg)](https://github.com/Microsoft/vscode-apimanagement/blob/master/LICENSE.md)\r\n\r\n# Azure API Management Extension for Visual Studio Code\r\n\r\nUse the Azure API Management extension to perform common management operations on your Azure API Management service instances without switching away from Visual Studio Code.\r\n\r\n[Azure API Management](https://aka.ms/apimrocks) is a fully managed service that helps customers to securely expose their APIs to external and internal consumers. API Management serves as a facade and a front door for the API implementations and enables their frictionless consumption by developers. Visit [this page](https://aka.ms/apimlove) for more information and resources related to Azure API Management.\r\n\r\n## Requirements\r\n\r\nAll you need is an Azure Subscription to get started. If you don't have one, [click here](https://azure.microsoft.com/en-us/free/) for a free subscription with $200 in Azure credits!\r\n\r\n## Main Features\r\n\r\n-   Create and delete an API Management instance\r\n-   Create an API by importing an OpenAPI specification\r\n-   Edit APIs and operations in Azure Resource Manager or OpenAPI formats\r\n-   Edit policies at any scope\r\n-   Associate an API with a product\r\n-   Create, delete, and edit Named Values\r\n-   Test an API using [REST Client](https://marketplace.visualstudio.com/items?itemName=humao.rest-client)\r\n-   Command Palette support for most features\r\n-   Extract API and service configurations into ARM templates\r\n-   Import Azure Functions - Transform HttpTriggers into APIs\r\n-   Import App Service WebApp\r\n-   Manage Self-Hosted Gateways\r\n-   Policy Debugging\r\n-   Scaffold Azure Functions\r\n-   Show diffs against last saved version\r\n-   Switch / Release API Revisions\r\n-   API Filter\r\n-   Policy Debugging on Self-Hosted Gateways\r\n\r\n## Create an API Management instance using defaults\r\n\r\n![Create-simple](resources/create-default.gif)\r\n\r\n## Create an API Management instance using custom options\r\n\r\n![Create-advanced](resources/create-advanced.gif)\r\n\r\n## Create an API by importing an OpenAPI specification\r\n\r\nPlease note: only JSON format is supported currently.\r\n![Import-OAS](resources/import-oas.gif)\r\n\r\n## Edit an API in Azure Resource Manager format\r\n\r\n![Edit-JSON](resources/edit-json.gif)\r\n\r\n## Edit an API in OpenAPI format\r\n\r\n![Edit-OAS](resources/edit-oas.gif)\r\n\r\n## Edit policies\r\n\r\n![Edit-Policy](resources/policy.gif)\r\n\r\n## Test an API\r\n\r\n![Test-API](resources/test-api.gif)\r\n\r\n## Create and edit a Named Value\r\n\r\n![Named-Values](resources/namedvalues.gif)\r\n\r\n## Extract Service or API\r\n\r\n![Extract](resources/extract.gif)\r\n\r\n## Import Function App\r\n![importFuncApp](resources/importFunc.gif)\r\n\r\n## Import App Service Web App\r\n![importWebApp](resources/importWebapp.gif)\r\n\r\n## Deploy Gateway with Docker or Kubernetes\r\n![deployGateway](resources/deployGw.gif)\r\n\r\n## Debug Policy\r\n![debugPolicy](resources/debug.gif)\r\n\r\n## Scaffold Azure Functions\r\n![generateFunctions](resources/stencil.gif)\r\n\r\n## Show diffs against last saved version\r\n![diffing](resources/diffing.gif)\r\n\r\n## Switch API Revision\r\n![SwitchRevision](resources/SwitchRevision.gif)\r\n\r\n## Release API Revision\r\n![ReleaseRevision](resources/ReleaseRevision.gif)\r\n\r\n## API Filter\r\n![apiFilter](resources/apiFilter.gif)\r\n\r\n## Self-Hosted Gateway Debugging\r\n![selfHostedDebugging](resources/selfdebug.gif)\r\n\r\n## Intellisense for Policy Expressions.\r\n\r\nFollow instructions [here](https://github.com/microsoft/vscode-apimanagement/issues/37#issuecomment-516551741).\r\n\r\n## Managing Azure Subscriptions\r\n\r\nIf you are not signed in to Azure, you will see a \"Sign in to Azure...\" link. Alternatively, you can select \"View->Command Palette\" in the VS Code menu, and search for \"Azure: Sign In\".\r\n\r\nIf you don't have an Azure Account, you can sign up for one today for free and receive $200 in credits by selecting \"Create a Free Azure Account...\" or selecting \"View->Command Palette\" and searching for \"Azure: Create an Account\".\r\n\r\nYou may sign out of Azure by selecting \"View->Command Palette\" and searching for \"Azure: Sign Out\".\r\n\r\nTo select which subscriptions show up in the extension's explorer, click on the \"Select Subscriptions...\" button on any subscription node (indicated by a \"filter\" icon when you hover over it), or select \"View->Command Palette\" and search for \"Azure: Select Subscriptions\". Note that this selection affects all VS Code extensions that support the [Azure Account and Sign-In](https://github.com/Microsoft/vscode-azure-account) extension.\r\n\r\n## Contributing\r\n\r\nThere are several ways you can contribute to this repo:\r\n\r\n-   **Ideas, feature requests and bugs**: We are open to all ideas and we want to get rid of bugs! Use the [Issues](https://github.com/Microsoft/vscode-apimanagement/issues) section to either report a new issue, share your ideas, or contribute to ongoing discussions.\r\n-   **Documentation**: Found a typo or an awkwardly worded sentence? Submit a PR!\r\n-   **Code**: Contribute bug fixes, features, or design changes:\r\n    -   Clone the repository locally and open in Visual Studio Code.\r\n    -   Install [TSLint for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=ms-vscode.vscode-typescript-tslint-plugin).\r\n    -   Open the terminal (press `` CTRL+` ``) and run `npm install`.\r\n    -   To build, press `F1` and type in `Tasks: Run Build Task`.\r\n    -   Debug: press `F5` to start debugging the extension.\r\n\r\n### Legal\r\n\r\nBefore we can accept your pull request you will need to sign a **Contribution License Agreement**. All you need to do is to submit a pull request, then the PR will get appropriately labelled (e.g. `cla-required`, `cla-norequired`, `cla-signed`, `cla-already-signed`). If you already signed the agreement we will continue with reviewing the PR, otherwise system will tell you how you can sign the CLA. Once you sign the CLA all future PR's will be labeled as `cla-signed`.\r\n\r\n### Code of Conduct\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n## Telemetry\r\n\r\nVS Code collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://go.microsoft.com/fwlink/?LinkID=528096&clcid=0x409) to learn more. If you don\u2019t wish to send usage data to Microsoft, you can set the `telemetry.enableTelemetry` setting to `false`. Learn more in our [FAQ](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting).\r\n\r\n## License\r\n\r\n[MIT](LICENSE.md)\r\n"
 },
 {
  "repo": "microsoft/DiskANN",
  "language": "C++",
  "readme_contents": "# DiskANN\n\nThe goal of the project is to build scalable, performant and cost-effective approximate nearest neighbor search algorithms.\nThe initial release has the in-memory version of the [DiskANN paper](https://papers.nips.cc/paper/9527-rand-nsg-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node.pdf) published in NeurIPS 2019. \nThis code reuses and builds upon some of the [code for NSG](https://github.com/ZJULearning/nsg) algoritm.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nSee [guidelines](CONTRIBUTING.md) for contributing to this project.\n\n\n\n##Linux build:\n\nInstall the following packages through apt-get, and Intel MKL either by downloading the installer or using [apt](https://software.intel.com/en-us/articles/installing-intel-free-libs-and-python-apt-repo) (we tested with build 2019.4-070).\n```\nsudo apt install cmake g++ libaio-dev libgoogle-perftools-dev clang-format-4.0 libboost-dev\n```\n\nBuild\n```\nmkdir build && cd build && cmake .. && make -j \n```\n\n##Windows build:\n\nThe Windows version has been tested with the Enterprise editions of Visual Studio 2017 and Visual Studio 2019. It should work with the Community and Professional editions as well without any changes. \n\n**Prerequisites:**\n\n* Install CMAKE (v3.15.2 or later) from https://cmake.org\n* Install MKL from https://software.intel.com/en-us/mkl\n* Install/download Boost from https://www.boost.org\n\n* Environment variables: \n    * Set a new System environment variable, called INTEL_ROOT to the \"windows\" folder under your MKL installation\n\t   (For instance, if your install folder is \"C:\\Program Files (x86)\\IntelSWtools\", set INTEL_ROOT to \"C:\\Program Files (x86)\\IntelSWtools\\compilers_and_libraries\\windows\")\n    * Set environment variable BOOST_ROOT to your boost folder.\n\n**Build steps:**\n-\tOpen a new command prompt window\n-\tCreate a \"build\" directory under diskann\n-\tChange to the \"build\" directory and run  \n```\n<full-path-to-cmake>\\cmake -G \"Visual Studio 16 2019\" -B. -A x64 ..\n```\nOR \n```\n<full-path-to-cmake>\\cmake -G \"Visual Studio 15 2017\" -B. -A x64 ..\n```\n\n**Note: Since VS comes with its own (older) version of cmake, you have to specify the full path to cmake to ensure that the right version is used.**\n-\tThis will create a \u201cdiskann\u201d solution file in the \"build\" directory\n-\tOpen the \"diskann\" solution and build the \u201cdiskann\u201d project. \n- \tThen build all the other binaries using the ALL_BUILD project that is part of the solution\n- \tGenerated binaries are stored in the diskann/x64/Debug or diskann/x64/Release directories.\n\nTo build from command line, change to the \"build\" directory and use msbuild to first build the \"diskpriority_io\" and \"diskann_dll\" projects. And then build the entire solution, as shown below.\n```\nmsbuild src\\dll\\diskann.vcxproj\nmsbuild diskann.sln\n```\nCheck msbuild docs for additional options including choosing between debug and release builds.\n\n\n##Usage:\n\nWe now detail the main binaries using which one can build and search indices which reside in memory as well as SSD-resident indices.\n\n**Usage for SSD-based indices**\n===============================\n\nTo generate an SSD-friendly index, use the `tests/build_disk_index` program. \n----------------------------------------------------------------------------\n\n```\n./tests/build_disk_index  [data_type<float/int8/uint8>]  [data_file.bin]  [index_prefix_path]  [R]  [L]  [B]  [M]  [T]. \n```\n\nThe arguments are as follows:\n\n(i) data_type:  The datatype is the type of dataset you wish to build an index. We support byte indices (signed int8 or unsigned uint8) or float indices. \n\n(ii) data_file: The input data over which to build an index, in .bin format. The first 4 bytes represent number of points as integer. The next 4 bytes represent the dimension of data as integer. The following n*d*sizeof(T) bytes contain the contents of the data one data point in time. sizeof(T) is 1 for byte indices, and 4 for float indices. This will be read by the program as int8_t for signed indices, uint8_t for unsigned indices or float for float indices.\n\n(iii) index_prefix_path: the index will generate a few files, all beginning with the specified prefix path. For example, if you provide ~/index_test as the prefix path, build  generates files such as ~/index_test_pq_pivots.bin, ~/index_test_pq_compressed.bin, ~/index_test_disk.index, etc. There may be between 8 and 10 files generated with this prefix depending on how we construct the index.\n\n(iv) R: the degree of our graph index, typically between 60 and 150. Again, larger values will result in bigger indices (with longer indexing times), but better search quality. Try to ensure that the L value is at least the R value unless you need to build indices really quickly, but can somewhat compromise on quality. \n\n(v) L: the size of search list we maintain during index building. Typical values are between 75 to 200. Larger values will take more time to build but result in indices that provide higher recall for the same search parameters.\n\n(vi) B: bound on the memory footprint of the index at search time. Once built, the index will use up only the specified RAM limit, the rest will reside on disk. This will dictate how aggressively we compress the data vectors to store in memory. Larger will yield better performance at search time.\n\n(vii) M: Limit on the memory allowed for building the index. If you specify a value less than what is required to build the index in one pass, the index is  built using a divide and conquer approach so that  sub-graphs will fit in the RAM budget. The sub-graphs are  stitched together to build the overall index. This approach can be upto 1.5 times slower than building the index in one shot. Try to allocate as much memory as possible for index build as your RAM allows.\n\n(viii) T: number of threads used by the index build process. Since the code is highly parallel, the  indexing time improves almost linearly with the number of threads (subject to the cores available on the machine).\n\nTo search the SSD-index, use the `tests/search_disk_index` program. \n----------------------------------------------------------------------------\n\n```\n./tests/search_disk_index  [index_type<float/int8/uint8>]  [index_prefix_path]  [num_nodes_to_cache]  [num_threads]  [beamwidth (use 0 to optimize internally)]  [query_file.bin]  [truthset.bin (use \"null\" for none)]  [K]  [result_output_prefix]  [L1]  [L2] etc.\n```\n\nThe arguments are as follows:\n\n(i) data type: same as (i) above in building index.\n\n(ii) index_prefix_path: same as (iii) above in building index.\n\n(iii) num_nodes_to_cache: our program stores the entire graph on disk. For faster search performance, we provide the support to cache a few nodes (which are closest to the starting point) in memory. \n\n(iv) num_threads: search using specified number of threads in parallel, one thread per query. More will result in more IOs, so find the balance depending on the bandwidth of the SSD.\n\n(v) beamwidth: maximum number of IO requests each query will issue per iteration of search code. Larger beamwidth williult in fewer IO round-trips per query, but might result in slightly higher number of IO requests to SSD per query. Specifying 0 will optimize the beamwidth depending on the number of threads performing search.\n\n(vi) query_file.bin: search on these queries, same format as data file (ii) above. The query file must be the same type as specified in (i).\n\n(vii) truthset.bin file. Must be in the following format, or specify \"null\": n, the number of queries (4 bytes) followed by d, the number of ground truth elements per query (4 bytes), followed by n*d entries per query representing the d closest IDs per query in integer format,  followed by n*d entries representing the corresponding distances (float). Total file size is 8 + 4*n*d + 4*n*d. The groundtruth file, if not available, can be calculated using our program, tests/utils/compute_groundtruth. If you just want to measure the latency numbers of search and output the nearest neighbors without calculating recall, enter \"null\".\n\n(viii) K: measure recall@k, meaning the accuracy of retrieving top-k nearest neighbors.\n\n(ix) result output prefix: search results will be stored in files with specified prefix, in bin format.\n\n(x, xi, ...) various search_list sizes to perform search with. Larger will result in slower latencies, but higher accuracies. Must be atleast the recall@ value in (vi).\n\n\n**Usage for in-memory indices**\n================================\n\nTo generate index, use the `tests/build_memory_index` program. \n--------------------------------------------------------------\n\n```\n./tests/build_memory_index  [data_type<int8/uint8/float>]  [data_file.bin]  [output_index_file]  [R]  [L]  [alpha]  [num_threads_to_use]\n```\n\nThe arguments are as follows:\n\n(i) data_type: same as (i) above in building disk index.\n\n(ii) data_file: same as (ii) above in building disk index, the input data file in .bin format of type int8/uint8/float.\n\n(iii) output_index_file: memory index will be saved here.\n\n(iv) R: max degree of index: larger is typically better, range (50-150). Preferrably ensure that L is at least R.\n\n(v) L: candidate_list_size for building index, larger is better (typical range: 75 to 200)\n\n(vi) alpha: float value which determines how dense our overall graph will be, and diameter will be log of n base alpha (roughly). Typical values are between 1 to 1.5. 1 will yield sparsest graph, 1.5 will yield denser graphs.\n\n(vii) number of threads to use: indexing uses specified number of threads.\n\n\nTo search the generated index, use the `tests/search_memory_index` program:\n---------------------------------------------------------------------------\n\n```\n./tests/search_memory_index  [index_type<float/int8/uint8>]  [data_file.bin]  [memory_index_path]  [query_file.bin]  [truthset.bin (use \"null\" for none)] [K]  [result_output_prefix]  [L1]  [L2] etc. \n```\n\nThe arguments are as follows:\n\n(i) data type: same as (i) above in building index.\n\n(ii) memory_index_path: enter path of index built (argument (iii) above in building memory index).\n\n(iii) query_bin: search on these queries, same format as data file (ii) above. The query file must be the same type as specified in (i).\n\n(iv) Truthset file. Must be in the following format: n, the number of queries (4 bytes) followed by d, the number of ground truth elements per query (4 bytes), followed by n*d entries per query representing the d closest IDs per query in integer format,  followed by n*d entries representing the corresponding distances (float). Total file size is 8 + 4*n*d + 4*n*d. The groundtruth file, if not available, can be calculated using our program, tests/utils/compute_groundtruth.\n\n(v) K: search for recall@k, meaning accuracy of retrieving top-k nearest neighbors.\n\n(vi) result output prefix: will search and store the computed results in the files with specified prefix in bin format.\n\n(vii, viii, ...) various search_list sizes to perform search with. Larger will result in slower latencies, but higher accuracies. Must be atleast the recall@ value in (vi).\n"
 },
 {
  "repo": "microsoft/react-native-macos",
  "language": "C++",
  "readme_contents": "<h1 align=\"center\"> React Native for macOS </h1>\n\n<p align=\"center\">\n  Build native macOS apps with React.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/microsoft/react-native-macos/blob/master/LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-MIT-blue.svg\" alt=\"React Native for macOS is released under the MIT license.\" />\n  </a>\n  <a href=\"https://www.npmjs.org/package/react-native-macos\">\n    <img src=\"https://img.shields.io/npm/v/react-native-macos?color=e80441&label=react-native-macos\" alt=\"Current npm package version.\" />\n  </a>\n  <a href=\"https://github.com/microsoft/react-native-macos/blob/master/CONTRIBUTING.md\">\n    <img src=\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg\" alt=\"PRs welcome!\" />\n  </a>\n</p>\n\n> See the official [React Native website](https://reactnative.dev/) for an introduction to React Native. \n\n[React Native](https://reactnative.dev) is a framework developed by Facebook that enables you to build world-class application experiences on native platforms using a consistent developer experience based on JavaScript and [React](https://reactjs.org/). The focus of React Native is on developer efficiency across all the platforms you care about - learn once, write anywhere.\n\nThis repository is a working fork of **facebook/react-native** that adds support for the official React Native for macOS implementation from Microsoft. \n\nYou can read more about the macOS implementation in our website - [React Native for Windows + macOS](https://microsoft.github.io/react-native-windows/)\n\n## Contents\n\n- [Requirements](#requirements)\n- [Getting Started](#getting-started)\n- [Contributing](#contributing)\n- [Documentation](#documentation)\n- [License](#license)\n- [Code of Conduct](#code-of-conduct)\n\n## Requirements\n\nYou can run React Native for macOS apps on Mac devices with versions Mojave (10.14) or newer.\n\nFor a full and detailed list of the system requirements and how to set up your development platform, see our [System Requirements](https://microsoft.github.io/react-native-windows/docs/rnm-dependencies) documentation on our website.\n\n## Getting Started\nSee the [Getting Started Guide](https://microsoft.github.io/react-native-windows/docs/rnm-getting-started) on our React Native for Windows + macOS website to build your first React Native for macOS app.\n\n### Logging Issues\nSearch the [existing issues](https://github.com/microsoft/react-native-macos/issues) and try to make sure your problem doesn\u2019t already exist before opening a new issue. If your issue doesn't exist yet, try to make sure you provide as much information as possible to us so we can help you sooner. It\u2019s helpful if you include information like:\n\n- The version of macOS, React Native, React Native macOS extension where you ran into the issue.\n- A stack trace and reduced repro case when possible.\n- Ensure the [appropriate template](https://github.com/microsoft/react-native-macos/issues/new/choose) is used when filing your issue(s).\n\n##  Contributing\nSee [Contributing guidelines](https://github.com/microsoft/react-native-macos/blob/master/CONTRIBUTING.md) for how to setup your fork of the repo and start a PR to contribute to React Native for macOS.\n\n[Good First Issue](https://github.com/microsoft/react-native-macos/labels/good%20first%20issue) and [help wanted](https://github.com/microsoft/react-native-macos/labels/help%20wanted) are great starting points for PRs.\n\n## Documentation\n[React Native already has great documentation](https://reactnative.dev/docs/getting-started.html) and we're working to ensure the React Native for Windows + macOS are part of that documentation story.\n\n[React Native for Windows + macOS](https://microsoft.github.io/react-native-windows/) has it's own separate documentation site where Windows and macOS\nspecific information, like API docs and blog updates live. We are bootstrapping documentation for macOS at this time, tune in for updates.\n\n### Examples\n\n- Using the CLI in the [Getting Started](https://microsoft.github.io/react-native-windows/docs/rnm-getting-started) guide will set you up with a sample React Native for macOS app that you can begin editing right away.\n- If you're looking for sample code, just browse the [RNTester folder](https://github.com/microsoft/react-native-macos/tree/master/RNTester) for examples\n\n## License\n\nThe React Native for macOS extension, including modifications to the original Facebook source code, and all newly contributed code is provided under the [MIT License](LICENSE). Portions of the React Native for macOS extension derived from React Native are copyright Facebook.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n"
 },
 {
  "repo": "microsoft/snmalloc",
  "language": "C++",
  "readme_contents": "# snmalloc\n\nsnmalloc is a high-performance allocator. \nsnmalloc can be used directly in a project as a header-only C++ library, \nit can be `LD_PRELOAD`ed on Elf platforms (e.g. Linux, BSD),\nand there is a [crate](https://crates.io/crates/snmalloc-rs) to use it from Rust.\n\nIts key design features are:\n\n* Memory that is freed by the same thread that allocated it does not require any\n  synchronising operations.\n* Freeing memory in a different thread to initially allocated it, does not take\n  any locks and instead uses a novel message passing scheme to return the\n  memory to the original allocator, where it is recycled.  This enables 1000s of remote \n  deallocations to be performed with only a single atomic operation enabling great\n  scaling with core count. \n* The allocator uses large ranges of pages to reduce the amount of meta-data\n  required.\n* The fast paths are highly optimised with just two branches on the fast path \n  for malloc (On Linux compiled with Clang).\n* The platform dependencies are abstracted away to enable porting to other platforms. \n\nsnmalloc's design is particular well suited to the following two difficult \nscenarios that can be problematic for other allocators:\n\n  * Allocations on one thread are freed by a different thread\n  * Deallocations occur in large batches\n\nBoth of these can cause massive reductions in performance of other allocators, but \ndo not for snmalloc.\n\nComprehensive details about snmalloc's design can be found in the\n[accompanying paper](snmalloc.pdf), and differences between the paper and the\ncurrent implementation are [described here](difference.md).\nSince writing the paper, the performance of snmalloc has improved considerably.\n\n[![Build Status](https://dev.azure.com/snmalloc/snmalloc/_apis/build/status/Microsoft.snmalloc?branchName=master)](https://dev.azure.com/snmalloc/snmalloc/_build/latest?definitionId=1?branchName=master)\n\n# Further documentation\n\n - [Instructions for building snmalloc](docs/BUILDING.md)\n - [Instructions for porting snmalloc](docs/PORTING.md)\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/Docker-Provider",
  "language": "Ruby",
  "readme_contents": "# About\n\nThis repository contains source code for Azure Monitor for containers Linux and Windows Agent\n\n# Questions?\n\nFeel free to contact engineering team owners in case you have any questions about this repository or project.\n\n# Prerequisites\n\n## Common\n- [Visual Studio Code](https://code.visualstudio.com/) for authoring\n- [Go lang](https://golang.org/) for building go code. Go lang version 1.14.1.\n\n> Note: If you are using WSL2, make sure you have cloned the code onto ubuntu not onto windows\n\n## WSL2\n- [WSL2](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\n- configure [Docker-for-windows-wsl2](https://docs.docker.com/docker-for-windows/wsl/)\n\n## Linux\n- Ubuntu 14.04 or higher to build Linux Agent.\n- [Docker](https://docs.docker.com/engine/install/ubuntu/) to build the docker image for Linux Agent\n> Note: if you are using WSL2, you can ignore Docker since Docker for windows will be used.\n\n## Windows\n- Windows 10 Professional machine to build  Windows Agent\n- [Docker for Windows](https://docs.docker.com/docker-for-windows/) to build docker image for Windows Agent\n- [.NET Core SDK](https://dotnet.microsoft.com/download) to build the Windows Agent code\n- [gcc for windows](https://github.com/jmeubank/tdm-gcc/releases/download/v9.2.0-tdm64-1/tdm64-gcc-9.2.0.exe) to build go code\n\n\n# Repo structure\n\nThe general directory structure is:\n\n```\n\u251c\u2500\u2500 .pipelines/                               - files related to azure devops ci and cd pipelines\n\u251c\u2500\u2500 build/                                    - files to related to  compile and build the code\n\u2502   \u251c\u2500\u2500 version                               - build version used for docker prvider and go shared object(so) files\n\u2502   \u251c\u2500\u2500 common/                               - common to both windows and linux installers\n\u2502   \u2502   \u251c\u2500\u2500 installer                         - files related to installer\n|   |   |   |\u2500\u2500 scripts/                      - script files related to configmap parsing\n\u2502   \u251c\u2500\u2500 linux/                                - Makefile and installer files for the Docker Provider\n\u2502   \u2502   \u251c\u2500\u2500 Makefile                          - Makefile to build the docker provider\n\u2502   \u2502   \u251c\u2500\u2500 installer                         - files related to installer\n|   |   |   |\u2500\u2500 bundle/                       - shell scripts to create shell bundle\n|   |   |   |\u2500\u2500 conf/                         - plugin configuration files\n|   |   |   |\u2500\u2500 datafiles/                    - data files for the installer\n|   |   |   |\u2500\u2500 scripts/                      - script files related to livenessproble, tomlparser etc..\n|   |   |   |\u2500\u2500 InstallBuilder/               - python script files for the install builder\n\u2502   \u251c\u2500\u2500 windows/                              - scripts to build the .net and go code\n|   |   |\u2500\u2500 Makefile.ps1                      - powershell script to build .net and go lang code and copy the files to omsagentwindows directory\n\u2502   \u2502   \u251c\u2500\u2500 installer                         - files related to installer\n|   |   |   |\u2500\u2500 conf/                         - fluent, fluentbit and out_oms plugin configuration files\n|   |   |   |\u2500\u2500 scripts/                      - script files related to livenessproble, filesystemwatcher, keepCertificateAlive etc..\n|   |   |   |\u2500\u2500 certificategenerator/         - .NET code for the generation self-signed certificate of the windows agent\n\u251c\u2500\u2500 charts/                                   - helm charts\n\u2502   \u251c\u2500\u2500 azuremonitor-containers/              - azure monitor for containers helm chart used for non-AKS clusters\n\u251c\u2500\u2500 alerts/                                   - alert queries\n\u251c\u2500\u2500 kubernetes/                               - files related to Linux and Windows Agent for Kubernetes\n\u2502   \u251c\u2500\u2500 linux/                                - scripts to build the Docker image for Linux Agent\n\u2502   \u2502   \u251c\u2500\u2500 dockerbuild                       - script to build docker provider, docker image and publish docker image\n\u2502   \u2502   \u251c\u2500\u2500 DockerFile                        - DockerFile for Linux Agent Container Image\n\u2502   \u2502   \u251c\u2500\u2500 main.sh                           - Linux Agent container entry point\n\u2502   \u2502   \u251c\u2500\u2500 setup.sh                          - setup file for Linux Agent Container Image\n\u2502   \u2502   \u251c\u2500\u2500 acrworkflows/                     - acr work flows for the Linux Agent container image\n\u2502   \u2502   \u251c\u2500\u2500 defaultpromenvvariables           - default environment variables for Prometheus scraping\n\u2502   \u2502   \u251c\u2500\u2500 defaultpromenvvariables-rs        - cluster level default environment variables for Prometheus scraping\n\u2502   \u2502   \u251c\u2500\u2500 defaultpromenvvariables-sidecar   - cluster level default environment variables for Prometheus scraping in sidecar\n\u2502   \u251c\u2500\u2500 windows/                              - scripts to build the Docker image for Windows Agent\n\u2502   \u2502   \u251c\u2500\u2500 dockerbuild                       - script to build the code and docker imag, and publish docker image\n\u2502   \u2502   \u251c\u2500\u2500 acrworkflows/                     - acr work flows for the Windows Agent container image\n\u2502   \u2502   \u251c\u2500\u2500 DockerFile                        - DockerFile for Windows Agent Container Image\n\u2502   \u2502   \u251c\u2500\u2500 main.ps1                          - Windows Agent container entry point\n\u2502   \u2502   \u251c\u2500\u2500 setup.ps1                         - setup file for Windows Agent Container Image\n\u2502   \u251c\u2500\u2500 omsagent.yaml                         - kubernetes yaml for both Linux and Windows Agent\n\u2502   \u251c\u2500\u2500 container-azm-ms-agentconfig.yaml     - kubernetes yaml for agent configuration\n\u251c\u2500\u2500 scripts/                                  - scripts for onboarding, troubleshooting and preview scripts related to Azure Monitor for containers\n\u2502   \u251c\u2500\u2500 troubleshoot/                         - scripts for troubleshooting of Azure Monitor for containers onboarding issues\n\u2502   \u251c\u2500\u2500 onboarding/                           - scripts related to Azure Monitor for containers onboarding.\n\u2502   \u251c\u2500\u2500 preview/                              - scripts related to preview features ...\n\u2502   \u251c\u2500\u2500 build/                                - scripts related to build such as installing pre-requisites etc.\n\u2502   \u251c\u2500\u2500 deployment/                           - scripts related to deployment goes here.\n\u2502   \u251c\u2500\u2500 release/                              - scripts related to release  goes here.\n\u251c\u2500\u2500 source/                                   - source code\n\u2502   \u251c\u2500\u2500 plugins/                              - plugins source code\n\u2502   \u2502   \u251c\u2500\u2500 go/                               - out_oms plugin code in go lang\n\u2502   \u2502   \u251c\u2500\u2500 ruby/                             - plugins code in ruby\n\u2502   \u2502   |   \u251c\u2500\u2500 health/                       - code for health feature\n\u2502   \u2502   |   \u251c\u2500\u2500 lib/                          - lib for app insights ruby and this code of application_insights gem\n\u2502   \u2502   |   ...                               - plugins in, out and filters code in ruby\n\u2502   \u251c\u2500\u2500 toml-parser/                          - code for parsing of toml configuration files\n\u251c\u2500\u2500 test/                                     - source code for tests\n\u2502   \u251c\u2500\u2500 e2e/                                  - e2e tests to validate agent and e2e workflow(s)\n\u2502   \u251c\u2500\u2500 unit-tests/                           - unit tests code\n\u2502   \u251c\u2500\u2500 scenario/                             - scenario tests code\n\u251c\u2500\u2500 !_README.md                               - this file\n\u251c\u2500\u2500 .gitignore                                - git config file with include/exclude file rules\n\u251c\u2500\u2500 LICENSE                                   - License file\n\u251c\u2500\u2500 Rakefile                                  - Rake file to trigger ruby plugin tests\n\u2514\u2500\u2500 ReleaseProcess.md                         - Release process instructions\n\u2514\u2500\u2500 ReleaseNotes.md                           - Release notes for the release of the Azure Monitor for containers agent\n```\n\n# Branches\n\n- `ci_prod` branch contains codebase currently in production (or being prepared for release).\n- `ci_dev` branch contains version in development.\n\nTo contribute: create your private branch off of `ci_dev`, make changes and use pull request to merge back to `ci_dev`.\nPull request must be approved by at least one engineering team members.\n\n# Authoring code\n\nWe recommend using [Visual Studio Code](https://code.visualstudio.com/) for authoring. Windows 10 with Ubuntu App can be used for both Windows and Linux  Agent development and recommened to clone the code onto Ubuntu app so that you dont need to worry about line ending issues LF vs CRLF.\n\n# Building code\n\n## Linux Agent\n\n### Install Pre-requisites\n\n1. Install go1.14.1, dotnet, powershell, docker and build dependencies to build go code for both Linux and Windows platforms\n```\nbash ~/Docker-Provider/scripts/build/linux/install-build-pre-requisites.sh\n```\n2. Verify python, docker and golang installed properly and also PATH and GOBIN environment variables set with go bin path.\n   For some reason go env not set by install-build-pre-requisites.sh script, run the following commands to set them\n   ```\n   export PATH=$PATH:/usr/local/go/bin\n   export GOBIN=/usr/local/go/bin\n   ```\n3. If you want to use Docker on the WSL2, verify following configuration settings configured on your Ubuntu app\n   ```\n   echo $DOCKER_HOST\n   # if either DOCKER_HOST not set already or doesnt have tcp://localhost:2375 value, set DOCKER_HOST value via this command\n   echo \"export DOCKER_HOST=tcp://localhost:2375\" >> ~/.bashrc && source ~/.bashrc\n   # on Docker Desktop for Windows make sure docker running linux mode and enabled Expose daemon on tcp://localhost:2375 without TLS\n   ```\n\n### Build Docker Provider Shell Bundle and Docker Image and Publish Docker Image\n\n> Note: If you are using WSL2, ensure `Docker for windows` running with Linux containers mode on your windows machine to build Linux agent image successfully\n\n```\ncd ~/Docker-Provider/kubernetes/linux/dockerbuild\nsudo docker login # if you want to publish the image to acr then login to acr via `docker login <acr-name>`\n# build provider, docker image and publish to docker image\nbash build-and-publish-docker-image.sh --image <repo>/<imagename>:<imagetag>\n```\n> Note: format of the imagetag will be `ci<release><MMDDYYYY>`. possible values for release are test, dev, preview, dogfood, prod etc.\n\nIf you prefer to build docker provider shell bundle and image separately, then you can follow below instructions\n\n##### Build Docker Provider shell bundle\n\n```\ncd ~/Docker-Provider/build/linux\nmake\n```\n##### Build and Push Docker Image\n\n```\ncd ~/Docker-Provider/kubernetes/linux/\ndocker build -t <repo>/<imagename>:<imagetag> --build-arg IMAGE_TAG=<imagetag> .\ndocker push <repo>/<imagename>:<imagetag>\n```\n## Windows Agent\n\nTo build the windows agent, you will have to build .NET and Go code, and docker image for windows agent.\nDocker image for windows agent can only build on Windows machine with `Docker for windows` with Windows containers mode but the .NET code and Go code can be built either on Windows or Linux or WSL2.\n\n### Install Pre-requisites\n\nInstall pre-requisites based on OS platform you will be using to build the windows agent code\n\n#### Option 1 - Using Windows Machine to Build the Windows agent\n\n```\npowershell # launch powershell with elevated admin on your windows machine\nSet-ExecutionPolicy -ExecutionPolicy bypass # set the execution policy\ncd %userprofile%\\Docker-Provider\\scripts\\build\\windows # based on your repo path\n.\\install-build-pre-requisites.ps1 #\n```\n\n#### Option 2 - Using WSL2 to Build the Windows agent\n\n```\npowershell # launch powershell with elevated admin on your windows machine\nSet-ExecutionPolicy -ExecutionPolicy bypass # set the execution policy\nnet use z: \\\\wsl$\\Ubuntu-16.04 # map the network drive of the ubuntu app to windows\ncd z:\\home\\sshadmin\\Docker-Provider\\scripts\\build\\windows # based on your repo path\n.\\install-build-pre-requisites.ps1 #\n```\n\n\n### Build Windows Agent code and Docker Image\n\n> Note: format of the windows agent imagetag will be `win-ci<release><MMDDYYYY>`. possible values for release are test, dev, preview, dogfood, prod etc.\n\n#### Option 1 - Using Windows Machine to Build the Windows agent\n\nExecute below instructions on elevated command prompt to build windows agent code and docker image, publishing the image to acr or docker hub\n\n```\ncd %userprofile%\\Docker-Provider\\kubernetes\\windows\\dockerbuild # based on your repo path\ndocker login # if you want to publish the image to acr then login to acr via `docker login <acr-name>`\npowershell -ExecutionPolicy bypass  # switch to powershell if you are not on powershell already\n.\\build-and-publish-docker-image.ps1 -image <repo>/<imagename>:<imagetag> # trigger build code and image and publish docker hub or acr\n```\n\n#### Option 2 - Using WSL2 to Build the Windows agent\n\n##### On WSL2, Build Certificate Generator Source code and Out OMS Go plugin code\n\n```\ncd ~/Docker-Provider/build/windows # based on your repo path on WSL2 Ubuntu app\npwsh #switch to powershell\n.\\Makefile.ps1 # trigger build and publish of .net and go code\n```\n\n####  On Windows machine, build and Push Docker Image\n\n> Note: Docker image for windows container can only built on windows hence you will have to execute below commands on windows via accessing network share or copying published bits omsagentwindows under kubernetes directory on to windows machine\n\n```\nnet use z: \\\\wsl$\\Ubuntu-16.04 # map the network drive of the ubuntu app to windows\ncd z:\\home\\sshadmin\\Docker-Provider\\kubernetes\\windows # based on your repo path\ndocker build -t <repo>/<imagename>:<imagetag> --build-arg IMAGE_TAG=<imagetag> .\ndocker push <repo>/<imagename>:<imagetag>\n```\n\n# Azure DevOps Build Pipeline\n\nNavigate to https://github-private.visualstudio.com/microsoft/_build?view=pipelines to see Linux and Windows Agent build pipelines. These pipelines are configured with CI triggers for ci_dev and ci_prod.\n\nDocker Images will be pushed to CDPX ACR repos and these needs to retagged and pushed to corresponding ACR or docker hub. Only onboarded Azure AD AppId has permission to pull the images from CDPx ACRs.\n\nPlease reach out the agent engineering team if you need access to it.\n\n## Onboarding feature branch\n\nHere are the instructions to onboard the feature branch to Azure Dev Ops pipeline\n\n 1. Navigate to https://github-private.visualstudio.com/microsoft/_apps/hub/azurecdp.cdpx-onboarding.cdpx-onboarding-tab\n 2. Select the repository as \"docker-provider\" from repository drop down\n 3. click on validate repository\n 4. select the your feature branch from Branch drop down\n 5. Select the Operation system as \"Linux\" and Build type as \"buddy\"\n 6. create build definition\n 7. enable continous integration on trigger on the build definition\n\n This will create build definition for the Linux agent.\n Repeat above steps except that this time select Operation system as \"Windows\" to onboard the pipeline for Windows agent.\n\n# Azure DevOps Release Pipeline\n\nIntegrated to Azure DevOps release pipeline for the ci_dev and ci_prod.With this, for every commit to ci_dev branch, latest bits automatically deployded to DEV AKS clusters in Build subscription and similarly for for every commit to ci_prod branch, latest bits automatically deployed to PROD AKS clusters in Build subscription.\n\nFor dev, agent image will be in this format mcr.microsoft.com/azuremonitor/containerinsights/cidev:cidev<git-commit-id>.\nFor prod, agent will be in this format mcr.microsoft.com/azuremonitor/containerinsights/ciprod:ciprod`<MM><DD><YYYY>`.\n\nNavigate to https://github-private.visualstudio.com/microsoft/_release?_a=releases&view=all to see the release pipelines.\n\n# Update Kubernetes yamls\n\nNavigate to Kubernetes directory and update the yamls with latest docker image of Linux and Windows Agent and other relevant updates.\n\n#  Deployment and Validation\n\nFor DEV and PROD branches, automatically deployed latest yaml with latest agent image (which automatically built by the azure devops pipeline) onto CIDEV and CIPROD AKS clusters in build subscription.  So, you can use CIDEV and CIPROD AKS cluster to validate E2E. Similarly, you can set up build and release pipelines for your feature branch.\n\n# E2E Tests\n\n## For executing tests\n\n1. Deploy the omsagent.yaml with your agent image. In the yaml, make sure `ISTEST` environment variable set to `true` if its not set already\n2. Update the Service Principal CLIENT_ID, CLIENT_SECRET and TENANT_ID placeholder values and apply e2e-tests.yaml to execute the tests \n    > Note: Service Principal requires reader role on log analytics workspace and cluster resource to query LA and metrics\n   ```\n   cd ~/Docker-Provider/test/e2e # based on your repo path    \n   kubectl apply -f e2e-tests.yaml # this will trigger job to run the tests in sonobuoy namespace \n   kubectl get po -n sonobuoy # to check the pods and jobs associated to tests   \n   ``` \n3. Download (sonobuoy)[https://github.com/vmware-tanzu/sonobuoy/releases] on your dev box to view the results of the tests\n   ```\n   results=$(sonobuoy retrieve) # downloads tar file which has logs and test results\n   sonobuoy results $results # get the summary of the results\n   tar -xzvf <downloaded-tar-file> # extract downloaded tar file and look for pod logs, results and other k8s resources if there are any failures\n   ```\n\n## For adding new tests\n\n1. Add the test python file with your test code under `tests` directory\n2. Build the docker image, recommended to use ACR & MCR \n  ```\n   cd ~/Docker-Provider/test/e2e/src # based on your repo path \n   docker login <acr> -u <user> -p <pwd> # login to acr\n   docker build -f ./core/Dockerfile -t <repo>/<imagename>:<imagetag> .\n   docker push <repo>/<imagename>:<imagetag>\n  ```\n3. update existing agentest image tag in e2e-tests.yaml with newly built image tag with MCR repo\n\n# Scenario Tests\nClusters are used in release pipeline already has the yamls under test\\scenario deployed. Make sure to validate these scenarios.\nIf you have new interesting scenarios, please add/update them.\n\n# Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct] (https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ] (https://opensource.microsoft.com/codeofconduct/faq/) or contact opencode@microsoft.com with any additional questions or comments.\n\n"
 },
 {
  "repo": "microsoft/apple-ux-guide",
  "language": null,
  "readme_contents": "# Apple UX Guide\n\nThis guide contains best practices for building great experiences and writing sustainable code using Apple's UX Frameworks. Guidance here comes from a combination of our collective practical experiences and documentation from Apple and other 3rd parties. This is meant to be a living document and all contents are perpetually open for debate and improvement.\n\n## Table of Contents\n\n* [Layout](Layout.md)\n* [Storyboards and Xibs](StoryboardsAndXibs.md)\n* [View Controllers](ViewControllers.md)\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Legal Notices\n\nMicrosoft and any contributors grant you a license to the Microsoft documentation and other content\nin this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),\nsee the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the\n[LICENSE-CODE](LICENSE-CODE) file.\n\nMicrosoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation\nmay be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\nThe licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\nMicrosoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n\nPrivacy information can be found at https://privacy.microsoft.com/en-us/\n\nMicrosoft and any contributors reserve all other rights, whether under their respective copyrights, patents,\nor trademarks, whether by implication, estoppel or otherwise.\n"
 },
 {
  "repo": "microsoft/STL",
  "language": "C++",
  "readme_contents": "# Microsoft's C++ Standard Library\r\n\r\nThis is the official repository for Microsoft's implementation of the C++ Standard Library (also known as the STL),\r\nwhich ships as part of the MSVC toolset and the Visual Studio IDE.\r\n\r\n* Our [Changelog][] tracks which updates to this repository appear in each VS release.\r\n* Our [Status Chart][] displays our overall progress over time.\r\n* Join our [Discord server][].\r\n\r\n[![Build Status](https://dev.azure.com/vclibs/STL/_apis/build/status/microsoft.STL?branchName=main)][Pipelines]\r\n\r\n# What This Repo Is Useful For\r\n\r\nIf you're a programmer who just wants to use the STL, you **don't** need this repo. Simply install the Visual Studio IDE\r\nand select the \"Desktop development with C++\" workload.\r\n\r\nIf you want to participate in the STL's development, welcome! You can report issues, comment on pull requests, and learn\r\nabout what we're working on. You can also submit pull requests to fix bugs or add features (see below).\r\n\r\nFinally, you can take our code and use it in other apps and libraries (according to the terms of our license, like\r\neverything else).\r\n\r\n# GitHub Migration Status\r\n\r\nWe're in the process of moving all of our work on the STL to GitHub. Current status:\r\n\r\n* Code: **Done.** Our source code is available under the Apache License v2.0 with LLVM Exception. (See\r\n[LICENSE.txt][] and [NOTICE.txt][] for more information.)\r\n\r\n* Build System: **In progress.** We're working on a CMake build system, which is currently capable of building one\r\nflavor of the STL (native desktop). We need to extend this to build all of the flavors required for the MSVC toolset\r\n(e.g. `/clr`, `/clr:pure`, OneCore, Spectre). Until that's done, we're keeping our legacy build system around in the\r\n`stl/msbuild` subdirectory. (We're keeping those files in this repo, even though they're unusable outside of Microsoft,\r\nbecause they need to be updated whenever source files are added/renamed/deleted. We'll delete the legacy machinery as\r\nsoon as possible.)\r\n\r\n* Tests: **In progress.** We rely on three test suites: std, tr1, and [libcxx][]. We've partially ported std and tr1,\r\nand fully ported libcxx to run under [lit][] using the various configurations/compilers we test internally.\r\n\r\n* Continuous Integration: **In progress.** We've set up Azure Pipelines to validate changes to the repository.\r\nCurrently, it builds the STL (native desktop for x86, x64, ARM, and ARM64). Also, it strictly verifies that all of our\r\nfiles have been formatted with [clang-format][] and follow our other whitespace conventions.\r\n\r\n* Contribution Guidelines: **Coming soon.** Working on the STL's code involves following many rules. We have codebase\r\nconventions, Standard requirements, Microsoft-specific requirements, binary compatibility (ABI) requirements, and more.\r\nWe're eager to begin accepting features and fixes from the community, but in addition to setting up a CI system, we need\r\nto write down all of the rules that are currently stored in our brains. (The ABI rules may be useful to other C++\r\nlibraries.)\r\n\r\n* Issues: **In progress.** We're going to use GitHub issues to track all of the things that we need to work on. This\r\nincludes C++20 features, [LWG issues][], conformance bugs, performance improvements, and other todos. There are\r\napproximately 200 active bugs in the STL's Microsoft-internal database; we need to manually replicate all of them to\r\nGitHub issues. Currently, the [cxx20 tag][] and [LWG tag][] are done; every remaining work item is tracked by a GitHub\r\nissue. The [bug tag][] and [enhancement tag][] are being populated.\r\n\r\n* Plans: **In progress.** We're writing up our [Roadmap][].\r\n\r\n# Goals\r\n\r\nWe're implementing the latest C++ Working Draft, currently [N4885][], which will eventually become the next C++\r\nInternational Standard. The terms Working Draft (WD) and Working Paper (WP) are interchangeable; we often\r\ninformally refer to these drafts as \"the Standard\" while being aware of the difference. (There are other relevant\r\nStandards; for example, supporting `/std:c++14` and `/std:c++17` involves understanding how the C++14 and C++17\r\nStandards differ from the Working Paper, and we often need to refer to the C Standard Library and ECMAScript regular\r\nexpression specifications.) We're currently prioritizing C++20 features before starting any work on C++23.\r\n\r\nOur primary goals are conformance, performance, usability, and compatibility.\r\n\r\n* Conformance: The Working Paper is a moving target; as features and LWG issue resolutions are added, we need to\r\nimplement them. That can involve a lot of work, because the STL is required to behave in very specific ways and to\r\nhandle users doing very unusual things.\r\n\r\n* Performance: The STL needs to be extremely fast at runtime; speed is one of C++'s core strengths, and most C++\r\nprograms use the STL extensively. As a result, we spend more time on optimization than most general-purpose libraries.\r\n(However, we're wary of changes that improve some scenarios at the expense of others, or changes that make code\r\nsignificantly more complicated and fragile. That is, there's a \"complexity budget\" that must be spent carefully.)\r\n\r\n* Usability: This includes parts of the programming experience like compiler throughput, diagnostic messages, and\r\ndebugging checks. For example, we've extensively marked the STL with `[[nodiscard]]` attributes because this helps\r\nprogrammers avoid bugs.\r\n\r\n* Compatibility: This includes binary compatibility and source compatibility. We're keeping VS 2019 binary-compatible\r\nwith VS 2017 and VS 2015, which restricts what we can change in VS 2019 updates. (We've found that significant changes\r\nare possible even though other changes are impossible, which we'll be documenting in our Contribution Guidelines soon.)\r\nWhile there are a few exceptions to this rule (e.g. if a feature is added to the Working Paper, we implement it, and\r\nthen the feature is significantly changed before the International Standard is finalized, we reserve the right to break\r\nbinary compatibility because `/std:c++latest` offers an experimental preview of such features), binary compatibility\r\ngenerally overrides all other considerations, even conformance. Source compatibility refers to being able to\r\nsuccessfully recompile user code without changes. We consider source compatibility to be important, but not\r\nall-important; breaking source compatibility can be an acceptable cost, if done for the right reasons in the right way\r\n(e.g. in a controlled manner with escape hatches).\r\n\r\n# Non-Goals\r\n\r\nThere are things that we aren't interested in doing with this project, for various reasons (most importantly, we need to\r\nfocus development effort on our goals). Some examples:\r\n\r\n* Non-goal: Porting to other platforms.\r\n\r\n* Non-goal: Adding non-Standard extensions.\r\n\r\n* Non-goal: Implementing Technical Specifications. (We're prioritizing features in the Working Paper. Occasionally, we\r\nmight implement some or all of a TS, often when we're working on the specification itself.)\r\n\r\nIf you're proposing a feature to WG21 (the C++ Standardization Committee), you're welcome (and encouraged!) to use our\r\ncode as a base for a proof-of-concept implementation. These non-goals simply mean that we're unable to consider pull\r\nrequests for a proposed feature until it has been voted into a Working Paper. After that happens, we'll be delighted to\r\nreview a production-ready pull request.\r\n\r\n# Reporting Issues\r\n\r\nYou can report STL bugs here, where they'll be directly reviewed by maintainers. You can also report STL bugs through\r\n[Developer Community][], or the VS IDE (Help > Send Feedback > Report a Problem...).\r\n\r\n**Please help us** efficiently process bug reports by following these rules:\r\n\r\n* Only STL bugs should be reported here. If it's a bug in the compiler, CRT, or IDE, please report it through Developer\r\nCommunity or Report A Problem. If it's a bug in the Windows SDK, please report it through the [Feedback Hub][hub] app.\r\nIf you aren't sure, try to reduce your test case and see if you can eliminate the STL's involvement while still\r\nreproducing the bug.\r\n\r\n* You should be reasonably confident that you're looking at an actual implementation bug, instead of undefined behavior\r\nor surprising-yet-Standard behavior. Comparing against other implementations can help (but remember that implementations\r\ncan differ while conforming to the Standard); try Godbolt's [Compiler Explorer][] and [Wandbox][]. If you still aren't\r\nsure, ask the nearest C++ expert.\r\n\r\n* You should prepare a self-contained command-line test case, ideally as small as possible. We need a source file, a\r\ncommand line, what happened (e.g. a compiler error, runtime misbehavior), and what you expected to happen. By\r\n\"self-contained\", we mean that your source file has to avoid including code that we don't have. Ideally, only CRT and\r\nSTL headers should be included. If you have to include other MSVC libraries, or the Windows SDK, to trigger an STL bug,\r\nthat's okay. But if you need parts of your own source code to trigger the STL bug, you need to extract that for us. (On\r\nDeveloper Community, we'll accept zipped IDE projects if you have no other way to reproduce a bug, but this is very\r\ntime-consuming for us to reduce.)\r\n\r\n* A good title is helpful. We prefer \"`<header_name>`: Short description of your issue\". You don't usually need to\r\nmention `std::` or C++. For example, \"`<type_traits>`: `is_cute` should be true for `enum class FluffyKittens`\".\r\n\r\nIt's okay if you report an apparent STL bug that turns out to be a compiler bug, or surprising-yet-Standard behavior.\r\nJust try to follow these rules, so we can spend more time fixing bugs and implementing features.\r\n\r\n# How To Build With The Visual Studio IDE\r\n\r\nThe STL uses boost-math headers to provide P0226R1 Mathematical Special Functions. We recommend using [vcpkg][] to\r\nacquire this dependency.\r\n\r\n1. Install Visual Studio 2019 16.10 Preview 2 or later.\r\n    * We recommend selecting \"C++ CMake tools for Windows\" in the VS Installer.\r\n    This will ensure that you're using supported versions of CMake and Ninja.\r\n    * Otherwise, install [CMake][] 3.20 or later, and [Ninja][] 1.10.2 or later.\r\n2. Open Visual Studio, and choose the \"Clone or check out code\" option. Enter the URL of this repository,\r\n   `https://github.com/microsoft/STL`.\r\n3. Open a terminal in the IDE with `` Ctrl + ` `` (by default) or press on \"View\" in the top bar, and then \"Terminal\".\r\n4. In the terminal, invoke `git submodule update --init --progress llvm-project vcpkg`\r\n5. In the terminal, invoke `.\\vcpkg\\bootstrap-vcpkg.bat`\r\n6. In the terminal, invoke `.\\vcpkg\\vcpkg.exe install boost-math:x86-windows boost-math:x64-windows`\r\n7. Choose the architecture you wish to build in the IDE, and build as you would any other project. All necessary CMake\r\n   settings are set by `CMakeSettings.json`.\r\n\r\n# How To Build With A Native Tools Command Prompt\r\n\r\n1. Install Visual Studio 2019 16.10 Preview 2 or later.\r\n    * We recommend selecting \"C++ CMake tools for Windows\" in the VS Installer.\r\n    This will ensure that you're using supported versions of CMake and Ninja.\r\n    * Otherwise, install [CMake][] 3.20 or later, and [Ninja][] 1.10.2 or later.\r\n2. Open a command prompt.\r\n3. Change directories to a location where you'd like a clone of this STL repository.\r\n4. `git clone https://github.com/microsoft/STL`\r\n5. `cd STL`\r\n6. `git submodule update --init --progress llvm-project vcpkg`\r\n7. `.\\vcpkg\\bootstrap-vcpkg.bat`\r\n8. `.\\vcpkg\\vcpkg.exe install boost-math:x86-windows boost-math:x64-windows`\r\n\r\nTo build the x86 target:\r\n\r\n1. Open an \"x86 Native Tools Command Prompt for VS 2019 Preview\".\r\n2. Change directories to the previously cloned `STL` directory.\r\n3. `cmake -G Ninja -S . -B out\\build\\x86`\r\n4. `ninja -C out\\build\\x86`\r\n\r\nTo build the x64 target:\r\n\r\n1. Open an \"x64 Native Tools Command Prompt for VS 2019 Preview\".\r\n2. Change directories to the previously cloned `STL` directory.\r\n3. `cmake -G Ninja -S . -B out\\build\\x64`\r\n4. `ninja -C out\\build\\x64`\r\n\r\n# How To Consume\r\n\r\nConsumption of the built library is largely based on the build system you're using. There are at least 2 directories\r\nyou need to hook up. Assuming you built the x64 target with the Visual Studio IDE, with the STL repository cloned to\r\n`C:\\Dev\\STL`, build outputs will end up at `C:\\Dev\\STL\\out\\build\\x64\\out`. Ensure that the `inc` directory is searched\r\nfor headers, and that `lib\\{architecture}` is searched for link libraries, before any defaults supplied by MSVC. The\r\nnames of the import and static libraries are the same as those that ship with MSVC. As a result, the compiler `/MD`,\r\n`/MDd`, `/MT`, or `/MTd` switches will work without modification of your build scripts or command-line muscle memory.\r\n\r\nShould you choose to use the DLL flavors, the DLLs to deploy are built to `bin\\{architecture}`. Note that the DLLs\r\ngenerated by the CMake build system here have a suffix, defaulting to `_oss`, which distinguishes them from the binaries\r\nthat ship with MSVC. That avoids any conflict with the DLLs installed by the [redistributables][] into System32, and\r\nensures that other components wanting to be a \"guest in your process\", like print drivers and shell extensions, see the\r\nexport surface of the STL they were built with. Otherwise, the \"`msvcp140.dll`\" you deployed in the same directory as\r\nyour .exe would \"win\" over the versions in System32.\r\n\r\n## Complete Example Using x64 DLL Flavor\r\n\r\nThe compiler looks for include directories according to the `INCLUDE` environment variable, and the linker looks for\r\nimport library directories according to the `LIB` environment variable, and the Windows loader will (eventually) look\r\nfor DLL dependencies according to directories in the `PATH` environment variable. From an\r\n\"x64 Native Tools Command Prompt for VS 2019 Preview\":\r\n\r\n```\r\nC:\\Users\\username\\Desktop>set INCLUDE=C:\\Dev\\STL\\out\\build\\x64\\out\\inc;%INCLUDE%\r\n\r\nC:\\Users\\username\\Desktop>set LIB=C:\\Dev\\STL\\out\\build\\x64\\out\\lib\\amd64;%LIB%\r\n\r\nC:\\Users\\username\\Desktop>set PATH=C:\\Dev\\STL\\out\\build\\x64\\out\\bin\\amd64;%PATH%\r\n\r\nC:\\Users\\username\\Desktop>type example.cpp\r\n#include <iostream>\r\n\r\nint main() {\r\n    std::cout << \"Hello STL OSS world!\\n\";\r\n}\r\n\r\nC:\\Users\\username\\Desktop>cl /nologo /EHsc /W4 /WX /MDd /std:c++latest .\\example.cpp\r\nexample.cpp\r\n\r\nC:\\Users\\username\\Desktop>.\\example.exe\r\nHello STL OSS world!\r\n\r\nC:\\Users\\username\\Desktop>dumpbin /IMPORTS .\\example.exe | findstr msvcp\r\n    msvcp140d_oss.dll\r\n```\r\n\r\n# How To Run The Tests With A Native Tools Command Prompt\r\n\r\n1. Follow either [How To Build With A Native Tools Command Prompt][] or [How To Build With The Visual Studio IDE][].\r\n2. Acquire [Python][] 3.9.4 or newer and have it on the `PATH` (or run it directly using its absolute or relative path).\r\n3. Have LLVM's `bin` directory on the `PATH` (so `clang-cl.exe` is available).\r\n    * We recommend selecting \"C++ Clang tools for Windows\" in the VS Installer. This will automatically add LLVM to the\r\n    `PATH` of the x86 and x64 Native Tools Command Prompts, and will ensure that you're using a supported version.\r\n    * Otherwise, use [LLVM's installer][] and choose to add LLVM to your `PATH` during installation.\r\n4. Follow the instructions below.\r\n\r\n## Running All The Tests\r\n\r\nAfter configuring and building the project, running `ctest` from the build output directory will run all the tests.\r\nCTest will only display the standard error output of tests that failed. In order to get more details from CTest's\r\n`lit` invocations, run the tests with `ctest -V`.\r\n\r\n## Running A Subset Of The Tests\r\n\r\n`${PROJECT_BINARY_DIR}\\tests\\utils\\stl-lit\\stl-lit.py` can be invoked on a subdirectory of a testsuite and will execute\r\nall the tests under that subdirectory. This can mean executing the entirety of a single testsuite, running all tests\r\nunder a category in libcxx, or running a single test in `std` and `tr1`.\r\n\r\n## Examples\r\n\r\nThese examples assume that your current directory is `C:\\Dev\\STL\\out\\build\\x64`.\r\n\r\n* This command will run all of the testsuites with verbose output.\r\n  + `ctest -V`\r\n* This command will also run all of the testsuites.\r\n  + `python tests\\utils\\stl-lit\\stl-lit.py ..\\..\\..\\llvm-project\\libcxx\\test ..\\..\\..\\tests\\std ..\\..\\..\\tests\\tr1`\r\n* This command will run all of the std testsuite.\r\n  + `python tests\\utils\\stl-lit\\stl-lit.py ..\\..\\..\\tests\\std`\r\n* If you want to run a subset of a testsuite, you need to point it to the right place in the sources. The following\r\nwill run the single test found under VSO_0000000_any_calling_conventions.\r\n  + `python tests\\utils\\stl-lit\\stl-lit.py ..\\..\\..\\tests\\std\\tests\\VSO_0000000_any_calling_conventions`\r\n* You can invoke `stl-lit` with any arbitrary subdirectory of a testsuite. In libcxx this allows you to have finer\r\ncontrol over what category of tests you would like to run. The following will run all the libcxx map tests.\r\n  + `python tests\\utils\\stl-lit\\stl-lit.py ..\\..\\..\\llvm-project\\libcxx\\test\\std\\containers\\associative\\map`\r\n\r\n## Interpreting The Results Of Tests\r\n\r\n### CTest\r\n\r\nWhen running the tests via CTest, all of the testsuites are considered to be a single test. If any single test in a\r\ntestsuite fails, CTest will simply report that the `stl` test failed.\r\n\r\nExample:\r\n```\r\n0% tests passed, 1 tests failed out of 1\r\n\r\nTotal Test time (real) = 2441.55 sec\r\n\r\nThe following tests FAILED:\r\n      1 - stl (Failed)\r\n```\r\n\r\nThe primary utility of CTest in this case is to conveniently invoke `stl-lit.py` with the correct set of arguments.\r\n\r\nCTest will output everything that was sent to stderr for each of the failed testsuites, which can be used to identify\r\nwhich individual test within the testsuite failed. It can sometimes be helpful to run CTest with the `-V` option in\r\norder to see the stdout of the tests.\r\n\r\n### stl-lit\r\n\r\nWhen running the tests directly via the generated `stl-lit.py` script the result of each test will be printed. The\r\nformat of each result is `{Result Code}: {Testsuite Name} :: {Test Name}:{Configuration Number}`.\r\n\r\nExample:\r\n```\r\n-- Testing: 28 tests, 12 workers --\r\nPASS: tr1 :: tests/cwchar1:01 (1 of 28)\r\nPASS: tr1 :: tests/cwchar1:11 (2 of 28)\r\nPASS: tr1 :: tests/cwchar1:02 (3 of 28)\r\nPASS: tr1 :: tests/cwchar1:03 (4 of 28)\r\nPASS: tr1 :: tests/cwchar1:00 (5 of 28)\r\nPASS: tr1 :: tests/cwchar1:04 (6 of 28)\r\nPASS: tr1 :: tests/cwchar1:05 (7 of 28)\r\nPASS: tr1 :: tests/cwchar1:09 (8 of 28)\r\nPASS: tr1 :: tests/cwchar1:06 (9 of 28)\r\nUNSUPPORTED: tr1 :: tests/cwchar1:20 (10 of 28)\r\nUNSUPPORTED: tr1 :: tests/cwchar1:21 (11 of 28)\r\nUNSUPPORTED: tr1 :: tests/cwchar1:22 (12 of 28)\r\nUNSUPPORTED: tr1 :: tests/cwchar1:23 (13 of 28)\r\nUNSUPPORTED: tr1 :: tests/cwchar1:24 (14 of 28)\r\nPASS: tr1 :: tests/cwchar1:07 (15 of 28)\r\nPASS: tr1 :: tests/cwchar1:08 (16 of 28)\r\nPASS: tr1 :: tests/cwchar1:10 (17 of 28)\r\nPASS: tr1 :: tests/cwchar1:16 (18 of 28)\r\nPASS: tr1 :: tests/cwchar1:17 (19 of 28)\r\nPASS: tr1 :: tests/cwchar1:14 (20 of 28)\r\nPASS: tr1 :: tests/cwchar1:12 (21 of 28)\r\nPASS: tr1 :: tests/cwchar1:13 (22 of 28)\r\nPASS: tr1 :: tests/cwchar1:19 (23 of 28)\r\nPASS: tr1 :: tests/cwchar1:18 (24 of 28)\r\nPASS: tr1 :: tests/cwchar1:15 (25 of 28)\r\nPASS: tr1 :: tests/cwchar1:25 (26 of 28)\r\nPASS: tr1 :: tests/cwchar1:26 (27 of 28)\r\nPASS: tr1 :: tests/cwchar1:27 (28 of 28)\r\n\r\nTesting Time: 3.96s\r\n  Expected Passes    : 23\r\n  Unsupported Tests  : 5\r\n```\r\n\r\nIn the above example we see that 23 tests succeeded and 5 were unsupported.\r\n\r\n### Result Code Values\r\n\r\nOur tests use the standard [lit result codes][], and an undocumented result code: `SKIPPED`. For our tests, only the\r\n`PASS`, `XFAIL`, `XPASS`, `FAIL`, `UNSUPPORTED`, and `SKIPPED` result codes are relevant.\r\n\r\nThe `PASS` and `FAIL` result codes are self-explanatory. We want our tests to `PASS` and not `FAIL`.\r\n\r\nThe `XPASS` and `XFAIL` result codes are less obvious. `XPASS` is actually a failure result and indicates that we\r\nexpected a test to fail but it passed. `XFAIL` is a successful result and indicates that we expected the test to fail\r\nand it did. Typically an `XPASS` result means that the `expected_results.txt` file for the testsuite needs to be\r\nmodified. If the `XPASS` result is a test legitimately passing, the usual course of action would be to remove a `FAIL`\r\nentry from the `expected_results.txt`. However, some tests from `libcxx` mark themselves as `XFAIL` (meaning they\r\nexpect to fail) for features they have added tests for but have yet to implement in `libcxx`. If the STL implements\r\nthose features first the tests will begin passing unexpectedly for us and return `XPASS` results. In order to resolve\r\nthis it is necessary to add a `PASS` entry to the `expected_results.txt` of the testsuite in question.\r\n\r\nThe `UNSUPPORTED` result code means that the requirements for a test are not met and so it will not be run. Currently\r\nall tests which use the `/clr` or `/clr:pure` options are unsupported. Also, the `/BE` option is unsupported for x64.\r\n\r\nThe `SKIPPED` result code indicates that a given test was explicitly skipped by adding a `SKIPPED` entry to the\r\n`expected_results.txt`. A test may be skipped for a number of reasons, which include, but are not limited to:\r\n* being an incorrect test\r\n* taking a very long time to run\r\n* failing or passing for the incorrect reason\r\n\r\n### Debugging Individual Tests\r\n\r\nWhile `stl-lit` is super awesome in finding out that *something* is wrong or not even compiling, it is not really\r\nhelpful in debugging *what* is going wrong. However, debugging individual tests is rather simple given some additional\r\nsteps. Let's assume we want to debug a new feature with tests located in `tests\\std\\tests\\GH_XXXX_meow`.\r\n\r\nAs always, build the STL from your branch and run the tests:\r\n```\r\nC:\\STL\\out\\build\\x64> ninja\r\nC:\\STL\\out\\build\\x64> python tests\\utils\\stl-lit\\stl-lit.py -v C:\\STL\\tests\\std\\tests\\GH_XXXX_meow\r\n```\r\n\r\nLet's assume one of the tests fails an assert and we want to debug that configuration. `stl-lit` will conveniently print\r\nthe build command, which is far too long to provide here in full. The important part is to add the following options to\r\nprovide debug symbols: `/Zi /Fdbark.pdb`.\r\n\r\nYou can replace `bark` with any descriptive name you like. Add these before the `\"-link\"` option in the command line\r\nand recompile. Example:\r\n```\r\nC:\\STL\\out\\build\\x64>cl \"C:\\STL\\tests\\std\\tests\\GH_XXXX_meow\\test.cpp\" [... more arguments ...]\r\n\"-FeC:\\STL\\out\\build\\x64\\tests\\std\\tests\\GH_XXXX_meow\\Output\\02\\GH_XXXX_meow.exe\" /Zi /Fdbark.pdb \"-link\"\r\n[... more arguments ...]\r\n```\r\n\r\nYou can now start debugging the test via:\r\n```\r\ndevenv \"C:\\STL\\out\\build\\x64\\tests\\std\\tests\\GH_XXXX_meow\\Output\\02\\GH_XXXX_meow.exe\"\r\n       \"C:\\STL\\tests\\std\\tests\\GH_XXXX_meow\\test.cpp\"\r\n```\r\n\r\nHowever, this might not work right away, as Visual Studio may complain about a missing `msvcp140_oss.dll`. The reason\r\nis that the STL builds those and other DLLs itself and we should under no circumstances overwrite the installed ones.\r\nIf you are testing one of the configurations with dynamic linkage (`/MD` or `/MDd`) the easiest solution is to add the\r\nbuild folder to your path:\r\n```\r\nset PATH=C:\\STL\\out\\build\\x64\\out\\bin\\amd64;%PATH%\r\n```\r\n\r\n# Editing And Testing The Debugger Visualizer\r\n\r\n### Modify The Visualizer\r\n\r\nTo modify how components are visualized in the debugger edit the file `stl\\debugger\\STL.natvis`. For more information on\r\nhow to modify this file check the [natvis documentation][].\r\n\r\n### Test Your Changes\r\n\r\nYou can add the natvis file to any Visual Studio C++ project if you right click your project > Add > Existing Item and\r\nselect the STL.natvis file. After doing this you should be able to see your changes in a Visual Studio debugging\r\nsession.\r\n\r\n# Block Diagram\r\n\r\nThe STL is built atop other compiler support libraries that ship with Windows and Visual Studio, like the UCRT,\r\nVCRuntime, and VCStartup. The following diagram describes the dependencies between those components and their ship\r\nvehicles.\r\n\r\n![MSVC Libraries Block Diagram](docs/msvc_libraries.plantuml.svg)\r\n\r\n# Contributing\r\n\r\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\n# Code Of Conduct\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct][]. For more information see the\r\n[Code of Conduct FAQ][] or contact [opencode@microsoft.com][] with any additional questions or comments.\r\n\r\n# License\r\n\r\nCopyright (c) Microsoft Corporation.\r\n\r\nSPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\r\n\r\n[Changelog]: https://github.com/microsoft/STL/wiki/Changelog\r\n[clang-format]: https://clang.llvm.org/docs/ClangFormat.html\r\n[CMake]: https://cmake.org/download\r\n[Code of Conduct FAQ]: https://opensource.microsoft.com/codeofconduct/faq/\r\n[Compiler Explorer]: https://godbolt.org\r\n[Developer Community]: https://aka.ms/feedback/report?space=62\r\n[Discord server]: https://discord.gg/XWanNww\r\n[How To Build With A Native Tools Command Prompt]: #how-to-build-with-a-native-tools-command-prompt\r\n[How To Build With The Visual Studio IDE]: #how-to-build-with-the-visual-studio-ide\r\n[LICENSE.txt]: LICENSE.txt\r\n[LLVM's installer]: https://releases.llvm.org/download.html\r\n[LWG issues]: https://cplusplus.github.io/LWG/lwg-toc.html\r\n[LWG tag]: https://github.com/microsoft/STL/issues?q=is%3Aopen+is%3Aissue+label%3ALWG\r\n[Microsoft Open Source Code of Conduct]: https://opensource.microsoft.com/codeofconduct/\r\n[N4885]: https://wg21.link/n4885\r\n[NOTICE.txt]: NOTICE.txt\r\n[Ninja]: https://ninja-build.org\r\n[Pipelines]: https://dev.azure.com/vclibs/STL/_build/latest?definitionId=4&branchName=main\r\n[Python]: https://www.python.org/downloads/windows/\r\n[Roadmap]: https://github.com/microsoft/STL/wiki/Roadmap\r\n[Status Chart]: https://microsoft.github.io/STL/\r\n[Wandbox]: https://wandbox.org\r\n[bug tag]: https://github.com/microsoft/STL/issues?q=is%3Aopen+is%3Aissue+label%3Abug\r\n[cxx20 tag]: https://github.com/microsoft/STL/issues?q=is%3Aopen+is%3Aissue+label%3Acxx20\r\n[enhancement tag]: https://github.com/microsoft/STL/issues?q=is%3Aopen+is%3Aissue+label%3Aenhancement\r\n[hub]: https://support.microsoft.com/en-us/help/4021566/windows-10-send-feedback-to-microsoft-with-feedback-hub-app\r\n[libcxx]: https://libcxx.llvm.org\r\n[lit]: https://llvm.org/docs/CommandGuide/lit.html\r\n[lit result codes]: https://llvm.org/docs/CommandGuide/lit.html#test-status-results\r\n[opencode@microsoft.com]: mailto:opencode@microsoft.com\r\n[redistributables]: https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads\r\n[vcpkg]: https://github.com/microsoft/vcpkg\r\n[natvis documentation]: https://docs.microsoft.com/en-us/visualstudio/debugger/create-custom-views-of-native-objects\r\n"
 },
 {
  "repo": "microsoft/ai-edu",
  "language": "HTML",
  "readme_contents": "# <font size=5>\u5fae\u8f6f\u4eba\u5de5\u667a\u80fd\u6559\u80b2\u4e0e\u5b66\u4e60\u5171\u5efa\u793e\u533a</font>\n\u672c\u793e\u533a\u662f\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662\uff08Microsoft Research Asia\uff0c\u7b80\u79f0MSRA\uff09\u4eba\u5de5\u667a\u80fd\u6559\u80b2\u56e2\u961f\u521b\u7acb\u7684\u4eba\u5de5\u667a\u80fd\u6559\u80b2\u4e0e\u5b66\u4e60\u5171\u5efa\u793e\u533a.\n\n\u5728\u6559\u80b2\u90e8\u6307\u5bfc\u4e0b\uff0c\u4f9d\u6258\u4e8e\u65b0\u4e00\u4ee3\u4eba\u5de5\u667a\u80fd\u5f00\u653e\u79d1\u7814\u6559\u80b2\u5e73\u53f0\uff0c\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662\u7814\u53d1\u56e2\u961f\u548c\u5b66\u672f\u5408\u4f5c\u90e8\u5c06\u4e3a\u672c\u793e\u533a\u63d0\u4f9b\u5168\u9762\u652f\u6301\u3002\u6211\u4eec\u5c06\u5728\u6b64\u63d0\u4f9b\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u5f00\u53d1\u7684\u771f\u5b9e\u6848\u4f8b\uff0c\u4ee5\u53ca\u914d\u5957\u7684\u6559\u7a0b\u3001\u5de5\u5177\u7b49\u5b66\u4e60\u8d44\u6e90\uff0c\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u4e00\u7ebf\u6559\u5e08\u53ca\u5b66\u4e60\u8005\u4e5f\u5c06\u5206\u4eab\u4ed6\u4eec\u7684\u8d44\u6e90\u4e0e\u7ecf\u9a8c\u3002\n\n\u6b63\u5982\u5fae\u8f6f\u7684\u4f7f\u547d\u201c\u4e88\u529b\u5168\u7403\u6bcf\u4e00\u4eba\u3001\u6bcf\u4e00\u7ec4\u7ec7\uff0c\u6210\u5c31\u4e0d\u51e1\u201d\u6240\u6307\u51fa\u7684\uff0c\u671f\u5f85\u501f\u7531\u672c\u793e\u533a\u7684\u5efa\u7acb\uff0c\u80fd\u4ee5\u5f00\u6e90\u7684\u65b9\u5f0f\uff0c\u4e0e\u5e7f\u5927\u5e08\u751f\u3001\u5f00\u53d1\u8005\u4e00\u8d77\u5b66\u4e60\u3001\u4e00\u8d77\u8d21\u732e\uff0c\u5171\u540c\u4e30\u5bcc\u3001\u5b8c\u5584\u672c\u793e\u533a\uff0c\u65e2\u800c\u4e3a\u4e2d\u56fd\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u6dfb\u7816\u52a0\u74e6\u3002\n\n\n\u672c\u793e\u533a\u6ce8\u660e\u7248\u6743\u51fa\u5904\u7684\u5185\u5bb9\u9002\u7528\u4e8e[License](./LICENSE.md)\u7248\u6743\u8bb8\u53ef\u3002\n\n[English Version](./0-EnglishVersion/README.md)\n\n# <font size=5>\u65b0\u95fb</font>\n\n**<font size=3>2021-04-20:</font>**  \n\n\u66f4\u65b0[\u4e2d\u6587\u6587\u672c\u8574\u542b](./B-\u5b9e\u8df5\u6848\u4f8b/B17-\u5feb\u901f\u6784\u5efa\u4e2d\u6587\u6587\u672c\u8574\u542b\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b/Readme.md)\u6848\u4f8b\n\n**<font size=3>2021-03-07:</font>**\n\nA7-\u5f3a\u5316\u5b66\u4e60\uff0c\u51c6\u5907\u4e2d\u3002\n\n**<font size=3>2021-02-07:</font>**\n\n\u65b0\u4e66\u51fa\u7248\uff01\n\n<img src=\"./A-\u57fa\u7840\u6559\u7a0b/A2-\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u539f\u7406/Images/cover.png\" width=300/>\n\n\u76ee\u524d\u5728\u5404\u5927\u7f51\u5e97\u90fd\u53ef\u4ee5\u4e70\u5230\u3002\u5168\u4e66400\u591a\u9875\uff0c\u5168\u5f69\u5370\u5237\uff0c\u7531\u9ad8\u7b49\u6559\u80b2\u51fa\u7248\u793e\u51fa\u7248\uff0c\u662f\u4e0b\u9762\u6240\u8ff0\u7684\u201c\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u539f\u7406\u6559\u7a0b\u201d\u7684\u5370\u5237\u7248\u3002\n\n**<font size=3>2021-01-07:</font>**\n\nA5-\u73b0\u4ee3\u8f6f\u4ef6\u5de5\u7a0b\uff0c\u5f00\u59cb\u7f16\u5199\u3002\n\n\n**<font size=3>2020-03-25:</font>**\n\n\u793e\u533a\u7ed3\u6784\u66f4\u65b0\u5566\uff01\u6a21\u5757\u8c03\u6574\u5e76\u91cd\u65b0\u547d\u540d\uff0c\u7ed3\u6784\u66f4\u6e05\u6670\uff01\n\n\u5c06[\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u539f\u7406\u6559\u7a0b](https://aka.ms/beginnerAI) \u79fb\u5165 [A-\u57fa\u7840\u6559\u7a0b](https://github.com/microsoft/ai-edu/tree/master/A-\u57fa\u7840\u6559\u7a0b) \u6a21\u5757\u3002\u8be5\u6a21\u5757\u4e0b\u8fd8\u6709 [\u6570\u5b66\u57fa\u7840](https://github.com/microsoft/ai-edu/tree/master/A-\u57fa\u7840\u6559\u7a0b/A1-PythonBasic/math_intro) \u548c [Python\u8bed\u8a00\u5bfc\u8bba](https://github.com/microsoft/ai-edu/tree/master/A-\u57fa\u7840\u6559\u7a0b/A1-PythonBasic/py_intro)\u3002\u6559\u7a0b\u66f4\u96c6\u4e2d\uff0c\u5b66\u4e60\u66f4\u65b9\u4fbf\uff01\n\n\u5b9e\u8df5\u6848\u4f8b\u5168\u90e8\u6c47\u96c6\u5728 [B-\u5b9e\u8df5\u6848\u4f8b](https://github.com/microsoft/ai-edu/tree/master/B-\u5b9e\u8df5\u6848\u4f8b) \u6a21\u5757\uff0c\u5e76\u914d\u4e0a\u6848\u4f8b\u6982\u89c8\u5e2e\u52a9\u6587\u6863\uff0c\u66f4\u6709\u9488\u5bf9\u6027\u5b66\u4e60\u6848\u4f8b\uff01\n\n[E-\u8bfe\u7a0b\u96c6\u9526](https://github.com/microsoft/ai-edu/tree/master/E-\u8bfe\u7a0b\u96c6\u9526/) \u6a21\u5757\u6c47\u96c6\u4e86\u5fae\u8f6f\u53ca\u591a\u6240\u9ad8\u6821\u5f00\u6e90\u4eba\u5de5\u667a\u80fd\u6559\u5b66\u5927\u7eb2\u53ca\u8bfe\u4ef6\u3002\u6b22\u8fce\u611f\u5174\u8da3\u7684\u670b\u53cb\u524d\u5f80\u67e5\u770b\uff01\n\n**<font size=3>2019-11-20:</font>**\n\n\u9996\u9875\u6539\u7248\u5566\uff01\u65b0\u7248\u672c\u7684\u9996\u9875\uff0c\u5c06\u793e\u533a\u8d44\u6e90\u8fdb\u4e00\u6b65\u7cfb\u7edf\u5316\uff0c\u6309\u8ba4\u8bc6AI\uff08\u521d\u7ea7\uff09\uff0c\u7406\u89e3AI\uff08\u4e2d\u7ea7\uff09,\u7814\u7a76AI\uff08\u9ad8\u7ea7\uff09\u7684\u7ed3\u6784\u5206\u7ea7\u7f16\u5199\u4e86\u5b66\u4e60\u8def\u5f84\uff0c\u5e76\u7ed9\u51fa\u5b66\u4e60\u65f6\u957f\u53c2\u8003\uff0c\u5148\u4fee\u77e5\u8bc6\u8d44\u6e90\u53c2\u8003\uff0c\u5faa\u5e8f\u6e10\u8fdb\uff0c\u65e8\u5728\u5e2e\u52a9\u5e7f\u5927\u5b66\u4e60\u8005\u66f4\u6700\u9ad8\u6548\u5730\u5b66\u4e60AI\uff0c\u8d76\u5feb\u5b66\u8d77\u6765\u5427\uff01\n\n**<font size=3>2019-11-19:</font>**\n\n\u66f4\u65b0[\u667a\u80fd\u5bf9\u8054](./B-\u5b9e\u8df5\u6848\u4f8b/B13-AI\u5bf9\u8054\u751f\u6210\u6848\u4f8b)\u6848\u4f8b\uff0c\u6848\u4f8b\u66f4\u52a0\u7b80\u6d01\u3001\u6e05\u6670\uff0c\u65b9\u4fbf\u4e0a\u624b\uff01\n\n**<font size=3>2019-11-15:</font>**\n\n[\u795e\u7ecf\u7f51\u7edc\u57fa\u672c\u539f\u7406\u7b80\u660e\u6559\u7a0b](https://aka.ms/beginnerAI)\u66a8**9\u6b65\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc**\u5168\u90e8\u5185\u5bb9\u5b8c\u6210\uff01\n\n# <font size=5>\u5b66\u4e60\u8d44\u6e90\u4ecb\u7ecd</font>\n\u4ecb\u7ecd\uff1a\n\n\u672c\u793e\u533a\u7684\u5b66\u4e60\u8d44\u6e90\u4f18\u8d28\u4e14\u514d\u8d39\uff0c\u7edd\u5927\u90e8\u5206\u4e3a\u539f\u521b\u5185\u5bb9\uff0c\u6838\u5fc3\u5b66\u4e60\u8d44\u6e90\u5305\u62ec**\u5b9e\u6218\u7bc7**\u548c**\u7406\u8bba\u7bc7**\u4e24\u5927\u90e8\u5206\uff0c\u8f85\u4ee5\u53c2\u8003\u5b66\u4e60\u8def\u5f84\u548c\u5148\u4fee\u77e5\u8bc6\u53c2\u8003\u8d44\u6e90\uff0c\u8ba9\u5e7f\u5927\u5b66\u4e60\u8005\u53ef\u4ee5\u6e05\u6670\u5730\u9009\u62e9\u9002\u5408\u81ea\u5df1\u7684\u5b66\u4e60\u8def\u5f84\uff0c\u9ad8\u6548\u5730\u5b66\u4e60\u3002\n\n**1. \u5b9e\u6218\u7bc7**\n\n\u4ee5\u201c\u505a\u4e2d\u5b66\u201c\u7684\u7406\u5ff5\u4e3a\u6838\u5fc3\uff0c\u4ece\u4eba\u5de5\u667a\u80fd\u771f\u5b9e\u7684\u5e94\u7528\u573a\u666f\u4e0e\u6848\u4f8b\u51fa\u53d1\uff0c\u5148\u8bb2\u751f\u52a8\u7684\u6848\u4f8b\uff0c\u914d\u5408\u8be6\u5b9e\u7684\u5b9e\u9645\u64cd\u4f5c\u8bf4\u660e\uff0c\u7136\u540e\u5728\u52a8\u624b\u5b9e\u73b0\u573a\u666f\u7684\u57fa\u7840\u4e0a\uff0c\u9010\u6b65\u5f15\u5165\u4eba\u5de5\u667a\u80fd\u5b66\u4e60\u4e2d\u7684\u76f8\u5173\u7406\u8bba\u77e5\u8bc6\uff0c\u4ee5\u9012\u8fdb\u5b66\u4e60\u7684\u65b0\u9896\u65b9\u5f0f\u5c42\u5c42\u5256\u6790\u4eba\u5de5\u667a\u80fd\u5f00\u53d1\u7684\u4e3b\u6d41\u573a\u666f\uff0c\u8ba9\u5927\u5bb6\u5728\u4e0d\u9700\u8981\u5927\u91cf\u65f6\u95f4\u5b66\u4e60\u5e9e\u5927\u7684\u7406\u8bba\u57fa\u7840\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u53ef\u4ee5\u771f\u6b63\u52a8\u624b\u5f00\u59cb\u8fdb\u884c\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u7684\u5f00\u53d1\uff0c\u63d0\u9ad8\u5b9e\u9645\u52a8\u624b\u7684\u80fd\u529b.\n\n[\u70b9\u6b64\u8fdb\u5165\u8be6\u7ec6\u5185\u5bb9](https://github.com/microsoft/ai-edu/tree/master/B-\u5b9e\u8df5\u6848\u4f8b)\n\n\n**2. \u7406\u8bba\u7bc7**\n\n\u7406\u8bba\u7bc7\u7684\u5185\u5bb9\u53c8\u79f0\u4f5c\u201c[9\u6b65\u5b66\u4e60\u795e\u7ecf\u7f51\u7edc](https://aka.ms/beginnerAI )\u201d,\u4e3a\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662\u7814\u53d1\u56e2\u961f\u539f\u521b\u5185\u5bb9\uff0c\u7740\u91cd\u8bb2\u8ff0\u504f\u7406\u8bba\u7684\u77e5\u8bc6\uff0c\u540c\u6837\u4ee5\u201c\u505a\u4e2d\u5b66\u201d\u4e3a\u6838\u5fc3\u6982\u5ff5\uff0c\u4f46\u662f\u72ec\u7279\u5730\u4ee5\u5316\u7e41\u4e3a\u7b80\uff0c\u6df1\u5165\u6d45\u51fa\u4e3a\u7279\u70b9\uff0c\u63d0\u4f9b\u901a\u4fd7\u6613\u61c2\u7684\u7406\u8bba\u8bb2\u89e3\uff0c\u6e05\u6670\u5de5\u6574\u7684\u4ee3\u7801\uff0c\u51c6\u786e\u65e0\u8bef\u7684\u5185\u5bb9\uff0c\u5b8c\u6574\u7684\u4f5c\u4e1a\u4f53\u7cfb\uff0c\u4e0d\u4f46\u6709\u7406\u8bba\uff0c\u8fd8\u6709\u5927\u91cf\u5b9e\u8df5\u52a8\u624b\u73af\u8282\uff0c\u5e2e\u52a9\u8bfb\u8005\u4e0d\u4f46\u8fc5\u901f\u638c\u63e1\u201c\u6df1\u5ea6\u5b66\u4e60\u201d\u7684\u57fa\u7840\u77e5\u8bc6\uff0c\u66f4\u597d\u5730\u7406\u89e3\u5e76\u4f7f\u7528\u73b0\u6709\u6846\u67b6\uff0c\u800c\u4e14\u53ef\u4ee5\u52a9\u529b\u8bfb\u8005\u5feb\u901f\u5b66\u4e60\u6700\u65b0\u51fa\u73b0\u7684\u5404\u79cd\u795e\u7ecf\u7f51\u7edc\u7684\u6269\u5c55\u6216\u8005\u53d8\u578b\uff0c\u8ddf\u4e0a\u5feb\u901f\u53d1\u5c55\u7684AI\u6d6a\u6f6e,\u4f7f\u5b66\u4e60\u8005\u4ece\u65b0\u7684\u89d2\u5ea6\u5feb\u901f\u4e0a\u624b\u795e\u7ecf\u7f51\u7edc\u7684\u5b66\u4e60\uff0c\u505a\u5230\u771f\u6b63\u7684\u4ece\u5165\u95e8\u5230\u7cbe\u901a\u3002\u8be5\u90e8\u5206\u5185\u5bb9\u5728\u9488\u5bf9\u5408\u4f5c\u4f19\u4f34\u7ebf\u4e0b\u7684\u57f9\u8bad\u4e2d\uff0c\u53d7\u5230\u5e7f\u5927\u5b66\u4e60\u8005\u7684\u5e7f\u6cdb\u597d\u8bc4\u3002\n\n[\u70b9\u6b64\u8fdb\u5165\u8be6\u7ec6\u5185\u5bb9](https://github.com/microsoft/ai-edu/tree/master/A-\u57fa\u7840\u6559\u7a0b)\n\n\n# <font size=5>AI \u524d\u6cbf\u7cbe\u9009</font>\n[\u5927\u89c4\u6a21\u5229\u7528\u5355\u8bed\u6570\u636e\u63d0\u5347\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1](https://www.msra.cn/zh-cn/news/features/emnlp-2019-exploiting-monolingual-data-at-scale-for-nmt)\n\n[\u57fa\u4e8e\u5c42\u6b21\u5316\u6ce8\u610f\u529b\u56fe\u7f51\u7edc\u548c\u591a\u89c6\u89d2\u5b66\u4e60\u7684\u5546\u54c1\u63a8\u8350](https://www.msra.cn/zh-cn/news/features/emnlp-2019-rmg)\n\n[AI\u6362\u8138\u9274\u522b\u7387\u8d8599.6%\uff0c\u5fae\u8f6f\u7528\u6280\u672f\u5e94\u5bf9\u865a\u5047\u4fe1\u606f](https://www.msra.cn/zh-cn/news/features/ai-detect-fake-face)\n\n[\u5fae\u8f6f\u4e9a\u6d32\u7814\u7a76\u9662\u7cbe\u9009\u8bba\u6587\u89e3\u8bfb](https://www.msra.cn/zh-cn/news/features/emnlp-2019)\n\n[\u67e5\u770b\u66f4\u591a...](https://www.msra.cn/zh-cn/news?wd&content-type=posts)\n\n\n# <font size=5>\u7b49\u4f60\u6765\u6218</font>\n  - [\u6311\u6218\u9ec4\u91d1\u70b9](./C-\u6311\u6218\u9879\u76ee/GoldenNumberGame)\n  - [\u5317\u4eac\u822a\u7a7a\u822a\u5929\u5927\u5b662019\u6625\u5b63](./C-\u6311\u6218\u9879\u76ee/BeihangUniversity2019Spring)\n  - [\u5c71\u4e1c\u5927\u5b662019\u6625\u5b63](./C-\u6311\u6218\u9879\u76ee/ShandongUniversity2019Spring)\n  - [Code Search](./C-\u6311\u6218\u9879\u76ee/CodeSearch)\n  - [2019\u5b9e\u8df5\u7a7a\u95f4\u7ad9](./C-\u6311\u6218\u9879\u76ee/2019studentclub)\n\n\n# <font size=5>\u5982\u4f55\u8d21\u732e</font>\n\u6211\u4eec\u975e\u5e38\u6b22\u8fce\u60a8\u53c2\u4e0e\u5230\u793e\u533a\u5171\u5efa\u4e2d\u6765\uff0c\u8d21\u732e\u9ad8\u8d28\u91cf\u7684\u5185\u5bb9\uff0c\u4e30\u5bcc\u793e\u533a\u8d44\u6e90\u5e76\u5e2e\u52a9\u66f4\u591a\u5b66\u4e60\u8005\u3002\u5728\u60a8\u51c6\u5907\u8d21\u732e\u4e4b\u524d\uff0c\u8bf7\u4ed4\u7ec6\u9605\u8bfb[\u5171\u5efa\u6307\u5357](./CONTRIBUTING.md)\uff0c \u5e76\u9075\u5b88\u5176\u4e2d\u7684\u89c4\u8303\uff0c\u5e76\u786e\u4fdd\u60a8\u6240\u8d21\u732e\u7684\u5185\u5bb9\u7b26\u5408\u6211\u4eec\u7684[License](./LICENSE.md)\u3002\u5982\u9700\u4e86\u89e3\u8d21\u732e\u7684\u6b65\u9aa4\u548c\u5177\u4f53\u6280\u5de7\uff0c\u8bf7\u53c2\u9605[\u5982\u4f55\u9ad8\u6548\u8d21\u732e](./contribute_efficiently.md)\u3002\n\n----\n\n<font size=2>[\u8bbf\u95ee\u65e7\u7248\u4e3b\u9875 (Version 1.0)](./README_1.0.md)</font>\n\n<font size=2>[\u8bbf\u95ee\u65e7\u7248\u4e3b\u9875 (Version 2.0)](./README_2.0.md)</font>"
 },
 {
  "repo": "microsoft/playwright-python",
  "language": "Python",
  "readme_contents": "# \ud83c\udfad [Playwright](https://playwright.dev) for Python [![PyPI version](https://badge.fury.io/py/playwright.svg)](https://pypi.python.org/pypi/playwright/) [![Join Slack](https://img.shields.io/badge/join-slack-infomational)](https://aka.ms/playwright-slack)\n\n#### [Docs](https://playwright.dev/python/docs/intro) | [API](https://playwright.dev/python/docs/api/class-playwright)\n\nPlaywright is a Python library to automate [Chromium](https://www.chromium.org/Home), [Firefox](https://www.mozilla.org/en-US/firefox/new/) and [WebKit](https://webkit.org/) browsers with a single API. Playwright delivers automation that is **ever-green**, **capable**, **reliable** and **fast**. [See how Playwright is better](https://playwright.dev/python/docs/why-playwright).\n\n|          | Linux | macOS | Windows |\n|   :---   | :---: | :---: | :---:   |\n| Chromium <!-- GEN:chromium-version -->92.0.4498.0<!-- GEN:stop --> | \u2705 | \u2705 | \u2705 |\n| WebKit <!-- GEN:webkit-version -->14.2<!-- GEN:stop --> | \u2705 | \u2705 | \u2705 |\n| Firefox <!-- GEN:firefox-version -->89.0b6<!-- GEN:stop --> | \u2705 | \u2705 | \u2705 |\n\nHeadless execution is supported for all browsers on all platforms.\n\n- [Usage](#usage)\n  - [Record and generate code](#record-and-generate-code)\n  - [Sync API](#sync-api)\n  - [Async API](#async-api)\n  - [With pytest](#with-pytest)\n  - [Interactive mode (REPL)](#interactive-mode-repl)\n- [Examples](#examples)\n  - [Mobile and geolocation](#mobile-and-geolocation)\n  - [Evaluate JS in browser](#evaluate-js-in-browser)\n  - [Intercept network requests](#intercept-network-requests)\n- [Documentation](#documentation)\n\n## Usage\n\n```sh\npip install playwright\nplaywright install\n```\n\nThis installs Playwright and browser binaries for Chromium, Firefox and WebKit. Playwright requires Python 3.7+.\n\n#### Record and generate code\n\nPlaywright can record user interactions in a browser and generate code. [See demo](https://user-images.githubusercontent.com/284612/95930164-ad52fb80-0d7a-11eb-852d-04bfd19de800.gif).\n\n```sh\n# Pass --help to see all options\nplaywright codegen\n```\n\nPlaywright offers both sync (blocking) API and async API. They are identical in terms of capabilities and only differ in how one consumes the API.\n\n#### Sync API\n\nThis is our default API for short snippets and tests. If you are not using asyncio in your\napplication, it is the easiest to use Sync API notation.\n\n```py\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    for browser_type in [p.chromium, p.firefox, p.webkit]:\n        browser = browser_type.launch()\n        page = browser.new_page()\n        page.goto('http://whatsmyuseragent.org/')\n        page.screenshot(path=f'example-{browser_type.name}.png')\n        browser.close()\n```\n\n#### Async API\n\nIf your app is based on the modern asyncio loop and you are used to async/await constructs,\nPlaywright exposes Async API for you. You should use this API inside a Python REPL supporting `asyncio` like with `python -m asyncio`\n\n```console\n$ python -m asyncio\n```\n\n```py\nimport asyncio\nfrom playwright.async_api import async_playwright\n\nasync def main():\n    async with async_playwright() as p:\n        for browser_type in [p.chromium, p.firefox, p.webkit]:\n            browser = await browser_type.launch()\n            page = await browser.new_page()\n            await page.goto('http://whatsmyuseragent.org/')\n            await page.screenshot(path=f'example-{browser_type.name}.png')\n            await browser.close()\n\nasyncio.run(main())\n```\n\n#### With pytest\n\nUse our [pytest plugin for Playwright](https://github.com/microsoft/playwright-pytest#readme).\n\n```py\ndef test_playwright_is_visible_on_google(page):\n    page.goto(\"https://www.google.com\")\n    page.type(\"input[name=q]\", \"Playwright GitHub\")\n    page.click(\"input[type=submit]\")\n    page.wait_for_selector(\"text=microsoft/Playwright\")\n```\n\n#### Interactive mode (REPL)\n\nBlocking REPL, as in CLI:\n\n```py\n>>> from playwright.sync_api import sync_playwright\n>>> playwright = sync_playwright().start()\n\n# Use playwright.chromium, playwright.firefox or playwright.webkit\n# Pass headless=False to see the browser UI\n>>> browser = playwright.chromium.launch()\n>>> page = browser.new_page()\n>>> page.goto(\"http://whatsmyuseragent.org/\")\n>>> page.screenshot(path=\"example.png\")\n>>> browser.close()\n>>> playwright.stop()\n```\n\nAsync REPL such as `asyncio` REPL:\n\n```console\n$ python -m asyncio\n```\n\n```py\n>>> from playwright.async_api import async_playwright\n>>> playwright = await async_playwright().start()\n>>> browser = await playwright.chromium.launch()\n>>> page = await browser.new_page()\n>>> await page.goto(\"http://whatsmyuseragent.org/\")\n>>> await page.screenshot(path=\"example.png\")\n>>> await browser.close()\n>>> await playwright.stop()\n```\n\n## Examples\n\n#### Mobile and geolocation\n\nThis snippet emulates Mobile Safari on a device at a given geolocation, navigates to maps.google.com, performs action and takes a screenshot.\n\n```py\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    iphone_11 = p.devices[\"iPhone 11 Pro\"]\n    browser = p.webkit.launch(headless=False)\n    context = browser.new_context(\n        **iphone_11,\n        locale=\"en-US\",\n        geolocation={\"longitude\": 12.492507, \"latitude\": 41.889938 },\n        permissions=[\"geolocation\"]\n    )\n    page = context.new_page()\n    page.goto(\"https://maps.google.com\")\n    page.click(\"text=Your location\")\n    page.screenshot(path=\"colosseum-iphone.png\")\n    browser.close()\n```\n\n<details>\n<summary>Async variant</summary>\n\n```py\nimport asyncio\nfrom playwright.async_api import async_playwright\n\nasync def main():\n    async with async_playwright() as p:\n        iphone_11 = p.devices[\"iPhone 11 Pro\"]\n        browser = await p.webkit.launch(headless=False)\n        context = await browser.new_context(\n            **iphone_11,\n            locale=\"en-US\",\n            geolocation={\"longitude\": 12.492507, \"latitude\": 41.889938},\n            permissions=[\"geolocation\"]\n        )\n        page = await context.newPage()\n        await page.goto(\"https://maps.google.com\")\n        await page.click(\"text=\"Your location\"\")\n        await page.screenshot(path=\"colosseum-iphone.png\")\n        await browser.close()\n\nasyncio.run(main())\n```\n\n</details>\n\n#### Evaluate JS in browser\n\nThis code snippet navigates to example.com in Firefox, and executes a script in the page context.\n\n```py\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.firefox.launch()\n    page = browser.new_page()\n    page.goto(\"https://www.example.com/\")\n    dimensions = page.evaluate(\"\"\"() => {\n      return {\n        width: document.documentElement.clientWidth,\n        height: document.documentElement.clientHeight,\n        deviceScaleFactor: window.devicePixelRatio\n      }\n    }\"\"\")\n    print(dimensions)\n    browser.close()\n```\n\n<details>\n<summary>Async variant</summary>\n\n```py\nimport asyncio\nfrom playwright.async_api import async_playwright\n\nasync def main():\n    async with async_playwright() as p:\n        browser = await p.firefox.launch()\n        page = await browser.new_page()\n        await page.goto(\"https://www.example.com/\")\n        dimensions = await page.evaluate(\"\"\"() => {\n          return {\n            width: document.documentElement.clientWidth,\n            height: document.documentElement.clientHeight,\n            deviceScaleFactor: window.devicePixelRatio\n          }\n        }\"\"\")\n        print(dimensions)\n        await browser.close()\n\nasyncio.run(main())\n```\n\n</details>\n\n#### Intercept network requests\n\nThis code snippet sets up request routing for a Chromium page to log all network requests.\n\n```py\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch()\n    page = browser.new_page()\n\n    def log_and_continue_request(route, request):\n        print(request.url)\n        route.continue_()\n\n    # Log and continue all network requests\n    page.route(\"**/*\", log_and_continue_request)\n\n    page.goto(\"http://todomvc.com\")\n    browser.close()\n```\n\n<details>\n<summary>Async variant</summary>\n\n```py\nimport asyncio\nfrom playwright.async_api import async_playwright\n\nasync def main():\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        page = await browser.new_page()\n\n        async def log_and_continue_request(route, request):\n            print(request.url)\n            await route.continue_()\n\n        # Log and continue all network requests\n        await page.route(\"**/*\", log_and_continue_request)\n        await page.goto(\"http://todomvc.com\")\n        await browser.close()\n\nasyncio.run(main())\n```\n\n</details>\n\n## Documentation\n\nCheck out our [new documentation site](https://playwright.dev/python/docs/intro)!\n"
 },
 {
  "repo": "microsoft/boll",
  "language": "TypeScript",
  "readme_contents": "# boll\n\nLint the whole repo.\n\n## Getting started\n\n### Install\n\nTo install, add `@boll/cli` as a dev dependency to your package with\nyour package manager of choice.\n\n```sh\nnpm install --save-dev @boll/cli\n```\n\n### Configure\n\nNext, run the `init` command to generate a configuration file that\nwill be used when boll runs.\n\n```sh\nnpx boll init\n```\n\nThis command will create a configuration file called `.boll.config.js`\nin your current directory, implementing the recoommended configuration\nby default. It should look like the following.\n\n```js\n\"use strict\";\nmodule.exports = {\n  extends: \"boll:recommended\"\n};\n```\n\n### Run\n\nTo run `boll`, simply pass the `run` command.\n\n```sh\nnpx boll run\n```\n\nIf everything is configured successfully and your project contains no\nboll violations, the command will exit with no output and an exit\nstatus of `0`.\n\n### Next steps\n\nLearn about configuring, tweaking, or adding rules in [the docs](https://microsoft.github.io/boll/).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/lisa",
  "language": "Python",
  "readme_contents": "# Linux Integration Services Automation (LISA)\n\n[![CI Workflow](https://github.com/microsoft/lisa/workflows/CI%20Workflow/badge.svg?branch=main)](https://github.com/microsoft/lisa/actions?query=workflow%3A%22CI+Workflow+for+LISAv3%22+event%3Apush+branch%3Amain)\n[![GitHub license](https://img.shields.io/github/license/microsoft/lisa)](https://github.com/microsoft/lisa/blob/main/LICENSE)\n\n**Linux Integration Services Automation (LISA)** is designed to be an end-to-end solution for verifying Linux kernels and distributions quality on Microsoft virtualization technologies. It can be used on other quality validation, and virtualization technologies as well.\n\n* **End-to-end**: LISA defines several sets of test suites to validate Linux kernels and distributions in Microsoft Azure, Hyper-V, etc. The test suites can help find integration issues easily.\n* **Ease-to-use**: The complexity and diversity of Linux kernels/distributions are wrapped in different components of LISA. When running LISA, it doesn't need to know details. Developers can focus on validation logic, when creating new tests.\n* **Extensibility**: LISA is extendable in many components to support various scenarios, including virtualization platforms, commands, Linux distributions, community test suites, etc. LISA supports to validate Microsoft virtualization platforms natively, but also can be extended to other cloud or on-premises platforms.\n\n## Why LISA\n\nThere are a lot of classic tools and tests, which focus on the quality of Linux kernels or distributions. They are important to ensure the quality of kernels and distributions. The integration validation on virtualization platforms is a little different with classic Linux testing. It covers diverse types of resources with manageable cost. So that, it needs to plan resources creation and deletion automatically.\n\nLISA focuses on validating the integration of Linux kernels/distributions and virtualization platforms. It needs more interactive with virtualization platforms to run tests for different purposes, like test different capabilities, hardware, and so on.\n\n## Documents\n\n* [Install LISA](docs/install.md)\n* [Run tests](docs/run.md)\n* [Microsoft tests](docs/microsoft_tests.md)\n* [Write test cases in LISA](docs/write_case.md)\n* [Command line reference](docs/command_line.md)\n* [Runbook reference](docs/runbook.md)\n* [Extend and customize LISA](docs/extension.md)\n* [Run previous version LISA (aka LISAv2)](docs/run_legacy.md)\n\n## Contribute\n\nYou are very welcome to contribute. Please follow [the contribution document](docs/contributing.md) for details.\n\n## History and road map\n\nThe previous LISA called LISAv2, which is in [master branch](https://github.com/microsoft/lisa/tree/master). The previous LISA can be used standalone or called from the current LISA. Learn more from [how to run LISAv2 test cases](docs/run_legacy.md).\n\nLISA is in active developing, and a lot of exciting features are implementing. We're listening your [feedback](https://github.com/microsoft/lisa/issues/new).\n\n## License\n\nThe entire codebase is under [MIT license](LICENSE).\n"
 },
 {
  "repo": "microsoft/linkcheckermd",
  "language": "TypeScript",
  "readme_contents": "# LinkCheckMD\nLoad a Markdown file and get highlights and hovers for links that contain a country code (en-us for example.) \n\nIf you use Alt+L, it will generate a report on the links in the document, including broken links. It attempts to check broken links by trying to resolve HTTP & HTTPS links, and relative links (../folder/file.md) by checking if the file exist on the local file system. The result of these checks are logged in an output window on the right of the editor.\n\n![Animated GIF of URLs being flagged as warnings and Alt+L functionality](./images/working.gif)\n\nNote that checking for broken links is more of an art than a science. Some sites don't actually return 404, but send you to a landing page. For example, Azure.com works this way. You can go to https://Azure.com/foo/bar and it will happily redirect you to https://Azure.com, with no 404 status returned. So take a status of \"OK\" with a grain of salt - you may not be arriving at the page you intend.\n\n## Install\n\nOpen Visual Studio Code and press `F1`; a field will appear at the top of the window. Type `ext install linkcheck`, hit enter, and reload the window to enable.\n\n![Animated GIF of installing the extension](./images/install.gif)\n\n## Check for country code\n\nChecking for country codes in links happens as you type, and will underline links with green.\n\n## Check for broken links\n\nTo check for broken links, use Alt+L. This will open a new column to the right of the VSCode window and display the status of the links as they are checked.\n\n## Changes\n\n### 0.1.5\n\n- Added country code warnings to the output window for Alt+L checking\n- Updated vscode dependency for the latest version\n\n## TODO\n\n* Refactor broken link checking to display the actual URL that you arrived at for \"OK\" results that were redirects to a different URL.\n\n"
 },
 {
  "repo": "microsoft/powerquery-parser",
  "language": "TypeScript",
  "readme_contents": "# powerquery-parser\r\n\r\n[![Build Status](https://dev.azure.com/ms/powerquery-parser/_apis/build/status/microsoft.powerquery-parser?branchName=master)](https://dev.azure.com/ms/powerquery-parser/_build/latest?definitionId=134&branchName=master)\r\n\r\nA parser for the [Power Query/M](https://docs.microsoft.com/en-us/power-query/) language, written in TypeScript. Designed to be consumed by other projects.\r\n\r\n## How to use\r\n\r\nThe most common way to consume the project is to interact with the helper functions found in [src/task.ts](src/task.ts). There are all-in-one functions, such as `tryLexParseInspection`, which does a full pass on a given document. There are also incremental functions, such as `tryLex` and `tryParse`, which perform one step at a time. Minimal code samples can be found in [example.ts](src/example.ts).\r\n\r\n## Things to note\r\n\r\n### Parser\r\n\r\nThe parser started off as a naive recursive descent parser with limited backtracking. It mostly followed the [official specification](https://docs.microsoft.com/en-us/powerquery-m/power-query-m-language-specification) released in October 2016. Deviations from the specification should be marked down in [specification.md](specification.md). A combinatorial parser has since been added which uses the naive parser as its base.\r\n\r\n### Style\r\n\r\nThis project uses [prettier](https://github.com/prettier/prettier) as the primary source of style enforcement. Additional style requirements are located in [style.md](style.md).\r\n\r\n## How to build\r\n\r\n- Install NodeJS\r\n- `npm install`\r\n- `npm run-script build`\r\n\r\n## How to run tests\r\n\r\n- Install NodeJS\r\n- `npm install`\r\n- `npm test`\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/BotFramework-Composer",
  "language": "TypeScript",
  "readme_contents": "# ![Microsoft Bot Framework Composer](./docs/Assets/gh-banner.png)\n\n# Microsoft Bot Framework Composer\n\n[![Build Status](https://github.com/microsoft/BotFramework-Composer/workflows/Composer%20CI/badge.svg?branch=main)](https://github.com/microsoft/BotFramework-Composer/actions?query=branch%3Amain)\n[![Coverage Status](https://coveralls.io/repos/github/microsoft/BotFramework-Composer/badge.svg?branch=main)](https://coveralls.io/github/microsoft/BotFramework-Composer?branch=main)\n[![Total alerts](https://img.shields.io/lgtm/alerts/g/microsoft/BotFramework-Composer.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/microsoft/BotFramework-Composer/alerts/)\n[![license](https://img.shields.io/badge/license-MIT%20License-00AAAA.svg)](https://github.com/microsoft/BotFramework-Composer/blob/main/LICENSE.md)\n\n## Overview\n\nBot Framework Composer is an open-source, visual authoring canvas for developers and multi-disciplinary teams to design and build conversational experiences with Language Understanding and QnA Maker, and a sophisticated composition of bot replies (Language Generation). Within this tool, you'll have everything you need to build a sophisticated conversational experience.\n\n- A visual editing canvas for conversation flows\n- In context editing for language understanding (NLU)\n- Tools to train, test and manage language understanding (NLU) and QnA components\n- Language generation and templating system\n- A ready-to-use bot runtime executable\n\nThe Bot Framework Composer is an open source tool based on the Bot Framework SDK. It is available as a [desktop application](#get-started) as well as a [web-based component](#build-composer-locally)\n\n<p align=\"center\">\n    <img alt=\"Bot Framework Composer Home Page\" src=\"./docs/Assets/Screenshot-Composer-overview.png\" style=\"max-width:700px;\" />\n</p>\n\n## Get Started\n\n- Download Composer for [Windows][201], [Mac][203] and [Linux][202]. Please see [supported OS versions][205].\n- To learn about the Bot Framework Composer, read the [documentation][5].\n- To get yourself familiar with the Composer, read [Introduction to Bot Framework Composer][1].\n- [Create your first bot][3]!\n- To find the most recent release and learn what has changed in Bot Framework Composer, see the [latest release][204].\n\n## Build Composer Locally\n\nTo build and run the Composer project locally as a web application, clone the source code from Github and build the application using the instructions below.\n\nPlease see [supported NodeJS versions][205] before building.\n\n```\n$ git clone https://github.com/microsoft/BotFramework-Composer.git\n$ cd BotFramework-Composer\n$ cd Composer // switch to Composer folder\n$ yarn install // install dependencies\n$ yarn build // build extensions and libs\n$ yarn startall // start client and server at the same time\n```\n\n## Extend Composer with Extensions\n\nMany aspects of Composer's functionality can be customized and extended through extensions. Features such as authentication, storage, publishing and even the samples and templates available on the homescreen can be customized by creating new extensions.\n\n[Read more about building Composer extensions &rarr;](extensions/README.md)\n\n## Support and Feedback\n\n- [Ask a question on Stack Overflow][10]\n- [Request a new feature][11]\n- [File an issue][12]\n\n## Related project\n\nThe Bot Framework Composer is part of the [Bot Framework][20] platform:\n\n- [Bot Framework SDK][21]\n- [Bot Framework Emulator][22]\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct][100].\nFor more information see the [Code of Conduct FAQ][101] or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Issues and feature requests\n\nPlease file issues and feature requests [here](https://github.com/microsoft/BotFramework-Composer/issues/issues).\n\nAlso, see current [known issues](https://github.com/microsoft/BotFramework-Composer/labels/known%20issue) for high impact bugs you may experience.\n\n### Submitting pull requests\n\nIf you'd like to contribute pull requests to Composer, see the [contributing guide](./CONTRIBUTING.md) for helpful information on our development workflow.\n\n## Reporting security issues\n\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security\nResponse Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should\nreceive a response within 24 hours. If for some reason you do not, please follow up via\nemail to ensure we received your original message. Further information, including the\n[MSRC PGP][102] key, can be found in\nthe [Security TechCenter][103].\n\n[1]: https://aka.ms/bf-composer-docs-introduction\n[2]: https://aka.ms/bf-composer-docs-setup-yarn\n[3]: https://aka.ms/bf-composer-docs-create-first-bot\n[4]: https://aka.ms/BF-Composer-Docs\n[5]: https://aka.ms/bf-composer-docs-welcome-page\n[10]: https://stackoverflow.com/questions/tagged/botframework?tab=Newest\n[11]: https://github.com/microsoft/BotFramework-Composer/issues/new?assignees=&labels=Type%3A+suggestion%2C+Needs-triage&template=bot-framework-composer-feature-request.md&title=\n[12]: https://github.com/microsoft/BotFramework-Composer/issues/new?assignees=&labels=Needs-triage%2C+Type%3A+bug&template=bot-framework-composer-bug.md&title=\n[20]: https://github.com/microsoft/botframework#microsoft-bot-framework\n[21]: https://github.com/microsoft/botframework-sdk#bot-framework-sdk\n[22]: https://github.com/Microsoft/BotFramework-Emulator#readme\n[100]: https://opensource.microsoft.com/codeofconduct/\n[101]: https://opensource.microsoft.com/codeofconduct/faq/\n[102]: https://technet.microsoft.com/en-us/security/dn606155\n[103]: https://technet.microsoft.com/en-us/security/default\n[201]: https://aka.ms/bf-composer-download-win\n[202]: https://aka.ms/bf-composer-download-linux\n[203]: https://aka.ms/bf-composer-download-mac\n[204]: https://github.com/microsoft/BotFramework-Composer/releases/latest\n[205]: https://aka.ms/bf-composer-supported-os\n"
 },
 {
  "repo": "microsoft/hermes-windows",
  "language": "C++",
  "readme_contents": "# Hermes JS Engine for React Native Windows\n[![MIT license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/facebook/hermes/blob/master/LICENSE)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://github.com/facebook/hermes/blob/master/CONTRIBUTING.md)\n<img src=\"./website/static/img/logo.svg\" alt=\"Hermes logo - large H with wings\" align=\"right\" width=\"20%\"/>\n\nHermes is a JavaScript engine optimized for fast start-up of [React Native](https://reactnative.dev/) apps. It features ahead-of-time static optimization and compact bytecode.\n\nIf you're only interested in using pre-built Hermes in a new or existing React Native app, you do not need to follow this guide or have direct access to the Hermes source. Instead, just follow [these instructions to enable Hermes](https://reactnative.dev/docs/hermes).\n\n> Noted that each Hermes release is aimed at a specific RN version. The rule of thumb is to always follow [Hermes releases](https://github.com/facebook/hermes/releases) strictly. Version mismatch can result in instant crash of your apps in the worst case scenario.\n\nIf you want to know how to build and hack on Hermes directly, and/or integrate Hermes built from source into a React Native app then read on.\n\nThe instructions here very briefly cover steps to build the Hermes CLI. They assume you have typical native development tools setup for your OS, and support for cmake and Ninja. For more details of required dependencies, building Hermes with different options, etc. follow these links instead:\n\n* [Building and Running Hermes](doc/BuildingAndRunning.md)\n* [Using a custom Hermes build in a React Native app](doc/ReactNativeIntegration.md#using-a-custom-hermes-build-in-a-react-native-app)\n\nTo build a local debug version of the Hermes CLI tools the following steps should get you started on macOS/Linux:\nThe following commands should get you going in a Windows Command Prompt:\n\n```shell\nmkdir hermes_workingdir\ncd hermes_workingdir\ngit clone https://github.com/facebook/hermes.git\nhermes/utils/build/configure.py\ncd build\nninja\n```\n\nOr if you're using Windows, the following should get you going in a Git Bash shell:\n\n```shell\nmkdir hermes_workingdir\ncd hermes_workingdir\ngit -c core.autocrlf=false clone https://github.com/facebook/hermes.git\nhermes/utils/build/configure.py --build-system='Visual Studio 16 2019' --cmake-flags='-A x64' --distribute\ncd build\nMSBuild.exe ALL_BUILD.vcxproj /p:Configuration=Release\n```\n\nYou will now be in a directory with the output of building Hermes into CLI tools. From here you can run a piece of JavaScript as follows:\n\n```shell\necho 'use strict'; function hello() { print('Hello World'); } hello(); | .\\bin\\Release\\hermes.exe\n```\n\nFor more details on Hermes for Android, see [here](https://github.com/facebook/hermes/blob/master/README.md).\n\n## Contributing\n\nThe main purpose of this repository is to brings Hermes support to [React Native Windows](https://github.com/microsoft/react-native-windows). We are grateful to the community for contributing bugfixes and improvements. Read below to learn how you can participate.\n\n### Code of Conduct\n\nBoth Microsoft and Facebook have adopted [Codes of Conduct](./CODE_OF_CONDUCT.md) that we expect project participants to adhere to. Microsoft's Code of Conduct can be found [here](https://opensource.microsoft.com/codeofconduct)  and Facebook's [here](https://code.fb.com/codeofconduct). Please read through them so that you can understand what actions will and will not be tolerated.\n\n### Contributing Guide\n\nRead our [contributing guide](CONTRIBUTING.md) to learn about our development process as well as how to propose bugfixes and improvements.\n\n### License\n\nHermes is [MIT licensed](./LICENSE).\n"
 },
 {
  "repo": "microsoft/PSRule",
  "language": "C#",
  "readme_contents": "# PSRule\n\nA cross-platform module to validate infrastructure as code (IaC) and objects using PowerShell rules.\nPSRule works great and integrates with popular continuous integration (CI) systems.\n\n![ci-badge]\n\nFeatures of PSRule include:\n\n- [Extensible](docs/features.md#extensible) - Use PowerShell, a flexible scripting language.\n- [Cross-platform](docs/features.md#cross-platform) - Run on MacOS, Linux, and Windows.\n- [Reusable](docs/features.md#reusable) - Share rules across teams or organizations.\n- [Recommendations](docs/features.md#recommendations) - Include detailed instructions to remediate issues.\n\n## Project objectives\n\n1. **Extensible**:\n   - Provide an execution environment (tools and language) to validate infrastructure code.\n   - Handling of common concerns such as input/ output/ reporting should be handled by the engine.\n   - Language must be flexible enough to support a wide range of use cases.\n2. **DevOps**:\n   - Validation should support and enhance DevOps workflows by providing fast feedback in pull requests.\n   - Allow quality gates to be implemented between environments such development, test, and production.\n3. **Cross-platform**:\n   - A wide range of platforms can be used to author and deploy infrastructure code.\nPSRule must support rule validation and authoring on Linux, MacOS, and Windows.\n   - Runs in a Linux container.\nFor continuous integration (CI) systems that do not support PowerShell, run in a container.\n4. **Reusable**:\n   - Validation should plug and play, reusable across teams and organizations.\n   - Any reusable validation will have exceptions.\nRules must be able to be disabled where they are not applicable.\n\nContinue reading the [PSRule design specification][spec].\n\n## Support\n\nThis project uses GitHub Issues to track bugs and feature requests.\nPlease search the existing issues before filing new issues to avoid duplicates.\n\n- For new issues, file your bug or feature request as a new [issue].\n- For help, discussion, and support questions about using this project, join or start a [discussion].\n\nSupport for this project/ product is limited to the resources listed above.\n\n## Getting the module\n\nYou can download and install the PSRule module from the PowerShell Gallery.\n\nModule | Description | Downloads / instructions\n------ | ----------- | ------------------------\nPSRule | Validate infrastructure as code (IaC) and objects using PowerShell rules. | [latest][module-psrule] / [instructions][install]\n\nFor rule and integration modules see [related projects](#related-projects).\n\n## Getting extensions\n\nCompanion extensions are available for the following platforms.\n\nPlatform           | Description | Downloads / instructions\n--------           | ----------- | ------------------------\nAzure Pipelines    | Validate infrastructure as code (IaC) and DevOps repositories using Azure Pipelines. | [latest][extension-pipelines] / [instructions][install]\nGitHub Actions     | Validate infrastructure as code (IaC) and DevOps repositories using GitHub Actions. | [latest][extension-actions] / [instructions][install]\nVisual Studio Code | Visual Studio Code extension for PSRule. | [latest][extension-vscode] / [instructions][install]\n\n## Getting started\n\nThe following example shows basic PSRule usage for validating PowerShell objects.\nFor specific use cases see [scenarios](#scenarios).\n\nFor frequently asked questions, see the [FAQ](docs/features.md#frequently-asked-questions-faq).\n\n### Define a rule\n\nTo define a rule, use a `Rule` block saved to a file with the `.Rule.ps1` extension.\n\n```powershell\nRule 'NameOfRule' {\n    # Rule conditions\n}\n```\n\nWithin the body of the rule provide one or more conditions.\nA condition is valid PowerShell that results in `$True` or `$False`.\n\nFor example:\n\n```powershell\nRule 'isFruit' {\n    # Condition to determine if the object is fruit\n    $TargetObject.Name -in 'Apple', 'Orange', 'Pear'\n}\n```\n\nAn optional result message can be added to by using the `Recommend` keyword.\n\n```powershell\nRule 'isFruit' {\n    # An recommendation to display in output\n    Recommend 'Fruit is only Apple, Orange and Pear'\n\n    # Condition to determine if the object is fruit\n    $TargetObject.Name -in 'Apple', 'Orange', 'Pear'\n}\n```\n\nThe rule is saved to a file named [`isFruit.Rule.ps1`](docs/scenarios/fruit/isFruit.Rule.ps1) file.\nOne or more rules can be defined within a single file.\n\n### Execute a rule\n\nTo execute the rule use `Invoke-PSRule`.\n\nFor example:\n\n```powershell\n# Define objects to validate\n$items = @();\n$items += [PSCustomObject]@{ Name = 'Fridge' };\n$items += [PSCustomObject]@{ Name = 'Apple' };\n\n# Validate each item using rules saved in current working path\n$items | Invoke-PSRule;\n```\n\nThe output of this example is:\n\n```text\n   TargetName: Fridge\n\nRuleName                            Outcome    Recommendation\n--------                            -------    --------------\nisFruit                             Fail       Fruit is only Apple, Orange and Pear\n\n\n   TargetName: Apple\n\nRuleName                            Outcome    Recommendation\n--------                            -------    --------------\nisFruit                             Pass       Fruit is only Apple, Orange and Pear\n```\n\n### Additional options\n\nTo filter results to only non-fruit results, use `Invoke-PSRule -Outcome Fail`.\nPassed, failed and error results are shown by default.\n\n```powershell\n# Only show non-fruit results\n$items | Invoke-PSRule -Outcome Fail;\n```\n\nFor a summary of results for each rule use `Invoke-PSRule -As Summary`.\n\nFor example:\n\n```powershell\n# Show rule summary\n$items | Invoke-PSRule -As Summary;\n```\n\nThe output of this example is:\n\n```text\nRuleName                            Pass  Fail  Outcome\n--------                            ----  ----  -------\nisFruit                             1     1     Fail\n```\n\nAn optional failure reason can be added to the rule block by using the `Reason` keyword.\n\n```powershell\nRule 'isFruit' {\n    # An recommendation to display in output\n    Recommend 'Fruit is only Apple, Orange and Pear'\n\n    # An failure reason to display for non-fruit\n    Reason \"$($PSRule.TargetName) is not fruit.\"\n\n    # Condition to determine if the object is fruit\n    $TargetObject.Name -in 'Apple', 'Orange', 'Pear'\n}\n```\n\nTo include the reason with output use `Invoke-PSRule -OutputFormat Wide`.\n\nFor example:\n\n```powershell\n# Show failure reason for failing results\n$items | Invoke-PSRule -OutputFormat Wide;\n```\n\nThe output of this example is:\n\n```text\n\n   TargetName: Fridge\n\nRuleName                            Outcome    Reason                              Recommendation\n--------                            -------    ------                              --------------\nisFruit                             Fail       Fridge is not fruit.                Fruit is only Apple, Orange and Pear\n\n\n   TargetName: Apple\n\nRuleName                            Outcome    Reason                              Recommendation\n--------                            -------    ------                              --------------\nisFruit                             Pass                                           Fruit is only Apple, Orange and Pear\n```\n\nThe final rule is saved to [`isFruit.Rule.ps1`](docs/scenarios/fruit/isFruit.Rule.ps1).\n\n### Scenarios\n\nFor walk through examples of PSRule usage see:\n\n- [Validate Azure resource configuration](docs/scenarios/azure-resources/azure-resources.md)\n- [Validate Azure resources tags](docs/scenarios/azure-tags/azure-tags.md)\n- [Validate Kubernetes resources](docs/scenarios/kubernetes-resources/kubernetes-resources.md)\n- [Using within continuous integration](docs/scenarios/validation-pipeline/validation-pipeline.md)\n- [Packaging rules in a module](docs/scenarios/rule-module/rule-module.md)\n- [Writing rule help](docs/scenarios/rule-docs/rule-docs.md)\n\n## Language reference\n\nPSRule extends PowerShell with domain specific language (DSL) keywords, cmdlets and automatic variables.\n\n### Keywords\n\nThe following language keywords are used by the `PSRule` module:\n\n- [Rule](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#rule) - A rule definition.\n- [Exists](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#exists) - Assert that a field or property must exist.\n- [Match](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#match) - Assert that the field must match any of the regular expressions.\n- [AnyOf](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#anyof) - Assert that any of the child expressions must be true.\n- [AllOf](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#allof) - Assert that all of the child expressions must be true.\n- [Within](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#within) - Assert that the field must match any of the values.\n- [TypeOf](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#typeof) - Assert that the object must be of a specific type.\n- [Reason](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#reason) - Return a reason for why the rule failed.\n- [Recommend](docs/keywords/PSRule/en-US/about_PSRule_Keywords.md#recommend) - Return a recommendation to resolve the issue and pass the rule.\n\n### Commands\n\nThe following commands exist in the `PSRule` module:\n\n- [Assert-PSRule](docs/commands/PSRule/en-US/Assert-PSRule.md) - Evaluate objects against matching rules and assert any failures.\n- [Get-PSRule](docs/commands/PSRule/en-US/Get-PSRule.md) - Get a list of rule definitions.\n- [Get-PSRuleBaseline](docs/commands/PSRule/en-US/Get-PSRuleBaseline.md) - Get a list of baselines.\n- [Get-PSRuleHelp](docs/commands/PSRule/en-US/Get-PSRuleHelp.md) - Get documentation for a rule.\n- [Get-PSRuleTarget](docs/commands/PSRule/en-US/Get-PSRuleTarget.md) - Get a list of target objects.\n- [Invoke-PSRule](docs/commands/PSRule/en-US/Invoke-PSRule.md) - Evaluate objects against matching rules and output the results.\n- [New-PSRuleOption](docs/commands/PSRule/en-US/New-PSRuleOption.md) - Create options to configure PSRule execution.\n- [Set-PSRuleOption](docs/commands/PSRule/en-US/Set-PSRuleOption.md) - Sets options that configure PSRule execution.\n- [Test-PSRuleTarget](docs/commands/PSRule/en-US/Test-PSRuleTarget.md) - Pass or fail objects against matching rules.\n\n### Concepts\n\nThe following conceptual topics exist in the `PSRule` module:\n\n- [Assert](docs/concepts/PSRule/en-US/about_PSRule_Assert.md)\n  - [Contains](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#contains)\n  - [EndsWith](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#endswith)\n  - [FileHeader](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#fileheader)\n  - [FilePath](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#filepath)\n  - [Greater](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#greater)\n  - [GreaterOrEqual](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#greaterorequal)\n  - [HasDefaultValue](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#hasdefaultvalue)\n  - [HasField](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#hasfield)\n  - [HasFields](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#hasfields)\n  - [HasFieldValue](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#hasfieldvalue)\n  - [HasJsonSchema](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#hasjsonschema)\n  - [In](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#in)\n  - [IsArray](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isarray)\n  - [IsBoolean](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isboolean)\n  - [IsDateTime](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isdatetime)\n  - [IsInteger](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isinteger)\n  - [IsLower](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#islower)\n  - [IsNumeric](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isnumeric)\n  - [IsString](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isstring)\n  - [IsUpper](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#isupper)\n  - [JsonSchema](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#jsonschema)\n  - [Less](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#less)\n  - [LessOrEqual](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#lessorequal)\n  - [Match](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#match)\n  - [NotHasField](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#nothasfield)\n  - [NotIn](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#notin)\n  - [NotMatch](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#notmatch)\n  - [NotNull](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#notnull)\n  - [NotWithinPath](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#notwithinpath)\n  - [Null](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#null)\n  - [NullOrEmpty](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#nullorempty)\n  - [TypeOf](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#typeof)\n  - [StartsWith](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#startswith)\n  - [Version](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#version)\n  - [WithinPath](docs/concepts/PSRule/en-US/about_PSRule_Assert.md#withinpath)\n- [Baselines](docs/concepts/PSRule/en-US/about_PSRule_Baseline.md)\n  - [Baseline specs](docs/concepts/PSRule/en-US/about_PSRule_Baseline.md#baseline-specs)\n  - [Baseline scopes](docs/concepts/PSRule/en-US/about_PSRule_Baseline.md#baseline-scopes)\n- [Conventions](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md)\n  - [Using conventions](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md#using-conventions)\n  - [Defining conventions](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md#defining-conventions)\n  - [Begin Process End blocks](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md#begin-process-end-blocks)\n  - [Including with options](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md#including-with-options)\n  - [Using within modules](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md#using-within-modules)\n  - [Execution order](docs/concepts/PSRule/en-US/about_PSRule_Conventions.md#execution-order)\n- [Docs](docs/concepts/PSRule/en-US/about_PSRule_Docs.md)\n  - [Getting documentation](docs/concepts/PSRule/en-US/about_PSRule_Docs.md#getting-documentation)\n  - [Online help](docs/concepts/PSRule/en-US/about_PSRule_Docs.md#online-help)\n  - [Creating documentation](docs/concepts/PSRule/en-US/about_PSRule_Docs.md#creating-documentation)\n- [Options](docs/concepts/PSRule/en-US/about_PSRule_Options.md)\n  - [Binding.Field](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingfield)\n  - [Binding.IgnoreCase](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingignorecase)\n  - [Binding.NameSeparator](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingnameseparator)\n  - [Binding.PreferTargetInfo](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingprefertargetinfo)\n  - [Binding.TargetName](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingtargetname)\n  - [Binding.TargetType](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingtargettype)\n  - [Binding.UseQualifiedName](docs/concepts/PSRule/en-US/about_PSRule_Options.md#bindingusequalifiedname)\n  - [Configuration](docs/concepts/PSRule/en-US/about_PSRule_Options.md#configuration)\n  - [Convention.Include](docs/concepts/PSRule/en-US/about_PSRule_Options.md#conventioninclude)\n  - [Execution.LanguageMode](docs/concepts/PSRule/en-US/about_PSRule_Options.md#executionlanguagemode)\n  - [Execution.InconclusiveWarning](docs/concepts/PSRule/en-US/about_PSRule_Options.md#executioninconclusivewarning)\n  - [Execution.NotProcessedWarning](docs/concepts/PSRule/en-US/about_PSRule_Options.md#executionnotprocessedwarning)\n  - [Input.Format](docs/concepts/PSRule/en-US/about_PSRule_Options.md#inputformat)\n  - [Input.IgnoreGitPath](docs/concepts/PSRule/en-US/about_PSRule_Options.md#inputignoregitpath)\n  - [Input.ObjectPath](docs/concepts/PSRule/en-US/about_PSRule_Options.md#inputobjectpath)\n  - [Input.PathIgnore](docs/concepts/PSRule/en-US/about_PSRule_Options.md#inputpathignore)\n  - [Input.TargetType](docs/concepts/PSRule/en-US/about_PSRule_Options.md#inputtargettype)\n  - [Logging.LimitDebug](docs/concepts/PSRule/en-US/about_PSRule_Options.md#logginglimitdebug)\n  - [Logging.LimitVerbose](docs/concepts/PSRule/en-US/about_PSRule_Options.md#logginglimitverbose)\n  - [Logging.RuleFail](docs/concepts/PSRule/en-US/about_PSRule_Options.md#loggingrulefail)\n  - [Logging.RulePass](docs/concepts/PSRule/en-US/about_PSRule_Options.md#loggingrulepass)\n  - [Output.As](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputas)\n  - [Output.Banner](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputbanner)\n  - [Output.Culture](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputculture)\n  - [Output.Encoding](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputencoding)\n  - [Output.Format](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputformat)\n  - [Output.Outcome](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputoutcome)\n  - [Output.Path](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputpath)\n  - [Output.Style](docs/concepts/PSRule/en-US/about_PSRule_Options.md#outputstyle)\n  - [Rule.Include](docs/concepts/PSRule/en-US/about_PSRule_Options.md#ruleinclude)\n  - [Rule.Exclude](docs/concepts/PSRule/en-US/about_PSRule_Options.md#ruleexclude)\n  - [Rule.Tag](docs/concepts/PSRule/en-US/about_PSRule_Options.md#ruletag)\n  - [Suppression](docs/concepts/PSRule/en-US/about_PSRule_Options.md#suppression)\n- [Selectors](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md)\n  - [AllOf](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#allof)\n  - [AnyOf](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#anyof)\n  - [Exists](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#exists)\n  - [Equals](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#equals)\n  - [Field](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#field)\n  - [Greater](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#greater)\n  - [GreaterOrEquals](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#greaterorequals)\n  - [HasValue](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#hasvalue)\n  - [In](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#in)\n  - [Less](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#less)\n  - [LessOrEquals](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#lessorequals)\n  - [Match](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#match)\n  - [Not](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#not)\n  - [NotEquals](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#notequals)\n  - [NotIn](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#notin)\n  - [NotMatch](docs/concepts/PSRule/en-US/about_PSRule_Selectors.md#notmatch)\n- [Variables](docs/concepts/PSRule/en-US/about_PSRule_Variables.md)\n  - [$Assert](docs/concepts/PSRule/en-US/about_PSRule_Variables.md#assert)\n  - [$Configuration](docs/concepts/PSRule/en-US/about_PSRule_Variables.md#configuration)\n  - [$LocalizedData](docs/concepts/PSRule/en-US/about_PSRule_Variables.md#localizeddata)\n  - [$PSRule](docs/concepts/PSRule/en-US/about_PSRule_Variables.md#psrule)\n  - [$Rule](docs/concepts/PSRule/en-US/about_PSRule_Variables.md#rule)\n  - [$TargetObject](docs/concepts/PSRule/en-US/about_PSRule_Variables.md#targetobject)\n\n### Schemas\n\nPSRule uses the following schemas:\n\n- [Options](schemas/PSRule-options.schema.json) - Schema for PSRule YAML options file.\n- [Resources](schemas/PSRule-language.schema.json) - Schema for PSRule YAML resources such as baselines.\n\n## Related projects\n\nThe following projects use or integrate with PSRule.\n\nName                      | Description\n----                      | -----------\n[PSRule.Rules.Azure]      | A suite of rules to validate Azure resources and infrastructure as code (IaC) using PSRule.\n[PSRule.Rules.Kubernetes] | A suite of rules to validate Kubernetes resources using PSRule.\n[PSRule.Rules.CAF]        | A suite of rules to validate Azure resources against the Cloud Adoption Framework (CAF) using PSRule.\n[PSRule.Rules.GitHub]     | A suite of rules to validate GitHub repositories using PSRule.\n[PSRule.Rules.MSFT.OSS]   | A suite of rules to validate repositories against Microsoft Open Source Software (OSS) requirements.\n[PSRule.Monitor]          | Send and query PSRule analysis results in Azure Monitor.\n[PSRule-pipelines]        | Validate infrastructure as code (IaC) and DevOps repositories using Azure Pipelines.\n[ps-rule]                 | Validate infrastructure as code (IaC) and DevOps repositories using GitHub Actions.\n[PSRule-vscode]           | Visual Studio Code extension for PSRule.\n\n## Changes and versioning\n\nModules in this repository use [semantic versioning](http://semver.org/) to declare breaking changes.\nFor a list of module changes please see the [change log](CHANGELOG.md).\n\n> Pre-release module versions are created on major commits and can be installed from the PowerShell Gallery.\n> Pre-release versions should be considered experimental.\n> Modules and change log details for pre-releases will be removed as stable releases are made available.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.\nIf you are ready to contribute, please visit the [contribution guide](CONTRIBUTING.md).\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Maintainers\n\n- [Bernie White](https://github.com/BernieWhite)\n\n## License\n\nThis project is [licensed under the MIT License](LICENSE).\n\n[issue]: https://github.com/Microsoft/PSRule/issues\n[discussion]: https://github.com/microsoft/PSRule/discussions\n[install]: docs/install-instructions.md\n[ci-badge]: https://dev.azure.com/bewhite/PSRule/_apis/build/status/PSRule-CI?branchName=main\n[module-psrule]: https://www.powershellgallery.com/packages/PSRule\n[extension-vscode]: https://marketplace.visualstudio.com/items?itemName=bewhite.psrule-vscode-preview\n[extension-pipelines]: https://marketplace.visualstudio.com/items?itemName=bewhite.ps-rule\n[extension-actions]: https://github.com/marketplace/actions/psrule\n[PSRule.Rules.Azure]: https://github.com/microsoft/PSRule.Rules.Azure\n[PSRule.Rules.Kubernetes]: https://github.com/microsoft/PSRule.Rules.Kubernetes\n[PSRule.Rules.CAF]: https://github.com/microsoft/PSRule.Rules.CAF\n[PSRule.Rules.GitHub]: https://github.com/microsoft/PSRule.Rules.GitHub\n[PSRule.Rules.MSFT.OSS]: https://github.com/microsoft/PSRule.Rules.MSFT.OSS\n[PSRule.Monitor]: https://github.com/microsoft/PSRule.Monitor\n[PSRule-pipelines]: https://github.com/microsoft/PSRule-pipelines\n[ps-rule]: https://github.com/microsoft/ps-rule\n[PSRule-vscode]: https://github.com/microsoft/PSRule-vscode\n[spec]: docs/specs/design-spec.md\n"
 },
 {
  "repo": "microsoft/checkedc",
  "language": "C",
  "readme_contents": "# Checked C\nChecked C adds static and dynamic checking to C to detect or prevent common programming\nerrors such as buffer overruns and out-of-bounds memory accesses. \nThe goal of the project is to improve systems programming by making fundamental improvements to C.\nThis repo contains\nsample code, the [extension specification](https://github.com/Microsoft/checkedc/releases),\nand test code.\n\n- For a quick overview of Checked C, more information, and pointers to example code,\n  see our [Wiki](https://github.com/Microsoft/checkedc/wiki).\n- The PDF of the specification is available [here](https://github.com/Microsoft/checkedc/releases).\n- Compilers are available [here](https://github.com/Microsoft/checkedc-clang/releases).\n- The Checked C clang repo is\n  [here](https://github.com/Microsoft/checkedc-clang).\n- The instructions to build and test the Checked C compiler are documented on\n  the [Checked C clang wiki](https://github.com/Microsoft/checkedc-clang/wiki).\n\n# Publications and Presentations\n- We presented a [research paper](https://www.microsoft.com/en-us/research/publication/checkedc-making-c-safe-by-extension/) on\nChecked C at the [IEEE 2018 Cybersecurity Development Conference](https://secdev.ieee.org/2018/home):\n\"Checked C: Making C Safe by Extension\".   The paper describes the key ideas of Checked C in 8 pages. Note that we have added features to Checked C for improving type safety (and reducing type confusion)\nsince writing the paper.  The [Wiki](https://github.com/Microsoft/checkedc/wiki) and [specification](https://github.com/Microsoft/checkedc/releases) provide up-to-date descriptions of Checked C.\n\n- We presented another [paper](https://www.microsoft.com/en-us/research/uploads/prod/2019/05/checkedc-post2019.pdf)\non Checked C at the [2019 Principles of Security and Trust Conference](http://www.etaps.org/2019/post): \n\"Achieving Safety Incrementally With Checked C\".\nThis paper describes a tool for converting existing C code to use Ptr types.  It also proves a blame\nproperty about checked regions that shows that checked regions are blameless for any memory corruption.  This proof is formalized for a core subset of the language extension.\n\n- We presented a\n[poster](https://github.com/microsoft/checkedc/blob/master/papers/posters/checkedc_for_memory_safety.pdf)\nat the [LLVM Dev Meeting\n2019](https://llvm.org/devmtg/2019-10/talk-abstracts.html#post6): \"Overflows Be\nGone: Checked C for Memory Safety\". The poster provides an introduction to\nChecked C, outlines the compiler implementation and presents an experimental\nevaluation of Checked C.\n\n- We presented a\n  [talk](https://www.youtube.com/watch?v=AIlBWIiV68U&ab_channel=LLVM) at the\n[2020 LLVM Virtual Dev Meeting](https://llvm.org/devmtg/2020-09/program):\n\"Checked C: Adding memory safety support to LLVM\". The talk describes the\ndesign of bounds annotations for checked pointers and array pointers as well as\nthe framework for the static checking of the soundness of bounds. We also\nbriefly describe novel algorithms to automatically widen bounds for\nnull-terminated arrays and for comparison of expressions for equivalence.\n\n# Build Status\n\n|Configuration|Testing|Status|\n|--------|---------------|-------|\n|Debug X86 Windows| Checked C and clang regression tests|![Debug X86 Windows status](https://msresearch.visualstudio.com/_apis/public/build/definitions/f6454e27-a46c-49d9-8453-29d89d53d2f9/211/badge)|\n|Debug X64 Windows| Checked C and clang regression tests| ![Debug X64 Windows status](https://msresearch.visualstudio.com/_apis/public/build/definitions/f6454e27-a46c-49d9-8453-29d89d53d2f9/205/badge)|\n|Debug X64 Linux  | Checked C and clang regression tests| ![Debug X64 Linux status](https://msresearch.visualstudio.com/_apis/public/build/definitions/f6454e27-a46c-49d9-8453-29d89d53d2f9/217/badge)|\n|Release X64 Linux| Checked C, clang, and LLVM nightly tests|![Release X64 Linux status](https://msresearch.visualstudio.com/_apis/public/build/definitions/f6454e27-a46c-49d9-8453-29d89d53d2f9/238/badge)|\n\n# Participating\nWe're happy to have the help! You can contribute by trying out Checked C, \nreporting bugs, and giving us feedback. There are other ways to [contribute](CONTRIBUTING.md) too.\nYou can join the [mailing lists](https://github.com/Microsoft/CheckedC/blob/master/MAILING-LISTS.md) for\nannouncements about the project.\n\n# Licensing\nThe software in this repository is covered by the MIT license.  See the file LICENSE.TXT for the license.   The\nChecked C specification is made available by Microsoft under the [OpenWeb Foundation Final\nSpecification Agreement, version 1.0](http://www.openwebfoundation.org/legal/the-owf-1-0-agreements/owfa-1-0).\nContributions of code to the Checked LLVM/clang repos are\nsubject to the [CLANG/LLVM licensing terms](https://github.com/Microsoft/checkedc-clang/blob/master/LICENSE.TXT).\n\n# Code of conduct\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the\n[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any\nadditional questions or comments.\n"
 },
 {
  "repo": "microsoft/checkedc-automation",
  "language": "Shell",
  "readme_contents": "\r\n# Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/checkedc-llvm-test-suite",
  "language": "C",
  "readme_contents": "# The Checked C LLVM test-suite repo\n\nThis repo contains a version of the LLVM test-suite repo that is being modified\nto use Checked C. The modified programs will be used to benchmark the Checked C\nversion of LLVM/clang.\n\nWe have deleted test-only code from the master branch of the repo and left only\nbenchmarks in the master branch.  That makes the repo easier to work with.  It\ndecreases disk usage from about 2.3 GBytes to under 500 MBytes when using the\nmaster branch.\n\nChecked C is an extension to C that adds checking to detect or prevent common \nprogramming  errors such as out-of-bounds memory accesses.  For more information\non Checked C, see the Checked C specification in the\n[Checked C repo](https://github.com/Microsoft/checkedc).  The Checked C\nversion of LLVM/clang lives in two repos: the\n[Checked C clang repo](https://github.com/Microsoft/checked-clang)\nand the [Checked C LLVM repo](https://github.com/Microsoft/checkedc-llvm).\n\n\n## Branch organization\n\nThere are 3 branches in the repo:\n- master: this branch contains benchmarks, some of which may have been modified\nto use Checked C.\n- baseline: this branch contains benchmarks that have not been modified.\n- original: this contains all the tests, including application tests.\n\nThis master branch should be used for modifying benchmarks.  This branch can be diffed\nagainst the baseline branch to see the changes in benchmarks.\nThe original branch can be used to test that\nthe Checked C implementation has not broken existing tests.\n\n## Running tests\n\n### On Linux\n1. Setup LNT\nNote: These steps have been adopted from the [LNT Quickstart Guide](http://llvm.org/docs/lnt/quickstart.html).\nThese instructions are for Ubuntu 20.\n```\nsudo apt install bison flex tclsh\nsudo apt install virtualenv\nsudo virtualenv ~/mysandbox\ngit clone https://github.com/llvm/llvm-lnt.git  ~/lnt\nsudo ~/mysandbox/bin/python ~/lnt/setup.py install\n```\n\n2. Invoke LNT tests\n\nPrerequisite: Make sure you have checked out and built the Checked C compiler.\n```\ngit clone https://github.com/microsoft/checkedc-automation.git <AUTOMATION_DIR>\nexport SRC_DIR=</path/to/llvm/src>\nexport BUILD_DIR=</path/to/llvm/build>\n<AUTOMATION_DIR>/UNIX/run-lnt-local.sh\n```\n\nOptional flags:\n```\nTEST_TARGET=\"X86_64;ARM\"\nLNT_BIN=</path/to/lnt> // By default, lnt is picked up from ~/mysandbox/bin/lnt.\n```\n\nThe test results are generated at:\n```\n<BUILD_DIR>/LNT-Results-Release-Linux/<TEST_TARGET>/test-<TIME_STAMP>/test.log\n```\n\n### On Windows\nThe LNT tests can also be run on Windows 10 using\nthe [Windows Subsystem for Linux](https://blogs.msdn.microsoft.com/wsl/2016/04/22/windows-subsystem-for-linux-overview/).\nSee the directions [here](docs/Benchmarking-on-Windows.md).\n\n## Contributing\n\nWe would be happy for people to convert existing benchmarks to use Checked C.\nFor code contributions, we follow the standard\n[Github workflow](https://guides.github.com/introduction/flow/).  See \n[Contributing to Checked C](https://github.com/Microsoft/checkedc/blob/master/CONTRIBUTING.md) for more detail.\nYou will need to sign a contributor license agreement before contributing a\nconverted benchmark.\n\nFor more information on contributing on the Checked C project, see \n[Contributing to Checked C](https://github.com/Microsoft/checkedc/blob/master/CONTRIBUTING.md).\n\n## Code of conduct\n\nThis project has adopted the\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the\n[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any\nadditional questions or comments.\n"
 },
 {
  "repo": "microsoft/vscode-generator-code",
  "language": "JavaScript",
  "readme_contents": "# Yo Code - Extension and Customization Generator\n\n[![Build Status](https://dev.azure.com/ms/vscode-generator-code/_apis/build/status/Microsoft.vscode-generator-code)](https://dev.azure.com/ms/vscode-generator-code/_build/latest?definitionId=17)\n\nWe have written a Yeoman generator to help get you started. We plan to add templates for most extension/customization types into this.\n\n## Install the Generator\n\nInstall Yeoman and the VS Code Extension generator:\n\n```bash\nnpm install -g yo generator-code\n```\n\n## Run Yo Code\nThe Yeoman generator will walk you through the steps required to create your customization or extension prompting for the required information.\n\nTo launch the generator simply type:\n\n```bash\nyo code\n```\n\n![The command generator](yocode.png)\n\n## Generator Output\n\nThese templates will\n* Create a base folder structure\n* Template out a rough `package.json`\n* Import any assets required for your extension e.g. tmBundles or the VS Code Library\n* For Extensions: Set-up `launch.json` for running your extension and attaching to a process\n\n## Command line\n\n```\nUsage:\n  yo code [<destination>] [options]\n\nArgument (optional):\n  The destination to create the extension in, absolute or relative to the current working\n  directory. Use '.' for the current folder.\n  If not provided, defaults to a folder in the current working directory with the extension\n  display name.\n\nOptions:\n  -h,   --help                  # Print the generator's options and usage\n  -i,   --insiders              # Show the insiders options for the generator\n  -q,   --quick                 # Quick mode, skip all optional prompts and use defaults\n  -o,   --open                  # Open the generated extension in Visual Studio Code\n  -O,   --openInInsiders        # Open the generated extension in Visual Studio Code Insiders\n  -t,   --extensionType         # ts, js, colortheme, language, snippets, keymap...\n        --extensionId           # Id of the extension\n        --extensionDescription  # Description of the extension\n        --pkgManager            # 'npm' or 'yarn'\n        --webpack               # Bundle the extension with webpack\n        --gitInit               # Initialize a git repo\n\nExample usages:\n  yo code                       # Create an extension in a folder with the extension's name.\n  yo code . -O                  # Create an extension in current folder and open with code-insiders\n  yo code Hello -t=ts -q        # Create an TypeScript extension in './Hello', skip prompts, use defaults.\n  yo code --insiders            # Show the insiders options for the generator\n```\n\n## Run Generator using Docker\nIf you don't want to install nodejs or any node packages, use this method to containerize the generator. \\\n\\\nGo into your project directory\n```bash\ncd <project directory>\n```\nBuild the docker image from the docker file\n```bash\ndocker build -t vscode-generator-code .\n```\nCreate a docker container with volumes\n```bash\ndocker run -v $(pwd):/usr/src/app vscode-generator-code\n```\n\n## History\n\n* 1.0.0: Generates a VS Code extension for TypeScript 2.0.3\n* 0.10.x: Generates a VS Code extension for TypeScript 1.8.10\n\n## License\n\n[MIT](LICENSE)\n"
 },
 {
  "repo": "microsoft/azure-devops-extension-yeoman-generator",
  "language": "TypeScript",
  "readme_contents": "# Azure DevOps extension generator\n\nGenerates a basic Azure DevOps extension with support for hot reload and debugging in VS Code. For more information about how hot reload and debugging works with Azure DevOps extensions, please see the [azure-devops-extension-hot-reload-and-debug](https://github.com/microsoft/azure-devops-extension-hot-reload-and-debug) repo, as well as the accompanying [blog post](https://devblogs.microsoft.com/devops/streamlining-azure-devops-extension-development/).\n\n## Installation\n\nFirst, install [Yeoman](http://yeoman.io) and generator-azure-devops-extension using [npm](https://www.npmjs.com/) (we assume you have pre-installed [Node.js](https://nodejs.org/)).\n\n```shell\nnpm install -g yo\nnpm install -g @microsoft/generator-azure-devops-extension\n```\n\nThen generate your new project:\n\n```shell\nyo @microsoft/azure-devops-extension\n```\n\n## Output\n\nRunning the generator will result in the following file structure:\n\n```text\n.\n\u251c\u2500\u2500 .eslintrc.js\n\u251c\u2500\u2500 .gitignore\n\u251c\u2500\u2500 .vscode\n\u2502   \u2514\u2500\u2500 launch.json\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 configs\n\u2502   \u251c\u2500\u2500 dev.json\n\u2502   \u2514\u2500\u2500 release.json\n\u251c\u2500\u2500 img\n\u2502   \u2514\u2500\u2500 world.png\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 src\n\u2502   \u2514\u2500\u2500 hub\n\u2502       \u251c\u2500\u2500 hub.html\n\u2502       \u251c\u2500\u2500 hub.scss\n\u2502       \u2514\u2500\u2500 hub.tsx\n\u251c\u2500\u2500 tsconfig.json\n\u251c\u2500\u2500 vss-extension.json\n\u2514\u2500\u2500 webpack.config.js\n```\n\n## What's next?\n\nNow that you have generated a new project, you are ready to start debugging. Refer to the generated readme in your new project for instructions on how to get started. You should also check out our [azure-devops-extension-hot-reload-and-debug](https://github.com/microsoft/azure-devops-extension-hot-reload-and-debug#deploy-your-dev-extension-to-azure-devops) repo for an in-depth look at how these features work.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/timelinestoryteller",
  "language": "JavaScript",
  "readme_contents": "# Timeline Storyteller\n\n![\"The Daily Routines of Famous Creative People\": A Story made with Timeline Storyteller](https://github.com/Microsoft/timelinestoryteller/blob/master/public/img/dailyroutines.gif \"'The Daily Routines of Famous Creative People': A Story made with Timeline Storyteller\")\n\n[Timeline Storyteller](https://timelinestoryteller.com/) is an expressive visual storytelling environment for presenting timelines in the browser or in [Microsoft Power BI](https://powerbi.microsoft.com/en-us/).\n\nUse it to present different aspects of timeline data using a palette of timeline representations, scales, and layouts, as well as controls for filtering, highlighting, and annotation.\n\n![Timeline Design dimensions](https://github.com/Microsoft/timelinestoryteller/blob/master/public/img/dims.png \"Timeline Design dimensions\")\n\nTo learn more about the research that informed this project, see [timelinesrevisited.github.io](https://timelinesrevisited.github.io/), which includes a survey of timeline tools and more than 200 bespoke timelines.\n\nSee [these examples](https://timelinestoryteller.com/#examples) of timelines and timeline stories made with Timeline Storyteller.\n\n## Project Team\n\n- [Matthew Brehmer](http://mattbrehmer.github.io/)\n- [Bonghsin Lee](http://research.microsoft.com/en-us/um/people/bongshin/)\n- [Nathalie Henry Riche](http://research.microsoft.com/en-us/um/people/nath/)\n- [Darren Edge](https://www.microsoft.com/en-us/research/people/daedge/)\n- [Christopher White](https://www.microsoft.com/en-us/research/people/chwh/)\n- [Kate Lytvynets](mailto:kalytv@microsoft.com)\n- [David Tittsworth](mailto:David.Tittsworth@microsoft.com)\n\n## Setup / Testing\n\n1. Clone the main branch of this repository: `git clone https://github.com/Microsoft/timelinestoryteller.git`\n\n2. Ensure that [nodejs](https://nodejs.org/), [npm](https://www.npmjs.com/), and [yarn](https://yarnpkg.com/en/) are installed.\n\n3. Open a terminal at the root of the repository and install node modules: `yarn` OR `npm_install`.\n\n4. Build public/app/timelinestoryteller.js: `npm test`\n\n5. Start the node server: `npm start`\n\n6. Open [localhost:8000](http://localhost:8000/)\n\nThe application source code can be found in the [src/](https://github.com/Microsoft/timelinestoryteller/tree/master/src) directory.\n\n## The Timeline Storyteller Power BI custom visual\n\nThis respository contains the source for Timeline Storyteller as a standalone web application. To generate the Timeline Storyteller custom visual for Power BI, refer to [github.com/Microsoft/PowerBI-visuals-TimelineStoryteller](https://github.com/Microsoft/PowerBI-visuals-TimelineStoryteller). \n\n## Preparing your data\n\nTimeline Storyteller currently supports datasets of events in CSV, JSON, or Google Spreadsheet format.\n\nEach event is specified by the following attributes:\n\n- __Required__: `start_date`, date: YYYY, YYYY-MM-DD, or YYYY-MM-DD HH:MMZ (ISO 8601) formats are supported (Z necessary for specifying UTC, otherwise HH:MM will be time-zone dependent). BC dates are permitted, e.g., -27, -13800000000\n- __Optional__: `end_date`, date: using same format as `start_date`\n- __Optional__: `category`, a string corresponding to the category of the event (which Timeline Storyteller encodes as colour)\n- __Optional__: `facet`,a string corresponding to another category of the event (which Timeline Storyteller uses to create a faceted timeline layout; `category` and `facet` can be identical if desired)\n- __Optional__: `content_text`, a string description of the event (which Timeline Storyteller exposes as event annotations)\n\n### Example event in JSON:\n\n`{\n  \"start_date\":\"1775\",\n  \"end_date\":\"1783\",\n  \"content_text\":\"American Revolutionary War: an armed struggle for secession from the British Empire by the Thirteen Colonies that would subsequently become the United States.\",\n  \"facet\":\"North America\",\n  \"category\":\"North America\"\n},`\n\n### Example event in CSV:\n\nheader row:\n\n`start_date,end_date,content_text,facet,category`\n\nexample event row:\n\n`1775,1783,American Revolutionary War: an armed struggle for secession from the British Empire by the Thirteen Colonies that would subsequently become the United States.,North America,North America`\n\n### Example CSV / Google Spreadsheet\n\nHere is the [The Daily Routines of Famous Creative People](https://podio.com/site/creative-routines) demo dataset used in Timeline Storyteller's demo in a [Google Sheet](https://docs.google.com/spreadsheets/d/1x8N7Z9RUrA9Jmc38Rvw1VkHslp8rgV2Ws3h_5iM-I8M/pubhtml).\n\n- Ensure that the spreadsheet is published (open the Google Spreadsheet 'File' menu, select 'Publish to the Web').\n- Ensure that `start_date` and `end_date` columns are formatted as text and not as dates (e.g., `'1926-06-29`).\n- __Required__: Spreadsheet URL\n- __Optional__: Worksheet title (i.e., tab name) for this dataset: `dailyroutines`\n- Enter the spreadsheet URL and worksheet title into Timeline Storyteller's load dialog.\n\n## Usage\n\nNote that more detailed usage instructions are available at [timelinestoryteller.com](https://timelinestoryteller.com/)\n\n1. Load timeline data (demo dataset, JSON, CSV, Google Spreadsheet) or saved timeline story (a JSON Blob with extension .cdc; see step 6)\n\n2. Select a combination of representation, scale, and layout from the menu at the top of the screen; only some combinations are valid; see [our guidance on selecting appropriate combinations for your story](http://timelinesrevisited.github.io/supplemental/gallery/). Mouseover these options to view a tooltip that describes how they might be useful.\n\n3. Edit the canvas\n\n\t* Click on events to annotate with their `content_text` label; resize and reposition labels; SHIFT + click to highlight events without showing label.\n\n\t* Annotate with captions and images; resize and reposition captions and images.\n\n \t* Filter events by category, facet, or segment. Filter by highlighting emphasizing matching events (de-emphasizing non-matching events).\n\n\t* You can also filter by hiding non-matching events.\n\n4. Record current canvas as a scene, which retains labels, captions, and images. Enter playback mode, navigate to previous / next recorded scene.\n\n5. Export current canvas as a PNG, SVG.\n\n6. Export the scenes as an animated GIF or as a JSON Blob (.cdc extension).\n\n## License\n\nTimeline Storyteller\n\nCopyright (c) Microsoft Corporation\n\nAll rights reserved.\n\nMIT License\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the Software), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n## Acknowledgements\n\n### Citing us\n\nIf you use Timeline Storyteller to make a timeline for a research paper, you can cite us in two ways. You can cite the tool itself:\n\n`@misc{TimelineStoryteller,\nauthor = {Matthew Brehmer and Bongshin Lee and Nathalie Henry Riche and Darren Edge and Christopher White and Kate Lytvynets and David Tittsworth},\ntitle = {Microsoft Timeline Storyteller},\nyear = {2017},\nnote = {\\url{https://timelinestoryteller.com}}\n}`\n\nOr you can cite our recent journal paper about the timeline design space:\n\n`@article{Brehmer2016,\nauthor = {Matthew Brehmer and Bongshin Lee and Benjamin Bach and Nathalie Henry Riche and Tamara Munzner},\ntitle = {Timelines Revisited: A Design Space and Considerations for Expressive Storytelling},\njournal = {IEEE Transactions on Visualization and Computer Graphics (TVCG)},\nyear = {2017},\nvolume = {23},\nissue = {9},\npages = {2151--2164},\ndoi = {10.1109/TVCG.2016.2614803},\nISSN = {1077-2626}\n}`\n\n### Demo dataset provenance\n\n- [Priestley's Chart of Biography](https://upload.wikimedia.org/wikipedia/commons/9/98/PriestleyChart.gif)\n- [Great Philosophers since the 8th Century BC](http://bl.ocks.org/rengel-de/5603464)\n- [History's Largest Empires](http://nowherenearithaca.github.io/empires/index.html)\n- [East Asian Dynasties](http://bl.ocks.org/bunkat/2338034)\n- [Epidemics since the 14th Century](https://en.wikipedia.org/wiki/List_of_epidemics)\n- [Prime Ministers of Canada](http://www.downloadexcelfiles.com/ca_en/download-excel-file-list-prime-ministers-canada)\n- [Presidents of France](http://www.downloadexcelfiles.com/fr_en/download-excel-file-list-presidents-france)\n- [Chancellors of Germany](https://en.wikipedia.org/wiki/List_of_Chancellors_of_Germany)\n- [Presidents of Italy](http://www.downloadexcelfiles.com/it_en/download-excel-file-list-presidents-italy)\n- [Prime Ministers of Japan](http://www.downloadexcelfiles.com/jp_en/download-excel-file-list-prime-ministers-japan)\n- [Prime Ministers of the UK](http://www.downloadexcelfiles.com/gb_en/download-excel-file-list-prime-ministers-uk)\n- [Presidents of the USA](https://raw.githubusercontent.com/hitch17/sample-data/master/presidents.json)\n- [C4-5 Hurricanes: 1960-2010](http://www.aoml.noaa.gov/hrd/hurdat/easyread-2011.html)\n- [The Daily Routines of Famous Creative People](https://podio.com/site/creative-routines)\n-['Visualizing painters' lives\" by Accurat](http://www.brainpickings.org/2013/06/07/painters-lives-accurat-giorgia-lupi/)\n- ['From first published to masterpieces' by Accurat](http://www.brainpickings.org/2013/11/29/accurat-modern-library/)\n- [Kurzweil's 'Countdown to Singularity'](http://www.singularity.com/images/charts/CountdowntoSingularityLog.jpg)\n- ['A Perspective on Time' by mayra.artes for Wait But Why](http://visual.ly/perspective-time)\n- ['Life of a Typical American' by Tim Urban for Wait But Why](http://waitbutwhy.com/2014/05/life-weeks.html)\n\n### Noun Project icons used in the user interface\n\nAll Icons [CC BY 3.0](https://creativecommons.org/licenses/by/3.0/us/), by name and author:\n\n- [check-mark](https://thenounproject.com/term/check-mark/608852) (Arthur Shlain)\n- [calendar](https://thenounproject.com/term/calendar/38869) (Kiril Tomilov)\n- [timeline](https://thenounproject.com/term/timeline/152347) (Alecander Bickov)\n- [gif-file](https://thenounproject.com/term/gif-file/446903) (Pranav Grover)\n- [png-file](https://thenounproject.com/term/png-file/446907) (Pranav Grover)\n- [svg-file](https://thenounproject.com/term/svg-file/446904) (Pranav Grover)\n- [json-file](https://thenounproject.com/term/json-file/446959) (Pranav Grover)\n- [csv-file](https://thenounproject.com/term/csv-file/446962) (Pranav Grover)\n- [drive](https://thenounproject.com/term/drive/128372) (Denis Klyuchnikov)\n- [grid](https://thenounproject.com/term/grid/539919) (Doejo)\n- [folder](https://thenounproject.com/term/folder/43216) (iconoci)\n- [filter](https://thenounproject.com/term/filter/132317) (Creative Shell)\n- [image](https://thenounproject.com/term/image/332296) (Creative Shell)\n- [quotation-mark](https://thenounproject.com/term/quotation-mark/378366) (Veronika Krpciarova)\n- [pin](https://thenounproject.com/term/pin/172903) (Alexandr Cherkinsky)\n- [eraser](https://thenounproject.com/term/eraser/3715) (Terrence Kevin Oleary)\n- [invisible](https://thenounproject.com/term/invisible/506290) (Kid A)\n- [book](https://thenounproject.com/term/book/861149) (Setyo Ari Wibowo)\n"
 },
 {
  "repo": "microsoft/MCW-Cloud-native-applications",
  "language": "CSS",
  "readme_contents": "### Let us know how we\u2019re doing!  \nPlease take a moment to fill out the [Microsoft Cloud Workshop Survey](https://forms.office.com/Pages/ResponsePage.aspx?id=v4j5cvGGr0GRqy180BHbRyEtIpX7sDdChuWsXhzKJXJUNjFBVkROWDhSSVdYT0dSRkY4UVFCVzZBVy4u) and help us improve our offerings.\n\n# Cloud-native applications\n\nFabrikam Medical Conferences provides conference web site services, tailored to the medical community. Their business has grown and the management of many instances of the code base and change cycle per tenant has gotten out of control.\n\nThe goal of this workshop is to help them build a proof of concept (POC) that will migrate their code to a more manageable process that involves containerization of tenant code, a better DevOps workflow, and a simple lift-and-shift story for their database backend.\n\nNovember 2020\n\n## Target Audience\n\n- Application developer\n- Infrastructure architect\n\n## Abstracts\n\n### Workshop\n\nIn this workshop, you will build a proof of concept (POC) that will transform an existing on-premises application to a container-based application. This POC will deliver a multi-tenant web app hosting solution leveraging Azure Kubernetes Service (AKS), Docker containers on Linux nodes, and a migration from MongoDB to CosmosDB.\n\nAt the end of this workshop, you will be better able to improve the reliability of and increase the release cadence of your container-based applications through time-tested DevOps practices.\n\n### Whiteboard Design Session\n\nIn this whiteboard design session, you will learn about the choices related to building and deploying containerized applications in Azure, critical decisions around this, and other aspects of the solution, including ways to lift-and-shift parts of the application to reduce applications changes.\n\nBy the end of this design session, you will be better able to design solutions that target Azure Kubernetes Service (AKS) and define a DevOps workflow for containerized applications.\n\n### Hands-on Lab\n\nThis hands-on lab is designed to guide you through the process of building and deploying Docker images to the Kubernetes platform hosted on Azure Kubernetes Services (AKS), in addition to learning how to work with dynamic service discovery, service scale-out, and high-availability.\n\nAt the end of this lab, you will be better able to build and deploy containerized applications to Azure Kubernetes Service and perform common DevOps procedures.\n\n## Azure services and related products\n\n- Azure Kubernetes Service (AKS)\n- Azure Container Registry\n- GitHub\n- Docker\n- Cosmos DB (including MongoDB API)\n\n## Azure solutions\n\nApp Modernization\n\n## Related references\n\n- [MCW](https://github.com/Microsoft/MCW)\n\n## Help & Support\n\nWe welcome feedback and comments from Microsoft SMEs & learning partners who deliver MCWs.  \n\n***Having trouble?***\n\n- First, verify you have followed all written lab instructions (including the Before the Hands-on lab document).\n- Next, submit an issue with a detailed description of the problem.\n- Do not submit pull requests. Our content authors will make all changes and submit pull requests for approval.\n\nIf you are planning to present a workshop, *review and test the materials early*! We recommend at least two weeks prior.\n\n### Please allow 5 - 10 business days for review and resolution of issues.\n"
 },
 {
  "repo": "microsoft/secure-data-sandbox",
  "language": "TypeScript",
  "readme_contents": "# Secure Data Sandbox ![.github/workflows/ci.yml](https://github.com/microsoft/secure-data-sandbox/workflows/.github/workflows/ci.yml/badge.svg)\r\n\r\n**`SDS` IS UNDER CONSTRUCTION AND NOT USABLE AT THIS POINT.\r\nTHIS PAGE WILL BE UPDATED AS FUNCTIONALITY BECOMES AVAILABLE.**\r\n\r\n`SDS` is a secure execution environment for conducting machine learning trials against confidential data.\r\n\r\nThe goal of `SDS` is to enable collaboration between data scientists and organizations with interesting problems.\r\nThe challenge is that interesting problems come with interesting data sets that are almost always proprietary. These data sets are rich with trade secrets and personably identifiable information, and are usually encumbered by contracts, regulated by statute, and subject to corporate data stewardship policies.\r\n\r\nIn-house data science departments know how to work with this data, but the compliance issues make it is hard for them to collaborate with third parties and experts from industry and academia.\r\n\r\n`SDS` aims to solve this problem by creating a sandbox for machine learning experiments inside the environment that hosts sensitive data.\r\nWith `SDS`, an organization can host machine learning challenges and invite third parties to submit solutions for evaluation against sensitive data that would otherwise be unavailable.\r\n\r\n## Try SDS\r\n\r\n### Building SDS\r\n`SDS` is a [Node.js](https://nodejs.org/en/) project,\r\nwritten in [TypeScript](https://www.typescriptlang.org/).\r\nIn order to use `SDS` you must have\r\n[Node](https://nodejs.org/en/download/) installed on your machine.\r\n`SDS` has been tested with Node version [12.16.3](https://nodejs.org/download/release/v12.16.3/).\r\n\r\nHere are the steps for cloning and building `SDS`:\r\n~~~\r\n% git clone https://github.com/microsoft/secure-data-sandbox.git\r\n% npm install\r\n% npm run compile\r\n~~~\r\n\r\n### Running SDS Locally\r\nNow that we've built `SDS`, let's run a local instance of the Laboratory service.\r\nThis local instance does not have a worker pool, so it won't be able to actually run tests, but it allows you to get a feel for the CLI commands. Note that the local instance does not run in a secure environment.\r\n\r\nOpen two shell windows. In the first window, start the laboratory service:\r\n~~~\r\n% npm run laboratory\r\n~~~\r\n\r\nWe can run the CLI run the second shell window. Let's start with the `help` command:\r\n~~~\r\n% npm run cli help\r\n\r\nUsage: sds [options] [command]\r\n\r\nSecure Data Sandbox CLI\r\n\r\nOptions:\r\n  -h, --help                   display help for command\r\n\r\nCommands:\r\n  connect [service]            Connect to a Laboratory [service] or print connection info.\r\n  create <type> <spec>         Create a benchmark, candidate, or suite from a specification where <type> is either \"benchmark\", \"candidate\", or\r\n                               \"suite\".\r\n  demo                         Configures Laboratory service with demo data.\r\n  deploy <server>              NOT YET IMPLEMENTED. Deploy a Laboratory service.\r\n  examples                     Show usage examples.\r\n  list <type>                  Display summary information about benchmarks, candidates, runs, and suites.\r\n  results <benchmark> <suite>  Display the results of all runs against a named benchmark and suite.\r\n  run <candidate> <suite>      Run a named <candidate> against a named <suite>.\r\n  show <type> [name]           Display all benchmarks, candidates, suites, or runs. If optional [name] is specified, only show matching items.\r\n  help [command]               display help for command\r\n\r\nFor more information and examples, see https://github.com/microsoft/secure-data-sandbox/blob/main/laboratory/README.md\r\n~~~\r\n\r\nThe first thing we need to do is connect the CLI to the laboratory service that we just started. Currently `packages/laboratory/dist/main.js` listens on port 3000 of localhost.\r\n~~~\r\n% npm run cli connect http://localhost:3000\r\n\r\nConnected to http://localhost:3000/.\r\n~~~\r\nThis writes the connection information to `~/.sds`, which is consulted every time the CLI is run. If you don't connect to a Laboratory, you will get the following error:\r\n~~~\r\n% npm run cli list benchmark\r\n\r\nError: No laboratory connection. Use the \"connect\" command to specify a laboratory.\r\n~~~\r\n\r\nNow that we're connected to a Laboratory service,\r\nwe can use the `demo` command to populate the server with sample data, including\r\n* A `benchmark`\r\n* A `candidate`\r\n* A `suite`\r\n* Two `runs` with results.\r\n\r\n~~~\r\n% npm run cli demo\r\n\r\n=== Sample benchmark ===\r\nname: benchmark1\r\nauthor: author1\r\napiVersion: v1alpha1\r\nstages:\r\n  - name: candidate\r\n    kind: candidate\r\n    volumes:\r\n      - name: training\r\n        path: /input\r\n  - name: scoring\r\n    image: benchmark-image\r\n    kind: container\r\n    volumes:\r\n      - name: reference\r\n        path: /reference\r\n\r\n\r\n=== Sample candidate ===\r\nname: candidate1\r\nauthor: author1\r\napiVersion: v1alpha1\r\nbenchmark: benchmark1\r\nimage: candidate1-image\r\n\r\n\r\n=== Sample suite ===\r\nname: suite1\r\nauthor: author1\r\napiVersion: v1alpha1\r\nbenchmark: benchmark1\r\nvolumes:\r\n  - name: training\r\n    type: AzureBlob\r\n    target: 'https://sample.blob.core.windows.net/training'\r\n  - name: reference\r\n    type: AzureBlob\r\n    target: 'https://sample.blob.core.windows.net/reference'\r\n\r\n\r\nInitiated run 0db6c510-d059-11ea-ab64-31e44163fc86\r\nInitiated run 0dba4780-d059-11ea-ab64-31e44163fc86\r\n~~~\r\n\r\nIf we didn't want to use the built-in `demo` command, we could have created the benchmark, candidate, suite, and runs manually as follows:\r\n~~~\r\n% npm run cli create benchmark sample-data/benchmark1.yaml\r\nbenchmark created\r\n\r\n% npm run cli create candidate sample-data/candidate1.yaml\r\ncandidate created\r\n\r\n% npm run cli create suite sample-data/suite1.yaml\r\nsuite created\r\n\r\n% npm run cli run candidate1 suite1\r\nScheduling run 1dae9970-d059-11ea-ab64-31e44163fc86\r\n\r\n% npm run cli run candidate1 suite1\r\nScheduling run 1fbe1880-d059-11ea-ab64-31e44163fc86\r\n~~~\r\n\r\nThe `demo` command does one thing we can't do through the CLI, and that is to pretend to be a worker and report status for the runs.\r\n\r\n**List benchmarks, candidates, suites**\r\n\r\n~~~\r\n% npm run cli list benchmark\r\nname         submitter   date\r\nbenchmark1   author1     2020-07-27 22:32:28 UTC\r\n\r\n% npm run cli list candidate\r\nname         submitter   date  \r\ncandidate1   author1     2020-07-27 22:32:28 UTC\r\n\r\n% npm run cli list suite\r\nname     submitter   date\r\nsuite1   author1     2020-07-27 22:32:28 UTC\r\n~~~\r\n\r\n**Show benchmarks, candidates, suites**\r\n~~~\r\n% npm run cli show benchmark benchmark1\r\nstages:\r\n  - name: candidate\r\n    kind: candidate\r\n    volumes:\r\n      - name: training\r\n        path: /input\r\n  - name: scoring\r\n    kind: container\r\n    image: benchmark-image\r\n    volumes:\r\n      - name: reference\r\n        path: /reference\r\nname: benchmark1\r\nauthor: author1\r\napiVersion: v1alpha1\r\ncreatedAt: 2020-07-27T22:32:28.865Z\r\nupdatedAt: 2020-07-27T22:32:43.284Z\r\n\r\n\r\n% npm run cli show candidate candidate1\r\nname: candidate1\r\nauthor: author1\r\napiVersion: v1alpha1\r\nbenchmark: benchmark1\r\nimage: candidate1-image\r\ncreatedAt: 2020-07-27T22:32:28.883Z\r\nupdatedAt: 2020-07-27T22:32:47.384Z\r\n\r\n\r\n% npm run cli show suite suite1\r\nvolumes:\r\n  - name: training\r\n    type: AzureBlob\r\n    target: 'https://sample.blob.core.windows.net/training'\r\n  - name: reference\r\n    type: AzureBlob\r\n    target: 'https://sample.blob.core.windows.net/reference'\r\nname: suite1\r\nauthor: author1\r\napiVersion: v1alpha1\r\nbenchmark: benchmark1\r\ncreatedAt: 2020-07-27T22:32:28.889Z\r\nupdatedAt: 2020-07-27T22:32:50.623Z\r\n~~~\r\n\r\n**List runs**\r\n~~~\r\n% npm run cli list run\r\nname                                   submitter   date                      candidate    suite    status   \r\n0db6c510-d059-11ea-ab64-31e44163fc86   unknown     2020-07-27 22:32:28 UTC   candidate1   suite1   completed\r\n0dba4780-d059-11ea-ab64-31e44163fc86   unknown     2020-07-27 22:32:28 UTC   candidate1   suite1   completed\r\n1dae9970-d059-11ea-ab64-31e44163fc86   unknown     2020-07-27 22:32:55 UTC   candidate1   suite1   created  \r\n1fbe1880-d059-11ea-ab64-31e44163fc86   unknown     2020-07-27 22:32:59 UTC   candidate1   suite1   created  \r\n~~~\r\n\r\n**Displaying Run Results**\r\n~~~\r\n% npm run cli results benchmark1 suite1\r\n\r\nrun                                    submitter   date                      passed   failed   skipped\r\n0db6c510-d059-11ea-ab64-31e44163fc86   unknown     2020-07-27 22:32:28 UTC        5        6       ---\r\n0dba4780-d059-11ea-ab64-31e44163fc86   unknown     2020-07-27 22:32:28 UTC        3      ---         7\r\n~~~\r\n\r\n## Deploying SDS to the cloud\r\n\r\nTODO\r\n\r\n## [Developer Guide](docs/development.md)\r\n\r\nFor developers looking to modify SDS itself, please refer to the [developer guide](docs/development.md)\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n"
 },
 {
  "repo": "microsoft/vscode-docs",
  "language": "CSS",
  "readme_contents": "<p align=\"center\">\n  <img alt=\"vscode logo\" src=\"images/logo-stable.png\" width=\"100px\" />\n  <h1 align=\"center\">Visual Studio Code Documentation</h1>\n</p>\n\nYou've found the Visual Studio Code documentation GitHub repository, which contains the content for the [Visual Studio Code documentation](https://code.visualstudio.com/docs).\n\nTopics submitted here will be published to the [Visual Studio Code](https://code.visualstudio.com) portal.\n\nIf you are looking for the VS Code product GitHub repository, you can find it [here](https://github.com/microsoft/vscode).\n\n## Index\n\n- [Index](#index)\n- [Visual Studio Code](#visual-studio-code)\n- [Feedback](#feedback)\n- [Documentation Issues](#documentation-issues)\n- [Contributing](#contributing)\n  - [Workflow](#workflow)\n  - [Cloning](#cloning)\n    - [Cloning without binary files](#cloning-without-binary-files)\n- [Publishing](#publishing)\n\n## Visual Studio Code\n\n[VS Code](https://code.visualstudio.com/) is a lightweight source code editor and powerful development environment for building and debugging modern web, mobile and cloud applications. It is free and available on your favorite platform - Linux, macOS, and Windows.\n\nIf you landed here looking for other information about VS Code, head over to [our website](https://code.visualstudio.com) for additional information.\n\n## Feedback\n\nIf you want to give documentation feedback, please use the feedback control located at the bottom of each documentation page.\n\n## Documentation Issues\n\nTo enter documentation bugs, please create a [new GitHub issue](https://github.com/microsoft/vscode-docs/issues). Please check if there is an existing issue first.\n\nIf you think the issue is with the VS Code product itself, please enter issues in the VS Code product repo [here](https://github.com/microsoft/vscode/issues).\n\n## Contributing\n\nTo contribute new topics/information or make changes to existing documentation, please read the [Contributing Guideline](./CONTRIBUTING.md#contributing).\n\n### Workflow\n\nThe two suggested workflows are:\n\n- For small changes, use the \"Edit\" button on each page to edit the Markdown file directly on GitHub.\n- If you plan to make significant changes or preview the Markdown files in VS Code, [clone](#cloning) the repo to [edit and preview](https://code.visualstudio.com/docs/languages/markdown) the files directly in VS Code.\n\n![Markdown Preview Button](images/MDPreviewButton.png)\n\n### Cloning\n\n1. Install [Git LFS](https://git-lfs.github.com/).\n2. Run `git lfs install` to setup global git hooks. You only need to run this once per machine.\n3. `git clone git@github.com:Microsoft/vscode-docs.git`.\n4. Now you can `git add` binary files and commit them. They'll be tracked in LFS.\n\n#### Cloning without binary files\n\nYou might want to clone the repo without the 1.6GB images. Here are the steps:\n\n1. Install [Git LFS](https://git-lfs.github.com/).\n2. Run `git lfs install` to setup global git hooks. You only need to run this once per machine.\n3. Clone the repo without binary files.\n    - macOS / Linux: `GIT_LFS_SKIP_SMUDGE=1 git clone git@github.com:Microsoft/vscode-docs.git`.\n    - Windows: `$env:GIT_LFS_SKIP_SMUDGE=\"1\"; git clone git@github.com:Microsoft/vscode-docs.git`.\n4. Now you can selectively checkout some binary files to work with. For example:\n    - `git lfs pull -I \"docs/nodejs\"` to only download images in `docs/nodejs`\n    - `git lfs pull -I \"release-notes/images/1_4*/*\"` to only download images in `release-notes/images/1_4*`\n    - `git lfs pull -I \"docs,api\"` to download all images in `docs` and in `api`\n    - `git lfs pull -I <PATTERN>`, as long as `<PATTERN>` is a valid [Git LFS Include and Exclude pattern](https://github.com/git-lfs/git-lfs/blob/main/docs/man/git-lfs-fetch.1.ronn#include-and-exclude).\n\nThe history of this repo before we adopted LFS can be found at [microsoft/vscode-docs-archive](https://github.com/microsoft/vscode-docs-archive).\n\n## Publishing\n\nSteps for how to publish documentation changes can be found [here](https://github.com/microsoft/vscode-website#publishing-a-documentation-change) in the (private) repository of the VS Code website.\n"
 },
 {
  "repo": "microsoft/msquic",
  "language": "C",
  "readme_contents": "MsQuic\n======\n\nMsQuic is a Microsoft implementation of the [IETF QUIC](https://datatracker.ietf.org/wg/quic/about/)\nprotocol. It is cross platform, written in C and designed to be a general purpose QUIC library.\n\n> **Important** The QUIC protocol is not an official RFC yet. It has been approved by the IESG and now is in the RFC editor queue (final step).\n\nIETF Drafts: [Transport](https://tools.ietf.org/html/draft-ietf-quic-transport), [TLS](https://tools.ietf.org/html/draft-ietf-quic-tls), [Recovery](https://tools.ietf.org/html/draft-ietf-quic-recovery), [Datagram](https://tools.ietf.org/html/draft-ietf-quic-datagram), [Load Balancing](https://tools.ietf.org/html/draft-ietf-quic-load-balancers), [Version Negotiation](https://tools.ietf.org/html/draft-ietf-quic-version-negotiation)\n\n[![Build Status](https://dev.azure.com/ms/msquic/_apis/build/status/CI?branchName=main)](https://dev.azure.com/ms/msquic/_build/latest?definitionId=347&branchName=main) [![Test Status](https://img.shields.io/azure-devops/tests/ms/msquic/347/main)](https://dev.azure.com/ms/msquic/_build/latest?definitionId=347&branchName=main) [![Perf Dashboard](https://img.shields.io/static/v1?label=Performance&message=Dashboard&color=blueviolet)](https://microsoft.github.io/msquic/) [![Code Coverage](https://img.shields.io/azure-devops/coverage/ms/msquic/347/main)](https://dev.azure.com/ms/msquic/_build/latest?definitionId=347&branchName=main) ![CodeQL](https://github.com/microsoft/msquic/workflows/CodeQL/badge.svg?branch=main) [![Language grade: C/C++](https://img.shields.io/lgtm/grade/cpp/g/microsoft/msquic.svg?logo=lgtm&logoWidth=18)](https://lgtm.com/projects/g/microsoft/msquic/context:cpp) [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4846/badge)](https://bestpractices.coreinfrastructure.org/projects/4846) [![Discord](https://img.shields.io/discord/827744285595271168?label=Discord&logo=discord&logoColor=white&color=7289DA)](https://discord.gg/YGAtCwTSsc)\n\n## Protocol Features\n\nQUIC has many benefits when compared to existing \"TLS over TCP\" scenarios:\n\n  * All packets are encrypted and handshake is authenticated with TLS 1.3.\n  * Parallel streams of (reliable and unreliable) application data.\n  * Exchange application data in the first round trip (0-RTT).\n  * Improved congestion control and loss recovery.\n  * Survives a change in the clients IP address or port.\n  * Stateless load balancing.\n  * Easily extendable for new features and extensions.\n\n## Library Features\n\nMsQuic has several features that differentiates it from other QUIC implementations:\n\n  * Optimized for client and server.\n  * Optimized for maximal throughput and minimal latency.\n  * Asynchronous IO.\n  * Receive side scaling ([RSS](https://docs.microsoft.com/en-us/windows-hardware/drivers/network/introduction-to-receive-side-scaling)) support.\n  * UDP send and receive coalescing support.\n\n# Documentation\n\n  * For frequently asked questions, see the [FAQs](./docs/FAQ.md).\n  * For platform support details, see the [Platforms docs](./docs/Platforms.md).\n  * For release details, see the [Release docs](./docs/Release.md).\n  * For performance data, see the [Performance dashboard](https://aka.ms/msquicperformance).\n  * For building the MsQuic library, see the [Build docs](./docs/BUILD.md).\n  * For using the MsQuic API, see the [API docs](./docs/API.md) or the [Sample](./src/tools/sample/sample.cpp).\n  * For deploying with MsQuic, see the [Deployment docs](./docs/Deployment.md).\n  * For diagnosing MsQuic, see the [Diagnostics docs](./docs/Diagnostics.md) and the [Trouble Shooting Guide](./docs/TSG.md).\n\n# Contributing\n\nFor information on contributing, please see our [contribution guidlines](./.github/CONTRIBUTING.md).\n"
 },
 {
  "repo": "microsoft/just",
  "language": "TypeScript",
  "readme_contents": "# Just\n\n[![npm version](https://badge.fury.io/js/just-task.svg)](https://badge.fury.io/js/just-task)\n[![NPM Downloads](https://img.shields.io/npm/dm/just-task.svg?style=flat)](https://www.npmjs.com/package/just-task)\n\n`Just` is a library that organizes build tasks for your JS projects. It consists of\n\n- a build task build definition library\n- sane preset build flows for node and browser projects featuring TypeScript, Webpack and jest\n- project scaffold tool that generates no-ejection needed repos that tracks template changes\n\n# Documentation\n\nAll the documentation is online at https://microsoft.github.io/just/\n\n# Building\n\nThis README contains only the instructions on how to build and contribute to the project. This is a monorepo that uses the [lerna](https://github.com/lerna/lerna) monorepo management utility. To get started, simply run the following:\n\n`yarn`\n\nand build all the packages this way:\n\n`yarn build`\n\nDevelopment is usually done one package at a time. So go into each package and develop with the innerloop npm script:\n\n```\ncd packages/just-task\nyarn dev\n```\n\nTests are run with the `test` npm script:\n\n```\ncd packages/just-task\nyarn test\n```\n\n# Packages\n\n| Package            | Description                                                                             |\n| ------------------ | --------------------------------------------------------------------------------------- |\n| create-just        | Invoked by `npm init just`, a tool that scaffolds project repos                         |\n| just-task          | The task definition library that wraps `undertaker` and `yargs` libraries               |\n| just-scripts       | A reusable preset of frequently used tasks in node and browser projects                 |\n| just-stack-\\*      | A set of templates to be used by the scaffold tool `create-just`                        |\n| just-scripts-utils | A set of utilities that are shared between `just-scripts` and `create-just`             |\n| just-task-logger   | A shared pretty logger used to display timestamps along with a message                  |\n| documentation      | The Docusaurus site content and styles which generates the Github page for this library |\n\n# Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com. Please refer [Contribution guide](https://github.com/microsoft/just/.github/CONTRIBUTING.md) for more details\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/accessibility-insights-web",
  "language": "TypeScript",
  "readme_contents": "<!--\nCopyright (c) Microsoft Corporation. All rights reserved.\nLicensed under the MIT License.\n-->\n\n## ![Product Logo](./src/icons/brand/blue/brand-blue-48px.png) Accessibility Insights for Web & Android\n\n[![Build Status](https://dev.azure.com/accessibility-insights/accessibility-insights-web/_apis/build/status/accessibility-insights-web%20CI?branchName=main)](https://dev.azure.com/accessibility-insights/accessibility-insights-web/_build/latest?definitionId=37&branchName=main)\n[![codecov](https://codecov.io/gh/microsoft/accessibility-insights-web/branch/main/graph/badge.svg)](https://codecov.io/gh/microsoft/accessibility-insights-web)\n[![Chrome Web Store](https://img.shields.io/chrome-web-store/v/pbjjkligggfmakdaogkfomddhfmpjeni.svg?label=Version)](https://chrome.google.com/webstore/detail/accessibility-insights-fo/pbjjkligggfmakdaogkfomddhfmpjeni)\n[![Chrome Web Store](https://img.shields.io/chrome-web-store/users/pbjjkligggfmakdaogkfomddhfmpjeni.svg)](https://chrome.google.com/webstore/detail/accessibility-insights-fo/pbjjkligggfmakdaogkfomddhfmpjeni)\n[![Chrome Web Store](https://img.shields.io/chrome-web-store/stars/pbjjkligggfmakdaogkfomddhfmpjeni.svg)](https://chrome.google.com/webstore/detail/accessibility-insights-fo/pbjjkligggfmakdaogkfomddhfmpjeni/reviews)\n[![Dependabot Status](https://api.dependabot.com/badges/status?host=github&repo=microsoft/accessibility-insights-web)](https://dependabot.com)\n\nTwo projects are built from this repository:\n\n-   **Accessibility Insights for Web** is a browser extension for Google Chrome and the new Microsoft Edge, used for assessing the accessibility of web sites and web applications.\n-   **Accessibility Insights for Android** is a cross-platform desktop tool used for testing accessibility of Android applications.\n\n### Install Accessibility Insights for Web\n\n-   ![Canary Logo](./src/icons/brand/red/brand-red-16px.png) [Canary](https://chrome.google.com/webstore/detail/hbcplehnakffdldhldncjlnbpfgogbem) (released continuously)\n-   ![Insider Logo](./src/icons/brand/violet/brand-violet-16px.png) [Insider](https://chrome.google.com/webstore/detail/nnmjfbmebeckhpejobgjjjnchlljiagp) (on feature completion)\n-   ![Production Logo](./src/icons/brand/blue/brand-blue-16px.png) [Production](https://chrome.google.com/webstore/detail/pbjjkligggfmakdaogkfomddhfmpjeni) (after validation in Insider)\n\n### Install Accessibility Insights for Android\n\n-   MacOS ([Canary](https://aka.ms/accessibility-insights-for-android/downloads/CanaryMacOS), [Insider](https://aka.ms/accessibility-insights-for-android/downloads/InsiderMacOS), [Production](https://aka.ms/accessibility-insights-for-android/downloads/MacOS))\n-   Windows ([Canary](https://aka.ms/accessibility-insights-for-android/downloads/CanaryWindows), [Insider](https://aka.ms/accessibility-insights-for-android/downloads/InsiderWindows), [Production](https://aka.ms/accessibility-insights-for-android/downloads/Windows))\n-   Linux ([Canary](https://aka.ms/accessibility-insights-for-android/downloads/CanaryLinux), [Insider](https://aka.ms/accessibility-insights-for-android/downloads/InsiderLinux), [Production](https://aka.ms/accessibility-insights-for-android/downloads/Linux))\n\n## Data/Telemetry\n\nBy opting into telemetry, you [help the community](https://go.microsoft.com/fwlink/?linkid=2077765) develop inclusive software. We collect anonymized data to identify the top accessibility issues found by the users. This will help focus the accessibility tools and standards community to improve guidelines, rules engines, and features.\n\nThis project collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://privacy.microsoft.com/en-us/privacystatement) to learn more.\n\n## Reporting security vulnerabilities\n\nIf you believe you have found a security vulnerability in this project, please follow [these steps](https://technet.microsoft.com/en-us/security/ff852094.aspx) to report it. For more information on how vulnerabilities are disclosed, see [Coordinated Vulnerability Disclosure](https://technet.microsoft.com/en-us/security/dn467923).\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\n\n## FAQ\n\nPlease visit our [FAQ](https://accessibilityinsights.io/docs/en/web/reference/faq) page.\n\n## Contributing\n\nAll contributions are welcome! To get started, please read through our [CONTRIBUTING](./CONTRIBUTING.md) guidelines for this project. After that, see:\n\n-   [Git branch setup](./docs/git-branch-setup.md)\n-   [Building Accessibility Insights for Web](./docs/building-web.md)\n-   [Building Accessibility Insights for Android (Unified)](./docs/building-unified.md)\n\n## Code of Conduct\n\nPlease read through our [Code of Conduct](./CODE_OF_CONDUCT.md) to this project.\n"
 },
 {
  "repo": "microsoft/flamegrill",
  "language": "HTML",
  "readme_contents": "# flamegrill\n\nflame grill your webpages for easy digestion\n\n## Prerequisites\n\nweb page to test\n\n## Usage\n\n```\nflamegrill [command] [options]\n```\n\n## Commands\n\n### cook (default)\n\nrun flamegrill against specified input\n\n## Options\n\n### --name, -n\n\nname for given scenario\n\n### --scenario, -s\n\nURL for scenario under test\n\n### --baseline, -b\n\noptional baseline scenario to compare against\n\n### --temp-dir, -t\n\nlocation to store intermediate files (default: cwd)\n\n### --out-dir, -o\n\nlocation to store test results (default: cwd)\n\n### --help, -?, -h\n\nhelp message\n\n## Examples\n\nThe following invocations perform the tests using a scenario that you can find [here](https://github.com/OfficeDev/office-ui-fabric-react/blob/master/apps/perf-test/src/scenarios/SplitButtonNew.tsx).\n\n```\n$ flamegrill cook -n SplitButton -s \"http://fabricweb.z5.web.core.windows.net/pr-deploy-site/refs/heads/master/perf-test/index.html?scenario=SplitButtonNew&iterations=5000\"\n\n$ flamegrill cook -n SplitButton -s \"http://fabricweb.z5.web.core.windows.net/pr-deploy-site/refs/heads/master/perf-test/index.html?scenario=SplitButtonNew&iterations=5000\" -b \"http://fabricweb.z5.web.core.windows.net/pr-deploy-site/refs/heads/master/perf-test/index.html?scenario=SplitButton&iterations=5000\"\n\n$ flamegrill cook -n SplitButtonNew -s \"http://fabricweb.z5.web.core.windows.net/pr-deploy-site/refs/heads/master/perf-test/index.html?scenario=SplitButtonNew&iterations=5000\" -o out -t temp\n```\n\n## Open Source Credits\n\n[Flamebearer](https://github.com/mapbox/flamebearer) is an inspiration for this project and is used to generate flamegraphs. Parts of Flamebearer have been modified and expanded upon to add more functionality to the flamegraphs.\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/azure-iot-developer-kit",
  "language": null,
  "readme_contents": "# Microsoft Azure IoT Developer Kit\r\n\r\nVisit the project overview page to get started: [https://microsoft.github.io/azure-iot-developer-kit/](https://microsoft.github.io/azure-iot-developer-kit/)\r\n\r\n## Repository Structure\r\n\r\n* [/docs](https://github.com/Microsoft/azure-iot-developer-kit/tree/master/docs) - Project home page with all other documents\r\n\r\n## Contributing\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/QuantumLibraries",
  "language": "Q#",
  "readme_contents": "# Microsoft Quantum Development Kit Libraries #\n\nWelcome to the Microsoft Quantum Development Kit!\n\nThis repository contains open-source libraries for the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum):\n\n- **[Docs/](./Docs)**: Additional documentation for developing on the libraries. Please see [QDK online documentation](https://docs.microsoft.com/azure/quantum/) for online documentation.\n- **[Standard/](./Standard)**: Q# sources used to implement [the Q# standard libraries](https://docs.microsoft.com/azure/quantum/user-guide/libraries/standard).\n- **[Chemistry/](./Chemistry)**: Q# and C# sources used to implement a library for [quantum chemistry](https://docs.microsoft.com/azure/quantum/user-guide/libraries/chemistry) and Hamiltonian simulation.\n- **[Numerics/](./Numerics)**: Q# sources used to implement the [quantum numerics library](https://docs.microsoft.com/azure/quantum/user-guide/libraries/numerics).\n- **[LICENSE](./LICENSE.txt)**: Terms of use and license details for the Quantum Development Kit libraries.\n\n## New to Quantum? ##\n\nSee the [introduction to quantum computing](https://docs.microsoft.com/azure/quantum/concepts-overview/) provided with the Quantum Development Kit.\n\n## Getting Started ##\n\nThe libraries provided in this repository are built using [.NET Core](https://docs.microsoft.com/en-us/dotnet/core/) and the\n[Quantum Development Kit](https://docs.microsoft.com/azure/quantum).\nPlease see the [installation guide](https://docs.microsoft.com/azure/quantum/install-overview-qdk) for how to get up and running.\n\nYou may also visit our [Quantum](https://github.com/Microsoft/Quantum) repository, which offers a wide variety\nof samples on how to use these libraries to write quantum based programs.\n\n## Build Status ##\n\n| branch | status    |\n|--------|-----------|\n| main | [![Build Status](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_apis/build/status/Microsoft.QuantumLibraries?branchName=main)](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_build/latest?definitionId=1&branchName=main) |\n\n## Feedback ##\n\nIf you have feedback about the content in this repository, please let us know by filing a [new issue](https://github.com/microsoft/quantumlibraries/issues/new/choose)!\nIf you have feedback about some other part of the Microsoft Quantum Development Kit, please see the [contribution guide](https://docs.microsoft.com/azure/quantum/contributing-overview/) for more information.\n\n## Contributing ##\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## [Optional] Using Prerelease Versions ##\n\nIf you're interested in helping test the Quantum Development Kit libraries, or if you want to try out new features before they are released, you can add the [Quantum Development Kit prerelease feed](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_packaging?_a=feed&feed=alpha) to your .NET Core SDK configuration.\nPackages on the prerelease feed are marked with `-alpha` in their version number, so that projects built using released versions of Quantum Development Kit libraries will not be affected.\nNote that the prerelease feed is used automatically when building libraries in this repository.\n\nTo use the prerelease feed, edit your `NuGet.Config` file to include the prerelease feed URL (`https://pkgs.dev.azure.com/ms-quantum-public/Microsoft Quantum (public)/_packaging/alpha/nuget/v3/index.json`) as a package source.\nThe location of this file varies depending on your operating system:\n\n| OS | NuGet config file location |\n|----|----------------------------|\n| Windows | `$Env:APPDATA/Roaming/NuGet/NuGet.Config` |\n| macOS / Linux | `~/.config/NuGet/NuGet.Config` or `~/.nuget/NuGet/NuGet.Config` |\n\nNote that this file may not already exist, depending on your configuration.\n\nFor example, the following `NuGet.Config` file includes both the main NuGet package feed, and the Quantum Development Kit prerelease feed:\n\n```xml\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<configuration>\n  <packageSources>\n    <add key=\"nuget.org\" value=\"https://api.nuget.org/v3/index.json\" protocolVersion=\"3\" />\n    <add key=\"qdk-alpha\" value=\"https://pkgs.dev.azure.com/ms-quantum-public/Microsoft Quantum (public)/_packaging/alpha/nuget/v3/index.json\" protocolVersion=\"3\" />\n  </packageSources>\n</configuration>\n```\n"
 },
 {
  "repo": "microsoft/QuantumKatas",
  "language": "Jupyter Notebook",
  "readme_contents": "# Introduction\n\nThe Quantum Katas are a collection of self-paced tutorials and programming exercises to help you learn quantum computing and Q# programming.\n\nEach kata is a separate set of exercises that includes:\n\n* A sequence of tasks progressing from easy to hard.\n  Each task requires you to fill in some code. The first task might require just one line, and the last one might require rather complicated code.\n* A testing framework that sets up, runs, and validates your solutions.\n  Each task is covered by a [unit test](https://docs.microsoft.com/visualstudio/test/getting-started-with-unit-testing) which initially fails. Once you write the code to make the test pass, you can move on to the next task.\n* Links to quantum computing and Q# reference material you might need to solve the tasks.\n* Hints, reference solutions and detailed explanations to help you if you're stuck.\n\nThe Quantum Katas also include *tutorials* that introduce the learner to the basic concepts and algorithms used in quantum computing, starting with the necessary math (complex numbers and linear algebra). They follow the same pattern of supplementing the theory with Q# demos and hands-on programming exercises. \n\n## Table of contents ##\n\n* [Learning path](#learning-path)\n* [Run the katas and tutorials online](#run-online)\n* [Run the katas locally](#kata-locally)\n  * [Quantum Development Kit installation](#install)\n  * [Download the Quantum Katas](#download)\n  * [Run a kata as a Jupyter Notebook](#kata-as-notebook)\n  * [Run a kata as a Q# project](#kata-as-project)\n  * [Run kata tests](#tests)\n  * [Run katas locally with Docker](#docker)\n* [Contributing](#contributing)\n* [Code of Conduct](#code-of-conduct)\n\n## Learning path <a name=\"learning-path\" /> ##\n\nHere is the learning path we suggest you to follow if you are starting to learn quantum computing and quantum programming. Once you're comfortable with the basics, you're welcome to jump ahead to the topics that pique your interest!\n\n#### Quantum Computing Concepts: Qubits and Gates\n\n* **[Complex arithmetic (tutorial)](./tutorials/ComplexArithmetic/)**.\n  Learn about complex numbers and the mathematics required to work with quantum computing.\n* **[Linear algebra (tutorial)](./tutorials/LinearAlgebra/)**.\n  Learn about vectors and matrices used to represent quantum states and quantum operations.\n* **[The qubit (tutorial)](./tutorials/Qubit/)**.\n  Learn what a qubit is.\n* **[Single-qubit gates (tutorial)](./tutorials/SingleQubitGates/)**.\n  Learn what a quantum gate is and about the most common single-qubit gates.\n* **[Basic quantum computing gates](./BasicGates/)**.\n  Learn to apply the most common gates used in quantum computing.\n* **[Multi-qubit systems (tutorial)](./tutorials/MultiQubitSystems/)**.\n  Learn to represent multi-qubit systems.\n* **[Multi-qubit gates (tutorial)](./tutorials/MultiQubitGates/)**.\n  Learn about the most common multi-qubit gates.\n* **[Superposition](./Superposition/)**.\n  Learn to prepare superposition states.\n\n#### Quantum Computing Concepts: Measurements\n\n* **[Single-qubit measurements (tutorial)](./tutorials/SingleQubitSystemMeasurements/)**.\n  Learn what quantum measurement is and how to use it for single-qubit systems.\n* **[Measurements](./Measurements/)**.\n  Learn to distinguish quantum states using measurements.\n* **[Distinguish unitaries](./DistinguishUnitaries/)**.\n  Learn to distinguish unitaries by designing and performing experiments with them.\n* **[Joint measurements](./JointMeasurements/)**.\n  Learn about using joint (parity) measurements to distinguish quantum states and to perform state transformations.\n\n#### Simple Algorithms\n\n* **[Random number generation (tutorial)](./tutorials/RandomNumberGeneration/)**.\n  Learn to generate random numbers using the principles of quantum computing.\n* **[Teleportation](./Teleportation/)**.\n  Implement standard teleportation protocol and its variations.\n* **[Superdense coding](./SuperdenseCoding/)**.\n  Implement the superdense coding protocol.\n\n#### Quantum Oracles and Simple Oracle Algorithms\n\n* **[Quantum oracles (tutorial)](./tutorials/Oracles/)**.\n  Learn to implement classical functions as equivalent quantum oracles. \n* **[Exploring Deutsch\u2013Jozsa algorithm (tutorial)](./tutorials/ExploringDeutschJozsaAlgorithm/)**.\n  Learn to implement classical functions and equivalent quantum oracles, and compare the quantum\n  solution to the Deutsch\u2013Jozsa problem to a classical one.\n* **[Deutsch\u2013Jozsa algorithm](./DeutschJozsaAlgorithm/)**.\n  Learn about quantum oracles which implement classical functions, and implement Bernstein\u2013Vazirani and Deutsch\u2013Jozsa algorithms.\n* **[Simon's algorithm](./SimonsAlgorithm/)**.\n  Learn about Simon's algorithm.\n\n#### Grover's search algorithm\n\n* **[Implementing Grover's algorithm](./GroversAlgorithm/)**.\n  Learn about Grover's search algorithm and how to write quantum oracles to use with it.\n* **[Exploring Grover's search algorithm (tutorial)](./tutorials/ExploringGroversAlgorithm/)**.\n  Learn more about Grover's search algorithm, picking up where the [Grover's algorithm kata](./GroversAlgorithm/) left off.\n* **[Solving SAT problems using Grover's algorithm](./SolveSATWithGrover/)**.\n  Explore Grover's search algorithm, using SAT problems as an example. Learn to implement quantum oracles based on the problem description instead of a hard-coded answer. Use Grover's algorithm to solve problems with an unknown number of solutions.\n* **[Solving graph coloring problems using Grover's algorithm](./GraphColoring/)**.\n  Continue the exploration of Grover's search algorithm, using graph coloring problems as an example.\n\n#### Tools and libraries/Building up to Shor's algorithm\n\n* **[Quantum Fourier transform](./QFT/)**.\n  Learn to implement quantum Fourier transform and to use it to perform simple state transformations.\n* **[Phase estimation](./PhaseEstimation/)**.\n  Learn about phase estimation algorithms.\n\n#### Entanglement games\n\n* **[CHSH game](./CHSHGame/)**.\n* **[GHZ game](./GHZGame/)**.\n* **[Mermin-Peres magic square game](./MagicSquareGame)**.\n\n#### Reversible computing\n\n* **[Truth tables](./TruthTables/)**.\n  Learn to represent and manipulate Boolean functions as truth tables and to implement them as quantum operations.\n* **[Ripple-carry adder](./RippleCarryAdder/)**.\n  Build a ripple-carry adder on a quantum computer.\n\n#### Miscellaneous\n\n* **[BB84 protocol](./KeyDistribution_BB84/)**.\n  Implement the BB84 key distribution algorithm.\n* **[Bit-flip error correcting code](./QEC_BitFlipCode/)**.\n  Learn about a 3-qubit error correcting code for protecting against bit-flip errors.\n* **[Unitary patterns](./UnitaryPatterns/)**.\n  Learn to implement unitaries with matrices that follow certain patterns of zero and non-zero elements.\n* **[Quantum classification (tutorial)](./tutorials/QuantumClassification/)**.\n  Learn about circuit-centric classifiers and the quantum machine learning library included in the QDK.\n\n> For a Q# programming language quick reference sheet, see [Q# Language Quick Reference](./quickref/qsharp-quick-reference.pdf).\n\n## Run the katas and tutorials online <a name=\"run-online\" /> ##\n\nThe Quantum Katas are now available as Jupyter Notebooks online! See [index.ipynb](https://mybinder.org/v2/gh/Microsoft/QuantumKatas/main?filepath=index.ipynb) for the list of all katas and tutorials, and instructions for running them online.\n\n> While running the Katas online is the easiest option to get started, if you want to save your progress and enjoy better performance, we recommend you to choose the local option. \n\n## Run the katas locally <a name=\"kata-locally\" /> ##\n\n### Quantum Development Kit Installation <a name=\"install\" /> ###\n\nTo use the Quantum Katas locally, you'll need the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum), available for Windows 10, macOS, and Linux.\nIf you don't already have the Quantum Development Kit installed, see the [install guide for the Quantum Development Kit](https://docs.microsoft.com/azure/quantum/install-overview-qdk).\n\n**If you want to run the katas and tutorials locally as Jupyter Notebooks**:\n1. Follow the steps in the [QDK install guide for Python](https://docs.microsoft.com/azure/quantum/install-python-qdk) \n  and the [QDK install guide for Jupyter Notebooks](https://docs.microsoft.com/azure/quantum/install-jupyter-qkd).\n2. Several tutorials require installing additional Python packages:\n   * \"Complex arithmetic\" and \"Linear algebra\" require the [`pytest` package](https://docs.pytest.org/en/latest/getting-started.html).\n   * \"Exploring Grover's search algorithm\" requires the [`matplotlib` package](https://matplotlib.org/3.1.1/users/installing.html).\n   * \"Quantum classification\" requires [`matplotlib`](https://matplotlib.org/3.1.1/users/installing.html) and [`numpy`](https://numpy.org/install/) packages.\n\n**If you want to run the katas and tutorials locally as Q# projects**:\n\nFollow the steps in the [QDK install guide](https://docs.microsoft.com/azure/quantum/install-command-line-qdk) for Visual Studio, \n Visual Studio Code or other editors.\n\n\n### Download the Quantum Katas <a name=\"download\" /> ###\n\nIf you have Git installed, clone the Microsoft/QuantumKatas repository:\n\n```bash\n$ git clone https://github.com/Microsoft/QuantumKatas.git\n```\n\n> [!TIP]\n> Both Visual Studio 2019 and Visual Studio Code make it easy to clone repositories from within your development environment.\n> For details, see the [Visual Studio 2019](https://docs.microsoft.com/azure/devops/repos/git/clone?view=azure-devops&tabs=visual-studio#clone-from-another-git-provider) and [Visual Studio Code](https://code.visualstudio.com/docs/editor/versioncontrol#_cloning-a-repository) documentation.\n\nIf you don't have Git installed, download the katas from https://github.com/Microsoft/QuantumKatas/archive/main.zip.\n\n\n### Run a kata as a Jupyter Notebook <a name=\"kata-as-notebook\" /> ###\n\nThe best way to run the katas as Jupyter Notebooks is to navigate to the root folder of the repository and to open `index.ipynb` using Jupyter:\n\n```bash\n$ cd QuantumKatas/\n$ jupyter notebook index.ipynb\n```\n\nThis will open the notebook that contains a list of all katas and tutorials, and you will be able to navigate to the one you want using links.\n\n> Note that this will start Jupyter Notebooks server in the same command line window you used to run the command. If you want to keep using that window for navigation, you can launch Jupyter Notebooks server in a new window using the following commands (on Windows):\n> ```bash\n> $ cd QuantumKatas/\n> $ start jupyter notebook index.ipynb\n> ```\n\nYou can also open an individual notebook directly, but this might render internal links invalid:\n\n```bash\n$ cd QuantumKatas/tutorials/ComplexArithmetic\n$ jupyter notebook ComplexArithmetic.ipynb\n```\n\n\n### Run a kata as a Q# project <a name=\"kata-as-project\" /> ###\n\nEach kata is in its own directory as a self-contained Q# project, solution and Jupyter Notebook triplet.\nFor instance, the BasicGates directory structure is:\n\n```bash\nQuantumKatas/\n  BasicGates/\n    README.md                  # Instructions specific to this kata.\n    .vscode/                   # Metadata used by Visual Studio Code.\n    BasicGates.sln             # Visual Studio 2019 solution file.\n    BasicGates.csproj          # Project file used to build both classical and quantum code.\n    BasicGates.ipynb           # Jupyter Notebook front-end for this kata.\n\n    Tasks.qs                   # Q# source code that you will fill as you solve each task.\n    Tests.qs                   # Q# tests that verify your solutions.\n    TestSuiteRunner.cs         # C# source code used to run the Q# tests.\n    ReferenceImplementation.qs # Q# source code containing solutions to the tasks.\n```\n\nTo open the **BasicGates** kata in Visual Studio 2019, open the **QuantumKatas/BasicGates/BasicGates.sln** solution file.\n\nTo open the **BasicGates** kata in Visual Studio Code, open the **QuantumKatas/BasicGates/** folder.\nPress **Ctrl + Shift + P** (or **\u2318 + Shift + P** on macOS) to open the **Command Palette**. Type **Open Folder** on Windows 10 or Linux or **Open** on macOS.\n\n> [!TIP]\n> Almost all commands available in Visual Studio Code are in the Command Palette.\n> If you get stuck, press **Ctrl + Shift + P** (or **\u2318 + Shift + P** on macOS) and start typing to search through all available commands.\n>\n> You can also launch Visual Studio Code from the command line:\n> ```bash\n> $ code QuantumKatas/BasicGates/\n> ```\n\n### Run kata tests <a name=\"tests\" /> ###\n\nOnce you have a kata open, it's time to run the tests using the following instructions.\nInitially all tests will fail. Don't panic!\nOpen **Tasks.qs** and start filling in the code to complete the tasks. Each task is covered by a unit test. Once you fill in the correct code for a task, rebuild the project and re-run the tests, and the corresponding unit test will pass.\n\n#### Visual Studio 2019\n\n1. Build the solution.\n2. From the main menu, open **Test Explorer** (**Test** > **Windows**) and select **Run All** to run all unit tests at once.\n3. Work on the tasks in the **Tasks.qs** file.\n4. To test your code changes for a task, rebuild the solution and re-run all unit tests using **Run All**, or run just the test for that task by right-clicking the test and selecting **Run Selected Tests**.\n\n#### Visual Studio Code\n\n1. Press **Ctrl + \\`** (or **\u2318 + \\`** on macOS) to open the integrated terminal.\n   The terminal should open to the kata directory. If it doesn't, navigate to the folder containing the *.csproj file for the kata using `cd` command.\n2. Run `dotnet test` in the integrated terminal.\n   This should build the kata project and run all of the unit tests. All of the unit tests should fail.\n3. Work on the tasks in the **Tasks.qs** file.\n4. To test your code changes for a task, from the integrated terminal run `dotnet test` again.\n\nFor convenience, a tasks.json configuration file exists for each kata. It allows Visual Studio Code to run the build and test steps from the Command Palette.\nPress **Ctrl + Shift + P** (or **\u2318 + Shift + P** on macOS) to open the Palette and type **Run Build Task** or **Run Test Task** and press **Enter**.\n\n## Run katas locally with Docker <a name=\"docker\" /> ##\n\nYou can use the included [Dockerfile](./Dockerfile) to create a docker image with all the necessary tools to run the katas from the command line or Jupyter.\n\n1. Install [Docker](https://docs.docker.com/install/).\n2. Build the docker image and tag it `katas`:\n\n```bash\ndocker build -t katas .\n```\n\n3. Run the image in the container named `katas-container` with interactive command-line and redirect container port `8888` to local port `8888` (needed to run Jupyter):\n\n```bash\ndocker run -it --name katas-container -p 8888:8888 katas /bin/bash\n```\n\n4. From the same command line that you used to run the container, run the C# version of the **BasicGates** kata:\n\n```bash\ncd ~/BasicGates/\ndotnet test\n```\n\n5. Start a Jupyter Notebook within the image for the **BasicGates** kata:\n\n```bash\ncd ~/BasicGates/ && jupyter notebook --ip=0.0.0.0 --no-browser\n```\n\n6. Once Jupyter has started, use your browser to open the kata in notebook format. You\nwill need a token generated by Jupyter when it started on the previous step:\n\n```\nhttp://localhost:8888/notebooks/BasicGates.ipynb\n```\n\nTo exit a docker container without killing it (daemon mode), press **Ctrl+P, Ctrl+Q**\n\nTo re-enter the existing `katas-container` (in daemon mode):\n\n```bash\ndocker attach katas-container\n```\n\nOnce you're done, remove the `katas-container`:\n\n```bash\ndocker rm --force katas-container\n```\n\n# Contributing <a name=\"contributing\" /> #\n\nThis project welcomes contributions and suggestions.  See [How Can I Contribute?](.github/CONTRIBUTING.md) for details.\n\n# Code of Conduct <a name=\"code-of-conduct\" /> #\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/Quantum-NC",
  "language": "F#",
  "readme_contents": "# Microsoft Quantum Development Kit: Non-Commercial Libraries\n\nWelcome to the Microsoft Quantum Development Kit!\n\nThis repository contains shared-source libraries that can be used for research and academics, but that cannot be used for commercial purposes.\nPlease note that these libraries are not intended for production use, and may be modified as research proceeds.\nFor more information please refer to the [LICENSE](LICENSE).\n\n## Using the non-commercial research libraries\n\nThe non-commercial libraries in this repository can be used via NuGet packages beginning with the prefix [\"Microsoft.Quantum.Research.\"](https://www.nuget.org/packages?q=owner:QuantumEngineering%20id:research)\nFor more details, please see:\n- [Research packages](https://github.com/microsoft/Quantum-NC/wiki/Research-packages) on the [Quantum-NC wiki](https://github.com/microsoft/Quantum-NC/wiki/)\n\n## Feedback\n\nIf you have feedback about the libraries in this repository, please let us know by filing a [new issue](https://github.com/microsoft/Quantum-NC/issues/new)!\nIf you have feedback about some other part of the Microsoft Quantum Development Kit, please see the [contribution guide](https://docs.microsoft.com/azure/quantum/contributing-overview) for more information on the best places to file it.\n\n## Contributing\n\nPlease note: **this project does not accept external contributions**.\n\nIf you'd like to contribute to the rest of the Quantum Development Kit, please see the [contribution guide](https://docs.microsoft.com/azure/quantum/contributing-overview).\n"
 },
 {
  "repo": "microsoft/Quantum",
  "language": "Jupyter Notebook",
  "readme_contents": "\ufeff# Microsoft Quantum Development Kit Samples\n\n [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/Microsoft/Quantum/\u2b50binder)\n\nThese samples demonstrate the use of the Quantum Development Kit for a variety of different quantum computing tasks.\n\nEach sample is self-contained in a folder, and demonstrates how to use Q# to develop quantum applications.\n\nA small number of the samples have additional installation requirements beyond those for the rest of the Quantum Development Kit.\nThese are noted in the README.md files for each sample, along with complete installation instructions.\n\n## Getting started\n\nYou can find instructions on how to install the Quantum Development Kit in [our online documentation](https://docs.microsoft.com/azure/quantum/install-overview-qdk/), which also includes\nan introduction to [quantum programming concepts](https://docs.microsoft.com/azure/quantum/concepts-overview/).\n\nFor a quick guide on how to set up a development environment from scratch using [Visual Studio Code](https://code.visualstudio.com) or [Visual Studio Codespaces](https://online.visualstudio.com/login), see [here](#setting-up-your-development-environment).\n\nA [Docker](https://docs.docker.com/install/) image definition is also provided for your convenience, see [here](#running-a-jupyter-notebook-with-docker) for instructions on how to build and use it.\n\n### First samples\n\nIf you're new to quantum or to the Quantum Development Kit, we recommend starting with the [Getting Started samples](./samples/getting-started/).\n\nAfter setting up your development environment using one of the options above, try to browse to `samples/getting-started/teleportation` via the terminal and run `dotnet run`. You should see something like the following:\n```\nRound 1: Sent False, got False.\nTeleportation successful!\nRound 2: Sent True, got True.\nTeleportation successful!\nRound 3: Sent False, got False.\nTeleportation successful!\nRound 4: Sent False, got False.\nTeleportation successful!\nRound 5: Sent False, got False.\nTeleportation successful!\nRound 6: Sent False, got False.\nTeleportation successful!\nRound 7: Sent True, got True.\nTeleportation successful!\nRound 8: Sent False, got False.\nTeleportation successful!\n```\n\nCongratulations, you can now start quantum programming!\n\n## Going further\n\nAs you go further with quantum development, we provide several different categories of samples for you to explore:\n\n- **[Algorithms](./samples/algorithms)**:\n  These samples demonstrate various quantum algorithms, such as database search and integer factorization.\n- **[Arithmetic](./samples/arithmetic)**:\n  These samples show how to coherently transform arithmetic data.\n- **[Characterization](./samples/characterization)**:\n  These samples demonstrate how to learn properties of quantum systems from classical data.\n- **[Chemistry](./samples/chemistry)**:\n- **[Diagnostics](./samples/diagnostics)**:\n  These samples show how to diagnose and test Q# applications.\n- **[Error Correction](./samples/error-correction)**:\n  These samples show how to work with quantum error correcting codes in Q# programs.\n- **[Interoperability](./samples/interoperability)**:\n  These samples show how to use Q# with different host languages.\n- **[Numerics](./samples/numerics)**:\n  The samples in this folder show how to use the numerics library.\n- **[Runtime](./samples/runtime)**:\n  These samples show how to work with the Q# simulation runtime.\n- **[Simulation](./samples/simulation)**:\n  These samples show how to simulate evolution under different Hamiltonians.\n\nWe also encourage taking a look at the [unit tests](./samples/tests) used to check the correctness of the Quantum Development Kit samples.\n\n## Setting up your development environment\n\nThis repo contains several configuration files that will make it easy to get started with coding. Below we lay out some instructions for getting started with [VSCode](#visual-studio-code) or with [Jupyter notebooks](#running-a-jupyter-notebook-with-docker).\n\n### Visual Studio Code\n\nIf you prefer to develop code locally, we recommend to install an editor such as [Visual Studio Code](https://code.visualstudio.com/download). Make sure to install the [.NET Core SDK 3.1 or later](https://www.microsoft.com/net/download) on your local machine. For more detailed instructions on how to set up VS Code for development with the QDK, go to our docs [here](https://docs.microsoft.com/azure/quantum/install-command-line-qdk).\n\nOnce you have installed VS Code and the .NET Core SDK, download this repository to your computer and open the folder in VS Code. The editor will automatically recognize the files in the `.vscode` folder and request you to install the recommended extension. This includes the [Microsoft Quantum Development Kit for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=quantum.quantum-devkit-vscode) extension, which is the fastest way to get started with the QDK.\n\nOpen a terminal to start running your first samples (see [here](#first-samples)).\n\n### Running a Jupyter Notebook with Docker\n\nAnother way to quickly start developing in Q# is to use Docker and launch a Jupyter notebook on your local machine. You can use the included [Dockerfile](./Dockerfile) to create a docker image with all the necessary libraries to use the Quantum Development Kit to build quantum applications in C#, Python or Jupyter.\n\nOnce you have installed [Docker](https://docs.docker.com/install/), you can\nuse the following commands to get you started:\n\nTo build the docker image and tag it `iqsharp`:\n```sh\ndocker build -t iqsharp .\n```\n\nTo run the image in the container named `iqsharp-container` with interactive command-line and \nredirect container port 8888 to local port 8888 (needed to run jupyter):\n```sh\ndocker run -it --name iqsharp-container -p 8888:8888 iqsharp /bin/bash\n```\n\nFrom the corresponding container command line, you can run the C# version of the Teleportation sample using: \n```sh\ncd ~/samples/getting-started/teleportation && dotnet run\n```\n\nSimilarly, you can run the Python version of the Teleportation sample using: \n```sh\ncd ~/samples/getting-started/teleportation && python host.py\n```\n\nFinally, to start jupyter notebook within the image for the Teleportation sample, use:\n```sh\ncd ~/samples/getting-started/teleportation && jupyter notebook --ip=0.0.0.0 --no-browser \n```\n\nOnce Jupyter has started, you can open in your browser the Teleportation notebook (you\nwill need a token generated by jupyter when it started on the previous step):\n\n> http://localhost:8888/notebooks/Notebook.ipynb\n\nOnce you're done, to remove container named `iqsharp-container`:\n```sh\ndocker rm --force iqsharp-container\n```\n"
 },
 {
  "repo": "microsoft/qsharp-runtime",
  "language": "C#",
  "readme_contents": "# Microsoft Quantum Development Kit: Q# runtime #\r\n\r\nWelcome to the Microsoft Quantum Development Kit!\r\n\r\nThis repository contains the runtime components for the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum/).\r\nIt consists of the libraries and packages needed to create and simulate quantum applications using Q#.\r\n\r\n- **[Azure/](./src/Azure/)**: Source for client package to create and manage jobs in Azure Quantum.\r\n- **[Simulation/](./src/Simulation/)**: Source for Q# simulation. Includes code generation, full-state and other simulators.\r\n- **[xUnit/](./src/Xunit/)**: Source for the xUnit's Q# test-case discoverer.\r\n\r\n## New to Quantum? ##\r\n\r\nSee the [introduction to quantum computing](https://docs.microsoft.com/azure/quantum/concepts-overview) provided with the Quantum Development Kit.\r\n\r\n\r\n## Installing the Quantum Development Kit\r\n\r\n**If you're looking to use Q# to write quantum applications, please see the instructions on how to get started with using the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum/install-overview-qdk) including the Q# compiler, language server, and development environment extensions.**\r\n\r\nPlease see the [installation guide](https://docs.microsoft.com/azure/quantum/install-overview-qdk) for further information on how to get started using the Quantum Development Kit to develop quantum applications.\r\nYou may also visit our [Quantum](https://github.com/microsoft/quantum) repository, which offers a wide variety of samples on how to write quantum based programs.\r\n\r\n\r\n## Building from Source ##\r\n\r\n[![Build Status](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_apis/build/status/microsoft.qsharp-runtime?branchName=main)](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_build/latest?definitionId=15&branchName=main)\r\n\r\nNote that when building from source, this repository is configured so that .NET Core will automatically look at the [Quantum Development Kit prerelease feed](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_packaging?_a=feed&feed=alpha) in addition to any other feeds you may have configured.\r\n\r\nBuilding **QIR Runtime** isn't enabled by default yet. Please see [its readme](./src/Qir/Runtime/README.md) for details.\r\n\r\n### Windows ###\r\n\r\nTo build on Windows:\r\n\r\n1. Install the pre-reqs:\r\n    * Install [CMake](https://cmake.org/install/)\r\n    * Install [Visual Studio 2019 (version 16.3 or later)](https://visualstudio.microsoft.com/downloads/). Make sure you install the following workloads:\r\n        * **Desktop development with C++**\r\n        * **From the Individual Components tab in VS Installer add Spectre-mitigated libs that match your C++ build tools version**\r\n        * **.NET Core 3 cross-platform development**\r\n2. Run [bootstrap.ps1](bootstrap.ps1) from PowerShell\r\n    * pre-req (in PowerShell): `Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser`\r\n    * The script might install additional tools (a specific compiler, build tools, etc)\r\n    * Then it builds release flavor of the native (C++) full-state simulator and debug flavor of the Simulation solution.\r\n    * You only need to run it once.\r\n3. Open and build the [`Simulation.sln`](./Simulation.sln) solution in Visual Studio.\r\n\r\nThe `Simulation.sln` solution does not include the full-state quantum simulator. To change it, you can open the `quantum-simulator.sln` solution created during bootstrap in the `src\\Simulation\\Native\\build`. To integrate your changes with the rest of the simulation components, you must manually build it.\r\n\r\n\r\n### macOS/Linux ###\r\n\r\nTo build on other platforms:\r\n\r\n1. Install the pre-reqs:\r\n    * Install [CMake](https://cmake.org/install/)\r\n    * Install [.NET Core 3 SDK](https://dotnet.microsoft.com/download)\r\n    * On [WSL](https://docs.microsoft.com/en-us/windows/wsl/)/Linux:\r\n      * Install `g++` (e.g. in Ubuntu 20.04 `sudo apt-get install g++`).\r\n      * The build does not accept `dotnet-*-5.0` packages, install `dotnet-*-3.1`\r\n        (`sudo apt-get install dotnet-sdk-3.1`). The possible result can be:\r\n\r\n```sh\r\nqsharp-runtime$ dpkg -l *dotnet*\r\nDesired=Unknown/Install/Remove/Purge/Hold\r\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\r\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\r\n||/ Name                      Version      Architecture Description\r\n+++-=========================-============-============-=================================================================\r\nun  dotnet                    <none>       <none>       (no description available)\r\nii  dotnet-apphost-pack-3.1   3.1.13-1     amd64        Microsoft.NETCore.App.Host 3.1.13\r\nii  dotnet-host               5.0.4-1      amd64        Microsoft .NET Host - 5.0.4\r\nii  dotnet-hostfxr-3.1        3.1.13-1     amd64        Microsoft .NET Core Host FX Resolver - 3.1.13 3.1.13\r\nun  dotnet-nightly            <none>       <none>       (no description available)\r\nii  dotnet-runtime-3.1        3.1.13-1     amd64        Microsoft .NET Core Runtime - 3.1.13 Microsoft.NETCore.App 3.1.13\r\nii  dotnet-runtime-deps-3.1   3.1.13-1     amd64        dotnet-runtime-deps-3.1 3.1.13\r\nii  dotnet-sdk-3.1            3.1.407-1    amd64        Microsoft .NET Core SDK 3.1.407\r\nii  dotnet-targeting-pack-3.1 3.1.0-1      amd64        Microsoft.NETCore.App.Ref 3.1.0\r\n```\r\n2. Run [bootstrap.ps1](./bootstrap.ps1)\r\n    * The script might install additional tools (a specific compiler, build tools, etc)\r\n    * Then it builds release flavor of the native (C++) full-state simulator and debug flavor of the Simulation solution.\r\n    * You only need to run it once.\r\n3. From the command line, run:\r\n    * `dotnet build Simulation.sln`\r\n\r\nThe `Simulation.sln` solution does not include the full-state simulator. To integrate any changes with the rest of the simulation components, you need to manually build it using `make` in the `src\\Simulation\\Native\\build` folder.\r\n\r\n\r\n## Testing ##\r\n\r\nAll unit tests are part of the `Simulation.sln` solution. To run the tests:\r\n\r\n* From [Visual Studio](https://docs.microsoft.com/en-us/visualstudio/test/getting-started-with-unit-testing?view=vs-2019#run-unit-tests):\r\n    * Open Test Explorer by choosing Test > Windows > Test Explorer from the top menu bar.\r\n    * Run your unit tests by clicking Run All.\r\n* From the command line, run:\r\n    * `dotnet test Simulation.sln`\r\n\r\n\r\n## Feedback ##\r\n\r\nIf you have feedback about the Q# simulators or any other runtime component, please let us know by filing a [new issue](https://github.com/microsoft/qsharp-runtime/issues/new)!\r\nIf you have feedback about some other part of the Microsoft Quantum Development Kit, please see the [contribution guide](https://docs.microsoft.com/azure/quantum/contributing-overview) for more information.\r\n\r\n\r\n## Reporting Security Issues\r\n\r\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security\r\nResponse Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should\r\nreceive a response within 24 hours. If for some reason you do not, please follow up via\r\nemail to ensure we received your original message. Further information, including the\r\n[MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in\r\nthe [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\r\n\r\n\r\n## Legal and Licensing ##\r\n\r\n\r\n## Contributing ##\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\nFor more details, please see [CONTRIBUTING.md](./CONTRIBUTING.md), or the [contribution guide](https://docs.microsoft.com/azure/quantum/contributing-overview).\r\n"
 },
 {
  "repo": "microsoft/qsharp-compiler",
  "language": "C#",
  "readme_contents": "# Microsoft Quantum Development Kit: <br>Q# Compiler and Language Server #\r\n\r\nWelcome to the Microsoft Quantum Development Kit!\r\n\r\nThis repository contains the Q# compiler included in the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum/),\r\nas well as the Q# language server included in our [Visual Studio extension](https://marketplace.visualstudio.com/items?itemName=quantum.DevKit) and our [Visual Studio Code extension](https://marketplace.visualstudio.com/items?itemName=quantum.quantum-devkit-vscode).\r\nFor more information related to the language server protocol take a look at [this repository](https://github.com/Microsoft/language-server-protocol).\r\nThese extensions provide the IDE integration for Q#, and can be found on this repository as well.\r\n\r\nThe Q# [compiler](./src/QsCompiler/Compiler) is distributed as a [NuGet package](https://www.nuget.org/packages/Microsoft.Quantum.Compiler), and the [CompilationLoader class](https://github.com/microsoft/qsharp-compiler/blob/main/src/QsCompiler/Compiler/CompilationLoader.cs) exposes the different configuration options for building a compilation.\r\nThe Q# [command line compiler](./src/QsCompiler/CommandLineTool) is included as a tool in the [Microsoft.Quantum.Sdk](./src/QuantumSdk) and provides an [extensibility mechanism](https://devblogs.microsoft.com/qsharp/extending-the-q-compiler/) for compilation steps. See the list of [project properties](./src/QuantumSdk#defined-project-properties) for more information about possible configuration options for Q# projects.\r\n\r\n- **[QsCompiler](./src/QsCompiler/)**: Q# compiler including the command line tool\r\n- **[QsCompiler/LanguageServer](./src/QsCompiler/LanguageServer/)**: Q# language server\r\n- **[Microsoft.Quantum.Sdk](./src/QuantumSdk)**: Sdk for building Q# projects and support for [compiler extensions](https://github.com/microsoft/qsharp-compiler/tree/main/examples/CompilerExtensions)\r\n- **[VSCodeExtension](./src/VSCodeExtension/)**: Visual Studio Code extension\r\n- **[VisualStudioExtension](./src/VisualStudioExtension/)**: Visual Studio extension\r\n\r\nQ# executables can be compiled into an LLVM-based [Quantum Intermediate Representation (QIR)](https://github.com/microsoft/qsharp-language/tree/main/Specifications/QIR). More details on that capability and how to use it can be found in this [README](https://github.com/microsoft/qsharp-compiler/tree/main/src/QsCompiler/QirGeneration).\r\n\r\n## New to Quantum? ##\r\n\r\nSee the [introduction to quantum computing](https://docs.microsoft.com/azure/quantum/concepts-overview/) provided with the Quantum Development Kit.\r\n\r\n## Installing the Quantum Development Kit\r\n\r\n**If you're looking to use Q# to write quantum applications, please see the instructions on how to get started with using the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum/install-overview-qdk/) including the Q# compiler, language server, and development environment extensions.**\r\n\r\nPlease see the [installation guide](https://docs.microsoft.com/azure/quantum/install-overview-qdk) for further information on how to get started using the Quantum Development Kit to develop quantum applications.\r\nYou may also visit our [Quantum](https://github.com/microsoft/quantum) repository, which offers a wide variety of samples on how to write quantum based programs.\r\n\r\n## Building from Source ##\r\n\r\nBefore you can build the source code on this repository and start contributing to the Q# compiler and extensions you need to run the PowerShell script [bootstrap.ps1](./bootstrap.ps1) to set up your environment.\r\nWe refer to the [PowerShell GitHub repository](https://github.com/powershell/powershell) for instructions on how to install PowerShell.\r\nThe script in particular generates the files that are needed for building based on the templates in this repository.\r\n\r\nThe Q# compiler and language server in this repository are built using [.NET Core](https://docs.microsoft.com/dotnet/core/). Building the [QsCompiler.sln](./QsCompiler.sln) builds the Q# compiler and language server. To test your changes to the compiler, open the project file of a Q# project that uses the latest version of the [Microsoft.Quantum.Sdk](https://www.nuget.org/packages/Microsoft.Quantum.Sdk/) in a text editor. You can confirm the Sdk version that the project is using by looking at the first line in the project file. You may need to edit that line to update to the latest version, and adjust your project as needed. Confirm that the project is building correctly using that version by executing the command\r\n```\r\ndotnet build MyProject.csproj\r\n```\r\nIf your project builds successfully, edit the project file in the text editor to add the following project property, adjusting the path as needed:\r\n```\r\n  <PropertyGroup>\r\n    <QscExe>dotnet $(MSBuildThisFileDirectory)src/QsCompiler/CommandLineTool/bin/$(Configuration)/netcoreapp3.1/qsc.dll</QscExe>\r\n  </PropertyGroup>\r\n```\r\nTo confirm that indeed the locally built compiler version is used, you can edit `Run<T>` in your local [Project.cs](./src/QsCompiler/CommandLineTool/Program.cs) file to include the following line:\r\n```csharp\r\nprivate static int Run<T>(Func<T, ConsoleLogger, int> compile, T options)\r\nwhere T : Options\r\n{\r\n    Console.WriteLine(\"Hi from your locally built compiler!\");\r\n    ...\r\n```\r\nFrom the root of this repository, build the compiler by executing the two commands\r\n```\r\ndotnet clean QsCompiler.sln\r\ndotnet build QsCompiler.sln -c Debug\r\n```\r\nBuild the Q# project as usual by invoking the following two commands:\r\n```\r\ndotnet clean MyProject.csproj\r\ndotnet build MyProject.csproj -c Debug\r\n```\r\nIn the build output you should now see the print statement inserted above.\r\nYou can also execute the project that has now been built using your local source code version of the compiler by executing the command\r\n```\r\ndotnet run --project MyProject.csproj -c Debug\r\n```\r\n\r\nIf you edit the [Microsoft.Quantum.Sdk](./src/QuantumSdk) as part of your changes, you will need to pack it using [NuGet 5.8.1](https://docs.microsoft.com/en-us/nuget/release-notes/nuget-5.8). Download it and use it to pack the Sdk by executing the following commands from the root of this repository:\r\n```\r\ndotnet publish src/QuantumSdk/Tools/Tools.sln -c Debug\r\ndotnet publish src/QsCompiler/CommandLineTool/CommandLineTool.csproj -c Debug\r\nnuget.exe pack src/QuantumSdk/QuantumSdk.nuspec -Version 1.0.0 -Properties Configuration=Debug\r\n```\r\nMove the created .nupkg file into your [local NuGet folder](https://docs.microsoft.com/en-us/nuget/hosting-packages/local-feeds). You can now use the package to build any Q# project by opening the project file in a text editor, and editing the Sdk version number in the first line to be\r\n```\r\n<Project Sdk=\"Microsoft.Quantum.Sdk/1.0.0\">\r\n```\r\nIf you are working in Visual Studio, you may need to unload and then reload the project. When you build the project it will now use your locally built version of the Microsoft.Quantum.Sdk.\r\n\r\nFor instructions on how to build and debug the Visual Studio Code extension take a look at [this file](./src/VSCodeExtension/BUILDING.md).\r\nBuilding and debugging the Visual Studio extension requires Visual Studio 2019. Open [the corresponding solution](./VisualStudioExtension.sln) and set the [QSharpVsix project](./src/VisualStudioExtension/QSharpVsix/) as startup project, then launch and debug the extension as usual.\r\nThe Visual Studio extension is built on the [.NET Framework 4.7.2](https://dotnet.microsoft.com/download/dotnet-framework/net472) that comes with Visual Studio 2019. Alternatively you can easily obtain it via the Visual Studio Installer.\r\n\r\nWe recommend uninstalling any other Q# extensions when working on the extensions in this repository.\r\n\r\n### Tips for using VSCode ###\r\nThis repository includes both C# and F# code, as well as .csproj and .fsproj projects organizing that code. The recommended extensions for interacting with these language types are the [Microsoft C# extension powered by OmniSharp](https://marketplace.visualstudio.com/items?itemName=ms-dotnettools.csharp) and the [Ionide FSharp extension](https://marketplace.visualstudio.com/items?itemName=Ionide.Ionide-fsharp). Several of the projects in each language express dependencies on the other language, which can cause errors resolving namespaces even when the builds succeed without errors. To resolve these errors in C# projects that depend on F# resources, ensure the the MSBuild utilized by Omnisharp comes from an install of Visual Studio or Visual Studio Community edition with support for F# installed. To resolve errors loading .csproj files in the Ionide extension, use the \"Change Workspace or Solution\" option in the F#: Solution Explorer to select the top level \"qsharp-compiler\" folder. This will allow Ionide to find only the .fsproj projects instead of trying to load both .csproj and .fsproj listed in the solution files.\r\n\r\n## Build Status ##\r\n\r\n| branch | status    |\r\n|--------|-----------|\r\n| main | [![Build Status](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_apis/build/status/microsoft.qsharp-compiler?branchName=main)](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_build/latest?definitionId=14&branchName=main) |\r\n\r\n## Feedback ##\r\n\r\nIf you have feedback about the content in this repository, please let us know by filing a [new issue](https://github.com/microsoft/qsharp-compiler/issues/new/choose)!\r\nIf you have feedback about some other part of the Microsoft Quantum Development Kit, please see the [contribution guide](https://docs.microsoft.com/azure/quantum/contributing-overview/) for more information.\r\n\r\n## Reporting Security Issues ##\r\n\r\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security\r\nResponse Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should\r\nreceive a response within 24 hours. If for some reason you do not, please follow up via\r\nemail to ensure we received your original message. Further information, including the\r\n[MSRC PGP](https://technet.microsoft.com/en-us/security/dn606155) key, can be found in\r\nthe [Security TechCenter](https://technet.microsoft.com/en-us/security/default).\r\n\r\n## Legal and Licensing ##\r\n\r\n### Telemetry ###\r\n\r\nBy default, sending out telemetry is disabled for all code in this repository, but it can be enabled via compilation flag.\r\nOur shipped extensions that are built based on the code in this repository support collecting telemetry.\r\nIn that case, opt-in or opt-out works via the corresponding setting in Visual Studio and Visual Studio Code,\r\nand the telemetry we collect falls under the [Microsoft Privacy Statement](https://privacy.microsoft.com/privacystatement).\r\n\r\n### Data Collection ###\r\n\r\nThe software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described in the repository. There are also some features in the software that may enable you and Microsoft to collect data from users of your applications. If you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together with a copy of Microsoft's privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. You can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.\r\n\r\n## Contributing ##\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\nFor more details, please see [CONTRIBUTING.md](./CONTRIBUTING.md).\r\n\r\n"
 },
 {
  "repo": "microsoft/qdk-python",
  "language": "Python",
  "readme_contents": "[![Build Status](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_apis/build/status/microsoft.qdk-python?branchName=main)](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_build/latest?definitionId=32&branchName=main)\n\n# QDK-Python\n\n## Introduction\n\nQDK-Python is the repository for Python packages of the Quantum Development Kit (QDK). Currently, this consists of the following packages:\n\n- `qdk` [![PyPI version](https://badge.fury.io/py/qdk.svg)](https://badge.fury.io/py/qdk)\n- `azure-quantum` [![PyPI version](https://badge.fury.io/py/azure-quantum.svg)](https://badge.fury.io/py/azure-quantum)\n\nComing soon:\n\n- qsharp\n\n## Installation and getting started\n\nTo install the packages, we recommend installing the Anaconda Python distribution. For instructions on installing Conda on your system, please follow the [Conda user guide](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html).\n\nTo install the QDK package, run\n\n```bash\npip install qdk\n```\n\nTo install the Azure Quantum package, run\n\n```bash\npip install azure-quantum\n```\n\nTo get started running examples, start a Jupyter notebook:\n\n```bash\ncd examples\njupyter notebook\n```\n\n## Development\n\nInstall pre-reqs:\n\n```bash\npip install azure_devtools pytest pytest-azurepipelines pytest-cov\n```\n\nTo create a new Conda environment, run:\n\n```bash\nconda env create -f environment.yml\n```\n\nin the root directory of the given package (`qdk` or `azure-quantum`).\n\nThen to activate the environment:\n\n```bash\nconda activate <env name>\n```\n\nwhere `<env name>` is the environment name (`qdk` or `azurequantum`).\n\nTo install the package in development mode, run:\n\n```bash\npip install -e .\n```\n\n### Integration tests\n\nFor instructions on how to run integration tests for the Azure Quantum package, please refer to the [README](azure-quantum/tests/integration/README.md) file.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/iqsharp",
  "language": "C#",
  "readme_contents": "# Microsoft Quantum Development Kit: IQ# Kernel #\r\n\r\nWelcome to the Microsoft Quantum Development Kit!\r\n\r\nThis repository contains the IQ# kernel for the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum/).\r\nThis kernel provides Q# support for the Jupyter platform, as well as the backend used by the Python client for Q#.\r\n\r\n- **[src/Core/](./src/Core/)**: Core of the IQ# kernel.\r\n- **[src/Kernel/](./src/Kernel/)**: Assembly used to interoperate between Jupyter and the rest of the IQ# kernel.\r\n- **[src/Python/](./src/Python)**: Python package for accessing IQ#.\r\n- **[src/Tests/](./src/Tests/)**: Unit tests for IQ#.\r\n- **[src/Tool/](./src/Tool/)**: .NET Core Global Tool used to install and launch IQ#.\r\n- **[src/Web/](./src/Web/)**: Provides a RESTful API into IQ#.\r\n\r\n## New to Quantum? ##\r\n\r\nSee the [introduction to quantum computing](https://docs.microsoft.com/azure/quantum/concepts-overview) provided with the Quantum Development Kit.\r\n\r\n## Getting Started ##\r\n\r\nThe Jupyter kernel provided in this repository is built using [.NET Core](https://docs.microsoft.com/dotnet/core/) (2.2 or later) and the compiler infrastructure provided with the [Quantum Development Kit](https://docs.microsoft.com/azure/quantum).\r\nPlease see the [getting started guide](https://docs.microsoft.com/azure/quantum/install-overview-qdk) for how to get up and running.\r\n\r\nYou may also visit the [**microsoft/quantum**](https://github.com/microsoft/quantum) repository, which offers a wide variety\r\nof samples on how to use this kernel to run Q# in Jupyter Notebooks, or from Python.\r\n\r\n### Building IQ# from Source ###\r\n\r\nTo obtain prerequisites, ensure that [Node.js](https://nodejs.org/) is installed, and then run `npm install` from the [src/Kernel/](./src/Kernel/) folder:\r\n\r\n```\r\ncd src/Kernel/\r\nnpm install\r\n```\r\n\r\nTo build IQ# from Visual Studio 2017 or later, please use the [`iqsharp.sln`](./iqsharp.sln) solution file.\r\nTo build using the .NET Core SDK, please run `dotnet build iqsharp.sln`.\r\n\r\nIn either case, the IQ# kernel can be installed by using `dotnet run`:\r\n\r\n```\r\ncd src/Tool/\r\ndotnet run -- install\r\n```\r\n\r\nOptionally, you can install IQ# in _development mode_, which instructs the Jupyter platform to rebuild IQ# whenever a new kernel is started:\r\n\r\n```\r\ncd src/Tool/\r\ndotnet run -- install --develop\r\n```\r\n\r\nThis can cause some issues, especially when running multiple instances of IQ#, such that we recommend against using development mode in general usage.\r\n\r\nNote that when building IQ# from source, this repository is configured so that .NET Core will automatically look at the [Quantum Development Kit prerelease feed](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_packaging?_a=feed&feed=alpha) in addition to any other feeds you may have configured.\r\n\r\n### Using IQ# as a Container ###\r\n\r\nThis repository provides a [Dockerfile](./images/iqsharp-base/Dockerfile) that includes the .NET Core SDK, Python, Jupyter Notebook, and the IQ# kernel.\r\n\r\nThe image built from this Dockerfile is hosted on the [Microsoft Container Registry](https://github.com/microsoft/ContainerRegistry) as the `quantum/iqsharp-base` repository.\r\nThe `iqsharp-base` image can be used, for instance, to quickly enable using [Binder](https://gke.mybinder.org/) with Q#-language repositories, or as a base image for [Visual Studio Code Development Containers](https://code.visualstudio.com/docs/remote/containers).\r\n\r\nTo use the `iqsharp-base` image in your own Dockerfile, make sure to begin your Dockerfile with a `FROM` line that points to the Microsoft Container Registry:\r\n\r\n```Dockerfile\r\nFROM mcr.microsoft.com/quantum/iqsharp-base:latest\r\n```\r\n\r\nTo use the `iqsharp-base` image as a development container for Visual Studio Code, add a [`.devcontainer` folder](https://code.visualstudio.com/docs/remote/containers#_using-an-image-or-dockerfile) that points to the Microsoft Container Registry:\r\n\r\n```json\r\n{\r\n    \"image\": \"mcr.microsoft.com/quantum/iqsharp-base:latest\",\r\n    \"extensions\": [\r\n        \"quantum.quantum-devkit-vscode\",\r\n        \"ms-vscode.csharp\"\r\n    ]\r\n}\r\n```\r\n\r\nIn either case, you can also use a Quantum Development Kit version number (0.8 or later) in place of `latest` to point to a specific version.\r\n\r\n## Build Status ##\r\n\r\n| branch | status    |\r\n|--------|-----------|\r\n| main | [![Build Status](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_apis/build/status/microsoft.iqsharp?branchName=main)](https://dev.azure.com/ms-quantum-public/Microsoft%20Quantum%20(public)/_build/latest?definitionId=14&branchName=main) |\r\n\r\n## Feedback ##\r\n\r\nIf you have feedback about IQ#, please let us know by filing a [new issue](https://github.com/microsoft/iqsharp/issues/new)!\r\nIf you have feedback about some other part of the Microsoft Quantum Development Kit, please see the [contribution guide](https://docs.microsoft.com/en-us/azure/quantum/contributing-overview) for more information.\r\n\r\n## Legal and Licensing ##\r\n\r\n### Telemetry ###\r\n\r\nBy default, IQ# collects information about the runtime performance of IQ#.\r\nTo opt-out of sending telemetry, create an environment variable called IQSHARP_TELEMETRY_OPT_OUT set to a value of 1 before starting IQ#.\r\nThe telemetry we collect falls under the [Microsoft Privacy Statement](https://privacy.microsoft.com/privacystatement).\r\n\r\n### Data Collection ###\r\n\r\nThe software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described in the repository. There are also some features in the software that may enable you and Microsoft to collect data from users of your applications. If you use these features, you must comply with applicable law, including providing appropriate notices to users of your applications together with a copy of Microsoft's privacy statement. Our privacy statement is located at https://go.microsoft.com/fwlink/?LinkID=824704. You can learn more about data collection and use in the help documentation and our privacy statement. Your use of the software operates as your consent to these practices.\r\n\r\n## Contributing ##\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\nFor more details, please see [CONTRIBUTING.md](./CONTRIBUTING.md), or the [contribution guide](https://docs.microsoft.com/en-us/azure/quantum/contributing-overview).\r\n"
 },
 {
  "repo": "microsoft/terminal",
  "language": "C++",
  "readme_contents": "![terminal-logos](https://user-images.githubusercontent.com/48369326/115790869-4c852b00-a37c-11eb-97f1-f61972c7800c.png)\n\n# Welcome to the Windows Terminal, Console and Command-Line repo\n\nThis repository contains the source code for:\n\n* [Windows Terminal](https://aka.ms/terminal)\n* [Windows Terminal Preview](https://aka.ms/terminal-preview)\n* The Windows console host (`conhost.exe`)\n* Components shared between the two projects\n* [ColorTool](https://github.com/microsoft/terminal/tree/main/src/tools/ColorTool)\n* [Sample projects](https://github.com/microsoft/terminal/tree/main/samples)\n  that show how to consume the Windows Console APIs\n\nRelated repositories include:\n\n* [Windows Terminal Documentation](https://docs.microsoft.com/windows/terminal)\n  ([Repo: Contribute to the docs](https://github.com/MicrosoftDocs/terminal))\n* [Console API Documentation](https://github.com/MicrosoftDocs/Console-Docs)\n* [Cascadia Code Font](https://github.com/Microsoft/Cascadia-Code)\n\n## Installing and running Windows Terminal\n\n> \ud83d\udd34 Note: Windows Terminal requires Windows 10 1903 (build 18362) or later\n\n### Microsoft Store [Recommended]\n\nInstall the [Windows Terminal from the Microsoft Store][store-install-link].\nThis allows you to always be on the latest version when we release new builds\nwith automatic upgrades.\n\nThis is our preferred method.\n\n### Other install methods\n\n#### Via GitHub\n\nFor users who are unable to install Windows Terminal from the Microsoft Store,\nreleased builds can be manually downloaded from this repository's [Releases\npage](https://github.com/microsoft/terminal/releases).\n\nDownload the `Microsoft.WindowsTerminal_<versionNumber>.msixbundle` file from\nthe **Assets** section. To install the app, you can simply double-click on the\n`.msixbundle` file, and the app installer should automatically run. If that\nfails for any reason, you can try the following command at a PowerShell prompt:\n\n```powershell\n# NOTE: If you are using PowerShell 7+, please run\n# Import-Module Appx -UseWindowsPowerShell\n# before using Add-AppxPackage.\n\nAdd-AppxPackage Microsoft.WindowsTerminal_<versionNumber>.msixbundle\n```\n\n> \ud83d\udd34 Note: If you install Terminal manually:\n>\n> * Terminal will not auto-update when new builds are released so you will need\n>   to regularly install the latest Terminal release to receive all the latest\n>   fixes and improvements!\n\n#### Via Windows Package Manager CLI (aka winget)\n\n[winget](https://github.com/microsoft/winget-cli) users can download and install\nthe latest Terminal release by installing the `Microsoft.WindowsTerminal`\npackage:\n\n```powershell\nwinget install --id=Microsoft.WindowsTerminal -e\n```\n\n#### Via Chocolatey (unofficial)\n\n[Chocolatey](https://chocolatey.org) users can download and install the latest\nTerminal release by installing the `microsoft-windows-terminal` package:\n\n```powershell\nchoco install microsoft-windows-terminal\n```\n\nTo upgrade Windows Terminal using Chocolatey, run the following:\n\n```powershell\nchoco upgrade microsoft-windows-terminal\n```\n\nIf you have any issues when installing/upgrading the package please go to the\n[Windows Terminal package\npage](https://chocolatey.org/packages/microsoft-windows-terminal) and follow the\n[Chocolatey triage process](https://chocolatey.org/docs/package-triage-process)\n\n#### Via Scoop (unofficial)\n\n[Scoop](https://scoop.sh) users can download and install the latest Terminal\nrelease by installing the `windows-terminal` package:\n\n```powershell\nscoop bucket add extras\nscoop install windows-terminal\n```\n\nTo update Windows Terminal using Scoop, run the following:\n\n```powershell\nscoop update windows-terminal\n```\n\nIf you have any issues when installing/updating the package, please search for\nor report the same on the [issues\npage](https://github.com/lukesampson/scoop-extras/issues) of Scoop Extras bucket\nrepository.\n\n---\n\n## Windows Terminal 2.0 Roadmap\n\nThe plan for delivering Windows Terminal 2.0 [is described\nhere](/doc/terminal-v2-roadmap.md) and will be updated as the project proceeds.\n\n## Project Build Status\n\nProject|Build Status\n---|---\nTerminal|[![Terminal Build Status](https://dev.azure.com/ms/terminal/_apis/build/status/terminal%20CI?branchName=main)](https://dev.azure.com/ms/terminal/_build?definitionId=136)\nColorTool|![Colortool Build Status](https://microsoft.visualstudio.com/_apis/public/build/definitions/c93e867a-8815-43c1-92c4-e7dd5404f1e1/17023/badge)\n\n---\n\n## Terminal & Console Overview\n\nPlease take a few minutes to review the overview below before diving into the\ncode:\n\n### Windows Terminal\n\nWindows Terminal is a new, modern, feature-rich, productive terminal application\nfor command-line users. It includes many of the features most frequently\nrequested by the Windows command-line community including support for tabs, rich\ntext, globalization, configurability, theming & styling, and more.\n\nThe Terminal will also need to meet our goals and measures to ensure it remains\nfast and efficient, and doesn't consume vast amounts of memory or power.\n\n### The Windows Console Host\n\nThe Windows Console host, `conhost.exe`, is Windows' original command-line user\nexperience. It also hosts Windows' command-line infrastructure and the Windows\nConsole API server, input engine, rendering engine, user preferences, etc. The\nconsole host code in this repository is the actual source from which the\n`conhost.exe` in Windows itself is built.\n\nSince taking ownership of the Windows command-line in 2014, the team added\nseveral new features to the Console, including background transparency,\nline-based selection, support for [ANSI / Virtual Terminal\nsequences](https://en.wikipedia.org/wiki/ANSI_escape_code), [24-bit\ncolor](https://devblogs.microsoft.com/commandline/24-bit-color-in-the-windows-console/),\na [Pseudoconsole\n(\"ConPTY\")](https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/),\nand more.\n\nHowever, because Windows Console's primary goal is to maintain backward\ncompatibility, we have been unable to add many of the features the community\n(and the team) have been wanting for the last several years including tabs,\nunicode text, and emoji.\n\nThese limitations led us to create the new Windows Terminal.\n\n> You can read more about the evolution of the command-line in general, and the\n> Windows command-line specifically in [this accompanying series of blog\n> posts](https://devblogs.microsoft.com/commandline/windows-command-line-backgrounder/)\n> on the Command-Line team's blog.\n\n### Shared Components\n\nWhile overhauling Windows Console, we modernized its codebase considerably,\ncleanly separating logical entities into modules and classes, introduced some\nkey extensibility points, replaced several old, home-grown collections and\ncontainers with safer, more efficient [STL\ncontainers](https://docs.microsoft.com/en-us/cpp/standard-library/stl-containers?view=vs-2019),\nand made the code simpler and safer by using Microsoft's [Windows Implementation\nLibraries - WIL](https://github.com/Microsoft/wil).\n\nThis overhaul resulted in several of Console's key components being available\nfor re-use in any terminal implementation on Windows. These components include a\nnew DirectWrite-based text layout and rendering engine, a text buffer capable of\nstoring both UTF-16 and UTF-8, a VT parser/emitter, and more.\n\n### Creating the new Windows Terminal\n\nWhen we started planning the new Windows Terminal application, we explored and\nevaluated several approaches and technology stacks. We ultimately decided that\nour goals would be best met by continuing our investment in our C++ codebase,\nwhich would allow us to reuse several of the aforementioned modernized\ncomponents in both the existing Console and the new Terminal. Further, we\nrealized that this would allow us to build much of the Terminal's core itself as\na reusable UI control that others can incorporate into their own applications.\n\nThe result of this work is contained within this repo and delivered as the\nWindows Terminal application you can download from the Microsoft Store, or\n[directly from this repo's\nreleases](https://github.com/microsoft/terminal/releases).\n\n---\n\n## Resources\n\nFor more information about Windows Terminal, you may find some of these\nresources useful and interesting:\n\n* [Command-Line Blog](https://devblogs.microsoft.com/commandline)\n* [Command-Line Backgrounder Blog\n  Series](https://devblogs.microsoft.com/commandline/windows-command-line-backgrounder/)\n* Windows Terminal Launch: [Terminal \"Sizzle\n  Video\"](https://www.youtube.com/watch?v=8gw0rXPMMPE&list=PLEHMQNlPj-Jzh9DkNpqipDGCZZuOwrQwR&index=2&t=0s)\n* Windows Terminal Launch: [Build 2019\n  Session](https://www.youtube.com/watch?v=KMudkRcwjCw)\n* Run As Radio: [Show 645 - Windows Terminal with Richard\n  Turner](http://www.runasradio.com/Shows/Show/645)\n* Azure Devops Podcast: [Episode 54 - Kayla Cinnamon and Rich Turner on DevOps\n  on the Windows\n  Terminal](http://azuredevopspodcast.clear-measure.com/kayla-cinnamon-and-rich-turner-on-devops-on-the-windows-terminal-team-episode-54)\n* Microsoft Ignite 2019 Session: [The Modern Windows Command Line: Windows\n  Terminal -\n  BRK3321](https://myignite.techcommunity.microsoft.com/sessions/81329?source=sessions)\n\n---\n\n## FAQ\n\n### I built and ran the new Terminal, but it looks just like the old console\n\nCause: You're launching the incorrect solution in Visual Studio.\n\nSolution: Make sure you're building & deploying the `CascadiaPackage` project in\nVisual Studio.\n\n> \u26a0 Note: `OpenConsole.exe` is just a locally-built `conhost.exe`, the classic\n> Windows Console that hosts Windows' command-line infrastructure. OpenConsole\n> is used by Windows Terminal to connect to and communicate with command-line\n> applications (via\n> [ConPty](https://devblogs.microsoft.com/commandline/windows-command-line-introducing-the-windows-pseudo-console-conpty/)).\n\n---\n\n## Documentation\n\nAll project documentation is located at [aka.ms/terminal-docs](https://aka.ms/terminal-docs). If you would like\nto contribute to the documentation, please submit a pull request on the [Windows\nTerminal Documentation repo](https://github.com/MicrosoftDocs/terminal).\n\n---\n\n## Contributing\n\nWe are excited to work alongside you, our amazing community, to build and\nenhance Windows Terminal\\!\n\n***BEFORE you start work on a feature/fix***, please read & follow our\n[Contributor's\nGuide](https://github.com/microsoft/terminal/blob/main/CONTRIBUTING.md) to\nhelp avoid any wasted or duplicate effort.\n\n## Communicating with the Team\n\nThe easiest way to communicate with the team is via GitHub issues.\n\nPlease file new issues, feature requests and suggestions, but **DO search for\nsimilar open/closed pre-existing issues before creating a new issue.**\n\nIf you would like to ask a question that you feel doesn't warrant an issue\n(yet), please reach out to us via Twitter:\n\n* Kayla Cinnamon, Program Manager:\n  [@cinnamon\\_msft](https://twitter.com/cinnamon_msft)\n* Dustin Howett, Engineering Lead: [@dhowett](https://twitter.com/DHowett)\n* Michael Niksa, Senior Developer:\n  [@michaelniksa](https://twitter.com/MichaelNiksa)\n* Mike Griese, Developer: [@zadjii](https://twitter.com/zadjii)\n* Carlos Zamora, Developer: [@cazamor_msft](https://twitter.com/cazamor_msft)\n* Leon Liang, Developer: [@leonmsft](https://twitter.com/leonmsft)\n* Pankaj Bhojwani, Developer\n* Leonard Hecker, Developer: [@LeonardHecker](https://twitter.com/LeonardHecker)\n\n## Developer Guidance\n\n## Prerequisites\n\n* You must be running Windows 1903 (build >= 10.0.18362.0) or later to run\n  Windows Terminal\n* You must [enable Developer Mode in the Windows Settings\n  app](https://docs.microsoft.com/en-us/windows/uwp/get-started/enable-your-device-for-development)\n  to locally install and run Windows Terminal\n* You must have the [Windows 10 1903\n  SDK](https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk)\n  installed\n* You must have at least [VS\n  2019](https://visualstudio.microsoft.com/downloads/) installed\n* You must install the following Workloads via the VS Installer. Note: Opening\n  the solution in VS 2019 will [prompt you to install missing components\n  automatically](https://devblogs.microsoft.com/setup/configure-visual-studio-across-your-organization-with-vsconfig/):\n  * Desktop Development with C++\n  * Universal Windows Platform Development\n  * **The following Individual Components**\n    * C++ (v142) Universal Windows Platform Tools\n\n## Building the Code\n\nThis repository uses [git\nsubmodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules) for some of its\ndependencies. To make sure submodules are restored or updated, be sure to run\nthe following prior to building:\n\n```shell\ngit submodule update --init --recursive\n```\n\nOpenConsole.sln may be built from within Visual Studio or from the command-line\nusing a set of convenience scripts & tools in the **/tools** directory:\n\n### Building in PowerShell\n\n```powershell\nImport-Module .\\tools\\OpenConsole.psm1\nSet-MsBuildDevEnvironment\nInvoke-OpenConsoleBuild\n```\n\n### Building in Cmd\n\n```shell\n.\\tools\\razzle.cmd\nbcz\n```\n\n## Running & Debugging\n\nTo debug the Windows Terminal in VS, right click on `CascadiaPackage` (in the\nSolution Explorer) and go to properties. In the Debug menu, change \"Application\nprocess\" and \"Background task process\" to \"Native Only\".\n\nYou should then be able to build & debug the Terminal project by hitting\n<kbd>F5</kbd>.\n\n> \ud83d\udc49 You will _not_ be able to launch the Terminal directly by running the\n> WindowsTerminal.exe. For more details on why, see\n> [#926](https://github.com/microsoft/terminal/issues/926),\n> [#4043](https://github.com/microsoft/terminal/issues/4043)\n\n### Coding Guidance\n\nPlease review these brief docs below about our coding practices.\n\n> \ud83d\udc49 If you find something missing from these docs, feel free to contribute to\n> any of our documentation files anywhere in the repository (or write some new\n> ones!)\n\nThis is a work in progress as we learn what we'll need to provide people in\norder to be effective contributors to our project.\n\n* [Coding Style](https://github.com/microsoft/terminal/blob/main/doc/STYLE.md)\n* [Code Organization](https://github.com/microsoft/terminal/blob/main/doc/ORGANIZATION.md)\n* [Exceptions in our legacy codebase](https://github.com/microsoft/terminal/blob/main/doc/EXCEPTIONS.md)\n* [Helpful smart pointers and macros for interfacing with Windows in WIL](https://github.com/microsoft/terminal/blob/main/doc/WIL.md)\n\n---\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of\nConduct][conduct-code]. For more information see the [Code of Conduct\nFAQ][conduct-FAQ] or contact [opencode@microsoft.com][conduct-email] with any\nadditional questions or comments.\n\n[conduct-code]: https://opensource.microsoft.com/codeofconduct/\n[conduct-FAQ]: https://opensource.microsoft.com/codeofconduct/faq/\n[conduct-email]: mailto:opencode@microsoft.com\n[store-install-link]: https://aka.ms/terminal\n"
 },
 {
  "repo": "microsoft/microsoft-ui-xaml",
  "language": "C#",
  "readme_contents": "\n# Windows UI Library\n\n[![Follow WinUI on Twitter](https://img.shields.io/twitter/follow/windowsui.svg?label=Follow%20WinUI%20on%20Twitter&style=social)](https://twitter.com/intent/follow?screen_name=windowsui)\n\nWinUI is a user interface layer that contains modern controls and styles for building Windows apps. </span> As the native UI layer in Windows it embodies <a href=\"https://www.microsoft.com/design/fluent/#/\">Fluent Design</a>, giving each Windows app the polished feel that customers expect.\n\nWinUI 2 is a library of controls that provides official native Microsoft UI controls and features for Windows [UWP apps](https://docs.microsoft.com/windows/uwp/index). WinUI 2 can be used in any Windows 10 UWP XAML app, or in a Xamarin.Forms app running on Windows 10 using [native view embedding](https://docs.microsoft.com/xamarin/xamarin-forms/platform/native-views).\n\nWinUI 3 is the next version of the WinUI framework, and the first stable, supported version has recently shipped. It dramatically expands WinUI into a full UX framework, making WinUI available for all types of Windows apps \u2013 from Win32 to UWP \u2013 for use as the UI layer.\n \n## WinUI Community Calls\n\nThe WinUI community call is your monthly opportunity to learn about native UX development for Windows with WinUI.\n\nIn these calls we\u2019ll discuss the WinUI roadmap, our status and your feedback.\n\nYou can watch them online here on YouTube at the [Windows Developer channel](https://www.youtube.com/channel/UCzLbHrU7U3cUDNQWWAqjceA).\n\nAdd the event to your calendar: [ICS calendar file](communitycalls/WinUICommunityCall.ics)\n\n## WinUI 3 - Project Reunion 0.5 Preview (March 2021)\n\nAs outlined in the [roadmap](docs/roadmap.md), we've recently shipped the first stable version of WinUI 3, which will greatly expand the scope of WinUI to include the full native Windows UI platform. We're continuously working on improving WinUI 3 and adding more features.\n\nYou can now [download WinUI 3 - Project Reunion 0.5](https://docs.microsoft.com/en-us/windows/apps/winui/winui3/) to try out - we'd love your feedback!\n\n## Using WinUI\nYou can download and use WinUI packages in your app using the NuGet package manager: see the [Getting Started with the Windows UI Library](https://docs.microsoft.com/uwp/toolkits/winui/getting-started) page for more information.\n\n### Packages\n\n| NuGet Package | Build Status | Latest Versions | Documentation |\n| --- | --- | --- | --- |\n| [Microsoft.UI.Xaml](https://www.nuget.org/packages/Microsoft.UI.Xaml) <br /> Controls and Fluent Design for UWP apps | [![Build Status](https://dev.azure.com/ms/microsoft-ui-xaml/_apis/build/status/WinUI-Public-MUX-CI?branchName=main)](https://dev.azure.com/ms/microsoft-ui-xaml/_build/latest?definitionId=20?branchName=main) | [![latest stable version](https://img.shields.io/nuget/v/Microsoft.UI.Xaml.svg)](https://www.nuget.org/packages/Microsoft.UI.Xaml) <br /> [![latest prerelease version](https://img.shields.io/nuget/vpre/Microsoft.UI.Xaml.svg)](https://www.nuget.org/packages/Microsoft.UI.Xaml/absoluteLatest) | [2.5 release](https://docs.microsoft.com/windows/apps/winui/winui2/release-notes/winui-2.5) |\n| [Microsoft.UI.Xaml.Core.Direct](https://www.nuget.org/packages/Microsoft.UI.Xaml.Core.Direct) <br /> Low-level APIs for middleware components | | [![latest prerelease version](https://img.shields.io/nuget/vpre/Microsoft.UI.Xaml.Core.Direct.svg)](https://www.nuget.org/packages/Microsoft.UI.Xaml.Core.Direct/absoluteLatest) | [2.0 prerelease](https://docs.microsoft.com/uwp/api/microsoft.ui.xaml.core.direct) |\n\nYou can also build a WinUI package yourself from source. See [Contributing to the Windows UI Library](CONTRIBUTING.md) for more information on building and contributing to WinUI.\n\n## Documentation\n\n**WinUI usage documentation**:  \nhttps://docs.microsoft.com/windows/apps/winui/\n\n**WinUI 2 Release notes**:  \nhttps://docs.microsoft.com/windows/apps/winui/winui2/release-notes/\n\n**WinUI 3 Release notes**:\nhttps://docs.microsoft.com/windows/apps/winui/winui3/release-notes/\n\n**Sample code**:  \nTo view the WinUI controls in an interactive format, check out the Xaml Controls Gallery:\n* Get the XAML Controls Gallery app from the [Microsoft Store](https://www.microsoft.com/store/productId/9MSVH128X2ZT)\n* Get the source code on [GitHub](https://github.com/Microsoft/Xaml-Controls-Gallery)\n\n[WinUI](https://microsoft.github.io/microsoft-ui-xaml/) also has its own website where you can learn more about it.\n\n## Contributing to WinUI\nThe WinUI team welcomes feedback and contributions!\n\nFor information on how to contribute please see [Contributing to the Windows UI Library](CONTRIBUTING.md).\n\nFor guidelines on making an impact on WinUI through non-code contributions, please see [Contributing ideas, feedback, and requests](CONTRIBUTING_feedback_and_requests.md).\n\n## WinUI features\n\n### Benefits\n\nWinUI 2 provides some useful benefits when building apps for Windows 10:\n\n1. **Helps you stay up to date**  \nWinUI helps keep your app up to date with the latest versions of key controls and features of [UWP XAML](https://docs.microsoft.com/windows/uwp/xaml-platform/xaml-overview) and the [Fluent Design System](https://www.microsoft.com/design/fluent)\n\n2. **Provides backward compatibility**  \nWinUI is backward-compatible with a wide range of Windows 10 versions: you can start building and shipping apps with new XAML features immediately as soon as they're released, even if your users aren't on the latest version of Windows 10\n\n3. **Makes it simpler to build version adaptive apps**  \nYou don't need version checks or conditional XAML markup to use WinUI controls or features: WinUI automatically adapts to the user's OS version\n\n### Version support\n\nThe Microsoft.UI.Xaml 2.4 NuGet package requires your project to have TargetPlatformVersion &gt;= 10.0.18362.0 and TargetPlatformMinVersion &gt;= 10.0.15063.0 when building. \n\nYour app's users can be on any of the following supported Windows 10 versions:\n\n* Windows 10 1703 - Build 15063 (Creators Update aka \"Redstone 2\") and newer (including Windows Insider Previews)\n\nSome features may have a reduced or slightly different user experience on older versions.\n\nFor WinUI 3, your app's users must be on Windows 10 1809 - Build 17763 or newer (including Windows Insider Previews).\n\n## Roadmap\n\nFor info on the WinUI release schedule and high level plans please see the [Windows UI Library Roadmap](docs/roadmap.md).\n\n## WinUI 3 is a part of the Project Reunion family\n[Project Reunion](https://github.com/microsoft/ProjectReunion) is a set of libraries, frameworks, components, and tools that you can use in your apps to access powerful Windows platform functionality from all kinds of apps on many versions of Windows. Project Reunion combines the powers of Win32 native applications alongside modern API usage techniques, so your apps light up everywhere your users are. \n \nOther Project Reunion components are: [WebView2](https://docs.microsoft.com/microsoft-edge/webview2/),  [MSIX (MSIX-Core)](https://docs.microsoft.com/windows/msix/overview), [C++/WinRT](https://github.com/microsoft/cppwinrt), [Rust/WinRT](https://github.com/microsoft/winrt-rs), and [C#/WinRT](https://github.com/microsoft/cswinrt). If you'd like to learn more and contribute to Project Reunion, or have **UWP/app model related questions**, visit our [Github repo](https://github.com/microsoft/ProjectReunion). \n\n## Data/Telemetry\n\nThis project collects usage data and sends it to Microsoft to help improve our products and services. See the [privacy statement](privacy.md) for more details.\n\nFor more information on telemetry implementation see the [developer guide](docs/developer_guide.md#Telemetry).\n"
 },
 {
  "repo": "microsoft/PowerApps-Samples",
  "language": "C#",
  "readme_contents": "# Power Apps Samples\n\nWelcome to the samples repo for Power Apps.\n\nFor Power Apps developer documentation, see [Power Apps for developers](https://docs.microsoft.com/powerapps/#pivot=home&panel=developer).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/powerquery-language-services",
  "language": "TypeScript",
  "readme_contents": "# powerquery-language-services\r\n\r\n[![Build Status](https://dev.azure.com/ms/powerquery-language-services/_apis/build/status/Microsoft.powerquery-language-services?branchName=master)](https://dev.azure.com/ms/powerquery-language-services/_build/latest?definitionId=343&branchName=master)\r\n\r\nThis project contains base functionality for implementing a language service for the Power Query / M language.\r\n\r\n## Build and test\r\n\r\nBuild\r\n\r\n```cmd\r\nnpm install\r\nnpm run build\r\n```\r\n\r\nTest\r\n\r\n```cmd\r\nnpm test\r\n```\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/ApplicationInsights-dotnet",
  "language": "C#",
  "readme_contents": "# Application Insights for .NET Apps\n\nThis is the .NET SDK for sending data to [Azure Monitor](https://docs.microsoft.com/azure/azure-monitor/overview) & [Application Insights](https://docs.microsoft.com/azure/azure-monitor/app/app-insights-overview).\n\n## Getting Started\n\nPlease review our How-to guides to review which packages are appropriate for your project:\n\n* [Console App](https://docs.microsoft.com/azure/azure-monitor/app/console)\n* [ASP.NET](https://docs.microsoft.com/azure/azure-monitor/app/asp-net)\n* [ASP.NET Core](https://docs.microsoft.com/azure/azure-monitor/app/asp-net-core)\n* [ILogger](https://docs.microsoft.com/azure/azure-monitor/app/ilogger)\n* [WorkerService](https://docs.microsoft.com/azure/azure-monitor/app/worker-service)\n\n### Understanding our SDK\n\nWe've gathered a list of concepts, code examples, and links to full guides [here](docs/concepts.md).\n\n## Contributing\n\nWe strongly welcome and encourage contributions to this project.\nPlease review our [Contributing guide](.github/CONTRIBUTING.md).\n\n## Branches\n\n* [master](https://github.com/Microsoft/ApplicationInsights-dotnet/tree/master) contains the *latest* published release located on [NuGet](https://www.nuget.org/packages/Microsoft.ApplicationInsights).\n* [develop](https://github.com/Microsoft/ApplicationInsights-dotnet/tree/develop) contains the code for the *next* release.\n\n## NuGet packages\n\nThe following packages are published from this repository:\n\n|                                                                                                                                                                | Nightly Build                                                                                                                                                                                                                                                                                         | Latest Official Release                                                                                                                                                                                       |\n|--------------------------------------------------------------------------------------------------------------------------------------------------------------- |------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| **Base SDKs**                                                                                                                                                  |                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                               |\n| - [Microsoft.ApplicationInsights](https://www.nuget.org/packages/Microsoft.ApplicationInsights/)                                                               | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights)                                                                       | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights/)                                                                |\n| - [Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel](https://www.nuget.org/packages/Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel)  | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel)         | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.WindowsServer.TelemetryChannel/)  |\n| **Auto Collectors (Generic)**                                                                                                                                  |                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                               |\n| - [Microsoft.ApplicationInsights.DependencyCollector](https://www.nuget.org/packages/Microsoft.ApplicationInsights.DependencyCollector/)                       | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.DependencyCollector?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.DependencyCollector)                               | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.DependencyCollector.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.DependencyCollector)                             |\n| - [Microsoft.ApplicationInsights.EventCounterCollector](https://www.nuget.org/packages/Microsoft.ApplicationInsights.EventCounterCollector)                    | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.EventCounterCollector?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.EventCounterCollector)                           | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.EventCounterCollector.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.EventCounterCollector)                         |\n| - [Microsoft.ApplicationInsights.PerfCounterCollector](https://www.nuget.org/packages/Microsoft.ApplicationInsights.PerfCounterCollector/)                     | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.PerfCounterCollector?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.PerfCounterCollector)                             | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.PerfCounterCollector.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.PerfCounterCollector)                           |\n| - [Microsoft.ApplicationInsights.WindowsServer](https://www.nuget.org/packages/Microsoft.ApplicationInsights.WindowsServer/)                                   | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.WindowsServer?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.WindowsServer)                                           | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.WindowsServer.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.WindowsServer)                                         |\n| **Auto Collectors (ASP.NET)**                                                                                                                                  |                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                               |\n| - [Microsoft.ApplicationInsights.Web](https://www.nuget.org/packages/Microsoft.ApplicationInsights.Web/)                                                       | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.Web?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.Web)                                                               | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.Web.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.Web)                                                             |\n| **Auto Collectors (ASP.NET Core)**                                                                                                                             |                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                               |\n| - [Microsoft.ApplicationInsights.AspNetCore](https://www.nuget.org/packages/Microsoft.ApplicationInsights.AspNetCore/)                                         | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.AspNetCore?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.AspNetCore)                                                 | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.AspNetCore.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.AspNetCore)                                               |\n| **Auto Collectors (WorkerService, Console Application, etc.)**                                                                                                 |                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                               |\n| - [Microsoft.ApplicationInsights.WorkerService](https://www.nuget.org/packages/Microsoft.ApplicationInsights.WorkerService/)                                   | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.WorkerService?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.WorkerService)                                           | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.WorkerService.svg)](https://nuget.org/packages/Microsoft.ApplicationInsights.WorkerService)                                         |\n| **Logging Adapters**                                                                                                                                           |                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                               |\n| - For `ILogger`: [Microsoft.Extensions.Logging.ApplicationInsights](https://www.nuget.org/packages/Microsoft.Extensions.Logging.ApplicationInsights/)          | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.Extensions.Logging.ApplicationInsights?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.Extensions.Logging.ApplicationInsights)                                 | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.Extensions.Logging.ApplicationInsights.svg)](https://www.nuget.org/packages/Microsoft.Extensions.Logging.ApplicationInsights/)                          |\n| - For `NLog`: [Microsoft.ApplicationInsights.NLogTarget](http://www.nuget.org/packages/Microsoft.ApplicationInsights.NLogTarget/)                              | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.NLogTarget?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.NLogTarget)                                                 | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.NLogTarget.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.NLogTarget/)                                          |\n| - For `Log4Net`: [Microsoft.ApplicationInsights.Log4NetAppender](http://www.nuget.org/packages/Microsoft.ApplicationInsights.Log4NetAppender/)                 | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.Log4NetAppender?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.Log4NetAppender)                                       | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.Log4NetAppender.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.Log4NetAppender/)                                |\n| - For `System.Diagnostics`: [Microsoft.ApplicationInsights.TraceListener](http://www.nuget.org/packages/Microsoft.ApplicationInsights.TraceListener/)          | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.TraceListener?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.TraceListener)                                           | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.TraceListener.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.TraceListener/)                                    |\n| - [Microsoft.ApplicationInsights.DiagnosticSourceListener](http://www.nuget.org/packages/Microsoft.ApplicationInsights.DiagnosticSourceListener/)              | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.DiagnosticSourceListener?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.DiagnosticSourceListener)                     | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.DiagnosticSourceListener.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.DiagnosticSourceListener/)              |\n| - [Microsoft.ApplicationInsights.EtwCollector](http://www.nuget.org/packages/Microsoft.ApplicationInsights.EtwCollector/)                                      | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.EtwCollector?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.EtwCollector)                                             | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.EtwCollector.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.EtwCollector/)                                      |\n| - [Microsoft.ApplicationInsights.EventSourceListener](http://www.nuget.org/packages/Microsoft.ApplicationInsights.EventSourceListener/)                        | [![Nightly](https://img.shields.io/myget/applicationinsights-dotnet-nightly/v/Microsoft.ApplicationInsights.EventSourceListener?label=)](https://www.myget.org/feed/applicationinsights-dotnet-nightly/package/nuget/Microsoft.ApplicationInsights.EventSourceListener)                               | [![Nuget](https://img.shields.io/nuget/vpre/Microsoft.ApplicationInsights.EventSourceListener.svg)](https://www.nuget.org/packages/Microsoft.ApplicationInsights.EventSourceListener/)                        |\n\nNightly Builds are available on our MyGet feed:\n`https://www.myget.org/F/applicationinsights-dotnet-nightly/api/v3/index.json`\nThese builds come from the develop branch. These are not signed and are not intended for production workloads.\n\n## Releases \nRefer to our [Milestones](https://github.com/microsoft/ApplicationInsights-dotnet/milestones) for progress on our next releases.\n\n## Support\n\nFor immediate support relating to the Application Insights .NET SDK we encourage you to file an [Azure Support Request](https://docs.microsoft.com/azure/azure-portal/supportability/how-to-create-azure-support-request) with Microsoft Azure instead of filing a GitHub Issue in this repository. \nYou can do so by going online to the [Azure portal](https://portal.azure.com/) and submitting a support request. Access to subscription management and billing support is included with your Microsoft Azure subscription, and technical support is provided through one of the [Azure Support Plans](https://azure.microsoft.com/support/plans/). For step-by-step guidance for the Azure portal, see [How to create an Azure support request](https://docs.microsoft.com/azure/azure-portal/supportability/how-to-create-azure-support-request). Alternatively, you can create and manage your support tickets programmatically using the [Azure Support ticket REST API](https://docs.microsoft.com/rest/api/support/).\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-formattingutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals FormattingUtils\n![Build](https://github.com/microsoft/powerbi-visuals-utils-formattingutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-formattingutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-formattingutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-formattingutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-formattingutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-formattingutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-formattingutils)\n\n> FormattingUtils is a set of functions and classes in order to format values for Power BI custom visuals\n\n## Usage\nLearn how to install and use the FormattingUtils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-formatting)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-formattingutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/ms-tpm-20-ref",
  "language": "C",
  "readme_contents": "# Official TPM 2.0 Reference Implementation (by Microsoft) #\r\n\r\n[![Build Status](https://travis-ci.org/Microsoft/ms-tpm-20-ref.svg?branch=master)](https://travis-ci.org/Microsoft/ms-tpm-20-ref)\r\n\r\nThis is the official TCG reference implementation of the [TPM 2.0 Specification](https://trustedcomputinggroup.org/tpm-library-specification). The project contains complete source code of the reference implementation with a Microsoft Visual Studio solution and Linux autotools build scripts.\r\n\r\nSee the definition of the `SPEC_VERSION`, `SPEC_YEAR` and `SPEC_DAY_OF_YEAR` values in the [TpmTypes.h](TPMCmd/tpm/include/TpmTypes.h) header for the exact revision/date of the TPM 2.0 specification, which the given source tree snapshot corresponds to.\r\n\r\nThe reference implementation can be directly used via the [TPM 2.0 simulator](TPMCmd/Simulator) that emulates a TPM 2.0 device and can be accessed via a custom TCP based protocol. The simplest way to work with the simulator is to use a [TSS library](https://github.com/Microsoft/TSS.MSR) for the programming language of your choice - C#/.Net, C++, Java, Python, JavaScript/Node.js are currently supported. The C language TSS implementing the TCG's TSS API specifiaction is available [here](https://github.com/tpm2-software/tpm2-tss).\r\n\r\n## Windows build ##\r\n\r\nWindows build is implemented as a Visual Studio 2017 solution. Before building it:\r\n\r\n* Setup one or both of the following underlying cryptographic libraries:\r\n\r\n   ### OpenSSL library ###\r\n\r\n   1. Create `TPMCmd/lib` folder and place a static OpenSSL library (`libcrypto.lib`) built for the `x86` architecture there. For the `x64` architecture use the `TPMCmd/lib/x64` folder.\r\n\r\n        The static libs can be either static libraries proper, or import libraries accompanying the corresponding DLLs. In the latter case you'll need to ensure that ther is a matching copy of the OpenSSL DLL in the standard Windows search path, so that it is available when you run the simulator executable (e.g. copy it into the same folder where `simulator.exe` is located).\r\n\r\n        Recommended version of OpenSSL is `1.1.1d` or higher.\r\n\r\n   2. Create `TPMCmd/OsslInclude/openssl` folder and copy there the contents of the `openssl/include/openssl` folder in the OpenSSL source tree used to build the OpenSSL library.\r\n\r\n      If you enable SM{2,3,4} algorithms in `TpmProfile.h`, the build may fail because of missing `SM{2,3,4}.h` headers. In this case you will need to manually copy them over from OpenSSL\u2019s `include/crypt` folder.\r\n\r\n   3. Build the solution with either Debug or Release as the active configuration.\r\n\r\n   ### Wolfcrypt library (wolfSSL) ###\r\n\r\n   1. WolfSSL is included as a submodule. Initialize and update the submodule to fetch the project and checkout the appropriate commit.\r\n\r\n        > git submodule init\r\n        > git submodule update\r\n\r\n        The current commit will point the minimum recommended version of wolfSSL. Moving to a more recent tag or commit should also be supported but might not be tested. \r\n\r\n   2. Build the solution with either WolfDebug or WolfRelease as the active configuration, either from inside the Visual Studio or with the following command line:\r\n\r\n        > msbuild TPMCmd\\simulator.sln /p:Configuration=WolfDebug\r\n\r\n* If necessary, update the definitions of the following macros in the [VendorString.h](TPMCmd/tpm/include/VendorString.h) header: `MANUFACTURER`, `VENDOR_STRING_1`, `FIRMWARE_V1 and FIRMWARE_V2`\r\n\r\n## Linux build\r\n\r\nFollows the common `./bootstrap && ./configure && make` convention.\r\n\r\nNote that autotools scripts require the following prerequisite packages: `autoconf-archive`, `pkg-config`, and sometimes `build-essential` and `automake`. Their absence is not automatically detected. The build also needs `gcc` and `libssl-dev` packages.\r\n\r\nSimilarly to the Windows build, if you enable SM{2,3,4} algorithms in `TpmProfile.h`, the build may fail because of missing `SM{2,3,4}.h` headers. In this case you will need to manually copy them over from OpenSSL\u2019s `include/crypt` folder.\r\n\r\n## Mac OS X build\r\n\r\nAs with the Linux build, use `./bootstrap`, `./configure`, and `make`.\r\nIf you used Homebrew to install OpenSSL, you may need to include its path in `PKG_CONFIG_PATH`.\r\nOS X compilers treat uninitialized global variables as\r\n[common symbols](https://developer.apple.com/library/archive/documentation/DeveloperTools/Conceptual/MachOTopics/1-Articles/executing_files.html),\r\nwhich can be eliminated with the `-fno-common` compiler option.\r\nFuture updates to the autotools configurations may automate one or both of these steps.\r\n\r\n```\r\n./bootstrap\r\nPKG_CONFIG_PATH=\"/usr/local/opt/openssl/lib/pkgconfig\" EXTRA_CFLAGS=-fno-common ./configure\r\nmake\r\n```\r\n"
 },
 {
  "repo": "microsoft/PSRule-pipelines",
  "language": "PowerShell",
  "readme_contents": "# PSRule extension for Azure Pipelines\n\nAn Azure DevOps extension for using PSRule within Azure Pipelines.\n\n![ci-badge] ![extension-version]\n\n## Support\n\nThis project uses GitHub Issues to track bugs and feature requests.\nPlease search the existing issues before filing new issues to avoid duplicates.\n\n- For new issues, file your bug or feature request as a new [issue].\n- For help, discussion, and support questions about using this project, join or start a [discussion].\n\nSupport for this project/ product is limited to the resources listed above.\n\n## Getting started\n\nThe PSRule extension includes the following tasks for Azure Pipelines:\n\nName                | Friendly name   | Description | Reference\n----                | -------------   | ----------- | ---------\n`ps-rule-assert`    | PSRule analysis | Run analysis with PSRule. | [reference][ps-rule-assert]\n`ps-rule-install`   | Install PSRule module | Install a PowerShell module containing rules. | [reference][ps-rule-install]\n\nTo add these tasks, use the name for YAML pipelines or friendly name of classic pipelines.\n\n### Installing PSRule extension\n\nTo use PSRule within Azure DevOps Services, install the [extension] from the [Visual Studio Marketplace][extension].\nFor detailed instructions see [Install extensions][extension-install].\n\nIf you don't have permissions to install extensions within your Azure DevOps organization,\nyou can request it to be installed by an admin instead.\n\n### Using within YAML pipelines\n\nTo use these tasks within YAML pipelines:\n\n- Install rule modules with the `ps-rule-install` task (optional).\n- Run analysis one or more times with the `ps-rule-assert` task.\n- Publish analysis results with the [Publish Test Results](https://docs.microsoft.com/azure/devops/pipelines/tasks/test/publish-test-results?view=azure-devops&tabs=yaml) builtin task.\n\nFor example:\n\n```yaml\nsteps:\n\n# Install PSRule.Rules.Azure from the PowerShell Gallery\n- task: ps-rule-install@0\n  inputs:\n    module: PSRule.Rules.Azure   # Install PSRule.Rules.Azure from the PowerShell Gallery.\n    latest: false                # Only install the module if not already installed.\n    prerelease: false            # Install stable versions only.\n\n# Run analysis from JSON files using the `PSRule.Rules.Azure` module and custom rules from `.ps-rule/`.\n- task: ps-rule-assert@0\n  inputs:\n    inputType: inputPath\n    inputPath: 'out/*.json'                  # Read objects from JSON files in 'out/'.\n    modules: 'PSRule.Rules.Azure'            # Analyze objects using the rules within the PSRule.Rules.Azure PowerShell module.\n    source: '.ps-rule/'                      # Additionally, analyze object using custom rules from '.ps-rule/'.\n    outputFormat: NUnit3                     # Save results to an NUnit report.\n    outputPath: reports/ps-rule-results.xml  # Write NUnit report to 'reports/ps-rule-results.xml'.\n\n# Publish NUnit report as test results\n- task: PublishTestResults@2\n  displayName: 'Publish PSRule results'\n  inputs:\n    testRunTitle: 'PSRule'                          # The title to use for the test run.\n    testRunner: NUnit                               # Import report using the NUnit format.\n    testResultsFiles: 'reports/ps-rule-results.xml' # The previously saved NUnit report.\n```\n\n## Changes and versioning\n\nExtensions and tasks in this repository will use the [semantic versioning](http://semver.org/) model to declare breaking changes from v1.0.0.\nPrior to v1.0.0, breaking changes may be introduced in minor (0.x.0) version increments.\nFor a list of module changes please see the [change log].\n\n## Contributing\n\nThis project welcomes contributions and suggestions.\nIf you are ready to contribute, please visit the [contribution guide].\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Maintainers\n\n- [Bernie White](https://github.com/BernieWhite)\n\n## License\n\nThis project is [licensed under the MIT License][license].\n\n[issue]: https://github.com/microsoft/PSRule-pipelines/issues\n[discussion]: https://github.com/microsoft/PSRule-pipelines/discussions\n[ci-badge]: https://dev.azure.com/bewhite/PSRule-pipelines/_apis/build/status/PSRule-pipelines-CI?branchName=main\n[extension]: https://marketplace.visualstudio.com/items?itemName=bewhite.ps-rule\n[extension-install]: https://docs.microsoft.com/en-us/azure/devops/marketplace/install-extension?view=azure-devops&tabs=browser\n[extension-version]: https://vsmarketplacebadge.apphb.com/version/bewhite.ps-rule.svg\n[ps-rule-assert]: docs/tasks.md#ps-rule-assert\n[ps-rule-install]: docs/tasks.md#ps-rule-install\n[contribution guide]: https://github.com/Microsoft/PSRule-pipelines/blob/main/CONTRIBUTING.md\n[change log]: https://github.com/Microsoft/PSRule-pipelines/blob/main/CHANGELOG.md\n[license]: https://github.com/Microsoft/PSRule-pipelines/blob/main/LICENSE\n"
 },
 {
  "repo": "microsoft/CromwellOnAzure",
  "language": "C#",
  "readme_contents": "# Welcome to Cromwell on Azure\r\n### Latest release\r\n * [Release 2.3.0](https://github.com/microsoft/CromwellOnAzure/releases/tag/2.3.0)<br/>\r\n [Release notes for version 2.3.0](docs/release-notes/2.3.0.md)\r\n \r\nCheck the \"Update Instructions\" section in the version 2.3.0 [release notes](docs/release-notes/2.3.0.md/#update-instructions) to learn how to update an existing Cromwell on Azure deployment to version 2.3.0. You can customize some parameters when updating. Please [see these customization instructions](docs/troubleshooting-guide.md/#Customize-your-Cromwell-on-Azure-deployment), specifically the \"Used by update\" and \"Comment\" columns in the table.<br/>\r\n\r\n#### Getting started\r\n * What is [Cromwell on Azure?](#Cromwell-on-Azure) <br/>\r\n * Deploy Cromwell on Azure now using this [guide](#Deploy-your-instance-of-Cromwell-on-Azure)<br/>\r\n * A brief [demo video](https://youtu.be/QlRQ63n_mKw) on how to run workflows using Cromwell on Azure<br/>\r\n\r\n#### Running workflows\r\n * Prepare, start or abort your workflow [using this guide](docs/managing-your-workflow.md/#Managing-your-workflow)<br/>\r\n * Here is an example workflow to [convert FASTQ files to uBAM files](docs/example-fastq-to-ubam.md/#Example-workflow-to-convert-FASTQ-files-to-uBAM-files)<br/>\r\n * Have an existing WDL file that you want to run on Azure? [Modify your existing WDL with these adaptations for Azure](docs/change-existing-WDL-for-Azure.md/#How-to-modify-an-existing-WDL-file-to-run-on-Cromwell-on-Azure)<br/>\r\n * Want to run commonly used workflows? [Find links to ready-to-use workflows here](#Run-Common-Workflows)<br/>\r\n * Want to see some examples of tertiary analysis or other genomics analysis? [Find links to related project here](#Related-Projects)<br/>\r\n\r\n#### Questions?\r\n * See our [Troubleshooting Guide](docs/troubleshooting-guide.md/#FAQs,-advanced-troubleshooting-and-known-issues-for-Cromwell-on-Azure) for more information<br/>\r\n * Known issues and work-arounds are [documented here](docs/troubleshooting-guide.md/#Known-Issues-And-Mitigation)<br/>\r\n\r\nIf you are running into an issue and cannot find any information in the troubleshooting guide, please open a GitHub issue!<br/>\r\n\r\n![Logo](/docs/screenshots/logo.png)\r\n\r\n## Cromwell on Azure \r\n\r\n[Cromwell](https://cromwell.readthedocs.io/en/stable/) is a workflow management system for scientific workflows, orchestrating the computing tasks needed for genomics analysis. Originally developed by the [Broad Institute](https://github.com/broadinstitute/cromwell), Cromwell is also used in the GATK Best Practices genome analysis pipeline. Cromwell supports running scripts at various scales, including your local machine, a local computing cluster, and on the cloud. <br />\r\n\r\nCromwell on Azure configures all Azure resources needed to run workflows through Cromwell on the Azure cloud, and uses the [GA4GH TES](https://cromwell.readthedocs.io/en/develop/backends/TES/) backend for orchestrating the tasks that create a workflow. The installation sets up a VM host to run the Cromwell server and uses Azure Batch to spin up virtual machines that run each task in a workflow. Cromwell workflows can be written using either the [WDL](https://github.com/openwdl/wdl) or the [CWL](https://www.commonwl.org/) scripting languages. To see examples of WDL scripts - see this ['Learn WDL'](https://github.com/openwdl/learn-wdl) repository on GitHub. To see examples of CWL scripts - see this ['CWL search result'](https://dockstore.org/search?descriptorType=CWL&searchMode=files) on Dockstore.<br />\r\n\r\n## Deploy your instance of Cromwell on Azure\r\n\r\n### Prerequisites\r\n\r\n1. You will need an [Azure Subscription](https://portal.azure.com/) to deploy Cromwell on Azure.\r\n2. You must have the proper [Azure role assignments](https://docs.microsoft.com/en-us/azure/role-based-access-control/overview) to deploy Cromwell on Azure.  To check your current role assignments, please follow [these instructions](https://docs.microsoft.com/en-us/azure/role-based-access-control/check-access).  You must have one of the following combinations of [role assignments](https://docs.microsoft.com/en-us/azure/role-based-access-control/built-in-roles):\r\n   1. `Owner` of the subscription<br/>\r\n   2. `Contributor` and `User Access Administrator` of the subscription\r\n   3. `Owner` of the resource group. *Note: this level of access will result in a warning during deployment, and will not use the latest VM pricing data.</i>  [Learn more](/docs/troubleshooting-guide.md/#How-are-Batch-VMs-selected-to-run-tasks-in-a-workflow?).  Also, you must specify the resource group name during deployment with this level of access (see below).*\r\n   4.  Note: if you only have `Service Administrator` as a role assignment, please assign yourself as `Owner` of the subscription.\r\n3. Install the [Azure Command Line Interface (az cli)](https://docs.microsoft.com/en-us/cli/azure/?view=azure-cli-latest), a command line experience for managing Azure resources.\r\n4. Run `az login` to authenticate with Azure.\r\n\r\n\r\n### Download the deployment executable\r\n\r\nDownload the required executable from [Releases](https://github.com/microsoft/CromwellOnAzure/releases). Choose the runtime of your choice from `win-x64`, `linux-x64`, `osx-x64`. *On Windows machines, we recommend using the `win-x64` runtime (deployment using the `linux-x64` runtime via the Windows Subsystem for Linux is not supported).*<br/>\r\n\r\n### Optional: build the executable yourself\r\nNote: Build instructions only provided for the latest release.\r\n\r\n#### Linux\r\n*Preqrequisites*:<br/>\r\n.NET Core 3.1 SDK for [Linux](https://docs.microsoft.com/en-us/dotnet/core/install/linux). Get instructions for your Linux distro and version to install the SDK. \r\n\r\nFor example, instructions for *Ubuntu 18.04* are available [here](https://docs.microsoft.com/en-us/dotnet/core/install/linux-ubuntu#1804-) and below for convenience:\r\n\r\n```\r\nwget https://packages.microsoft.com/config/ubuntu/18.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb\r\nsudo dpkg -i packages-microsoft-prod.deb\r\nsudo apt-get update && \\\r\nsudo apt-get install -y apt-transport-https && \\\r\nsudo apt-get update && \\\r\nsudo apt-get install -y dotnet-sdk-3.1\r\n```\r\n\r\n#### Windows\r\n*Preqrequisites*:<br/>\r\n.NET Core 3.1 SDK for [Windows](https://dotnet.microsoft.com/download). Get the executable and follow the wizard to install the SDK.\r\n\r\n*Recommended*:<br/>\r\nVS 2019\r\n\r\n#### Build steps\r\n1. Clone the [Cromwell on Azure repository](https://github.com/microsoft/CromwellOnAzure)\r\n2. Build the solution using `dotnet build` on bash or Powershell. For Windows, you can choose to build and test using VS 2019\r\n3. Run tests using `dotnet test` on bash or Powershell\r\n4. [Publish](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish#synopsis) the `deploy-cromwell-on-azure` project [as a self-contained deployment with your target runtime identifier (RID)](https://docs.microsoft.com/en-us/dotnet/core/deploying/#self-contained-deployments-scd) to produce the executable\r\n\r\nExample<br/> \r\nLinux: `dotnet publish -r linux-x64`<br/>\r\nWindows: `dotnet publish -r win-x64`<br/>\r\n\r\nLearn more about `dotnet` commands [here](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet#dotnet-commands)\r\n\r\n### Run the deployment executable\r\n\r\n1. **Linux and OS X only**: assign execute permissions to the file by running the following command on the terminal:<br/>\r\n`chmod +x <fileName>`. Replace `<fileName>` with the correct name: `deploy-cromwell-on-azure-linux` or `deploy-cromwell-on-azure-osx.app`\r\n1. You must specify the following parameters:\r\n   1. `SubscriptionId` (**required**)\r\n      1.  This can be obtained by navigating to the [subscriptions blade in the Azure portal](https://portal.azure.com/#blade/Microsoft_Azure_Billing/SubscriptionsBlade)\r\n   1. `RegionName` (**required**)\r\n      1. Specifies the region you would like to use for your Cromwell on Azure instance. To find a list of all available regions, run `az account list-locations` on the command line or in PowerShell and use the desired region's \"name\" property for `RegionName`.\r\n   1. `MainIdentifierPrefix` (*optional*)\r\n      1. This string will be used to prefix the name of your Cromwell on Azure resource group and associated resources. If not specified, the default value of \"coa\" followed by random characters is used as a prefix for the resource group and all Azure resources created for your Cromwell on Azure instance. After installation, you can search for your resources using the `MainIdentifierPrefix` value.<br/>\r\n   1. `ResourceGroupName` (*optional*, **required** when you only have owner-level access of the *resource group*)\r\n      1. Specifies the name of a pre-existing resource group that you wish to deploy into.\r\n      \r\nRun the following at the command line or terminal after navigating to where your executable is saved:\r\n```\r\n.\\deploy-cromwell-on-azure.exe --SubscriptionId <Your subscription ID> --RegionName <Your region> --MainIdentifierPrefix <Your string> \r\n```\r\n\r\n**Example:**\r\n```\r\n.\\deploy-cromwell-on-azure.exe --SubscriptionId 00000000-0000-0000-0000-000000000000 --RegionName westus2 --MainIdentifierPrefix coa \r\n```\r\n\r\nA [test workflow](#Hello-World-WDL-test) is run to ensure successful deployment. If your [Batch account does not have enough resource quotas](https://docs.microsoft.com/en-us/azure/batch/batch-quota-limit#resource-quotas), you will see the error while deploying. You can request more quotas by following [these instructions](https://docs.microsoft.com/en-us/azure/batch/batch-quota-limit#increase-a-quota).\r\n\r\nDeployment, including a small test workflow can take up to 25 minutes to complete. **At installation, a user is created to allow managing the host VM with username \"vmadmin\". The password is randomly generated and shown during installation. You may want to save the username, password and resource group name to allow for advanced debugging later.**\r\n\r\nPrepare, start or abort a workflow using instructions [here](docs/managing-your-workflow.md).\r\n\r\n### Cromwell on Azure deployed resources\r\n\r\nOnce deployed, Cromwell on Azure configures the following Azure resources:\r\n\r\n* [Host VM](https://azure.microsoft.com/en-us/services/virtual-machines/) - runs [Ubuntu 18.04 LTS](https://github.com/microsoft/CromwellOnAzure/blob/421ccd163bfd53807413ed696c0dab31fb2478aa/src/deploy-cromwell-on-azure/Configuration.cs#L16) and [Docker Compose with four containers](https://github.com/microsoft/CromwellOnAzure/blob/master/src/deploy-cromwell-on-azure/scripts/docker-compose.yml) (Cromwell, MySQL, TES, TriggerService).  [Blobfuse](https://github.com/Azure/azure-storage-fuse) is used to mount the default storage account as a local file system available to the four containers.  Also created are an OS and data disk, network interface, public IP address, virtual network, and network security group. [Learn more](https://docs.microsoft.com/en-us/azure/virtual-machines/linux/)\r\n* [Batch account](https://docs.microsoft.com/en-us/azure/batch/) - The Azure Batch account is used by TES to spin up the virtual machines that run each task in a workflow.  After deployment, create an Azure support request to increase your core quotas if you plan on running large workflows.  [Learn more](https://docs.microsoft.com/en-us/azure/batch/batch-quota-limit#resource-quotas)\r\n* [Storage account](https://docs.microsoft.com/en-us/azure/storage/) - The Azure Storage account is mounted to the host VM using [blobfuse](https://github.com/Azure/azure-storage-fuse), which enables [Azure Block Blobs](https://docs.microsoft.com/en-us/rest/api/storageservices/understanding-block-blobs--append-blobs--and-page-blobs) to be mounted as a local file system available to the four containers running in Docker. By default, it includes the following Blob containers - `configuration`, `cromwell-executions`, `cromwell-workflow-logs`, `inputs`, `outputs`, and `workflows`.\r\n* [Application Insights](https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview) - This contains logs from TES and the Trigger Service to enable debugging.\r\n* [Cosmos DB](https://docs.microsoft.com/en-us/azure/cosmos-db/introduction) - This database is used by TES, and includes information and metadata about each TES task that is run as part of a workflow.\r\n\r\n![Cromwell-On-Azure](/docs/screenshots/cromwellonazure.png)\r\n\r\nAll of these resources will be grouped under a single resource group in your account, which you can view on the [Azure Portal](https://portal.azure.com). **Note that your specific resource group name, host VM name and host VM password for username \"vmadmin\" are printed to the screen during deployment. You can store these for your future use, or you can reset the VM's password at a later date via the Azure Portal.**<br/>\r\n\r\nYou can [follow these steps](/docs/troubleshooting-guide.md/#Use-input-data-files-from-an-existing-Storage-account-that-my-lab-or-team-is-currently-using) if you wish to mount a different Azure Storage account that you manage or own, to your Cromwell on Azure instance.\r\n\r\n### Connect to existing Azure resources I own that are not part of the Cromwell on Azure instance by default\r\n\r\nCromwell on Azure uses [managed identities](https://docs.microsoft.com/en-us/azure/active-directory/managed-identities-azure-resources/overview) to allow the host VM to connect to Azure resources in a simple and secure manner.  \r\n\r\nAt the time of installation, a managed identity is created and associated with the host VM. \r\n\r\n**Cromwell on Azure version 2.x**\r\n\r\nSince version 2.0, a user managed identity is created with the name `{resource-group-name}-identity` in the deployment resource group.\r\n\r\n**Cromwell on Azure version 1.x**\r\n\r\nFor version 1.x and below, a system managed identity is created. You can find the identity via the Azure Portal by searching for the VM name in Azure Active Directory, under \"All Applications\". Or you may use Azure CLI `show` command as described [here](https://docs.microsoft.com/en-us/cli/azure/vm/identity?view=azure-cli-latest#az-vm-identity-show).\r\n\r\nTo allow the host VM to connect to **custom** Azure resources like Storage Account, Batch Account etc. you can use the [Azure Portal](https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-portal) or [Azure CLI](https://docs.microsoft.com/en-us/azure/role-based-access-control/role-assignments-cli) to find the managed identity of the host VM (if using Cromwell on Azure version 1.x) or the user-managed identity (if using Cromwell on Azure version 2.x and above) and add it as a Contributor to the required Azure resource.<br/>\r\n\r\n![Add Role](/docs/screenshots/add-role.png)\r\n\r\n\r\nFor convenience, some configuration files are hosted on your Cromwell on Azure Storage account, in the \"configuration\" container - `containers-to-mount`, and `cromwell-application.conf`. You can modify and save these file using Azure Portal UI \"Edit Blob\" option or simply upload a new file to replace the existing one.\r\n\r\n![Edit Configuration](/docs/screenshots/edit-config.png)\r\n\r\n\r\nSee [this section in the advanced configuration on details of how to connect a different storage account, batch account, or a private Azure Container Registry](/docs/troubleshooting-guide.md/#Customizing-your-Cromwell-on-Azure-instance).<br/>\r\n\r\n\r\nFor these changes to take effect, be sure to restart your Cromwell on Azure VM through the Azure Portal UI or run `sudo reboot`.\r\n\r\n![Restart VM](/docs/screenshots/restartVM.png)\r\n\r\n\r\n### Hello World WDL test\r\n\r\nAs part of the Cromwell on Azure deployment, a \"Hello World\" workflow is automatically run as a check. The input files for this workflow are found in the `inputs` container, and the output files can be found in the `cromwell-executions` container of your default storage account. \r\nOnce it runs to completion you can find the trigger JSON file that started the workflow in the `workflows` container in the `succeeded` directory, if it ran successfully.<br/>\r\n\r\nHello World WDL file:\r\n```\r\ntask hello {\r\n  String name\r\n\r\n  command {\r\n    echo 'Hello ${name}!'\r\n  }\r\n  output {\r\n\tFile response = stdout()\r\n  }\r\n  runtime {\r\n\tdocker: 'ubuntu:16.04'\r\n  }\r\n}\r\n\r\nworkflow test {\r\n  call hello\r\n}\r\n```\r\n\r\nHello World inputs.json file:\r\n```\r\n{\r\n  \"test.hello.name\": \"World\"\r\n}\r\n```\r\n\r\nHello World trigger JSON file as seen in your storage account's `workflows` container in the `succeeded` directory:\r\n```\r\n{\r\n  \"WorkflowUrl\": \"/<storageaccountname>/inputs/test/test.wdl\",\r\n  \"WorkflowInputsUrl\": \"/<storageaccountname>/inputs/test/test.json\",\r\n  \"WorkflowOptionsUrl\": null,\r\n  \"WorkflowDependenciesUrl\": null\r\n}\r\n```\r\n\r\nIf your \"Hello-World\" test workflow or other workflows consistently fail, make sure to [check your Azure Batch account quotas](docs/troubleshooting-guide.md/#Check-Azure-Batch-account-quotas).\r\n\r\n## Run Common Workflows\r\n\r\nRun Broad Institute of MIT and Harvard's Best Practices Pipelines on Cromwell on Azure:\r\n\r\n[Data pre-processing for variant discovery](https://github.com/microsoft/gatk4-data-processing-azure)<br/>\r\n\r\n[Germline short variant discovery (SNPs + Indels)](https://github.com/microsoft/gatk4-genome-processing-pipeline-azure)<br/>\r\n\r\n[Somatic short variant discovery (SNVs + Indels)](https://github.com/microsoft/gatk4-somatic-snvs-indels-azure)<br/>\r\n\r\n[Variant-filtering with Convolutional Neural Networks](https://github.com/microsoft/gatk4-cnn-variant-filter-azure)<br/>\r\n\r\n[Sequence data format conversion](https://github.com/microsoft/seq-format-conversion-azure)<br/>\r\n\r\n## Related Projects\r\n\r\n[Genomics Data Analysis with Jupyter Notebooks on Azure](https://github.com/microsoft/genomicsnotebook)<br/>\r\n"
 },
 {
  "repo": "microsoft/EconML",
  "language": "Jupyter Notebook",
  "readme_contents": "[![Build Status](https://dev.azure.com/ms/EconML/_apis/build/status/Microsoft.EconML?branchName=master)](https://dev.azure.com/ms/EconML/_build/latest?definitionId=49&branchName=master)\n[![PyPI version](https://img.shields.io/pypi/v/econml.svg)](https://pypi.org/project/econml/)\n[![PyPI wheel](https://img.shields.io/pypi/wheel/econml.svg)](https://pypi.org/project/econml/)\n[![Supported Python versions](https://img.shields.io/pypi/pyversions/econml.svg)](https://pypi.org/project/econml/)\n\n\n\n<h1><img src=\"https://www.microsoft.com/en-us/research/wp-content/uploads/2016/12/MSR-ALICE-HeaderGraphic-1920x720_1-800x550.jpg\" width=\"130px\" align=\"left\" style=\"margin-right: 10px;\"> EconML: A Python Package for ML-Based Heterogeneous Treatment Effects Estimation</h1>\n\n**EconML** is a Python package for estimating heterogeneous treatment effects from observational data via machine learning. This package was designed and built as part of the [ALICE project](https://www.microsoft.com/en-us/research/project/alice/) at Microsoft Research with the goal to combine state-of-the-art machine learning \ntechniques with econometrics to bring automation to complex causal inference problems. The promise of EconML:\n\n* Implement recent techniques in the literature at the intersection of econometrics and machine learning\n* Maintain flexibility in modeling the effect heterogeneity (via techniques such as random forests, boosting, lasso and neural nets), while preserving the causal interpretation of the learned model and often offering valid confidence intervals\n* Use a unified API\n* Build on standard Python packages for Machine Learning and Data Analysis\n\nOne of the biggest promises of machine learning is to automate decision making in a multitude of domains. At the core of many data-driven personalized decision scenarios is the estimation of heterogeneous treatment effects: what is the causal effect of an intervention on an outcome of interest for a sample with a particular set of features? In a nutshell, this toolkit is designed to measure the causal effect of some treatment variable(s) `T` on an outcome \nvariable `Y`, controlling for a set of features `X, W` and how does that effect vary as a function of `X`. The methods implemented are applicable even with observational (non-experimental or historical) datasets. For the estimation results to have a causal interpretation, some methods assume no unobserved confounders (i.e. there is no unobserved variable not included in `X, W` that simultaneously has an effect on both `T` and `Y`), while others assume access to an instrument `Z` (i.e. an observed variable `Z` that has an effect on the treatment `T` but no direct effect on the outcome `Y`). Most methods provide confidence intervals and inference results.\n\nFor detailed information about the package, consult the documentation at https://econml.azurewebsites.net/.\n\nFor information on use cases and background material on causal inference and heterogeneous treatment effects see our webpage at https://www.microsoft.com/en-us/research/project/econml/\n\n<details>\n<summary><strong><em>Table of Contents</em></strong></summary>\n\n- [News](#news)\n- [Getting Started](#getting-started)\n  - [Installation](#installation)\n  - [Usage Examples](#usage-examples)\n    - [Estimation Methods](#estimation-methods)\n    - [Interpretability](#interpretability)\n    - [Causal Model Selection and Cross-Validation](#causal-model-selection-and-cross-validation)\n    - [Inference](#inference)\n- [For Developers](#for-developers)\n  - [Running the tests](#running-the-tests)\n  - [Generating the documentation](#generating-the-documentation)\n- [Blogs and Publications](#blogs-and-publications)\n- [Citation](#citation)\n- [Contributing and Feedback](#contributing-and-feedback)\n- [References](#references)\n\n</details>\n\n# News\n\n**May 8, 2021:** Release v0.11.0, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.11.0)\n\n<details><summary>Previous releases</summary>\n\n**March 22, 2021:** Release v0.10.0, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.10.0)\n\n**March 11, 2021:** Release v0.9.2, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.9.2)\n\n**March 3, 2021:** Release v0.9.1, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.9.1)\n\n**February 20, 2021:** Release v0.9.0, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.9.0)\n\n**January 20, 2021:** Release v0.9.0b1, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.9.0b1)\n\n**November 20, 2020:** Release v0.8.1, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.8.1)\n\n**November 18, 2020:** Release v0.8.0, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.8.0)\n\n**September 4, 2020:** Release v0.8.0b1, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.8.0b1)\n\n**March 6, 2020:** Release v0.7.0, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.7.0)\n\n**February 18, 2020:** Release v0.7.0b1, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.7.0b1)\n\n**January 10, 2020:** Release v0.6.1, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.6.1)\n\n**December 6, 2019:** Release v0.6, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.6)\n\n**November 21, 2019:** Release v0.5, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.5). \n\n**June 3, 2019:** Release v0.4, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.4). \n\n**May 3, 2019:** Release v0.3, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.3).\n\n**April 10, 2019:** Release v0.2, see release notes [here](https://github.com/Microsoft/EconML/releases/tag/v0.2).\n\n**March 6, 2019:** Release v0.1, welcome to have a try and provide feedback.\n\n</details>\n\n# Getting Started\n\n## Installation\n\nInstall the latest release from [PyPI](https://pypi.org/project/econml/):\n```\npip install econml\n```\nTo install from source, see [For Developers](#for-developers) section below.\n\n## Usage Examples\n### Estimation Methods\n\n<details>\n  <summary>Double Machine Learning (aka RLearner) (click to expand)</summary>\n\n  * Linear final stage\n\n  ```Python\n  from econml.dml import LinearDML\n  from sklearn.linear_model import LassoCV\n  from econml.inference import BootstrapInference\n\n  est = LinearDML(model_y=LassoCV(), model_t=LassoCV())\n  ### Estimate with OLS confidence intervals\n  est.fit(Y, T, X=X, W=W) # W -> high-dimensional confounders, X -> features\n  treatment_effects = est.effect(X_test)\n  lb, ub = est.effect_interval(X_test, alpha=0.05) # OLS confidence intervals\n\n  ### Estimate with bootstrap confidence intervals\n  est.fit(Y, T, X=X, W=W, inference='bootstrap')  # with default bootstrap parameters\n  est.fit(Y, T, X=X, W=W, inference=BootstrapInference(n_bootstrap_samples=100))  # or customized\n  lb, ub = est.effect_interval(X_test, alpha=0.05) # Bootstrap confidence intervals\n  ```\n\n  * Sparse linear final stage\n\n  ```Python\n  from econml.dml import SparseLinearDML\n  from sklearn.linear_model import LassoCV\n\n  est = SparseLinearDML(model_y=LassoCV(), model_t=LassoCV())\n  est.fit(Y, T, X=X, W=W) # X -> high dimensional features\n  treatment_effects = est.effect(X_test)\n  lb, ub = est.effect_interval(X_test, alpha=0.05) # Confidence intervals via debiased lasso\n  ```\n\n  * Generic Machine Learning last stage\n  \n  ```Python\n  from econml.dml import NonParamDML\n  from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n\n  est = NonParamDML(model_y=RandomForestRegressor(),\n                    model_t=RandomForestClassifier(),\n                    model_final=RandomForestRegressor(),\n                    discrete_treatment=True)\n  est.fit(Y, T, X=X, W=W) \n  treatment_effects = est.effect(X_test)\n  ```\n\n</details>\n\n<details>\n  <summary>Causal Forests (click to expand)</summary>\n\n  ```Python\n  from econml.dml import CausalForestDML\n  from sklearn.linear_model import LassoCV\n  # Use defaults\n  est = CausalForestDML()\n  # Or specify hyperparameters\n  est = CausalForestDML(criterion='het', n_estimators=500,       \n                        min_samples_leaf=10, \n                        max_depth=10, max_samples=0.5,\n                        discrete_treatment=False,\n                        model_t=LassoCV(), model_y=LassoCV())\n  est.fit(Y, T, X=X, W=W)\n  treatment_effects = est.effect(X_test)\n  # Confidence intervals via Bootstrap-of-Little-Bags for forests\n  lb, ub = est.effect_interval(X_test, alpha=0.05)\n  ```\n</details>\n\n\n<details>\n  <summary>Orthogonal Random Forests (click to expand)</summary>\n\n  ```Python\n  from econml.orf import DMLOrthoForest, DROrthoForest\n  from econml.sklearn_extensions.linear_model import WeightedLasso, WeightedLassoCV\n  # Use defaults\n  est = DMLOrthoForest()\n  est = DROrthoForest()\n  # Or specify hyperparameters\n  est = DMLOrthoForest(n_trees=500, min_leaf_size=10,\n                       max_depth=10, subsample_ratio=0.7,\n                       lambda_reg=0.01,\n                       discrete_treatment=False,\n                       model_T=WeightedLasso(alpha=0.01), model_Y=WeightedLasso(alpha=0.01),\n                       model_T_final=WeightedLassoCV(cv=3), model_Y_final=WeightedLassoCV(cv=3))\n  est.fit(Y, T, X=X, W=W)\n  treatment_effects = est.effect(X_test)\n  # Confidence intervals via Bootstrap-of-Little-Bags for forests\n  lb, ub = est.effect_interval(X_test, alpha=0.05)\n  ```\n</details>\n\n<details>\n\n<summary>Meta-Learners (click to expand)</summary>\n  \n  * XLearner\n\n  ```Python\n  from econml.metalearners import XLearner\n  from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n\n  est = XLearner(models=GradientBoostingRegressor(),\n                propensity_model=GradientBoostingClassifier(),\n                cate_models=GradientBoostingRegressor())\n  est.fit(Y, T, X=np.hstack([X, W]))\n  treatment_effects = est.effect(np.hstack([X_test, W_test]))\n\n  # Fit with bootstrap confidence interval construction enabled\n  est.fit(Y, T, X=np.hstack([X, W]), inference='bootstrap')\n  treatment_effects = est.effect(np.hstack([X_test, W_test]))\n  lb, ub = est.effect_interval(np.hstack([X_test, W_test]), alpha=0.05) # Bootstrap CIs\n  ```\n  \n  * SLearner\n\n  ```Python\n  from econml.metalearners import SLearner\n  from sklearn.ensemble import GradientBoostingRegressor\n\n  est = SLearner(overall_model=GradientBoostingRegressor())\n  est.fit(Y, T, X=np.hstack([X, W]))\n  treatment_effects = est.effect(np.hstack([X_test, W_test]))\n  ```\n\n  * TLearner\n\n  ```Python\n  from econml.metalearners import TLearner\n  from sklearn.ensemble import GradientBoostingRegressor\n\n  est = TLearner(models=GradientBoostingRegressor())\n  est.fit(Y, T, X=np.hstack([X, W]))\n  treatment_effects = est.effect(np.hstack([X_test, W_test]))\n  ```\n</details>\n\n<details>\n<summary>Doubly Robust Learners (click to expand)\n</summary>\n\n* Linear final stage\n\n```Python\nfrom econml.dr import LinearDRLearner\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n\nest = LinearDRLearner(model_propensity=GradientBoostingClassifier(),\n                      model_regression=GradientBoostingRegressor())\nest.fit(Y, T, X=X, W=W)\ntreatment_effects = est.effect(X_test)\nlb, ub = est.effect_interval(X_test, alpha=0.05)\n```\n\n* Sparse linear final stage\n\n```Python\nfrom econml.dr import SparseLinearDRLearner\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n\nest = SparseLinearDRLearner(model_propensity=GradientBoostingClassifier(),\n                            model_regression=GradientBoostingRegressor())\nest.fit(Y, T, X=X, W=W)\ntreatment_effects = est.effect(X_test)\nlb, ub = est.effect_interval(X_test, alpha=0.05)\n```\n\n* Nonparametric final stage\n\n```Python\nfrom econml.dr import ForestDRLearner\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n\nest = ForestDRLearner(model_propensity=GradientBoostingClassifier(),\n                      model_regression=GradientBoostingRegressor())\nest.fit(Y, T, X=X, W=W) \ntreatment_effects = est.effect(X_test)\nlb, ub = est.effect_interval(X_test, alpha=0.05)\n```\n</details>\n\n<details>\n<summary>Orthogonal Instrumental Variables (click to expand)</summary>\n\n* Intent to Treat Doubly Robust Learner (discrete instrument, discrete treatment)\n\n```Python\nfrom econml.iv.dr import LinearIntentToTreatDRIV\nfrom sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\nfrom sklearn.linear_model import LinearRegression\n\nest = LinearIntentToTreatDRIV(model_Y_X=GradientBoostingRegressor(),\n                              model_T_XZ=GradientBoostingClassifier(),\n                              flexible_model_effect=GradientBoostingRegressor())\nest.fit(Y, T, Z=Z, X=X) # OLS inference by default\ntreatment_effects = est.effect(X_test)\nlb, ub = est.effect_interval(X_test, alpha=0.05) # OLS confidence intervals\n```\n\n</details>\n\n<details>\n<summary>Deep Instrumental Variables (click to expand)</summary>\n\n```Python\nimport keras\nfrom econml.iv.nnet import DeepIV\n\ntreatment_model = keras.Sequential([keras.layers.Dense(128, activation='relu', input_shape=(2,)),\n                                    keras.layers.Dropout(0.17),\n                                    keras.layers.Dense(64, activation='relu'),\n                                    keras.layers.Dropout(0.17),\n                                    keras.layers.Dense(32, activation='relu'),\n                                    keras.layers.Dropout(0.17)])\nresponse_model = keras.Sequential([keras.layers.Dense(128, activation='relu', input_shape=(2,)),\n                                  keras.layers.Dropout(0.17),\n                                  keras.layers.Dense(64, activation='relu'),\n                                  keras.layers.Dropout(0.17),\n                                  keras.layers.Dense(32, activation='relu'),\n                                  keras.layers.Dropout(0.17),\n                                  keras.layers.Dense(1)])\nest = DeepIV(n_components=10, # Number of gaussians in the mixture density networks)\n             m=lambda z, x: treatment_model(keras.layers.concatenate([z, x])), # Treatment model\n             h=lambda t, x: response_model(keras.layers.concatenate([t, x])), # Response model\n             n_samples=1 # Number of samples used to estimate the response\n             )\nest.fit(Y, T, X=X, Z=Z) # Z -> instrumental variables\ntreatment_effects = est.effect(X_test)\n```\n</details>\n\nSee the <a href=\"#references\">References</a> section for more details.\n\n### Interpretability\n<details>\n  <summary>Tree Interpreter of the CATE model (click to expand)</summary>\n  \n  ```Python\n  from econml.cate_interpreter import SingleTreeCateInterpreter\n  intrp = SingleTreeCateInterpreter(include_model_uncertainty=True, max_depth=2, min_samples_leaf=10)\n  # We interpret the CATE model's behavior based on the features used for heterogeneity\n  intrp.interpret(est, X)\n  # Plot the tree\n  plt.figure(figsize=(25, 5))\n  intrp.plot(feature_names=['A', 'B', 'C', 'D'], fontsize=12)\n  plt.show()\n  ```\n  ![image](notebooks/images/dr_cate_tree.png)\n  \n</details>\n\n<details>\n  <summary>Policy Interpreter of the CATE model (click to expand)</summary>\n\n  ```Python\n  from econml.cate_interpreter import SingleTreePolicyInterpreter\n  # We find a tree-based treatment policy based on the CATE model\n  intrp = SingleTreePolicyInterpreter(risk_level=0.05, max_depth=2, min_samples_leaf=1,min_impurity_decrease=.001)\n  intrp.interpret(est, X, sample_treatment_costs=0.2)\n  # Plot the tree\n  plt.figure(figsize=(25, 5))\n  intrp.plot(feature_names=['A', 'B', 'C', 'D'], fontsize=12)\n  plt.show()\n  ```\n  ![image](notebooks/images/dr_policy_tree.png)\n\n</details>\n\n<details>\n  <summary>SHAP values for the CATE model (click to expand)</summary>\n\n  ```Python\n  import shap\n  from econml.dml import CausalForestDML\n  est = CausalForestDML()\n  est.fit(Y, T, X=X, W=W)\n  shap_values = est.shap_values(X)\n  shap.summary_plot(shap_values['Y0']['T0'])\n  ```\n\n</details>\n\n\n### Causal Model Selection and Cross-Validation\n\n\n<details>\n  <summary>Causal model selection with the `RScorer` (click to expand)</summary>\n\n  ```Python\n  from econml.score import Rscorer\n\n  # split data in train-validation\n  X_train, X_val, T_train, T_val, Y_train, Y_val = train_test_split(X, T, y, test_size=.4)\n\n  # define list of CATE estimators to select among\n  reg = lambda: RandomForestRegressor(min_samples_leaf=20)\n  clf = lambda: RandomForestClassifier(min_samples_leaf=20)\n  models = [('ldml', LinearDML(model_y=reg(), model_t=clf(), discrete_treatment=True,\n                               linear_first_stages=False, cv=3)),\n            ('xlearner', XLearner(models=reg(), cate_models=reg(), propensity_model=clf())),\n            ('dalearner', DomainAdaptationLearner(models=reg(), final_models=reg(), propensity_model=clf())),\n            ('slearner', SLearner(overall_model=reg())),\n            ('drlearner', DRLearner(model_propensity=clf(), model_regression=reg(),\n                                    model_final=reg(), cv=3)),\n            ('rlearner', NonParamDML(model_y=reg(), model_t=clf(), model_final=reg(),\n                                     discrete_treatment=True, cv=3)),\n            ('dml3dlasso', DML(model_y=reg(), model_t=clf(),\n                               model_final=LassoCV(cv=3, fit_intercept=False),\n                               discrete_treatment=True,\n                               featurizer=PolynomialFeatures(degree=3),\n                               linear_first_stages=False, cv=3))\n  ]\n\n  # fit cate models on train data\n  models = [(name, mdl.fit(Y_train, T_train, X=X_train)) for name, mdl in models]\n\n  # score cate models on validation data\n  scorer = RScorer(model_y=reg(), model_t=clf(),\n                   discrete_treatment=True, cv=3, mc_iters=2, mc_agg='median')\n  scorer.fit(Y_val, T_val, X=X_val)\n  rscore = [scorer.score(mdl) for _, mdl in models]\n  # select the best model\n  mdl, _ = scorer.best_model([mdl for _, mdl in models])\n  # create weighted ensemble model based on score performance\n  mdl, _ = scorer.ensemble([mdl for _, mdl in models])\n  ```\n\n</details>\n\n<details>\n  <summary>First Stage Model Selection (click to expand)</summary>\n\nFirst stage models can be selected either by passing in cross-validated models (e.g. `sklearn.linear_model.LassoCV`) to EconML's estimators or perform the first stage model selection outside of EconML and pass in the selected model. Unless selecting among a large set of hyperparameters, choosing first stage models externally is the preferred method due to statistical and computational advantages.\n\n```Python\nfrom econml.dml import LinearDML\nfrom sklearn import clone\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\ncv_model = GridSearchCV(\n              estimator=RandomForestRegressor(),\n              param_grid={\n                  \"max_depth\": [3, None],\n                  \"n_estimators\": (10, 30, 50, 100, 200),\n                  \"max_features\": (2, 4, 6),\n              },\n              cv=5,\n           )\n# First stage model selection within EconML\n# This is more direct, but computationally and statistically less efficient\nest = LinearDML(model_y=cv_model, model_t=cv_model)\n# First stage model selection ouside of EconML\n# This is the most efficient, but requires boilerplate code\nmodel_t = clone(cv_model).fit(W, T).best_estimator_\nmodel_y = clone(cv_model).fit(W, Y).best_estimator_\nest = LinearDML(model_y=model_t, model_t=model_y)\n```\n\n\n</details>\n\n### Inference\n\nWhenever inference is enabled, then one can get a more structure `InferenceResults` object with more elaborate inference information, such\nas p-values and z-statistics. When the CATE model is linear and parametric, then a `summary()` method is also enabled. For instance:\n\n  ```Python\n  from econml.dml import LinearDML\n  # Use defaults\n  est = LinearDML()\n  est.fit(Y, T, X=X, W=W)\n  # Get the effect inference summary, which includes the standard error, z test score, p value, and confidence interval given each sample X[i]\n  est.effect_inference(X_test).summary_frame(alpha=0.05, value=0, decimals=3)\n  # Get the population summary for the entire sample X\n  est.effect_inference(X_test).population_summary(alpha=0.1, value=0, decimals=3, tol=0.001)\n  #  Get the parameter inference summary for the final model\n  est.summary()\n  ```\n  \n  <details><summary>Example Output (click to expand)</summary>\n  \n  ```Python\n  # Get the effect inference summary, which includes the standard error, z test score, p value, and confidence interval given each sample X[i]\n  est.effect_inference(X_test).summary_frame(alpha=0.05, value=0, decimals=3)\n  ```\n  ![image](notebooks/images/summary_frame.png)\n  \n  ```Python\n  # Get the population summary for the entire sample X\n  est.effect_inference(X_test).population_summary(alpha=0.1, value=0, decimals=3, tol=0.001)\n  ```\n  ![image](notebooks/images/population_summary.png)\n  \n  ```Python\n  #  Get the parameter inference summary for the final model\n  est.summary()\n  ```\n  ![image](notebooks/images/summary.png)\n  \n  </details>\n  \n\n### Policy Learning\n\nYou can also perform direct policy learning from observational data, using the doubly robust method for offline\npolicy learning. These methods directly predict a recommended treatment, without internally fitting an explicit\nmodel of the conditional average treatment effect.\n\n<details>\n  <summary>Doubly Robust Policy Learning (click to expand)</summary>\n\n```Python\nfrom econml.policy import DRPolicyTree, DRPolicyForest\nfrom sklearn.ensemble import RandomForestRegressor\n\n# fit a single binary decision tree policy\npolicy = DRPolicyTree(max_depth=1, min_impurity_decrease=0.01, honest=True)\npolicy.fit(y, T, X=X, W=W)\n# predict the recommended treatment\nrecommended_T = policy.predict(X)\n# plot the binary decision tree\nplt.figure(figsize=(10,5))\npolicy.plot()\n# get feature importances\nimportances = policy.feature_importances_\n\n# fit a binary decision forest\npolicy = DRPolicyForest(max_depth=1, min_impurity_decrease=0.01, honest=True)\npolicy.fit(y, T, X=X, W=W)\n# predict the recommended treatment\nrecommended_T = policy.predict(X)\n# plot the first tree in the ensemble\nplt.figure(figsize=(10,5))\npolicy.plot(0)\n# get feature importances\nimportances = policy.feature_importances_\n```\n\n\n  ![image](images/policy_tree.png)\n</details>\n\nTo see more complex examples, go to the [notebooks](https://github.com/Microsoft/EconML/tree/master/notebooks) section of the repository. For a more detailed description of the treatment effect estimation algorithms, see the EconML [documentation](https://econml.azurewebsites.net/).\n\n# For Developers\n\nYou can get started by cloning this repository. We use \n[setuptools](https://setuptools.readthedocs.io/en/latest/index.html) for building and distributing our package.\nWe rely on some recent features of setuptools, so make sure to upgrade to a recent version with\n`pip install setuptools --upgrade`.  Then from your local copy of the repository you can run `python setup.py develop` to get started.\n\n## Running the tests\n\nThis project uses [pytest](https://docs.pytest.org/) for testing.  To run tests locally after installing the package, \nyou can use `python setup.py pytest`.\n\n## Generating the documentation\n\nThis project's documentation is generated via [Sphinx](https://www.sphinx-doc.org/en/master/index.html).  Note that we use [graphviz](https://graphviz.org/)'s \n`dot` application to produce some of the images in our documentation, so you should make sure that `dot` is installed and in your path.\n\nTo generate a local copy of the documentation from a clone of this repository, just run `python setup.py build_sphinx -W -E -a`, which will build the documentation and place it under the `build/sphinx/html` path. \n\nThe reStructuredText files that make up the documentation are stored in the [docs directory](https://github.com/Microsoft/EconML/tree/master/doc); module documentation is automatically generated by the Sphinx build process.\n\n# Blogs and Publications\n\n* June 2019: [Treatment Effects with Instruments paper](https://arxiv.org/pdf/1905.10176.pdf)\n\n* May 2019: [Open Data Science Conference Workshop](https://odsc.com/speakers/machine-learning-estimation-of-heterogeneous-treatment-effect-the-microsoft-econml-library/) \n\n* 2018: [Orthogonal Random Forests paper](http://proceedings.mlr.press/v97/oprescu19a.html)\n\n* 2017: [DeepIV paper](http://proceedings.mlr.press/v70/hartford17a/hartford17a.pdf)\n\n# Citation\n\nIf you use EconML in your research, please cite us as follows:\n\n   Microsoft Research. **EconML: A Python Package for ML-Based Heterogeneous Treatment Effects Estimation.** https://github.com/microsoft/EconML, 2019. Version 0.x.\n\nBibTex:\n\n```\n@misc{econml,\n  author={Microsoft Research},\n  title={{EconML}: {A Python Package for ML-Based Heterogeneous Treatment Effects Estimation}},\n  howpublished={https://github.com/microsoft/EconML},\n  note={Version 0.x},\n  year={2019}\n}\n```\n\n# Contributing and Feedback\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# References\n\nAthey, Susan, and Stefan Wager.\n**Policy learning with observational data.**\nEconometrica 89.1 (2021): 133-161.\n\nX Nie, S Wager.\n**Quasi-Oracle Estimation of Heterogeneous Treatment Effects.**\n[*Biometrika*](https://doi.org/10.1093/biomet/asaa076), 2020\n\nV. Syrgkanis, V. Lei, M. Oprescu, M. Hei, K. Battocchi, G. Lewis.\n**Machine Learning Estimation of Heterogeneous Treatment Effects with Instruments.**\n[*Proceedings of the 33rd Conference on Neural Information Processing Systems (NeurIPS)*](https://arxiv.org/abs/1905.10176), 2019\n**(Spotlight Presentation)**\n\nD. Foster, V. Syrgkanis.\n**Orthogonal Statistical Learning.**\n[*Proceedings of the 32nd Annual Conference on Learning Theory (COLT)*](https://arxiv.org/pdf/1901.09036.pdf), 2019\n**(Best Paper Award)**\n\nM. Oprescu, V. Syrgkanis and Z. S. Wu.\n**Orthogonal Random Forest for Causal Inference.**\n[*Proceedings of the 36th International Conference on Machine Learning (ICML)*](http://proceedings.mlr.press/v97/oprescu19a.html), 2019.\n\nS. K\u00fcnzel, J. Sekhon, J. Bickel and B. Yu.\n**Metalearners for estimating heterogeneous treatment effects using machine learning.**\n[*Proceedings of the national academy of sciences, 116(10), 4156-4165*](https://www.pnas.org/content/116/10/4156), 2019.\n\nS. Athey, J. Tibshirani, S. Wager.\n**Generalized random forests.**\n[*Annals of Statistics, 47, no. 2, 1148--1178*](https://projecteuclid.org/euclid.aos/1547197251), 2019.\n\nV. Chernozhukov, D. Nekipelov, V. Semenova, V. Syrgkanis.\n**Plug-in Regularized Estimation of High-Dimensional Parameters in Nonlinear Semiparametric Models.**\n[*Arxiv preprint arxiv:1806.04823*](https://arxiv.org/abs/1806.04823), 2018.\n\nS. Wager, S. Athey.\n**Estimation and Inference of Heterogeneous Treatment Effects using Random Forests.**\n[*Journal of the American Statistical Association, 113:523, 1228-1242*](https://www.tandfonline.com/doi/citedby/10.1080/01621459.2017.1319839), 2018.\n\nJason Hartford, Greg Lewis, Kevin Leyton-Brown, and Matt Taddy. **Deep IV: A flexible approach for counterfactual prediction.** [*Proceedings of the 34th International Conference on Machine Learning, ICML'17*](http://proceedings.mlr.press/v70/hartford17a/hartford17a.pdf), 2017.\n\nV. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, and a. W. Newey. **Double Machine Learning for Treatment and Causal Parameters.** [*ArXiv preprint arXiv:1608.00060*](https://arxiv.org/abs/1608.00060), 2016.\n\nDudik, M., Erhan, D., Langford, J., & Li, L.\n**Doubly robust policy evaluation and optimization.**\nStatistical Science, 29(4), 485-511, 2014."
 },
 {
  "repo": "microsoft/Workbooks-Localization",
  "language": null,
  "readme_contents": "Localization files for Application-Insights-Workbooks\n"
 },
 {
  "repo": "microsoft/MLOS",
  "language": "HTML",
  "readme_contents": "[![codecov](https://codecov.io/gh/microsoft/MLOS/branch/main/graph/badge.svg?token=14T6RFL2KR)](https://codecov.io/gh/microsoft/MLOS)\n\n# MLOS: Machine Learning Optimized Systems\n\n## MLOS: An Infrastructure for Automated Software Performance Engineering\n\n> MLOS is an ML-powered infrastructure and methodology to democratize and automate Performance Engineering. MLOS enables continuous, instance-based, robust, and trackable systems optimization.\n\nFrom the [MLOS paper at DEEM 2020](https://arxiv.org/abs/2006.02155)\n\n## Overview\n\n### Problem\n\nAll systems software (e.g. SqlServer, MySQL, LevelDB, OpenSSL, etc.) is full of parameter choices.\n\nSometimes these are encoded in the software as constants embedded in the code (e.g. choice of abstract data structure implementation, buffer limit size or alignment, etc.).\nOther times they may be exposed as configuration parameters either at startup or runtime.\n\nCareful selection of these parameters can yield dramatic performance differences for different _contexts_ of a system (e.g. different workloads, hardware, etc.).\nNote that _performance_ can be interpreted in different ways (e.g. reducing average/variability of latency/memory, increasing throughput, decreasing MTTR, etc.)\n\nGenerally speaking, this process is referred to as *Software Performance Engineering*, and typically involves a lot of manual effort that is brittle and not well tracked.\n\n### Goals\n\nMLOS is about using machine-learning and data-science to optimize systems for a given context through these tunable choices.\n\n![MLOS data science experience for software performance engineering](./documentation/images/MLOS-Experience.png)\n\nRoughly, this can happen in two modes:\n\n1. Offline (e.g. at development time)\n\n    In this case, developers can use (micro)benchmarks to explore a parameter space for a component either interactively or with a background CI/CD pipeline and then interact with that data through a notebook experience to select the right value to check in to the code, along with the results of the experiments and analysis, all encoded in the notebook.\n\n2. Online (e.g. at runtime)\n\n    In this case a system component provides hooks to adjust its parameters at runtime and exports data about its current state/performance.  These can be combined with additional contextual information from the system to build a model (or simple heuristics) to invoke the hooks to adjust the component to improve performance at runtime.\n\n### Architecture\n\n![MLOS architecture overview](./documentation/images/MLOS-Architecture.png)\n\nTo achieve this MLOS provides:\n\n1. *Code Annotations* to help describe additional *settings metadata* for tunables (a.k.a. `Settings`).\n\n    For instance, metadata can include things like constraints on acceptable values a Setting can take on as well as developer intuition to help guide the automated search process.\n\n    Currently these are implemented as C# Attributes to provide reflection and easy cross-platform and cross-compiler support for C++ projects.\n\n2. *Code Generation* tools to use that metadata to expose those settings to different target systems/languages (e.g. Python Notebooks, C++, C#, etc.)\n\n    For instance, we generate efficient messages over shared memory communication channels for\n\n    1. exporting data about the component using that Setting\n\n        For instance, this may include performance statistics, workload traces, etc.\n\n    2. receiving feedback (e.g. to change the Setting's value)\n\n        This may involve a reconfiguration step or simply update a cache for the next instantiation to read.\n\n3. An external agent (`Mlos.Agent.Server`) which can consume the information exported by the target system (e.g. SqlServer, MySQL, LevelDB, etc.) with mimimal impact on the target system.\n\n    The external agent can perform workload summarization, binning, cataloging, model inference, heuristic invocation, etc. based on the events exposed by the target system to then influence it.\n\n    Once hooks are created in the target system, iteration on the external agent can be more rapidly developed and deployed.\n\n## Python Quickstart\n\nThe easiest way to get started with MLOS is to just the Python package.\nYou can find installation instructions in the [Prerequisites: Python Quickstart](./documentation/01-Prerequisites.md#python-quickstart).\n\n## Full Build (C# and C++ components)\n\nMLOS supports Windows and Linux build environments.\n\nFor detailed instructions, please refer to:\n\n  1. [Prerequisites](./documentation/01-Prerequisites.md)\n  2. [Build](./documentation/02-Build.md)\n\n## Examples\n\nCode and documentation for examples of using MLOS to optimize a system are described in the [Notebooks](https://microsoft.github.io/MLOS/notebooks/) section.\nAdditional code is in the  [source/Examples](./source/Examples/#mlos-github-tree-view) source directory.\nYou can find the source of the notebooks [on github as well](./source/Mlos.Notebooks/#mlos-github-tree-view).\n\n> Some of the notebooks have been used as lab assignments for a seminar class run in collaboration between Microsoft and UW-Madison:\n> <https://aka.ms/MLOS_Seminar>\n\n## Documentation\n\n- Additional overview documentation is available in the [documentation](./documentation/) tree.\n\n- Individual components may also include more detailed documentation in their respective subdirectories.\n\n## Contributing\n\nWe welcome contributions!  Please see [Contributing](./CONTRIBUTING.md) and [Code of Conduct](./CODE_OF_CONDUCT.md) for details.\n\nAlso, please see the [Roadmap](#) of planned features.\n\n## Contact\n\nFor more formal enquiries, you can [contact us](mailto:mlos-maintainers@service.microsoft.com).\n\n## License\n\n- [MIT License](./LICENSE.txt)\n"
 },
 {
  "repo": "microsoft/vscode-cmake-tools",
  "language": "TypeScript",
  "readme_contents": "# CMake Tools\n\n[CMake Tools](https://marketplace.visualstudio.com/items?itemName=ms-vscode.cmake-tools) provides the native developer a full-featured, convenient, and powerful workflow for CMake-based projects in Visual Studio Code.\n\n## Important doc links\n\n- [CMake Tools quick start](https://code.visualstudio.com/docs/cpp/CMake-linux)\n- [Configure and build a project with CMake Presets](docs/cmake-presets.md)\n- [Configure a project with kits and variants](docs/how-to.md#configure-a-project)\n- [Build a project with kits and variants](docs/how-to.md#build-a-project)\n- [Debug a project](docs/how-to.md#debug-a-project)\n- [Configure CMake Tools settings](docs/cmake-settings.md)\n- [How to](docs/how-to.md)\n- [FAQ](docs/faq.md)\n- [Read the online documentation](docs/README.md)\n- [Contribute](docs/contribute.md)\n\n## Issues? Questions? Feature requests?\n\n**PLEASE**, if you experience any problems, have any questions, or have an idea\nfor a new feature, create an issue on [the GitHub page](https://github.com/microsoft/vscode-cmake-tools)!\n\nThis extension itself *does not* provide language support for the CMake\nscripting language. For that we recommend [this extension](https://marketplace.visualstudio.com/items?itemName=twxs.cmake).\n\n### Microsoft Open Source Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact opencode@microsoft.com with any additional questions or comments.\n\n### Data/Telemetry\n\nThis extension collects usage data and sends it to Microsoft to help improve our products and services. Collection of telemetry is controlled via the same setting provided by Visual Studio Code: `\"telemetry.enableTelemetry\"`. Read our [privacy statement](https://privacy.microsoft.com/en-us/privacystatement) to learn more.\n\n### Credits\n\nThis project was started by [@vector-of-bool](https://github.com/vector-of-bool) and is now currently maintained by Microsoft.\n"
 },
 {
  "repo": "microsoft/vscode-typescript-next",
  "language": "JavaScript",
  "readme_contents": "# JavaScript and TypeScript Nightly\r\n\r\nVS Code extension that enables the nightly build of TypeScript (`typescript@next`) as VS Code's built-in TypeScript version used to power JavaScript and TypeScript IntelliSense.\r\n\r\n## Enabling\r\nThis extension replaces VS Code's built-in TypeScript version with `typescript@next`. It does not affect workspace versions of TypeScript, or custom user `typescript.tsdk` settings.\r\n\r\nTo make sure you are using `typescript@next`:\r\n\r\n1. Open a JavaScript or TypeScript file in VS Code.\r\n1. In the VS Code command palette, run the `TypeScript: Select TypeScript version` command.\r\n1. Make sure you have `Use VS Code's version selected`\r\n\r\nNote that this extension also includes the [latest JavaScript and TypeScript grammar](https://github.com/microsoft/TypeScript-TmLanguage).\r\n"
 },
 {
  "repo": "microsoft/Azure-Analytics-and-AI-Engagement",
  "language": "Jupyter Notebook",
  "readme_contents": "# Setting the scene\n\nThe intent of Data and AI Engagement Accelerators for PoC is to provide a conceptual starting point for our sellers, using our industry scenario differentiator demos, to gain customer confidence in the feasibility of a Microsoft solution. \n\nThe Data and AI Engagement Accelerators for PoC will leverage our new and existing industry scenario demos to create packaged content (including Azure resource management templates, code, sample data etc.) that sellers can easily deploy and quickly configure on the customer\u2019s Azure subscription and then modify using the customer\u2019s sample data from which the customer can begin to build their own solution.\n\nIndustries these days have multiple business, they have multiple factories and multiple subsidiaries, it is important to keep a track of what is happening in each subsidiary through Power BI Analytics. The use of analytics has the potential to unlock how industries understand the story of their factories, ***the people, the machines, and the financials in the past, present and future***. An insight into the above can give us a sneak peek to two different scenarios at the same time.\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/etcd3",
  "language": "TypeScript",
  "readme_contents": "# etcd3 [![Run Tests](https://github.com/microsoft/etcd3/workflows/Run%20Tests/badge.svg)](https://github.com/microsoft/etcd3/actions?query=workflow%3A%22Run+Tests%22)\n\netcd3 is a high-quality, production-ready client for the Protocol Buffer-based [etcd](https://etcd.io/) v3 API. It includes:\n\n- [load balancing](https://microsoft.github.io/etcd3/interfaces/ioptions.html)\n- [fault handling and reconnections](https://microsoft.github.io/etcd3/interfaces/ioptions.html#faulthandling)\n- [transactions](https://microsoft.github.io/etcd3/classes/comparatorbuilder.html)\n- [software transactional memory](https://microsoft.github.io/etcd3/classes/softwaretransaction.html)\n- [high-level query builders](https://microsoft.github.io/etcd3/classes/etcd3.html)\n- [lease management](https://microsoft.github.io/etcd3/classes/lease.html)\n- [watchers](https://microsoft.github.io/etcd3/classes/watchbuilder.html)\n- [user](https://microsoft.github.io/etcd3/classes/etcd3.html#user) and [role](https://microsoft.github.io/etcd3/classes/etcd3.html#role) [mocking](https://microsoft.github.io/etcd3/classes/etcd3.html#mock) management\n- [elections](https://microsoft.github.io/etcd3/classes/election.html)\n\nand is type-safe for TypeScript consumers.\n\n### Quickstart\n\nInstall via:\n\n```\nnpm install --save etcd3\n```\n\nStart building!\n\n```js\nconst { Etcd3 } = require('etcd3');\nconst client = new Etcd3();\n\n(async () => {\n  await client.put('foo').value('bar');\n\n  const fooValue = await client.get('foo').string();\n  console.log('foo was:', fooValue);\n\n  const allFValues = await client.getAll().prefix('f').keys();\n  console.log('all our keys starting with \"f\":', allFValues);\n\n  await client.delete().all();\n})();\n```\n\n### API Documentation\n\nOur [TypeDoc docs are available here](https://microsoft.github.io/etcd3/classes/etcd3.html).\n\nOur [test cases](https://github.com/microsoft/etcd3/tree/master/src/test/) are also readable.\n\n### Running tests\n\n```sh\n$ npm install\n$ cd src/test/containers/3.2 && docker-compose up # in a separate shell\n$ npm test\n$ docker-compose down\n```\n\n### Contributing\n\nRunning tests for this module requires running an etcd3 server locally. The tests try to use the default port initially, and you can configure this by setting the `ETCD_ADDR` environment variable, like `export ETCD_ADDR=localhost:12345`.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/node-pty",
  "language": "TypeScript",
  "readme_contents": "# node-pty\n\n[![Build Status](https://dev.azure.com/vscode/node-pty/_apis/build/status/Microsoft.node-pty)](https://dev.azure.com/vscode/node-pty/_build/latest?definitionId=11)\n\n`forkpty(3)` bindings for node.js. This allows you to fork processes with pseudoterminal file descriptors. It returns a terminal object which allows reads and writes.\n\nThis is useful for:\n\n- Writing a terminal emulator (eg. via [xterm.js](https://github.com/sourcelair/xterm.js)).\n- Getting certain programs to *think* you're a terminal, such as when you need a program to send you control sequences.\n\n`node-pty` supports Linux, macOS and Windows. Windows support is possible by utilizing the [Windows conpty API](https://blogs.msdn.microsoft.com/commandline/2018/08/02/windows-command-line-introducing-the-windows-pseudo-console-conpty/) on Windows 1809+ and the [winpty](https://github.com/rprichard/winpty) library in older version.\n\n## API\n\nThe full API for node-pty is contained within the [TypeScript declaration file](https://github.com/microsoft/node-pty/blob/main/typings/node-pty.d.ts), use the branch/tag picker in GitHub (`w`) to navigate to the correct version of the API.\n\n## Example Usage\n\n```js\nvar os = require('os');\nvar pty = require('node-pty');\n\nvar shell = os.platform() === 'win32' ? 'powershell.exe' : 'bash';\n\nvar ptyProcess = pty.spawn(shell, [], {\n  name: 'xterm-color',\n  cols: 80,\n  rows: 30,\n  cwd: process.env.HOME,\n  env: process.env\n});\n\nptyProcess.on('data', function(data) {\n  process.stdout.write(data);\n});\n\nptyProcess.write('ls\\r');\nptyProcess.resize(100, 40);\nptyProcess.write('ls\\r');\n```\n\n## Real-world Uses\n\n`node-pty` powers many different terminal emulators, including:\n\n- [Microsoft Visual Studio Code](https://code.visualstudio.com)\n- [Hyper](https://hyper.is/)\n- [Upterm](https://github.com/railsware/upterm)\n- [Script Runner](https://github.com/ioquatix/script-runner) for Atom.\n- [Theia](https://github.com/theia-ide/theia)\n- [FreeMAN](https://github.com/matthew-matvei/freeman) file manager\n- [terminus](https://atom.io/packages/terminus) - An Atom plugin for providing terminals inside your Atom workspace.\n- [x-terminal](https://atom.io/packages/x-terminal) - Also an Atom plugin that provides terminals inside your Atom workspace.\n- [Termination](https://atom.io/packages/termination) - Also an Atom plugin that provides terminals inside your Atom workspace.\n- [atom-xterm](https://atom.io/packages/atom-xterm) - Also an Atom plugin that provides terminals inside your Atom workspace.\n- [electerm](https://github.com/electerm/electerm) Terminal/SSH/SFTP client(Linux, macOS, Windows).\n- [Extraterm](http://extraterm.org/)\n- [Wetty](https://github.com/krishnasrinivas/wetty) Browser based Terminal over HTTP and HTTPS\n- [nomad](https://github.com/lukebarnard1/nomad-term)\n- [DockerStacks](https://github.com/sfx101/docker-stacks) Local LAMP/LEMP stack using Docker\n- [TeleType](https://github.com/akshaykmr/TeleType): cli tool that allows you to share your terminal online conveniently. Show off mad cli-fu, help a colleague, teach, or troubleshoot.\n- [mesos-term](https://github.com/criteo/mesos-term): A web terminal for Apache Mesos. It allows to execute commands within containers.\n- [Commas](https://github.com/CyanSalt/commas): A hackable terminal and command runner.\n- [ENiGMA\u00bd BBS Software](https://github.com/NuSkooler/enigma-bbs): A modern BBS software with a nostalgic flair!\n- [Tinkerun](https://github.com/tinkerun/tinkerun): A new way of running Tinker.\n\nDo you use node-pty in your application as well? Please open a [Pull Request](https://github.com/Tyriar/node-pty/pulls) to include it here. We would love to have it in our list.\n\n## Building\n\n```bash\n# Install dependencies and build C++\nnpm install\n# Compile TypeScript -> JavaScript\nnpm run build\n```\n\n## Dependencies\n\nNode.JS 12+ or Electron 8+ is required to use `node-pty`.\n\n### Linux (apt)\n\n```sh\nsudo apt install -y make python build-essential\n```\n\n### macOS\n\nXcode is needed to compile the sources, this can be installed from the App Store.\n\n### Windows\n\n`npm install` requires some tools to be present in the system like Python and C++ compiler. Windows users can easily install them by running the following command in PowerShell as administrator. For more information see https://github.com/felixrieseberg/windows-build-tools:\n\n```sh\nnpm install --global --production windows-build-tools\n```\n\nThe following are also needed:\n\n- [Windows SDK](https://developer.microsoft.com/en-us/windows/downloads/windows-10-sdk) - only the \"Desktop C++ Apps\" components are needed to be installed\n\n## Debugging\n\n[The wiki](https://github.com/Microsoft/node-pty/wiki/Debugging) contains instructions for debugging node-pty.\n\n## Security\n\nAll processes launched from node-pty will launch at the same permission level of the parent process. Take care particularly when using node-pty inside a server that's accessible on the internet. We recommend launching the pty inside a container to protect your host machine.\n\n## Thread Safety\n\nNote that node-pty is not thread safe so running it across multiple worker threads in node.js could cause issues.\n\n## Flow Control\n\nAutomatic flow control can be enabled by either providing `handleFlowControl = true` in the constructor options or setting it later on:\n\n```js\nconst PAUSE = '\\x13';   // XOFF\nconst RESUME = '\\x11';  // XON\n\nconst ptyProcess = pty.spawn(shell, [], {handleFlowControl: true});\n\n// flow control in action\nptyProcess.write(PAUSE);  // pty will block and pause the child program\n...\nptyProcess.write(RESUME); // pty will enter flow mode and resume the child program\n\n// temporarily disable/re-enable flow control\nptyProcess.handleFlowControl = false;\n...\nptyProcess.handleFlowControl = true;\n```\n\nBy default `PAUSE` and `RESUME` are XON/XOFF control codes (as shown above). To avoid conflicts in environments that use these control codes for different purposes the messages can be customized as `flowControlPause: string` and `flowControlResume: string` in the constructor options. `PAUSE` and `RESUME` are not passed to the underlying pseudoterminal if flow control is enabled.\n\n## Troubleshooting\n\n### Powershell gives error 8009001d\n\n> Internal Windows PowerShell error.  Loading managed Windows PowerShell failed with error 8009001d.\n\nThis happens when PowerShell is launched with no `SystemRoot` environment variable present.\n\n### ConnectNamedPipe failed: Windows error 232\n\nThis error can occur due to anti-virus software intercepting winpty from creating a pty. To workaround this you can exclude this file from your anti-virus scanning `node-pty\\build\\Release\\winpty-agent.exe`\n\n## pty.js\n\nThis project is forked from [chjj/pty.js](https://github.com/chjj/pty.js) with the primary goals being to provide better support for later Node.JS versions and Windows.\n\n## License\n\nCopyright (c) 2012-2015, Christopher Jeffrey (MIT License).<br>\nCopyright (c) 2016, Daniel Imms (MIT License).<br>\nCopyright (c) 2018, Microsoft Corporation (MIT License).\n"
 },
 {
  "repo": "microsoft/moab",
  "language": "SCSS",
  "readme_contents": "# Project Moab microsite\n\nLocation for the Project Moab assets, tutorial, documentation and HTML\ncontent.\n\n### Installation\n```shell\nnpm install\n```\n\n### Develop\n\nStarts a local server.  This will start a 11ty server and auto reload on changes.\n\n```shell\nnpm run start\n```\n\n\n### Deploy\n\nBuilds and commits to gh-pages branch.\n\n```shell\nnpm run deploy\n```\n"
 },
 {
  "repo": "microsoft/MentalHealthPlatform",
  "language": "TypeScript",
  "readme_contents": "This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Project Setup\n\nTo set up and run the application, please follow the procedures outlined in the following subsections:\n\n## Setting up the local project\n\n1. Clone the repository to your local machine:\n\n   ```\n   git clone https://github.com/Microsoft/MentalHealthPlatform.git\n   ```\n\n2. Download and install Node.js onto your development machine from\nhttps://nodejs.org/.\n\n3. Check whether the installation of Node was successful by running the following command; a version number should be printed:\n   \n   ```\n   node -v\n   ```\n\n4. Download and install Yarn on your development machine from https://yarnpkg.com/lang/en/docs/install/.\n\n5. Similar to that of the installation of Node.js, check whether the installation of Yarn was successful by running the following command; a version number should be printed:\n   \n   ```\n   yarn -v\n   ```\n\n## Setting up the database\n\n1.  Download and install MongoDB from the MongoDB website:\n  \n    https://docs.mongodb.com/manual/installation/\n\n2. If using a Windows machine, one may need to add mongo to the environment variables. The instructions regarding the addition of environment variables can be found in the Microsoft Docs article for installing and configuring MongoDB:\n\n    https://docs.microsoft.com/en-us/azure/virtual-machines/windows/install-mongodb\n\n3. Create a directory to store the data.\n\n    ```\n    mkdir <path>\n    ```\n\n4. Set the path for storing the data: \n\n    ```\n    mongod --dbpath /data/<path>\n    ```\n5. Run the service using the following command:\n\n    ```\n    brew services start mongodb-community@4.2\n    ```\n\n6.  After installing MongoDB, launch the MongoDB terminal by using the following command:\n  \n    ```\n    mongo\n    ```\n\n7.  To add sample data, enter the commands listed in the **\"docs/database_ commands.txt\"** file of this repository\n\n## Setting up the server\n\n1.  In the cloned project, navigate to the **server** directory:\n\n    ```\n    cd server\n    ```\n\n2.  Install the dependencies:\n\n    ```\n    yarn\n    ```\n\n3.  Run the server:\n\n    ```\n    yarn start\n    ```\n    \n    The console should then print a statement about the server running on a certain port:\n\n    > Server is running on Port 3000...\n\n## Setting up the client\n\n1.  In the cloned project, navigate to the **client** directory:\n\n    ```\n    cd client\n    ```\n\n2.  Install all dependencies:\n\n    ```\n    yarn\n    ```\n\n## Running the project\n\n1.  Run the client:\n\n    ```\n    yarn start\n    ```\n\n    The console should then print a statement with a URL in which the application is running.\n\n    For example:\n\n    > Project is running at http://localhost:8080/\n\n2.  Launch the application in a web browser by navigating to the URL printed by the console\n\n# Pages\n\n## Dashboard (Home) Page\n\n![Topics page](./docs/screenshots/dashboard.png)\n\n## Topics Page\n\n![Topics page](./docs/screenshots/topics.png)\n\n## Forum Page\n\n![Forum page](./docs/screenshots/forum.png)\n\n## Chat Page\n\n![Chat page](./docs/screenshots/chat.png)\n\n## Contacts Page\n\n![Contacts page](./docs/screenshots/contacts.png)\n\n## Events Page\n\n![Events page](./docs/screenshots/events.png)\n\n## News Page\n\n![Events page](./docs/screenshots/news.png)\n\n## Therapists Page\n\n![Events page](./docs/screenshots/therapists.png)\n\n## Crisis Page\n\n![Crisis page](./docs/screenshots/crisis.png)"
 },
 {
  "repo": "microsoft/appcenter-cli",
  "language": "JavaScript",
  "readme_contents": "# App Center Command Line Interface (CLI)\n\nVisual Studio App Center command line interface (CLI) is a unified tool for running App Center services from the command line.\nOur aim is to offer a concise and powerful tool for our developers to use App Center services and easily script a sequence of\ncommands that they'd like to execute. You can currently login and view/configure all the apps that you have access to in App Center.\n\n## Prerequisites\n\nThe recommended Node.js version is 12 or higher.\n\n## Installation\n\n```\nnpm install -g appcenter-cli\n```\n\nOnce installed, use the `appcenter` command. See below for the available commands.\n\n## Getting Help\n\nTo get a top level list of the available commands, run `appcenter help`.\n\nTo get help on a specific command or category, run `appcenter help command` or pass the `-h` flag to any command or category name.\n\nApp Center provides SDK support directly within the App Center portal. Any time you need help, just sign in to [App Center](https://appcenter.ms), then choose **'Contact support'** inside the help menu on the upper right of the App Center portal and our dedicated support team will respond to your questions and feedback. \n\n## Commands\n\nBelow is the list of commands currently supported by Visual Studio App Center CLI:\n\n| Command                               | Description                                                    |\n| ------------------------------------- | -------------------------------------------------------------- |\n| `appcenter help` | Get help using appcenter commands |\n| `appcenter login` | Log in |\n| `appcenter logout` | Log out |\n| `appcenter setup-autocomplete` | Setup tab completion for your shell |\n| | |\n| `appcenter analytics app-versions` | Shows versions of the application |\n| `appcenter analytics audience` | Show audience statistics |\n| `appcenter analytics log-flow` | Command to see the incoming logs in real time |\n| `appcenter analytics sessions` | Show statistics for sessions |\n| `appcenter analytics events delete` | Delete event |\n| `appcenter analytics events show` | Show statistics for events |\n| | |\n| `appcenter apps create` | Create a new app |\n| `appcenter apps delete` | Delete an app |\n| `appcenter apps get-current` | Get the application that's set as default for all CLI commands |\n| `appcenter apps list` | Get list of configured applications |\n| `appcenter apps set-current` | Set default application for all CLI commands. Not compatible when authenticating with '--token' or an environment variable. Use environment variable 'MOBILE_CENTER_CURRENT_APP' to set the default app instead |\n| `appcenter apps show` | Get the details of an app |\n| `appcenter apps update` | Update an app |\n| | |\n| `appcenter build download` | Download the binary, logs or symbols for a completed build |\n| `appcenter build logs` | Displays log for build |\n| `appcenter build queue` | Queue a new build |\n| `appcenter build branches list` | Show list of branches |\n| `appcenter build branches show` | Show branch build status |\n| | |\n| `appcenter codepush patch` | Update the metadata for an existing CodePush release |\n| `appcenter codepush promote` | Create a new release for the destination deployment, which includes the exact code and metadata from the latest release of the source deployment |\n| `appcenter codepush release-cordova` | Release a Cordova update to an app deployment |\n| `appcenter codepush release-electron` | Release an Electron update to a deployment |\n| `appcenter codepush release-react` | Release a React Native update to an app deployment |\n| `appcenter codepush release` | Release an update to an app deployment |\n| `appcenter codepush rollback` | Rollback a deployment to a previous release |\n| `appcenter codepush deployment add` | Add a new deployment to an app |\n| `appcenter codepush deployment clear` | Clear the release history associated with a deployment |\n| `appcenter codepush deployment history` | Display the release history for a CodePush deployment |\n| `appcenter codepush deployment list` | List the deployments associated with an app |\n| `appcenter codepush deployment remove` | Remove CodePush deployment |\n| `appcenter codepush deployment rename` | Rename CodePush deployment |\n| | |\n| `appcenter crashes upload-mappings` | Upload the Android mappings for the application |\n| `appcenter crashes upload-missing-symbols` | Upload missing crash symbols for the application (only from macOS) |\n| `appcenter crashes upload-symbols` | Upload the crash symbols for the application |\n| | |\n| `appcenter distribute release` | Upload release binary and trigger distribution, at least one of --store or --group must be specified |\n| `appcenter distribute groups create` | Create new distribution group |\n| `appcenter distribute groups delete` | Deletes the distribution group |\n| `appcenter distribute groups download` | Download release package for the distribution group |\n| `appcenter distribute groups list` | Lists all distribution groups of the app |\n| `appcenter distribute groups publish` | Publish an app file to a group |\n| `appcenter distribute groups show` | Shows information about the distribution group |\n| `appcenter distribute groups update` | Update existing distribution group |\n| `appcenter distribute releases add-destination` | Distribute an existing release to an additional destination |\n| `appcenter distribute releases delete` | Deletes the release |\n| `appcenter distribute releases edit-notes` | Update release notes |\n| `appcenter distribute releases edit` | Toggles enabling and disabling the specified release |\n| `appcenter distribute releases list` | Shows the list of all releases for the application |\n| `appcenter distribute releases show` | Shows full details about release |\n| `appcenter distribute stores list` | Lists all stores of the app |\n| `appcenter distribute stores publish` | Publish an app file to a store |\n| | |\n| `appcenter orgs create` | Create a new organization |\n| `appcenter orgs list` | Lists organizations in which current user is collaborator |\n| `appcenter orgs show` | Show information about organization |\n| `appcenter orgs update` | Update organization information |\n| `appcenter orgs apps create` | Create a new app in an organization |\n| `appcenter orgs apps list` | Lists applications of organization |\n| `appcenter orgs collaborators list` | Lists collaborators of organization |\n| `appcenter orgs collaborators update` | Update list of organization collaborators |\n| | |\n| `appcenter profile list` | Get information about logged in user |\n| `appcenter profile update` | Update user information |\n| | |\n| `appcenter telemetry off` | Turn off the sending of telemetry |\n| `appcenter telemetry on` | Turn on the sending of telemetry |\n| | |\n| `appcenter test download` | Download the report artifacts, unpack and merge them. This command is only available for UITest and Appium test runs |\n| `appcenter test status` | Checks the status of the started test run |\n| `appcenter test stop` | Stop the started test run |\n| `appcenter test wizard` | Start a test run interactively. All the parameters will be prompted on-the-go |\n| `appcenter test generate appium` | Generates an Appium project |\n| `appcenter test generate uitest` | Generates a Xamarin.UITest project |\n| `appcenter test prepare appium` | Creates an artifacts directory with Appium tests |\n| `appcenter test prepare calabash` | Creates an artifacts directory with Calabash tests |\n| `appcenter test prepare espresso` | Creates an artifacts directory with Espresso tests |\n| `appcenter test prepare uitest` | Creates an artifacts directory with Xamarin UI Tests |\n| `appcenter test prepare xcuitest` | Creates an artifacts directory with XCUITest tests |\n| `appcenter test run appium` | Starts a test run with Appium tests |\n| `appcenter test run calabash` | Starts a test run with Calabash tests |\n| `appcenter test run espresso` | Starts a test run with Espresso tests |\n| `appcenter test run manifest` | Starts a test run with previously prepared artifacts |\n| `appcenter test run uitest` | Starts a test run with Xamarin UI Tests |\n| `appcenter test run xcuitest` | Starts a test run with XCUITest tests |\n| | |\n| `appcenter tokens create` | Create a new API token |\n| `appcenter tokens delete` | Delete an API token |\n| `appcenter tokens list` | Get a list of API tokens |\n\nPlease use the `appcenter help` command to get more information about each one.\n\n## Contributing\n\nPlease see the [contributing](./contributing.md) file\nfor an introduction to the codebase and what the various moving parts are.\n\n## Known issues\n\nCheck out [known issues](./KNOWN_ISSUES.md) for a list of known issues, and potential workarounds.\n\n## Security\n\nCheck out [SECURITY.md](SECURITY.md) for any security concern with this project.\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact opencode@microsoft.com with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/pai",
  "language": "JavaScript",
  "readme_contents": "# Open Platform for AI (OpenPAI) ![alt text][logo]\n\n[logo]: ./pailogo.jpg \"OpenPAI\"\n\n[![Build Status](https://openpai.visualstudio.com/OpenPAI/_apis/build/status/OpenPAI-nightly-build?branchName=master)](https://openpai.visualstudio.com/OpenPAI/_build/latest?definitionId=25&branchName=master)\n[![Join the chat at https://gitter.im/Microsoft/pai](https://badges.gitter.im/Microsoft/pai.svg)](https://gitter.im/Microsoft/pai?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Version](https://img.shields.io/github/release/Microsoft/pai.svg)](https://github.com/Microsoft/pai/releases/latest)\n\n**OpenPAI [v1.7.0](./RELEASE_NOTE.md#April-2021-version-170) has been released!**\n\nWith the release of v1.0, OpenPAI is switching to a more robust, more powerful and lightweight architecture. OpenPAI is also becoming more and more modular so that the platform can be easily customized and expanded to suit new needs. OpenPAI also provides many AI user-friendly features, making it easier for end users and administrators to complete daily AI tasks.\n\n <table>\n   <tr>\n      <td align=\"center\">\n        <span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>\n        <br/>\n        <a href=\"https://github.com/microsoft/openpaimarketplace\" target=\"_blank\">\n          <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture1.svg\" width=\"610\" alt=\"Marketplace Logo\" />\n        </a>\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture2.svg\" width=\"200\" alt=\" Web Portal\" />\n        <a href=\"https://github.com/microsoft/openpaisdk\" target=\"_blank\">\n          <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture3.svg\" width=\"200\" alt=\"VScode\" />\n        </a>\n        <a href=\"https://github.com/microsoft/openpaivscode\" target=\"_blank\">\n          <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture4.svg\" width=\"200\" alt=\"SDK\" />\n        </a>\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture5.svg\" width=\"610\" alt=\"API\" />\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture18.svg\" width=\"610\" alt=\"Services\" />\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture19.svg\" width=\"304\" alt=\"User Authentication\" />\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture20.svg\" width=\"304\" alt=\"User/Group Management\" />\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture21.svg\" width=\"304\" alt=\"Storage Management\" />\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture22.svg\" width=\"304\" alt=\"Cluster/Job Monitoring\" />\n        <br/>\n        <a href=\"https://github.com/microsoft/frameworkcontroller\" target=\"_blank\">\n          <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture23.svg\" width=\"304\" alt=\"Job Orchestration\" />\n        </a>\n        <a href=\"https://github.com/microsoft/hivedscheduler\" target=\"_blank\">\n          <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture24.svg\" width=\"304\" alt=\"Job Scheduling\" />\n        </a>\n        <br/>\n        <a href=\"https://github.com/microsoft/openpai-runtime\" target=\"_blank\">\n          <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture25.svg\" width=\"304\" alt=\"Job Runtime\" />\n        </a>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture26.svg\" width=\"304\" alt=\"Job Error Analysis\" />\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture15.svg\" width=\"610\" alt=\"Kubernetes Cluster Management\" />\n        <br/>\n        <img src=\"https://openpai.readthedocs.io/en/latest/images/architecture/Picture16.svg\" width=\"610\" alt=\"CPU/GPU/FPGA/InfiniBand\" />\n     </td>\n   </tr>\n </table>\n\n## Table of Contents\n\n  - [When to consider OpenPAI](#when-to-consider-openpai)\n  - [Why choose OpenPAI](#why-choose-openpai)\n      - [Support on-premises and easy to deploy](#support-on-premises-and-easy-to-deploy)\n      - [Support popular AI frameworks and heterogeneous hardware](#support-popular-ai-frameworks-and-heterogeneous-hardware)\n      - [Most complete solution and easy to extend](#most-complete-solution-and-easy-to-extend)\n  - [Get started](#get-started)\n    - [For cluster administrators](#for-cluster-administrators)\n    - [For cluster users](#for-cluster-users)\n  - [Standalone Components](#standalone-components)\n  - [Reference](#reference)\n  - [Related Projects](#related-projects)\n  - [Get involved](#get-involved)\n  - [How to contribute](#how-to-contribute)\n    - [Contributor License Agreement](#contributor-license-agreement)\n    - [Call for contribution](#call-for-contribution)\n    - [Who should consider contributing to OpenPAI](#who-should-consider-contributing-to-openpai)\n    - [Contributors](#contributors)\n\n## When to consider OpenPAI\n\n1. When your organization needs to share powerful AI computing resources (GPU/FPGA farm, etc.) among teams.\n2. When your organization needs to share and reuse common AI assets like Model, Data, Environment, etc.\n3. When your organization needs an easy IT ops platform for AI.\n4. When you want to run a complete training pipeline in one place.\n\n## Why choose OpenPAI\n\nThe platform incorporates the mature design that has a proven track record in Microsoft's large-scale production environment.\n\n#### Support on-premises and easy to deploy\n\nOpenPAI is a full stack solution. OpenPAI not only supports on-premises, hybrid, or public Cloud deployment but also supports single-box deployment for trial users.\n\n#### Support popular AI frameworks and heterogeneous hardware\n\nPre-built docker for popular AI frameworks. Easy to include heterogeneous hardware. Support Distributed training, such as distributed TensorFlow.\n\n#### Most complete solution and easy to extend\n\nOpenPAI is a most complete solution for deep learning, support virtual cluster, compatible with Kubernetes eco-system, complete training pipeline at one cluster etc. OpenPAI is architected in a modular way: different module can be plugged in as appropriate. [Here](./docs/system_architecture.md) is the architecture of OpenPAI, highlighting technical innovations of the platform.\n\n## Get started\n\nOpenPAI manages computing resources and is optimized for deep learning. Through docker technology, the computing hardware are decoupled with software, so that it's easy to run distributed jobs, switch with different deep learning frameworks, or run other kinds of jobs on consistent environments.\n\nAs OpenPAI is a platform, there are typically two different roles:\n\n- **Cluster users** are the consumers of the cluster's computing resources. According to the deployment scenarios, cluster users could be researchers of Machine Learning and Deep Learning, data scientists, lab teachers, students and so on.\n- **Cluster administrators** are the owners and maintainers of computing resources. The administrators are responsible for the deployment and availability of the cluster.\n\nOpenPAI provides end-to-end manuals for both cluster users and administrators.\n\n### For cluster administrators\n\nThe [admin manual](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/README.html) is a comprehensive guide for cluster administrators, it covers (but not limited to) the following contents:\n\n- **Installation and upgrade**. The installation is based on Kubespray, and here is the [system requirements](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/installation-guide.html#installation-requirements). OpenPAI provides an [installation guide](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/installation-guide.html) to facilitate the installation.\n\n  If you are considering upgrade from older version to the latest v1.0.0, please refer to the table below for a brief comparison between `v0.14.0` and the `v1.0.0`. More detail about the upgrade considerations can be found [upgrade guide](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/upgrade-guide.html).\n\n  |                   | `v0.14.0`                | `v1.0.0`                |\n  | ----------------- | ------------------------ | ----------------------- |\n  | Architecture      | Kubernetes + Hadoop YARN | Kubernetes              |\n  | Scheduler         | YARN Scheduler           | HiveD / K8S default     |\n  | Job Orchestrating | YARN Framework Launcher  | Framework Controller    |\n  | RESTful API       | v1 + v2                  | pure v2                 |\n  | Storage           | Team-wise storage plugin | PV/PVC storage sharing  |\n  | Marketplace       | Marketplace v2           | openpaimarketplace      |\n  | SDK               | Python                   | JavaScript / TypeScript |\n\n  _If there is any question during deployment, please check [installation FAQs and troubleshooting](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/installation-faqs-and-troubleshooting.html) first. If it is not covered yet, refer to [here](#get-involved) to ask question or submit an issue._\n\n- **Basic cluster management**. Through the Web-portal and a command-line tool `paictl`, administrators could complete [cluster managements](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/basic-management-operations.html), such as [adding (or removing) nodes](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/how-to-add-and-remove-nodes.html), [monitoring nodes and services](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/basic-management-operations.html#management-on-webportal), and [storages setup and permission control](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/how-to-set-up-storage.html).\n\n- **Users and groups management**. Administrators could manage the [users and groups](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/how-to-manage-users-and-groups.html) easily.\n\n- **Alerts management**. Administrators could [customize alerts rules and actions](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/how-to-customize-alerts.html).\n\n- **Customization**. Administrators could customize the cluster by [plugins](https://openpai.readthedocs.io/en/latest/manual/cluster-admin/how-to-customize-cluster-by-plugins.html). Administrators could also upgrade (or downgrade) a single component (e.g. rest servers) to address customized application demands.\n\n### For cluster users\n\nThe [user manual](https://openpai.readthedocs.io/en/latest/manual/cluster-user/README.html) is a guidance for cluster users, who could train and serve deep learning (and other) tasks on OpenPAI.\n\n- **Job submission and monitoring**. The [quick start tutorial](https://openpai.readthedocs.io/en/latest/manual/cluster-user/quick-start.html) is a good start for learning how to train models on OpenPAI. And more examples and supports to multiple mainstream frameworks (out-of-the-box docker images) are in [here](https://openpai.readthedocs.io/en/latest/manual/cluster-user/docker-images-and-job-examples.html). OpenPAI also provides supports for [good debuggability](https://openpai.readthedocs.io/en/latest/manual/cluster-user/how-to-debug-jobs.html) and [advanced job functionalities](https://openpai.readthedocs.io/en/latest/manual/cluster-user/advanced-jobs.html).\n\n- **Data managements**. Users could use cluster provisioned storages and custom storages in their jobs. The cluster provisioned storages are well integrated and easy to configure in a job [(refer to here)](https://openpai.readthedocs.io/en/latest/manual/cluster-user/how-to-manage-data.html).\n\n- **Collaboration and sharing**. OpenPAI provides facilities for collaboration in teams and organizations. The cluster provisioned storages are organized by teams (groups). And users could easily share their works (e.g. jobs) in the [marketplace](https://openpai.readthedocs.io/en/latest/manual/cluster-user/use-marketplace.html), where others could discover and reproduce (clone) by one-click.\n\nBesides the webportal, OpenPAI provides [VS Code extension](https://openpai.readthedocs.io/en/latest/manual/cluster-user/use-vscode-extension.html) and [command line tool (preview)](https://github.com/microsoft/openpaisdk). The VS Code extension is a friendly, GUI based client tool of OpenPAI, and it's highly recommended. It's an extension of Visual Studio Code. It can submit job, simulate jobs locally, manage multiple OpenPAI environments, and so on.\n\n## Standalone Components\n\nWith the `v1.0.0` release, OpenPAI starts using a more modularized component design and re-organize the code structure to 1 main repo together with 7 standalone key component repos. [pai](https://github.com/microsoft/pai) is the main repo, and the 7 component repos are:\n\n- [hivedscheduler](https://github.com/microsoft/hivedscheduler) is a Kubernetes Scheduler Extender for Multi-Tenant GPU clusters, which provides various advantages over standard k8s scheduler.\n- [frameworkcontroller](https://github.com/microsoft/frameworkcontroller) is built to orchestrate all kinds of applications on Kubernetes by a single controller.\n- [openpai-protocol](https://github.com/microsoft/openpai-protocol) is the specification of OpenPAI job protocol.\n- [openpai-runtime](https://github.com/microsoft/openpai-runtime) provides runtime support which is necessary for the OpenPAI protocol.\n- [openpaisdk](https://github.com/microsoft/openpaisdk) is a JavaScript SDK designed to facilitate the developers of OpenPAI to offer more user-friendly experience.\n- [openpaimarketplace](https://github.com/microsoft/openpaimarketplace) is a service which stores examples and job templates. Users can use it from webportal plugin to share their jobs or run-and-learn others' sharing job.\n- [openpaivscode](https://github.com/microsoft/openpaivscode) is a VSCode extension, which makes users connect OpenPAI clusters, submit AI jobs, simulate jobs locally and manage files in VSCode easily.\n\n## Reference\n\n- [PyTorch CIFAR-10](https://github.com/microsoft/pai/tree/pai-for-edu/contrib/edu-examples/pytorch_cifar10) and [TensorFlow CIFAR-10](https://github.com/microsoft/pai/tree/pai-for-edu/contrib/edu-examples/tensorflow_cifar10) job examples\n- [RESTful API](https://redocly.github.io/redoc/?url=https://raw.githubusercontent.com/microsoft/pai/master/src/rest-server/docs/swagger.yaml)\n- Design documents could be found [here](docs) if you are curious.\n\n## Related Projects\n\nTargeting at openness and advancing state-of-art technology, [Microsoft Research (MSR)](https://www.microsoft.com/en-us/research/group/systems-research-group-asia/) and [Microsoft Software Technology Center Asia (STCA)](https://www.microsoft.com/en-us/ard/default.aspx) had also released few other open source projects.\n\n- [NNI](https://github.com/Microsoft/nni) : An open source AutoML toolkit for neural architecture search and hyper-parameter tuning.\n  We encourage researchers and students leverage these projects to accelerate the AI development and research.\n- [MMdnn](https://github.com/Microsoft/MMdnn) : A comprehensive, cross-framework solution to convert, visualize and diagnose deep neural network models. The \"MM\" in MMdnn stands for model management and \"dnn\" is an acronym for deep neural network.\n- [NeuronBlocks](https://github.com/Microsoft/NeuronBlocks) : An NLP deep learning modeling toolkit that helps engineers to build DNN models like playing Lego. The main goal of this toolkit is to minimize developing cost for NLP deep neural network model building, including both training and inference stages.\n- [SPTAG](https://github.com/Microsoft/SPTAG) : Space Partition Tree And Graph (SPTAG) is an open source library for large scale vector approximate nearest neighbor search scenario.\n\n## Get involved\n\n- [Stack Overflow](./docs/stackoverflow.md): If you have questions about OpenPAI, please submit question at Stack Overflow under tag: openpai\n- [Gitter chat](https://gitter.im/Microsoft/pai): You can also ask questions in Microsoft/pai conversation.\n- [Create an issue or feature request](https://github.com/Microsoft/pai/issues/new/choose): If you have issue/ bug/ new feature, please submit it to GitHub.\n\n## How to contribute\n\n### Contributor License Agreement\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Call for contribution\n\nWe are working on a set of major features improvement and refactor, anyone who is familiar with the features is encouraged to join the design review and discussion in the corresponding issue ticket.\n\n- GPU fairness usage [Issue 4266](https://github.com/Microsoft/pai/issues/4266)\n\n### Who should consider contributing to OpenPAI\n\n- Folks who want to add support for other ML and DL frameworks\n- Folks who want to make OpenPAI a richer AI platform (e.g. support for more ML pipelines, hyperparameter tuning)\n- Folks who want to write tutorials/blog posts showing how to use OpenPAI to solve AI problems\n\n### Contributors\n\nOne key purpose of OpenPAI is to support the highly diversified requirements from academia and industry. OpenPAI is completely open: it is under the MIT license. This makes OpenPAI particularly attractive to evaluate various research ideas, which include but not limited to the [components](./docs/research_education.md).\n\nOpenPAI operates in an open model. It is initially designed and developed by [Microsoft Research (MSR)](https://www.microsoft.com/en-us/research/group/systems-research-group-asia/) and [Microsoft Software Technology Center Asia (STCA)](https://www.microsoft.com/en-us/ard/default.aspx) platform team.\nWe are glad to have [Peking University](http://eecs.pku.edu.cn/EN/), [Xi'an Jiaotong University](http://www.aiar.xjtu.edu.cn/), [Zhejiang University](http://www.cesc.zju.edu.cn/index_e.htm), [University of Science and Technology of China](http://eeis.ustc.edu.cn/) and [SHANGHAI INESA AI INNOVATION CENTER (SHAIIC)](https://www.shaiic.com/) joined us to develop the platform jointly.\nContributions from academia and industry are all highly welcome.\n"
 },
 {
  "repo": "microsoft/vsts-team-calendar",
  "language": "TypeScript",
  "readme_contents": "# Team Calendar Extension for Visual Studio Team Services\n\n![buildstatus](https://mseng.visualstudio.com/_apis/public/build/definitions/b924d696-3eae-4116-8443-9a18392d8544/5979/badge)\n\nTeam Calendar helps busy teams stay on track and informed about important deadlines, sprint schedules, and upcoming milestones. It is the one place to see and manage the date important to your teams, including sprint schedule, days off (for individuals or the team), and custom events.\n\nTeam Calendar installs into either a Visual Studio Team Services account or into Team Foundation Server.\n\n![screenshot](static/v2-images/calendar-screen-shot.png)\n\nSee [overview](overview.md) to learn more about the features of the extension.\n\n## About extensions\n\nExtensions enable you to create first-class integration experiences within Visual Studio Team Services, just the way you have always wanted. An extension can be a simple context menu or toolbar action or can be a complex and powerful custom UI experience that light up within the account, collection, or project hubs.\n\nTo learn more about Extensions, see the [overview of extensions](https://www.visualstudio.com/docs/integrate/extensions/overview).\n\n## Install\n\nTo try out the extension in your VSTS account, visit the [Team Calendar extension](https://marketplace.visualstudio.com/items?itemName=ms-devlabs.team-calendar) page on the Visual Studio Marketplace.\n\nDon't have a [free] VSTS account? [Learn more](https://www.visualstudio.com/team-services/) about getting one.\n\n## Develop\n\nTeam Calendar is written in [TypeScript](https://www.typescriptlang.org/). To build and package the extension:\n\n### Get the pre-reqs\n\n1. Get [Node.js](https://nodejs.org/)\n2. Install TypeScript: `npm install -g typescript`\n3. Install the TFX CLI (needed to package the extension): `npm install -g tfx-cli`\n4. Install required modules: `npm install` (from the root of t\n\n### Compile the code\n\nTo compile and package the extension run:\n\n```\nnpm run build\n```\n\nThis will compile the TypeScript code in the project and create a .vsix file.\n\n### Package the extension\n\nTo install your own version of the Team Calendar extension into your VSTS account, you need to create a publisher on the Visual Studio Marketplace. There is no cost for creating or having a publisher. [Learn how to create a publisher](https://www.visualstudio.com/docs/integrate/extensions/publish/overview).\n\n1. Update your version of the extension manifest (`vss-extension.json`) file:\n    1. Set the `publisher` property to your Visual Studio Marketplace publisher ID\n    2. Set the `public` property to `false`\n2. Package the extension (`npm run build`) to produce a .vsix file. Note: you should see your publisher ID in the name of this file.\n3. Go to the [manage](https://marketplace.visualstudio.com/manage) page of the Marketplace and click **Upload** to publish your version of the extension (don't worry, only you will be able to see it)\n4. After uploading, select the extension, click **Share** ,and enter the name of the VSTS account you want to be able to install the extension into\n5. Click the extension's title to open its details page\n6. Click the install button, choose your account from the drop-down, and install the extension\n\n## Code of Conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-pulsechart",
  "language": "TypeScript",
  "readme_contents": "# Pulse Chart\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-pulsechart.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-pulsechart) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-pulsechart/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-pulsechart?branch=master) [![Build Status](https://dev.azure.com/customvisuals/public/_apis/build/status/Microsoft.powerbi-visuals-chord)](https://dev.azure.com/customvisuals/public/_build/latest?definitionId=4)\n\n> Line chart annotated with key events. Perfect for story telling with data.\n\n![stacked area chart screenshot](./assets/screenshot2.png)\n\n# Overview\n\nThe Pulse chart shows key events on a timeline, and lets you play back the events to reveal insights.\n\nThe Pulse Chart allows you to playback the data to see the trend unfold in front of your eyes. When an event appears, the playback pauses to filter the rest of the report, revealing hidden relationships. You can use this feature to grab your audience\u2019s attention and highlight specific insights. There\u2019s an auto play feature that starts the playback when the report loads. Pulse Charts are ideal for use with publish to web or when sharing reports with your coworkers.\n\nWhen a data point is selected on the Pulse Chart, you get a customizable popup. You can specify the title and description, and show or hide the timestamp as well. This lets you clearly call attention to what\u2019s important about the data point.\n\nCreating a Pulse Chart is really easy - you just need to provide data that is a time series. You add columns to the time series data that define the events you want to show on the line. For those columns, non-blank values become events and are shown as circles on the Pulse chart.\n\nSee also [Pulse Chart at Microsoft AppSource](https://appsource.microsoft.com/en-us/product/power-bi-visuals/WA104381006)\n"
 },
 {
  "repo": "microsoft/arcade-machine",
  "language": "TypeScript",
  "readme_contents": "# arcade-machine\n\narcade-machine is an Angular plugin to provide navigation and interactive semantics using the GamePad API. This allows the application to be navigated using a controller connected to a PC, the PC's keyboard, or on Universal Windows Platform (UWP) web applications running on the Xbox.\n\n> See the [reference controller](https://i-msdn.sec.s-msft.com/en-us/windows/uwp/input-and-devices/images/designing-for-tv/hardware-buttons-gamepad-remote.png) for mappings with buttons.\n\nWe use [WinJS' navigation algorithm](https://github.com/winjs/winjs/blob/master/src/js/WinJS/XYFocus.ts#L11) to move between focusable components on the page. Most interactive components, including link tags `<a>`, buttons, and form controls are able to receive focus by default, and for those which are not focusable by default you can use the `arc` directive.\n\n> Here we have a basic app which contains three buttons. The user can use their joystick to navigate between each selectable button. Note that the app itself is marked as focusable; this is how bootstrapping is done. More on this in a minute.\n>\n> ```html\n> <my-app arc>\n>   <button>Button 1</button>\n>   <button>Button 2</button>\n>   <button>Button 3</button>\n> </my-app>\n> ```\n\nFor the majority of navigation, we represent controller actions as keyboard events; the left joystick or arrow keys on a keyboard can be used to fire up, down, left, and right events in order to navigate the page. We determine the next element to focus in a direction using WinJS' algorithm based on each focusable element's physical location, but you can also fine tune what happens when via directives. This can help to avoid [inaccessible UI](https://msdn.microsoft.com/windows/uwp/input-and-devices/designing-for-tv#inaccessible-ui) and provide more fined-tuned experiences on each platform.\n\n> By default only elements that explicity have `tabindex >= 0` are considered for focus\n\n## Demo App\n\nYou can see a demo Angular 2 app in the `demo` folder and run it locally with `npm start`.\n\n## Usage\n\n### Directives & Attributes\n\n##### arc\n\nYou must define `arc` directive on element which you want to be focusable that are not otherwise focusable, or when you want to define custom logic. That is, anything except the following tags:\n\n- `a`\n- `button`\n- `input`\n- `select`\n- `textarea`\n\n##### [arc-exclude-this]=\"value\"\n\nYou can pass a value to `arc-exclude-this` which, if not `false`, exclude this element from arcade-machine's focus.\n\n##### [arc-exclude]=\"value\"\n\nYou can pass a value to `arc-exclude-this` which, if not `false`, exclude this element and all its children from arcade-machine's focus.\n\n\n##### [arc-set-focus]=\"Observable\\<boolean\\>\"\n\nYou can pass an Observable to `arc-set-focus` which, when fired, will forcefully cause the element to be focused.\n\n##### arc-default-focus\n\nWhen `arc-focus` is on an element, that element will steal the page focus when it's instantiated. Setting this is a shortcut to passing `Observable.of(undefined)` to `arc-set-focus` to immediately trigger a focus capture.\n\nIt can also be used with *ngFor. For instance, following will focus the 3rd element in ngFor\n```html\n<div\n  *ngFor=\"let box of boxes; let i = index\"\n  arc [arc-default-focus]=\"i === 2\">\n</div>\n```\n\n##### arc-focus-inside\n\nIf arc-focus-inside is present on a focusable element; on focus, it transfers the focus to its next best child element.\nThis is particularly useful to make elements focusable that are not directly in the focus direction.\n\n```html\n<div tabindex=\"0\" arc arc-focus-inside=\"true\">\n  <div tabindex=\"0\">I will be focused instead</div>\n</div>\n```\n\n##### (arc-capture-outgoing)=\"onEvent(IArcEvent)\"\n\n`arc-capture-outgoing` can be set to handle, and possibly cancel, events sent while the element or one of its children are focused. See the `IArcEvent` type for more details:\n\n##### (arc-capture-incoming)=\"onEvent(IArcEvent)\"\n\n`arc-capture-incoming` can be set to handle, and possibly cancel, events sent while the element is the next target of navigation. See the `IArcEvent` type for more details:\n\n```typescript\n/**\n * IArcEvents are fired on an element when an input occurs. They include\n * information about the input and provide utilities similar to standard\n * HTML events.\n */\nexport interface IArcEvent {\n  // The 'arc' directive reference, may not be filled for elements which\n  // are focusable without the directive, like form controls.\n  readonly directive?: IArcHandler;\n  // `next` is the element that we'll select next, on directional navigation,\n  // unless the element is cancelled. This *is* settable and you can use it\n  // to modify the focus target. This will be set to `null` on non-directional\n  // navigation or if we can't find a subsequent element to select.\n  next?: Element;\n\n  readonly event: Direction;\n  readonly target: Element;\n  readonly defaultPrevented: boolean;\n\n  stopPropagation(): void;\n  preventDefault(): void;\n}\n\n/**\n * Direction is an enum of possible gamepad events which can fire.\n */\nexport enum Direction {\n  SUBMIT = 0,\n  BACK = 1,\n  X = 2,\n  Y = 3,\n  TABLEFT = 4, // Left Bumper\n  TABRIGHT = 5, // Right Bumper\n  TABUP = 6, // Left Trigger\n  TABDOWN = 7, // Right Trigger\n  UP = 12,\n  DOWN = 13,\n  LEFT = 14,\n  RIGHT = 15,\n}\n```\n\n##### (arc-focus)=\"onFocusChange(Element?)\"\n\n`arc-focus` is an event that's fired when the element or any of its children gain or lose focus. The newly-selected element will be passed to the function, and `null` will be passed if none of the elements in the node's tree are selected.\n\n##### (arc-submit)=\"onSubmit(IArcEvent)\"\n\n`arc-submit` is a shortcut to create a handler via `arc-capture-outgoing` that fires when a \"submit\" event is fired.\n\n##### (arc-back)=\"onBack(IArcEvent)\"\n\n`arc-back` is a shortcut to create a handler via `arc-capture-outgoing` that fires when a \"back\" event is fired.\n\n##### [arc-[left|right|up|down]]=\"Element\"\n\nAllows you to explicitly tell the directive which element to focus when off the element in the provided direction. Again, this is a shortcut to a `arc-capture-outgoing` handler which sets the `next` element if it matches the target direction.\n\n##### [arc-focus-[left|right|up|down]]=\"Element | CSSQueryString\"\n\nAllows you to explicitly tell the directive which element to focus when off the element in the provided direction. This will take precedence over all other FindFocus strategies\n\n### Focus Service\n\n#### trapFocus\n```typescript\ntrapFocus(newRootElem: HTMLElement)\n```\nTo trap the focus inside newRootElem.\nTo release the focus, call releaseFocus\n\n#### releaseFocus\n\n```typescript\nreleaseFocus(releaseElem?: HTMLElement)\n```\nTo trap the release the previously trapped focus.\nMultiple call to this method will precedurally remove focus traps all the way up to body.\nFurther calls without releaseElem param will throw a warning on console while keeping the focus at body.\nIf releaseElem is provided, this method will release focus only if the last trapped focus element was releaseElem.\n\n#### releaseFocus\n```typescript\nclearAllTraps()\n```\nUseful for resetting all focus traps e.g. on page navigation\n\n### Classes\n\nBy default, the `arc--selected-direct` class is added to the selected node.\n\n### Events\n#### arcselectingnode\n\nFired when arcade machine is about to select a node\n\n#### arcfocuschanging\n\nFire when arcade-machine is about to call native focus method. This event can be canceled for example to smooth-scroll to the element before focusing it in browser.\n"
 },
 {
  "repo": "microsoft/thematic",
  "language": "TypeScript",
  "readme_contents": "# Thematic\n\nThis repository holds all of the packages for creating shareable, perceptually-balanced and tastefully complementary (hopefully!) application and data viz themes. There are adapter libraries and tools to apply themes across several environments, which will be detailed below. We briefly describe the intentions and usage of the library in [a paper on visualizing workgroup collaboration](https://arxiv.org/pdf/2005.00402.pdf).\n\nThis repository is structured as a yarn monorepo. It contains separate packages for all of the theme generation, management, and applications. To use thematic in your app, you should only need to install the relevant packages for your use case(s).\n\nThe webapp package is a guide for everything Thematic. In particular, it comprises:\n\n- A running application for configuring theme parameters\n- An example app using thematic itself, so you can see what controls and charts look like\n- A variety of code examples to explore showing how to use thematic in practice\n\n## Organization\n\nOur thematic packages are published under the `@thematic` scope.\n\nThese are the core Thematic libraries, see individual README.md files for greater detail:\n\n- [@thematic/color](packages/color/README.md) - this contains color conversion and scale generation logic. If you need functions to convert between color spaces, this is the place. This also has the color scheme compute logic that dictates how all of the color scales are generated from a few selected input parameters.\n- [@thematic/core](packages/core/README.md) - this is the main package for working with Themes. You can load them from a Theme JSON specification, then use the attributes directly in your app to apply the generated colors in a consistent way. We've used SVG notation for all of our mark properties (e.g., 'fill').\n- [@thematic/d3](packages/d3/README.md) - this package has helpers to apply the themes to viz created with [d3](https://d3js.org/). We provide a variety of SVG mark primitives that operate on a d3 Selection, so you can apply the theme elements using `selection.call(fn, [params])` as needed.\n- [@thematic/fluent](packages/fluent/README.md) - helpers for applying Thematic to the [Fluent UI library](https://developer.microsoft.com/en-us/fluentui#/controls/web)\n- [@thematic/react](packages/react/README.md) - helpers to bootstrap theming into React-based apps, particularly a provider and context hook (useThematic) for grabbing the theme anywhere it is needed.\n- [@thematic/vega](packages/vega/README.md) - this has a helper that applies our theme spec as default configuration for Vega charts so they automatically adopt the theme.\n- [@thematic/webapp](packages/webapp/README.md) - this is the theme editor webapp that you can run or access at https://microsoft.github.io/thematic.\n\n## Getting Started\n\nIf you want to run locally and work on the app or any theme components, you can run the whole thing from the root folder. The web app will run using `yarn start:webapp` as with our typical development structure, and changes to any of the other packages will be reflected live. See the Available Scripts section below.\n\n## Publishing\n\nCommits to `main` will automatically deploy to the hosted website. Pull requests should use `yarn version check --interactive` to create semantic versioning documents describing the impact of the PR. When a release is ready, run`yarn release_all` to publish packages to npm.\n\n## Available Scripts\n\nIn the project directory, you can run:\n\n### `yarn start`\n\nRuns the app in the development mode.\nAn available port will be selected automatically, such as 8080. Open [http://localhost:8080](http://localhost:8080) to view it in the browser.\n\nThe page will reload if you make edits.\nYou will also see any lint errors in the console.\n\n### `yarn test`\n\nLaunches the test runner using Jest.\n\n### `yarn build:all`\n\nBuilds packages for production to their respective `dist` and `lib` folders. Note that the webapp uses a `bundle` command more appropriate to creating an optimized web bundle. CI systems will want to invoke both of these to produce complete\n\n### `yarn clean:all`\n\nCleans out the node_modules and built lib directories for every package.\n\n# Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/essex-alpha-build-infra",
  "language": "TypeScript",
  "readme_contents": "![CI](https://github.com/microsoft/essex-alpha-build-infra/workflows/CI/badge.svg?branch=main)\n\n# essex-alpha-build-infra\n\nThis project contains build infrastructure for the Project Essex Alpha team.\n\n# Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Please follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments."
 },
 {
  "repo": "microsoft/powerbi-visuals-utils-chartutils",
  "language": "TypeScript",
  "readme_contents": "# Microsoft Power BI visuals ChartUtils\n![Build status](https://github.com/microsoft/powerbi-visuals-utils-chartutils/workflows/build/badge.svg) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-utils-chartutils/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-utils-chartutils?branch=master) [![npm version](https://img.shields.io/npm/v/powerbi-visuals-utils-chartutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-chartutils) [![npm](https://img.shields.io/npm/dm/powerbi-visuals-utils-chartutils.svg)](https://www.npmjs.com/package/powerbi-visuals-utils-chartutils)\n\n> ChartUtils is a set of interfaces for creating powerbi custom visuals\n\n## Usage\nLearn how to install and use the chartutils in your custom visuals:\n* [Usage Guide](https://docs.microsoft.com/en-us/power-bi/developer/visuals/utils-chart)\n\n## Contributing\n* Read our [contribution guideline](./CONTRIBUTING.md) to find out how to contribute bugs fixes and improvements\n* [Issue Tracker](https://github.com/Microsoft/powerbi-visuals-utils-chartutils/issues)\n* [Development workflow](./docs/dev/development-workflow.md)\n* [How to build](./docs/dev/development-workflow.md#how-to-build)\n* [How to run unit tests locally](./docs/dev/development-workflow.md#how-to-run-unit-tests-locally)\n\n## License\nSee the [LICENSE](./LICENSE) file for license rights and limitations (MIT).\n"
 },
 {
  "repo": "microsoft/Recognizers-Text",
  "language": "C#",
  "readme_contents": "# Microsoft Recognizers Text Overview\r\n\r\n![Build Status](https://msrasia.visualstudio.com/_apis/public/build/definitions/310c848f-b260-4305-9255-b97bfb69974b/116/badge)\r\n![Build Status](https://ci.appveyor.com/api/projects/status/github/Microsoft/Recognizers-Text?branch=master&svg=true&passingText=all%20plats%20-%20OK)\r\n\r\nMicrosoft.Recognizers.Text provides robust recognition and resolution of entities like numbers, units, and date/time; expressed in multiple languages. Full support for Chinese, English, French, Spanish, Portuguese, German, Italian, Turkish, and Hindi. Partial support for Dutch, Japanese, Korean, and Swedish. More on the way.\r\n\r\n# Utilizing the Project\r\n\r\nMicrosoft.Recognizers.Text powers pre-built entities in both [**LUIS: Language Understanding Intelligent Service**](https://www.luis.ai/home) and [**Microsoft Bot Framework**](https://dev.botframework.com/); base entity types in [**Text Analytics Cognitive Service**](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-entity-linking); and it is also available as standalone packages (for the base classes and the different entity recognizers).\r\n\r\nThe Microsoft.Recognizers.Text packages currently target four platforms:\r\n* [C#/.NET](https://github.com/Microsoft/Recognizers-Text/tree/master/.NET) - **NuGet packages** available at: https://www.nuget.org/profiles/Recognizers.Text\r\n* [JavaScript/TypeScript](https://github.com/Microsoft/Recognizers-Text/tree/master/JavaScript/packages/recognizers-text-suite) - **NPM packages** available at: https://www.npmjs.com/~recognizers.text\r\n* [Python](https://github.com/Microsoft/Recognizers-Text/tree/master/Python) - **PyPI packages** available at: https://pypi.org/user/recognizers-text/ (alpha)\r\n* [Java](https://github.com/Microsoft/Recognizers-Text/tree/master/Java) (in progress)\r\n\r\nContributions are greatly welcome! Both for fixes and extensions in the currently supported languages and for expansion to new ones.\r\nEspecially for Dutch, Japanese, Korean, Hindi, and others! More info below.\r\n\r\n# Help\r\n\r\nIf you have any questions, please go ahead and [open an issue](https://github.com/Microsoft/Recognizers-Text/issues/new/choose), even if it's not an actual bug. Issues are an acceptable discussion forum as well.\r\n\r\n# Contributing\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\nGood starting points for contribution are:\r\n* the list of [open issues](https://github.com/Microsoft/Recognizers-Text/issues) (especially those marked as ```help wanted```); \r\n* the json spec cases temporarily marked as ```NotSupported``` ([Specs](./Specs)); and\r\n* translating json test spec cases that work in English, but don't yet exist in a target language.\r\n\r\nThe links below describe the project structure and provide both an overview and tips on how to contribute (although some steps may have become a little out-of-date). Thank you!\r\n\r\n* [Overview and language resources](https://blog.botframework.com/2018/01/24/contributing-luis-microsoft-recognizers-text-part-1/)\r\n* [Implementing language specific behaviour](https://blog.botframework.com/2018/02/01/contributing-luis-microsoft-recognizers-text-part-2/)\r\n* [Test specs and testing in general](https://blog.botframework.com/2018/02/12/contributing-luis-microsoft-recognizers-text-part-3/)\r\n\r\n# Supported Entities across Cultures\r\n\r\nThe table below summarizes the currently supported entities. Support for English is usually more complete than others. The primary platform is .NET (shown in table) and support should propagate to the others.\r\n\r\n| Entity Type       | EN      | ZH-CN   | NL    | FR     | DE    | IT      | JA     | KO     | PT     | ES      |\r\n|:-----------------:|:-------:|:-------:|:-----:|:------:|:-----:|:-------:|:------:|:------:|:------:|:-------:| \r\n| Number (cardinal)    | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | \u2713      | \u2713      | \u2713     | \u2713       |\r\n| Ordinal              | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | \u2713      | PA/EO  | \u2713     | \u2713       |\r\n| Percentage           | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | \u2713      | PA/EO  | \u2713     | \u2713       |\r\n| Number Range         | \u2713    | \u2713       | \u2713    | :x:    | :x:   | \u2713      | PA/EO   | PA/EO  | :x:    | \u2713      |\r\n| Unit - Age           | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | \u2713      | PA/EO  | \u2713     | \u2713       |\r\n| Unit - Currency      | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | \u2713      | PA/EO  | \u2713     | \u2713       |\r\n| Unit - Dimensions    | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | :x:    | PA/EO  | \u2713      | \u2713      | \r\n| Unit - Temperature   | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | :x:    | PA/EO  | \u2713      | \u2713      | \r\n| Choice - Boolean     | \u2713    | \u2713       | \u2713    | \u2713     | \u2713     | \u2713       | \u2713      | **SO** | \u2713     | \u2713       | \r\n| Seq. - E-mail        | G    | G*       | G    | G      | G     | G       | G*     | G*     | G      | G       |\r\n| Seq. - GUID          | G    | G        | G    | G      | G     | G       | G      | G      | G      | G       |\r\n| Seq. - Social        | G    | G        | G    | G      | G     | G       | G      | G      | G      | G       |\r\n| Seq. - IP Address    | G    | G        | G    | G      | G     | G       | G      | G      | G      | G       |\r\n| Seq. - Phone Number  | G    | G        | G    | G      | G     | G       | G      | G      | G      | G       |\r\n| Seq. - URL           | G    | G*       | G    | G      | G     | G       | G*     | G*     | G      | G       |\r\n| DateTime (+subtypes) | \u2713    | \u2713       | **PA** | \u2713    | \u2713     | \u2713      | **SP** | **SP** | \u2713     | \u2713       | \r\n\r\n| Entity Type       | SV      | BG      | TR    | HI     | AR    |         |        |        |        |         |\r\n|:-----------------:|:-------:|:-------:|:-----:|:------:|:-----:|:-------:|:------:|:------:|:------:|:-------:| \r\n| Number (cardinal)    | \u2713    | :x:     | \u2713    | \u2713      | PA/EO |         |        |        |        |         |\r\n| Ordinal              | \u2713    | :x:     | \u2713    | \u2713      | PA/EO |         |        |        |        |         |\r\n| Percentage           | \u2713    | :x:     | \u2713    | \u2713      | PA/EO |         |        |        |        |         |\r\n| Number Range         | :x:  | :x:     | \u2713     | \u2713     | PA/EO |         |        |        |        |         |\r\n| Unit - Age           | \u2713    | :x:     | \u2713     | \u2713     | :x:   |         |        |        |        |         |\r\n| Unit - Currency      | \u2713    | :x:     | \u2713     | \u2713     | :x:   |         |        |        |        |         |\r\n| Unit - Dimensions    | \u2713    | :x:     | \u2713     | \u2713     | :x:   |         |        |        |        |         | \r\n| Unit - Temperature   | \u2713    | :x:     | \u2713     | \u2713     | :x:   |         |        |        |        |         | \r\n| Choice - Boolean     | \u2713    | \u2713      | \u2713     | \u2713      | \u2713    |         |        |        |        |         |\r\n| Seq. - E-mail        | G    | G       | G     | G      | G     |         |        |        |        |         |\r\n| Seq. - GUID          | G    | G       | G     | G      | G     |         |        |        |        |         |\r\n| Seq. - Social        | G    | G       | G     | G      | G     |         |        |        |        |         |\r\n| Seq. - IP Address    | G    | G       | G     | G      | G     |         |        |        |        |         |\r\n| Seq. - Phone Number  | :x:  | :x:     | :x:   | :x:    | :x:   |         |        |        |        |         |\r\n| Seq. - URL           | G    | G       | G     | G*     | G*    |         |        |        |        |         |\r\n| DateTime (+subtypes) | :x:  | :x:     | \u2713     | \u2713      | :x:   |         |        |        |        |         |\r\n\r\n* G: Generic entity, not language-specific (* unicode TLDs not-supported);\r\n* EO: Extraction-only (parsing/resolution/normalization pending);\r\n* PA: Partial support (type not fully supported);\r\n* SO: Specs-only (test specs coverage OK, but support pending);\r\n* SP: Partial specs;\r\n* SI: Very initial specs (typically language support start for a new language).\r\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-globemap",
  "language": "TypeScript",
  "readme_contents": "# GlobeMap\n[![Build Status](https://travis-ci.org/Microsoft/powerbi-visuals-globemap.svg?branch=master)](https://travis-ci.org/Microsoft/powerbi-visuals-globemap) [![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-globemap/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-globemap?branch=master)\n\n> A 3D visual using WebGL for plotting locations, with category values displayed as bar heights and heat maps. Shift+Click on bar to change center point. Slicing data points will animate to average location. \n\n![GlobeMap screenshot](https://az158878.vo.msecnd.net/marketing/Partner_21474836617/Product_42949680586/Asset_87f58068-9b83-4a54-8889-66617065ec5a/GlobeMapscreenshot2.png)\n\n# Overview\nGlobe Map is a 3D Map that makes the map exploration experience more immersive and magical. It provide the sense of connection to the data with the physical world. This, combined with our spatial ability, brings a new perspective to the data when presented as 3D objects.\n\nUse it with any location data. The location could be an address, city, county , state/province or country/region. On this 3D map, you can project a measure as the height of the bar. The 3D bars reduce the clutter of overlapping bubbles and allow you to get instant insight. GlobeMap also allows you to rotate the Globe and see it from different angles.\n\nGlobe Map also supports heat map on the spatial map. You can use a second measure for heat intensity and draw immediate attention to the right areas.\n\nSee also [Globe Map at Microsoft AppStore](https://appsource.microsoft.com/en-us/product/power-bi-visuals/WA104380799)"
 },
 {
  "repo": "microsoft/perfview",
  "language": "C#",
  "readme_contents": "# PerfView Overview\nPerfView is a free performance-analysis tool that helps isolate CPU and memory-related performance issues.  It is a Windows tool, but it also has some support for analyzing data collected on Linux machines.  It works for a wide variety of scenarios, but has a number of special features for investigating performance issues in code written for the .NET runtime.  \n\nIf you are unfamiliar with PerfView, there are [PerfView video tutorials](http://channel9.msdn.com/Series/PerfView-Tutorial). \nAlso, [Vance Morrison's blog](https://docs.microsoft.com/en-us/archive/blogs/vancem/) gives overview and getting \nstarted information. \n\n### Getting PerfView \nPlease see the [PerfView Download Page](documentation/Downloading.md) for the link and instructions for downloading the \ncurrent version of PerfView.  \n\n### Are you here about the TraceEvent Library?\n\nPerfView is built on a library called Microsoft.Diagnostics.Tracing.TraceEvent, that knows how to both collect and parse Event Tracing for Windows (ETW) data.   Thus if there is any information that PerfView collects and processes that you would like to manipulate yourself programmatically, you would probably be interested in the [TraceEvent Library Documentation](documentation/TraceEvent/TraceEventLibrary.md)\n\n### Learning about PerfView \n\nThe PerfView User's Guide is part of the application itself. In addition, you can click the\n[Users Guide link](http://htmlpreview.github.io/?https://github.com/Microsoft/perfview/blob/main/src/PerfView/SupportFiles/UsersGuide.htm) \nto see the [GitHub HTML Source File](src/PerfView/SupportFiles/UsersGuide.htm) rendered in your browser.  You can also simply\ndownload PerfView using the instructions above and select the Help -> User's Guide menu item. \n\n### Asking Questions / Reporting Bugs \n\nWhen you have question about PerfView, your first reaction should be to search the Users Guide (Help -> User's Guide) and \nsee if you can find the answer already.   If that does not work you can ask a question by creating a [new PerfView Issue](https://github.com/Microsoft/perfview/issues/new).\nState your question succinctly in the title, and if necessary give details in the body of the issue, there is a issue tag\ncalled 'question' that you should use as well that marks your issue as a question rather than some bug report.\nIf the question is specific to a particular trace (*.ETL.ZIP file) you can drag that file onto the issue and it will be downloaded.\nThis allows those watching for issues to reproduce your environment and give much more detailed and useful answers.\n\nNote that once you have your question answered, if the issue is likely to be common, you should strongly consider updating the\ndocumentation to include the information.  The documentation is pretty much just\none file https://github.com/Microsoft/perfview/blob/main/src/PerfView/SupportFiles/UsersGuide.htm.\nYou will need to clone the repository and create a pull request (see [OpenSourceGitWorkflow](https://github.com/Microsoft/perfview/blob/main/documentation/OpenSourceGitWorkflow.md)\nfor instructions for setting up and creating a pull request.  \n\nReporting bugs works pretty much the same way as asking a question.  It is very likely that you will want to include the *.ETL.ZIP\nfile needed to reproduce the problem as well as any steps and the resulting undesirable behavior.\n\n# Building PerfView Yourself\n\nIf you just want to do a performance investigation, you don't need to build PerfView yourself.\nJust use the one from the [PerfView Download Page](documentation/Downloading.md).\nHowever if you want new features or just want to contribute to PerfView to make it better\n(see [issues](https://github.com/Microsoft/perfview/issues) for things people want)\nyou can do that by following the rest of these instructions.\n\n### Tools Needed to Build PerfView\n\nThe only tools you need to build PerfView are Visual Studio 2017 and the .NET Core SDK.   The\n[Visual Studio 2017 Community Edition](https://www.visualstudio.com/vs/community/) can be downloaded *for free* and,\nalong with the .NET Core SDK, has everything you need to fetch PerfView from GitHub, build and test it. We expect you\nto download Visual Studio 2017 Community Edition if you don't already have Visual Studio 2017.\n\nPerfView is mostly C# code, however there is a small amount of C++ code to implement some advanced features of PerfView \n(The ETWCLrProfiler dlls that allow PerfView to intercept the .NET Method calls; see .NET Call in the Collect dialog).  \nIf you downloaded the Visual Studio 2017 Community Edition, it does not install the C++ compilation tools by default and\nit also does not include the Windows 8.1 SDK by default (we build PerfView so it can run on Win8 as well as Win10).  Thus\nwhen you install Visual Studio 2017 check the 'Desktop Development with C++' option and then look the right pane to see\nthe optional sub-components, and make sure the Windws 8.1 SDK is also checked (it typically is not).   If you have\nalready installed VS 2017, you can add these options by going to Control Panel -> Programs and Features -> Visual Studio 2017, and click 'Modify'.   This will get you to the place where you can selecte the Desktop Development with C++ and the Windows 8.1 SDK. \nIf you get any errors compiling the ETWClrProfiler* dlls, it is likely associated with getting this Win 8.1 SDK.  See \nthe troubleshooting sections below for more if you need it.  \n\nThe .NET Core SDK should be part of the default VS 2017 installation now, but if not it can be installed easily from [here](https://www.microsoft.com/net/download/windows).\n\n### Cloning the PerfView GitHub Repository. \n\nThe first step in getting started with the PerfView source code is to clone the PerfView GitHub repository.\nIf you are already familiar with how GIT, GitHub, and Visual Studio 2017 GIT support works, then you can skip this section.\nHowever, if not, the [Setting up a Local GitHub repository with Visual Studio 2017](documentation/SettingUpRepoInVS.md) document\nwill lead you through the basics of doing this. All it assumes is that you have Visual Studio 2017 installed.\n\n### How to Build and Debug PerfView \n\nPerfView is developed in Visual Studio 2017 using features through C# 6.\n\n  * The solution file is PerfView.sln.  Opening this file in Visual Studio (or double clicking on it in \n  the Windows Explorer) and selecting Build -> Build Solution, will build it. You can also build the \n  non-debug version from the command line using msbuild or the build.cmd file at the base of the repository.\n  The build follows standard Visual Studio conventions, and the resulting PerfView.exe file ends up in\n  src/PerfView/bin/*BuildType*/PerfView.exe. You need only deploy this one EXE to use it.  \n\n  * The solution consists of 11 projects, representing support DLLs and the main EXE. To run PerfView in the \n  debugger **you need to make sure that the 'Startup Project' is set to the 'PerfView' project** so that it launches \n  the main EXE.   If the PerfView project in the Solution Explorer (on the right) is not bold, right click on the PerfView project \n  and select 'Set as Startup Project'. After doing this 'Start Debugging' (F5) should work.\n  (It is annoying that this is not part of the .sln file...).  \n\n### Deploying your new version of Perfview\n\nYou will want to deploy the 'Release' rather than the 'Debug' version of PerfView.  Thus, first set your build configuration\nto 'Release' (Text window in the top toolbar, or right click on the .SLN file -> Configuration Manager -> Active Solution Configuration).\nNext build (Build -> Build Solution (Ctrl-Shift-B)).   The result will be that in the src\\perfView\\bin\\net45\\Release directory there will be\namong other things a PerfView.exe.   This one file is all you need to deploy.   Simply copy it to where you wish to deploy the app.  \n\n### Information for build troubleshooting.  \n\n  * One of the unusual things about PerfView is that it incorporates its support DLLs into the EXE itself, and these get \n  unpacked on first launch.  This means that there are tricky dependencies in the build that are not typical.    You will \n  see errors that certain DLLs can't be found if there were build problems earlier in the build.   Typically you can fix \n  this simply by doing a normal (non-clean) build, since the missing file will be present from the last compilation.\n  If this does not fix things, see if the DLL being looked for actually exists (if it does, then rebuilding should fix it).\n  It can make sense to go down the projects one by one and build them individually to see which one fails 'first'.\n  \n  * Another unusual thing about PerfView is that it includes an extension mechanism complete with samples.\n  This extensions mechanism is the 'Global' project (called that because it is the Global Extension whose commands don't have an\n  explicit 'scope') and needs to refer to PerfView to resolve some of its references.   Thus you will get many 'not found'\n  issues in the 'Global' project.  These can be ignored until you get every other part of the build working.\n\n  * One of the invariants of the repo is that if you are running Visual Studio 2017 and you simply sync and build the\n  PerfView.sln file, it is supposed to 'just work'.   If that does not happen, and the advice above does not help, then\n  we need to either fix the repo or update the advice above. Thus it is reasonable to open a GitHub issue. If you\n  do this, the goal is to fix the problem, which means you have to put enough information into the issue to do that.\n  This includes exactly what you tried, and what the error messages were.\n  \n  * You can also build PerfView from the command line (but you still need VS 2017 installed).   It is a two step process.\n  First you must restore all the needed nuget packages, then you do the build itself. To do this:\n    1. Open a developer command prompt.  You can do this by hitting the windows key (by the space bar) and type\n       'Developer command prompt'.  You should see a entry for this that you can select (if VS 2017 is installed).\n    2. Change directory to the base of your PerfView source tree (where PerfView.sln lives). \n    3. Restore the nuget packages by typing the command 'msbuild /t:restore'\n    4. Build perfView by typing the command 'msbuild'\n  \n  * If you get an error \"MSB8036: The Windows SDK version 8.1 was not found\",  Or you get a 'assert.h' not found error, or \n  frankly any error associated with building the ETWClrProfiler dlls, you should make sure that you have the Windows 8.1 \n  SDK installed (We like to build PerfView so it works event on Windows 8).    Unfortunately this library tends not to be \n  installed with Visual Studio anymore unless you ask for it explicitly.   To fix it \n     * windows-Key -> type Control panel -> Programs and Features, and right click on your VS2017 and select 'Modify'. Then look under the C++ Desktop Development and check that the Windows SDK 8.1 option is selected.  If not, select it and have the setup install this.  Then try building PerfView again.\n  \n### Running Tests\n\nPerfView has a number of *.Test projects that have automated tests.  They can be run in Visual Studio by selecting the\nTest -> Run -> All Tests menu item.    For the most thorough results (and certainly if you intend to submit changes) you \nneed to run these tests with a Debug build of the product (see the text window in the top toolbar, it says 'Debug' or 'Release').\nIf tests fail you can right click on the failed test and select the 'Debug' context menu item to run the test under \nthe debugger to figure out what went wrong.  \n\n### Check in testing and code coverage statistica\n\nThis repository uses [AppVeyor](https://www.appveyor.com/) and Azure DevOps to automatically build and test pull requests, which allows\nthe community to easily view build results. Code coverage is provided by [codecov.io](https://codecov.io). The build and\ncoverage status reflected here is the AppVeyor and Azure DevOps build status of the **main** branch.\n\n[![Build status](https://dev.azure.com/ms/perfview/_apis/build/status/CI?label=build)](https://dev.azure.com/ms/perfview/_build/latest?definitionId=332)\n\n[![Build status](https://ci.appveyor.com/api/projects/status/fxtu3xa874whk2w0?svg=true)](https://ci.appveyor.com/project/sharwell/perfview)\n\n[![codecov](https://codecov.io/gh/Microsoft/perfview/branch/main/graph/badge.svg)](https://codecov.io/gh/Microsoft/perfview)\n\n> :warning: Builds produced by AppVeyor and Azure DevOps CI are not considered official builds of PerfView, and are not signed or otherwise\n> validated for safety or security in any way. This build integration is provided as a convenience for community\n> participants, but is not endorsed by Microsoft nor is it considered an official release channel in any way. For\n> information about official builds, see the [PerfView Download Page](documentation/Downloading.md) page.\\\n\n### Contributing to PerfView \n\nYou can get a lot of value out of the source code base simply by being able to build the code yourself, debug\nthrough it or make a local, specialized feature, but the real power of open source software happens when\nyou contribute back to the shared code base and thus help the community as a whole.   **While we encourage this it \nrequires significantly more effort on your part**.   If you are interested in stepping up, see the \n[PerfView Contribution Guide](CONTRIBUTING.md) and [PerfView Coding Standards](documentation/CodingStandards.md) before you start.\n\n### Code Organization \n\nThe code is broken into several main sections:\n\n  * PerfView - GUI part of the application\n    * StackViewer - GUI code for any view with the 'stacks' suffix\n    * EventViewer - GUI code for the 'events' view window\n    * Dialogs - GUI code for a variety of small dialog boxes (although the CollectingDialog is reasonably complex)\n    * Memory - Contains code for memory investigations, in particular it defines 'Graph' and 'MemoryGraph' which are used \n      to display node-arc graphs (e.g. GC heaps)\n  * TraceEvent - Library that understands how to decode Event Tracing for Windows (ETW) which is used to actually \n  collect the data for many investigations\n  * MainWindow - GUI code for the window that is initially launched (lets you select files or collect new data)\n  * ETWClrProfiler* - There are two projects that build the same source either 32 or 64 bit.   This is (the only) native code\n  project in PerfView, and implements the CLR Profiler API and emits ETW events. It is used to trace object allocation\n  stacks and .NET method calls.  \n  * HeapDump* There are 32 and 64 bit versions of this project.  These make standalone executables that can dump the GC\n  heap using Microsoft.Diagnostics.Runtime APIs.  This allows getting heap dumps from debugger process dumps.  \n  * Global - An example of using PerfView's extensibility mechanism\n  * CSVReader - old code that lets PerfView read .ETL.CSV files generated by XPERF (probably will delete)\n  * Zip - a clone of System.IO.Compression.dll so that PerfView can run on pre V4.5 runtimes (probably will delete)\n  * [PerfViewJS](src/PerfViewJS/README.md) - contains a version of the GUI based on HTML and JavaScript (for Linux support). (experimental)\n\n### Other Documentation\n\nThese docs are for specialized scenarios \n\n  * [Updating SupportFiles](documentation/MakingSupportFilesNugetPackages.md) PerfView uses some binary files that it\ndoes not build itself. We created two nuget packages to hold these.  This document tells you how to update this\nnuget package when these files need to be updated. Very few people should care about these instructions.  \n\n  * [Internal Docs](https://devdiv.visualstudio.com/DevDiv/_git/perfview?_a=preview&path=%2Fdocumentation%2Finternal%2FinternalDocs.md&version=GBmain) This is documentation that is only \n  useful for internal Microsoft users. By design the link will not work for most people.\n"
 },
 {
  "repo": "microsoft/windows-admin-center-sdk",
  "language": "TypeScript",
  "readme_contents": "# Windows Admin Center SDK #\n\nWelcome to the Windows Admin Center SDK!  Windows Admin Center is an evolution of Windows Server in-box management tools; a locally deployed, browser-based management experience that supports scenarios where customers need full control of all aspects of their deployment, including private networks which aren\u2019t Internet-connected.\n\n### Get started with the SDK ###\n\nGetting started with Windows Admin Center development is easy!  Follow along with [step-by-step directions](https://docs.microsoft.com/windows-server/manage/windows-admin-center/extend/prepare-development-environment) to prepare your environment, and learn more about writing and publishing extensions at our [documentation site](https://aka.ms/WACSDKDocs).\n\nDon't have Windows Admin Center installed yet?  [Download](https://aka.ms/WACDownloadPage) Windows Admin Center.\n\n### Sample Code included with the SDK ###\n\n* Sample code can be found for **tool**, **solution**, and **gateway plugin** extension types in our [SDK documentation](https://aka.ms/WACSDKDocs).  There you will leverage the Windows Admin Center CLI to build a new extension project, then follow the individual guides to customize your project to meet your needs.\n\n* [Developer Tools](/windows-admin-center-developer-tools) is a repository of code to give you an example of how to use and include Windows Admin Center controls and styles in your extensions.  Just use the CLI to create your tool or solution, and then reference the code in the repository to see what is available.\n\nTo actually see the code in action, Use the [Extension Manager](/https://docs.microsoft.com/en-us/windows-server/manage/windows-admin-center/configure/using-extensions) to find the \"Windows Admin Center Developer Tools (Preview)\" extension and install it.  This will add a new solution to your gateway instance that has tools to help you explore the development environment.\n\n### SDK design toolkit ###\n\nCheck out our Windows Admin Center [SDK design toolkit](WindowsAdminCenterDesignToolkit.zip)! This toolkit is designed to help you rapidly mock up extensions in PowerPoint using Windows Admin Center styles, controls, and page templates. See what your extension can look like in Windows Admin Center before you start coding!\n\n### Contributing ###\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/react-native-dualscreen",
  "language": "TypeScript",
  "readme_contents": "# React Native dual-screen\nThis repo contains Microsoft's offerings to streamline [dual-screen](https://docs.microsoft.com/en-us/dual-screen/) cross-platform development using React Native. The modules in the repo will work on any platform, but only Android actually has a dual screen device (Duo).\n\n### Repo status\nSee below.  We currently have three npm packages for dual screen devices.\n\n\n## Offerings\nThis repo provides three modules\n* **TwoPaneView** layout component\n* **DualScreenInfo** lower-level module\n* **TwoPane-Navigation** navigation library for dual screen devices\n\nPlease find more details about the features as they were proposed and implemented.  Feel free to chime in with comments about [TwoPaneview](https://github.com/react-native-community/discussions-and-proposals/issues/197), [DualScreenInfo](https://github.com/react-native-community/discussions-and-proposals/issues/189) and \n[TwoPane-Navigation](https://github.com/microsoft/react-native-dualscreen/tree/master/twopane-navigation)!\n\n# React Native for Windows\nIn the meantime, for more information about React Native for Windows, including steps for [getting started](https://microsoft.github.io/react-native-windows/docs/getting-started), please visit our [website](https://microsoft.github.io/react-native-windows/). And keep an eye on our [blog](https://microsoft.github.io/react-native-windows/blog/) or follow [@ReactWindows](https://twitter.com/ReactWindows) on Twitter for new announcements!\n"
 },
 {
  "repo": "microsoft/sarif-pattern-matcher",
  "language": "C#",
  "readme_contents": "# sarif-pattern-matcher\n\n[![release](https://img.shields.io/github/v/release/microsoft/sarif-pattern-matcher?label=release)](https://github.com/microsoft/sarif-pattern-matcher/releases/latest)\n[![releases](https://img.shields.io/github/v/release/microsoft/sarif-pattern-matcher?include_prereleases&label=pre-release)](https://github.com/microsoft/sarif-pattern-matcher/releases)\n[![license](https://img.shields.io/github/license/microsoft/sarif-pattern-matcher)](https://github.com/microsoft/sarif-pattern-matcher/blob/master/LICENSE)\n\nQuality domain agnostic regular expression pattern matcher that persists results to SARIF\n\n## NuGet packages\n\nThe following packages are published from this repository:\n\n|| Latest Official Release|\n|-|-|\n| [Sarif.Pattern.Matcher](https://www.nuget.org/packages/Sarif.PatternMatcher/)| [![Nuget](https://img.shields.io/nuget/vpre/Sarif.PatternMatcher)](https://www.nuget.org/packages/Sarif.PatternMatcher/)|\n| [Sarif.Pattern.Matcher.Cli](https://www.nuget.org/packages/Sarif.PatternMatcher.Cli/)| [![Nuget](https://img.shields.io/nuget/vpre/Sarif.PatternMatcher.Cli)](https://www.nuget.org/packages/Sarif.PatternMatcher.Cli/)|\n| [Sarif.Pattern.Matcher.Sdk](https://www.nuget.org/packages/Sarif.PatternMatcher.Sdk/)| [![Nuget](https://img.shields.io/nuget/vpre/Sarif.PatternMatcher.Sdk)](https://www.nuget.org/packages/Sarif.PatternMatcher.Sdk/)|\n| [Sarif.Pattern.Matcher.Security](https://www.nuget.org/packages/Sarif.PatternMatcher.Security/)| [![Nuget](https://img.shields.io/nuget/vpre/Sarif.PatternMatcher.Security)](https://www.nuget.org/packages/Sarif.PatternMatcher.Security/)|\n| [RE2.Managed](https://www.nuget.org/packages/RE2.Managed/)| [![Nuget](https://img.shields.io/nuget/vpre/RE2.Managed)](https://www.nuget.org/packages/RE2.Managed/)|\n| [Strings.Interop](https://www.nuget.org/packages/Strings.Interop/)| [![Nuget](https://img.shields.io/nuget/vpre/Strings.Interop)](https://www.nuget.org/packages/Strings.Interop/)|\n\n## Getting started\n- [Creating plugins](./docs/getting-started/creating-plugins.md)\n- [Using the client tool](./docs/getting-started/using-the-client-tool.md)\n- [Using the library](./docs/getting-started/using-the-library.md)\n\n## How To Contribute\n\nsarif-pattern-matcher is accepting contributions. If you've submitted a PR for an existing issue, please post a comment in the issue to avoid duplication of effort. See our [CONTRIBUTING](/CONTRIBUTING.md) file for more information - it also contains guidelines for how to submit a PR.\n\n## License\n\n\"Sarif-pattern-matcher\" is licensed under `MIT license`. View [license](https://github.com/microsoft/sarif-pattern-matcher/blob/master/LICENSE).\n"
 },
 {
  "repo": "microsoft/Powerbi-Visuals-SampleMatrix",
  "language": "TypeScript",
  "readme_contents": "# Abstract\r\nThis is a reference visual demoing the Subtotals API availiable starting with the API 2.6 and announced/documented here: \r\nhttps://powerbi.microsoft.com/da-dk/blog/power-bi-developer-community-april-may-update/\r\n\r\n\r\n# Note: use pbiviz 2.5 to build the visual\r\n\r\nAs of Nov 14, 2019 the most recent version of PBIVIZ is producing a malfunctioning visual when packaged with \"pbiviz package\". \r\n\r\nUnless fixed in the future PBIVIZ releases, I would suggest that you use the older PBIVIZ toolset of verions 2.5.0. \r\n\r\nTo install it run: \r\n\r\nnpm install -g powerbi-visuals-tools@2.5.0\r\n\r\n# Known issue: subtotals not working in the debugger visual\r\n\r\nAs of Nov 17, 2019, subtotals are not working in the debugger visual. It\u2019s a known issue and I am currently investigating the root cause. \r\n\r\nPlease note the issue only affects the development process, while the release visuals (i.e., packaged PBIVIZ files) are working correctly in terms of the subtotals. \r\n\r\nCurrently, the best (partial) workaround would be to disable the minimization of the visuals in development (--no-minify pbiviz flag) and debugging in F12. \r\n"
 },
 {
  "repo": "microsoft/Ironclad",
  "language": "Dafny",
  "readme_contents": "# About\r\n\r\nTo learn more about the Ironclad Apps project, please see the related [README](./ironclad-apps/README.md) file.\r\n\r\nTo learn more about the IronFleet project, please see the related [README](./ironfleet/README.md) file.\r\n\r\n"
 },
 {
  "repo": "microsoft/setup-msbuild",
  "language": "TypeScript",
  "readme_contents": "# microsoft/setup-msbuild\r\nYou know how handy that 'Visual Studio Developer Command Prompt' is on your local machine?  And how it adds several things to `PATH` to allow you to just issue commands like `msbuild` or otherwise?  Use this action to setup similar flexibility in your Windows-based GitHub Actions runners.  This will let you discover where the `MSBuild` tool is and automatically add it to the `PATH` environment variables for you so future steps in your Actions workflow can just initiate `msbuild` commands without knowing the full path.\r\n\r\n> Please note this tools is not to replicate the full 'Developer Command Prompt' but only discover and assist with MSBuild and not other tools like cl.exe\r\n\r\n## Usage\r\n\r\n```yml\r\n- name: Add msbuild to PATH\r\n  uses: microsoft/setup-msbuild@v1.0.2\r\n```\r\n\r\n## Specifying specific versions of Visual Studio\r\nYou may have a situation where your Actions runner has multiple versions of Visual Studio and you need to find a specific version of the tool.  Simply add the `vs-version` input to specify the range of versions to find.  If looking for a specific version, specify the minimum and maximum versions as shown in the example below, which will look for just 16.4.\r\n\r\n```yml\r\n- name: Add msbuild to PATH\r\n  uses: microsoft/setup-msbuild@v1.0.2\r\n  with:\r\n    vs-version: '[16.4,16.5)'\r\n```\r\n\r\nThe syntax is the same used for Visual Studio extensions, where square brackets like \"[\" mean inclusive, and parenthesis like \"(\" mean exclusive. A comma is always required, but eliding the minimum version looks for all older versions and eliding the maximum version looks for all newer versions. See the [vswhere wiki](https://github.com/microsoft/vswhere/wiki) for more details.\r\n\r\n## How does this work?\r\nThis makes use of the vswhere tool which is a tool delivered by Microsoft to help in identifying Visual Studio installs and various components.  This tool is installed on the hosted Windows runners for GitHub Actions.  If you are using a self-hosted runner, you either need to make sure vswhere.exe is in your agent's PATH or specify a full path to the location using:\r\n\r\n```yml\r\n- name: Add msbuild to PATH\r\n  uses: microsoft/setup-msbuild@v1.0.2\r\n  with:\r\n    vswhere-path: 'C:\\path\\to\\your\\tools\\'\r\n```\r\n\r\n## Notes on arguments\r\nWhile the Action enables you to specify a `vswhere` path as well as a `vs-version`, these are more advanced options and when using GitHub-hosted runners you should not need these and is recommended you don't specify them.  Using these require you to fully understand the runner environment, updates to the tools on the runner, and can cause failures if you are out of sync.  For GitHub-hosted runners, omitting these arguments is the preferred usage.\r\n\r\n## Building this repo\r\nAs with most GitHub Actions, this requires NodeJS development tools.  After installing NodeJS, you can build this by executing:\r\n\r\n```bash\r\nnpm install\r\nnpm run build\r\nnpm run pack\r\n```\r\n\r\nwhich will modify/create the /dist folder with the final index.js output\r\n\r\n# Credits\r\nThank you to [Warren Buckley](https://github.com/warrenbuckley) for being a core contributor to this Action for the benefit of all developers!\r\n\r\n# Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/azure-devops-engineering-extensions",
  "language": "TypeScript",
  "readme_contents": "# Azure DevOps Engineering Marketplace Extensions\n\nAzureDevOps Marketplace Extensions to do various engineering tasks.\n\n## Email Report Task\nGenerates a Report with the information from the pipeline and sends it as email. Goal is to provide all the relevant info happened in the pipeline, in a concise and neat manner. \n\nRead more [here](Tasks/emailReportTask/README.md).\n\n## Pull Request Insights Task\nPullRequestInsightsTask provides insights into pipelines. This extension has two main functions:\n\n1. Investigating pull request validation failures\n2. Alerting pull request owners to the introduction of long running tasks.\n\nRead more [here](Tasks/pullRequestInsightsTask/README.md).\n\n# Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nTo build:\n\n```\nnpm install\nnpm run build // builds all tasks\nnpm run build:t1 // build specific task - first task\nnpm run build:t2 // builds second task - Refer package.json\n```\n\nTo run unit tests (at root): \n\n```\nnpm test\n```\n\nTo run PullRequestInsights task E2E w/o installing it on a pipeline: \n\n```\nnpm run e2e:emailreport // or look below\nnpm run e2e:t1 // proxy for above\nnpm run e2e:t2 // proxy for prinsights\n```\nVS Code Debugging option is also available. Use launch.json under .vscode directory.\nNote: E2E test(s) will fail by default with 401 errors as the restclients are not authenticated without providing correct credentials. Change E2E test code to supply correct credentials to test the scenario.\n\nPackaging:\n\nRun the pack command for each task. t1/t2/... are shortcuts for tasks in alphabhetical order. Please check package.json to confirm or use the actual names if preferred.\n```\nnpm run pack:t1 // if option not specified, \"dev\" is default. Doesn't create VSIX.\nnpm run pack:t1 prod // creates VSIX for emailReport\nnpm run pack:t2  // Doesn't create VSIX\nnpm run pack:t2 prod // Creates VSIX for pullRequestInsights\n```\nNote: Option \"dev\" doesn't create a VSIX file. Instead, it prepares the output task folder ready for upload to an AzureDevOps account and test it.\n\n####\n"
 },
 {
  "repo": "microsoft/azure-repos-pr-multi-cherry-pick",
  "language": "TypeScript",
  "readme_contents": "# Multi Cherry-Pick Tool\n\n[![Build Status](https://dev.azure.com/1es-cat/azure-repos-pr-multi-cherry-pick/_apis/build/status/microsoft.azure-repos-pr-multi-cherry-pick?branchName=master)](https://dev.azure.com/1es-cat/azure-repos-pr-multi-cherry-pick/_build/latest?definitionId=24&branchName=master)\n[![Release Status](https://vsrm.dev.azure.com/1es-cat/_apis/public/Release/badge/a185aa03-7d78-4c7d-b5fb-f7d997b096f9/1/1)](https://dev.azure.com/1es-cat/azure-repos-pr-multi-cherry-pick/_release?definitionId=1)\n\nThis tool offers an easy way to use the git cherry-pick operation to apply changes to multiple branches.\nFor each branch selected, a new topic branch will be created with the applied changes.\nIf the **Pull request** option is selected, a pull request will be opened to the target branch.\n\n<img width=\"434\" alt=\"Screen Shot 2019-05-13 at 1 00 27 PM\" src=\"https://user-images.githubusercontent.com/19557880/57650379-87229e00-757f-11e9-8966-e00bb5416c8f.png\"><img width=\"436\" alt=\"Screen Shot 2019-05-13 at 1 00 46 PM\" src=\"https://user-images.githubusercontent.com/19557880/57650380-87229e00-757f-11e9-9143-549002959cea.png\">\n\n## Quick steps to get started using the tool\n\n1. Install the extension from the [marketplace](https://marketplace.visualstudio.com/items?itemName=1ESLighthouseEng.pr-multi-cherry-pick) into your Azure DevOps organization.\n2. Navigate to your pull request.\n3. Select the context menu (...)\n4. Select **Multi-cherry-pick**.\n\n<p style=\"padding-left:25px\">\n<img width=\"409\" alt=\"Screen Shot 2019-05-10 at 4 20 10 PM\" src=\"https://user-images.githubusercontent.com/19557880/57596172-1a1af400-74fe-11e9-8c0d-18291d20590a.png\">\n</p>\n\n5. Add as many cherry-pick targets as you would like.\n6. After you click **Complete**, a summary page will appear with links to branches and PRs created from the tool.\n\n## Technologies used to develop the extension\n\n- Code written in Typescript; styling defined using SASS.\n- Webpack for watching and building files during development, and for building optimized bundles for production.\n- React for rendering a complex UI with user interaction.\n\n## How to build\n\n### **Download the required tools**\n\nYou will need:\n\n- [Visual Studio Code](https://code.visualstudio.com/download)\n- [Firefox](https://www.mozilla.org/firefox/) (the VS Code Debugger for Chrome extension [doesn\u2019t support iframes](https://github.com/microsoft/vscode-chrome-debug/issues/786) yet)\n- The [Debugger for Firefox](https://marketplace.visualstudio.com/items?itemName=hbenl.vscode-firefox-debug) VS Code extension\n\n### **Prereq: Organization permission level**\n\n- To develop and test the extension, you will need an organization in which you have permission to install extensions (e.g. you are the owner).\n- If you don't have a personal organization, you can [create an organization for free](https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/create-organization?view=azure-devops).\n\n### **Prereq: Node and NPM**\n\n- **Windows and Mac OSX**: Download and install node from [nodejs.org](http://nodejs.org/).\n\n- **Linux**: Install [using package manager](https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager).\n\nFrom a terminal ensure at least node 10.15 and npm 6.9. Use the following command to figure out what version you have installed locally:\n\n```bash\nnode -v && npm -v\n```\n\nThe following should appear in your terminal:\n\n```bash\nv10.15.0\n6.9.0\n```\n\nTo install npm separately and verify that it installed properly:\n\n```\n[sudo] npm install npm@6 -g\nnpm -v\n```\n\n**Note:** On Windows, if it's still returning npm 2.x, run `where npm`. Notice hits in program files. Rename those two npm files and the 5.6.0 in AppData will win.\n\n### **Prereq: Create a publisher**\n\nAll extensions, including extensions from Microsoft, live under a publisher. Anyone can create a publisher and publish extensions under it. You can also give other people access to your publisher if a team is developing the extension.\n\nYou will do one of two things:\n\n- Sign in to the Visual Studio Marketplace management portal\n- If you don't already have a publisher, you'll be prompted to create one. Learn how to create one [here](https://docs.microsoft.com/en-us/azure/devops/extend/publish/overview?view=azure-devops)\n\n### **Install dependencies**\n\nRun this command once:\n\n```bash\nnpm install\n```\n\n### **Build the Extension**\n\nThis extension uses webpack for bundling and webpack-dev-server for watching files and serving bundles during development.\nTwo bundles are defined for webpack: one for the main dialog and one for the extension context menu registration.\nAll actions can be triggered using npm scripts (`npm run <target>`) with no additional task runner required.\n\n### **Deploy the Extension**\n\nYou will need to deploy your extension to the marketplace at least once so that you can share it with your organization\nand install it. In order to do this, you will need to generate a personal access token (PAT). Learn how to do that [here](https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops). When creating your PAT, under **Organization**, select **All accessible organizations**, and set the **Marketplace** scope to **Publish**.\n\nThen run once, inserting your PAS into [token]:\n\n```bash\nnpm run publish:dev -- \u00a0--token [token]\n```\n\nYou will then need to install and share your extension, learn how to do that [here](https://docs.microsoft.com/en-us/azure/devops/extend/get-started/node?toc=%2Fazure%2Fdevops%2Fextend%2Ftoc.json&bc=%2Fazure%2Fdevops%2Fextend%2Fbreadcrumb%2Ftoc.json&view=azure-devops#install-your-extension).\n\nOnce the extension is installed, you will notice that it won\u2019t load correctly. It isn't loading because we configured it to load all its resources (html, images, etc.) from `localhost:3000`, but there is no server running yet.\n\nTo start webpack-dev-server run:\n\n```bash\nnpm run start:dev\n```\n\nNow if you go to `localhost:3000` in your browser, you should get an untrusted certificate error page. Select **Advanced** and then trust the certificate. Go back to Azure DevOps and your extension should now load correctly and any changes to the source code will cause webpack to recompile and reload the extension automatically.\n\nAlthough most code changes will be reflected immediately, you may still need to occasionally update your extension in the marketplace. The dev extension loads all its resources from the webpack-dev-server, but the manifest itself is being loaded from the published code. Therefore, any changes to the manifest file will not be properly reflected in Azure DevOps until the extension has been republished.\n\n### **Configure your VS Code project to debug against Azure DevOps**\n\nIn VS Code, press **F5** to start debugging (making sure the webpack-dev-server is still running). The default launch configuration should be set to **Firefox**. \n\n**Note**: Chrome configurations are included in the sample as well in case the Chrome debugging extension eventually supports iframes. However, debugging iframes is only supported in the Debugger for Firefox extension for now.\n\nOnce Firefox starts up, you will have to go through the steps of allowing the `localhost:3000` certificate again and log into your Azure DevOps account. From now on, if you leave this Firefox window open, the debugger will reattach instead of starting a clean Firefox instance each time.\n\nOnce you are logged in to Azure DevOps, your extension should be running. Set a breakpoint in a method in VS Code and you should see that breakpoint hit when that method executes.\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/botframework-components",
  "language": "C#",
  "readme_contents": "# Bot Framework Components\n\nThis repository contains *components* published by Microsoft for bots built on the Azure Bot Framework technology stack. They are part of the component model for building bots with re-usable building blocks. The model is built on a configurable [adaptive runtime](#adaptive-runtime), that can be extended by adding your own code, importing [packages](#packages) of functionality or connecting to other bots as [skills](#skills). Getting started [templates](#templates) provide dynamic code scaffolding, helping users get started quickly based on their scenario.\n\n## Using Components\n\nYou'll primarily use components through [**Bot Framework Composer**](https://github.com/microsoft/BotFramework-Composer) - our visual bot authoring canvas for developers. From Composer you can add and remove packages from your bot, and the creation process creates bots built from the templates here.\n\n## Creating your own components\n\nYou can also create your own packages and templates for use from Composer. We document creating components [here](/docs/overview.md). You can use this repository as examples for building your own components.\n\n## Index of Content\n\n### Templates\n\nTemplates are pre-built bot projects designed for specific scenarios. We use [yeoman](https://yeoman.io) generators for scaffolding our templates.\n\n| Name         | npm | Description |\n|:------------:|:---:|:------------|\n|[Empty Bot](/generators/generator-bot-empty) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-empty.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-empty) | A simple bot with a root dialog and greeting dialog. |\n|[Core Bot with Azure Language Understanding](/generators/generator-bot-core-language) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-core-language.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-core-language) | A simple bot with Azure Language Understanding (LUIS) and common trigger phrases used to direct the conversation flow. |\n|[Core Assistant Bot](/generators/generator-bot-core-assistant) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-core-assistant.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-core-assistant) | A bot with Azure Language Understanding (LUIS) and common trigger phrases used to direct the conversation flow and help customers accomplish basic tasks. Designed to be extended with skills. |\n|[Enterprise Assistant Bot](/generators/generator-bot-enterprise-assistant) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-enterprise-assistant.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-enterprise-assistant) | A Core Assistant Bot with Calendar & People as skills. |\n|[Enterprise Calendar Bot](/generators/generator-bot-enterprise-calendar) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-enterprise-calendar.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-enterprise-calendar) | A bot with the ability to interact with M365 Calendar using Microsoft Graph. |\n|[Enterprise People Bot](/generators/generator-bot-enterprise-people) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-enterprise-people.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-enterprise-people) | A bot with the ability to search for people within Azure Active Directory using Microsoft Graph.|\n|[Adaptive Bot Generator](/generators/generator-bot-adaptive) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-adaptive.svg)](https://badge.fury.io/js/%40microsoft%2Fgenerator-bot-adaptive) | Used by other generators to scaffold web app or functions project. |\n\n### Packages\n\nPackages are bits of bots that you can add to your bot project. They can contain coded extensions like custom actions, adapters, or triggers, and declarative assets like dialogs, language generation or language understanding files.\n\n| Name         |Type   | NuGet | npm |Description |\n|:------------:|:------|:-----:|:---:|:-----------|\n|[Welcome](/packages/Welcome) | Dialogs | [![NuGet Badge](https://buildstats.info/nuget/Microsoft.Bot.Components.Welcome?includePreReleases=true)](https://www.nuget.org/packages/Microsoft.Bot.Components.Welcome/)| [![npm version](https://badge.fury.io/js/%40microsoft%2Fbot-components-welcome.svg)](https://badge.fury.io/js/%40microsoft%2Fbot-components-welcome) | Declarative assets supporting scenarios that welcome new and returning users. |\n|[HelpAndCancel](/packages/HelpAndCancel) | Dialogs | [![NuGet Badge](https://buildstats.info/nuget/Microsoft.Bot.Components.HelpAndCancel?includePreReleases=true)](https://www.nuget.org/packages/Microsoft.Bot.Components.HelpAndCancel/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fbot-components-helpandcancel.svg)](https://badge.fury.io/js/%40microsoft%2Fbot-components-helpandcancel) | Declarative assets supporting scenarios for \"help\" and \"cancel\" utterances. |\n|[Graph](/packages/Graph) | Custom Actions | [![NuGet Badge](https://buildstats.info/nuget/Microsoft.Bot.Components.Graph?includePreReleases=true)](https://www.nuget.org/packages/Microsoft.Bot.Components.Graph/) | | Custom actions for working with calendars and people through the MS Graph API.|\n|[Teams](/packages/Teams) | Triggers Actions | [![NuGet Badge](https://buildstats.info/nuget/Microsoft.Bot.Components.Teams?includePreReleases=true)](https://www.nuget.org/packages/Microsoft.Bot.Components.Teams/) | | Triggers and actions for working with Microsoft Teams.|\n\n### Virtual Assistant skills (Legacy)\n\nSkills built to work with the [Virtual Assistant](https://docs.microsoft.com/azure/bot-service/bot-builder-virtual-assistant-introduction) template. You can find the list of Virtual Assistant skills [here](/skills/csharp/readme.md).\n\n## Need Help?\n\nPlease use this GitHub repository issue to raise any [issues](https://github.com/Microsoft/botframework-components/issues/new?assignees=&labels=Type%3A+Bug&template=bug_report.md&title=) you encounter consuming these components, or [feature requests](https://github.com/Microsoft/botframework-components/issues/new?assignees=&labels=Type%3A+Feature&template=feature_request.md&title=) you'd like to see added.\n\n## Contributing\n\nWe welcome contributions to this repository! Please see our [wiki](https://github.com/microsoft/botframework-components/wiki) for details on how to contribute.\n\nIf you'd like to contribute a completely new package or template, please use our [community repo](https://github.com/BotBuilderCommunity/) and we can help publish them for you, or feel free to blaze your own trail and publish them independently.\n\n## Reporting Security Issues\n\nSecurity issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) at [secure@microsoft.com](mailto:secure@microsoft.com). You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the [MSRC PGP](https://technet.microsoft.com/security/dn606155) key, can be found in the [Security TechCenter](https://technet.microsoft.com/security/default).\n\n## License\n\nMIT License\n\nCopyright (c) Microsoft Corporation.\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE."
 },
 {
  "repo": "microsoft/WinAppDriver",
  "language": "C#",
  "readme_contents": "## Windows Application Driver\nWindows Application Driver (WinAppDriver) is a service to support Selenium-like UI Test Automation on Windows Applications. This service supports testing **Universal Windows Platform (UWP)**, **Windows Forms (WinForms)**, **Windows Presentation Foundation (WPF)**, and **Classic Windows (Win32)** apps on **Windows 10 PCs**. \n\n### Install & Run WinAppDriver\n1. Download Windows Application Driver installer from <https://github.com/Microsoft/WinAppDriver/releases>\n2. Run the installer on a Windows 10 machine where your application under test is installed and will be tested\n3. Enable [Developer Mode](https://docs.microsoft.com/en-us/windows/uwp/get-started/enable-your-device-for-development) in Windows settings\n4. Run `WinAppDriver.exe` from the installation directory (E.g. `C:\\Program Files (x86)\\Windows Application Driver`)\n\nWindows Application Driver will then be running on the test machine listening to requests on the default IP address and port (`127.0.0.1:4723`). You can then run any of our [Tests](/Tests/) or [Samples](/Samples). `WinAppDriver.exe` can be configured to listen to a different IP address and port as follows:\n\n```\nWinAppDriver.exe 4727\nWinAppDriver.exe 10.0.0.10 4725\nWinAppDriver.exe 10.0.0.10 4723/wd/hub\n```\n\n> **Note**: You must run `WinAppDriver.exe` as **administrator** to listen to a different IP address and port.\n\n### Write an Automation Script\nNow that you've successfully installed WinAppDriver, you can get started with [authoring your first automation script](./Docs/AuthoringTestScripts.md)! \n\n### Supported APIs\n\nSee [here](./Docs/SupportedAPIs.md) for a list of supported APIs by WinAppDriver. API support may differ from Appium and other counterparts.\n\n## FAQ & Documentation\nAdditional documentation on WinAppDriver and related topics can be found under [/Docs/](./Docs/), such as the following:\n   - [Frequently Asked Questions](./Docs/FAQ.md) \n     - [General Development & Best Practices](./Docs/FAQ.md#general-development--best-practices) \n     - [Using with Appium](./Docs/UsingAppium.md)\n   - [Running WinAppDriver in CI (with Azure Pipelines)](./Docs/CI_AzureDevOps.md) \n   - [Using UI Recorder](./Docs/UsingUIRecorder.md)\n   - [Authoring Test Scripts](./Docs/AuthoringTestScripts.md)\n   - [Using the Selenium Grid](./Docs/SeleniumGrid.md) \n   - [Running On a Remote Machine](./Docs/RunningOnRemoteMachine.md)\n\n## Repository Content\nThis repository includes the following content:\n* [Samples](https://github.com/Microsoft/WinAppDriver/tree/master/Samples) - used to showcase various commands and operations such as opening applications, finding elements, clicking elements, typing keystrokes, reading texts, etc; and can be run against built-in Windows 10 applications such as **Alarms & Clock**, **Calculator**, and **Notepad**. \n* [Tests](https://github.com/Microsoft/WinAppDriver/tree/master/Tests) - used to verify the functionality of **Windows Application Driver** itself. The tests cover each API endpoints extensively and also against all basic UI control scenario, and demonstrate how to invoke certain command in C#. In addition, they show how to interact with some more complex UI elements such as **DatePicker**, **SplitViewPane**, **Slider**, etc.\n* [UI Recorder](https://github.com/microsoft/WinAppDriver/tree/master/Tools/UIRecorder) - standalone tool that aims to provide users a simpler way of creating automaton scripts by recording UI events performed by the user and generating XPath queries and C# code on the fly. Read more about it on our [Wiki](https://github.com/Microsoft/WinAppDriver/wiki/WinAppDriver-UI-Recorder). \n* [Docs](./Docs/) - subdirectory hosting WinAppDriver related documentation. \n\n## Vote on New Features\nAdd your feature request in [issues](../../issues/) or :+1: (+1) existing issues labeled as **Enhancement**\n"
 },
 {
  "repo": "microsoft/responsible-ai-widgets",
  "language": "TypeScript",
  "readme_contents": "![Responsible AI Widgets Python Build](https://github.com/microsoft/responsible-ai-widgets/workflows/Responsible%20AI%20Widgets/badge.svg) ![CD](https://github.com/microsoft/responsible-ai-widgets/workflows/CD/badge.svg) ![MIT license](https://img.shields.io/badge/License-MIT-blue.svg) ![PyPI raiwidgets](https://img.shields.io/pypi/v/raiwidgets?color=blue) ![PyPI rai_core_flask](https://img.shields.io/pypi/v/rai_core_flask?color=blue) ![npm fairness](https://img.shields.io/npm/v/@responsible-ai/fairness?label=npm%20%40responsible-ai%2Ffairness) ![npm interpret](https://img.shields.io/npm/v/@responsible-ai/interpret?label=npm%20%40responsible-ai%2Finterpret) ![npm mlchartlib](https://img.shields.io/npm/v/@responsible-ai/mlchartlib?label=npm%20%40responsible-ai%2Fmlchartlib) ![npm core-ui](https://img.shields.io/npm/v/@responsible-ai/core-ui?label=npm%20%40responsible-ai%2Fcore-ui) ![npm dataset-explorer](https://img.shields.io/npm/v/@responsible-ai/dataset-explorer?label=npm%20%40responsible-ai%2Fdataset-explorer) ![npm causality](https://img.shields.io/npm/v/@responsible-ai/causality?label=npm%20%40responsible-ai%2Fcausality) ![npm counterfactuals](https://img.shields.io/npm/v/@responsible-ai/counterfactuals?label=npm%20%40responsible-ai%2Fcounterfactuals)\n\n# Responsible-AI-Widgets\n\n\nResponsible-AI-Widgets provides a collection of model and data exploration and assessment user interfaces that enable better understanding of AI systems. Together, these interfaces empower developers and stakeholders of AI systems to develop and monitor AI more responsibly. Currently, there are three widgets demonstrating how to interpret models and assess their errors and fairness issues.\n\nThis repository contains the Jupyter notebooks with examples to showcase how to use these widgets.\n\n## Contents\n\n- [Overview of Responsible-AI-Widgets](#intro)\n- [Interpretability Dashboard](#interpretability-dashboard)\n- [Error Analysis Dashboard](#error-analysis-dashboard)\n- [Fairness Dashboard](#fairness-dashboard)\n- [Supported Models](#supported-models)\n- [Getting Started](#getting-started)\n\n<a name=\"intro\"></a>\n\n## Overview of Responsible-AI-Widgets\nResponsible-AI-Widgets extends the [Interpret-Community](https://github.com/interpretml/interpret-community) and [Fairlearn](https://github.com/fairlearn/fairlearn) repositories and provides user interfaces for model interpretability and fairness assessment of machine learning models. It introduces Error Analysis, a toolkit to identify and diagnose errors in machine learning models.  The following table shows a list of the user interfaces available in this repository:\n\n| User Interface | Description | Use Case  (Assessing a loan allocation model to accept or deny home loan applicants.) |\n| --- | --- | --- |\n| Interpretability Dashboard |  User interface for [Interpret-Community](https://github.com/interpretml/interpret-community) which enables you to 1) evaluate your model by observing its performance metrics, 2) explore your dataset statistics, 3) understand the most important factors impacting your model\u2019s overall (global) and individual (local) predictions, 4) debug models by performing a variety of feature perturbation operations (e.g., what-if analysis and Individual Conditional Expectation Plots), and 5) Understand your model\u2019s explanations on different demographics. | Use the Interpretability dashboard to understand which factors have the most impact on your model's accept/deny decisions. Observe this for the whole population, for a subset of applicants (e.g., females), and individuals (such as why Mary\u2019s loan got rejected). |\n| Error Analysis (+ Interpretability) Dashboard |  Use the Error Analysis dashboard to 1) ***Identify*** cohorts with high error rate versus benchmark and visualize how the error rate is distributed. 2) ***Diagnose*** the root causes of the errors by visually diving deeper into the characteristics of data and models (via its embedded interpretability capabilities) | Use Error Analysis to discover that the model has a higher error rate for a specific cohort (e.g., females with income <$50K) vs. the rest of the population. Next, use the embedded interpretability capabilities of this dashboard to understand most impactful factors responsible for this subset\u2019s erroneous predictions. Moreover, use interpretability to inspect some individuals of that cohort receiving erroneous predictions, understand their feature importance values, and perform what-if analysis on them to diagnose the contributing error factors better. |\n| Fairness Dashboard |  User interface for [Fairlearn](https://github.com/fairlearn/fairlearn) which enables you to use common fairness metrics to assess which groups of people may be negatively impacted (females vs. males vs. non-binary gender). Also explore Fairlearn's state-of-the-art unfairness mitigation algorithms to mitigate fairness issues in your classification and regression models.  | Use Fairness dashboard to assess harm of allocation (i.e., to understand whether your loan allocation model approves more applications of a specific advantaged group). Use Fairness dashboard to assess harm of quality of service (i.e., Understand how your model performs on applications of your qualified males group vs. qualified females/non-binary gender.) Navigate trade offs between fairness and performance of your loan allocation model. Use [Fairlearn](https://github.com/fairlearn/fairlearn)'s mitigation algorithms to mitigate the observed fairness issues. |\n\nBesides the above functionalities, this repository provides foundational blocks such as \n\n- A shared Flask service layer which also maintains utilities to determine the environment that it is running in so that it can configure the local flask service accordingly. This layer is published in the ```rai_core_flask``` package on PyPI.\n\n- A base typescript library with common controls used across responsible AI dashboards. For information on how to contribute please refer to our [Contributor Guide](CONTRIBUTING.md).\n\n## Example Notebooks\n\n- [Interpretability for binary classification (employee attrition)](https://github.com/microsoft/responsible-ai-widgets/blob/master/notebooks/interpretability-dashboard-employee-attrition.ipynb)\n- [Fairness assessment of a loan allocation model](https://github.com/microsoft/responsible-ai-widgets/blob/master/notebooks/fairness-dashboard-loan-allocation.ipynb)\n- [Joint Example: Interpretability and fairness assessment a loan allocation model](https://github.com/microsoft/responsible-ai-widgets/blob/master/notebooks/fairness-interpretability-dashboard-loan-allocation.ipynb)\n\n- [Error analysis and interpretability of a census income prediction model](https://github.com/microsoft/responsible-ai-widgets/blob/master/notebooks/erroranalysis-interpretability-dashboard-census.ipynb)\n- [Error analysis and interpretability of a breast cancer prediction model](https://github.com/microsoft/responsible-ai-widgets/blob/master/notebooks/erroranalysis-interpretability-dashboard-breast-cancer.ipynb)\n\n\n<a name=\"interpretability dashboard\"></a>\n\n## Interpretability Dashboard\n\nPlease refer to [Interpret-Community](https://github.com/interpretml/interpret-community)'s README and [sample notebooks](https://github.com/interpretml/interpret-community/tree/master/notebooks) to learn how you can train and generate model explanations.  Once your model is trained and your explanation object is generated, load the interpretability visualization dashboard in your notebook to understand and interpret your model:\n\n```python\nfrom raiwidgets import ExplanationDashboard\n\nExplanationDashboard(global_explanation, model, dataset=x_test, true_y=y_test)\n```\nOnce you load the visualization dashboard, you can investigate different aspects of your dataset and trained model via four tab views: \n\n* Model Performance\n* Data Explorer\t\n* Aggregate Feature Importance\n* Individual Feature Importance and what-if\t\n\n---\n**NOTE**\n\nClick on \"Open in a new tab\" on the top left corner to get a better view of the dashboard in a new tab.\n\n---\n\nYou can further create custom cohorts (subgroups of your dataset) to explore the insights across different subgroups (e.g., women vs. men). The created cohorts can contain more than one filter (e.g., age < 30 and sex = female) and will be visible from all of the four tabs. The following sections demonstrate the visualization dashboard capabilities on a [classification model trained on employee attrition dataset](https://github.com/microsoft/responsible-ai-widgets/blob/master/notebooks/interpretability-dashboard-employee-attrition.ipynb). Besides the default cohort (including the whole dataset), there are two additional cohorts created: employees with Age <= 35 and employees with Age > 35.\n\n![Visualization Dashboard Cohorts](./img/Interpretability-Cohorts.png)\n\n### Model performance\n\nThis tab enables you to evaluate your model by observing its performance metrics and prediction probabilities/classes/values across different cohorts.\n\n![Visualization Dashboard Cohorts](./img/Interpretability-ModelPerformance.png)\n\n### Dataset explorer\nYou can explore your dataset statistics by selecting different filters along the X, Y, and color axes of this tab to slice your data into different dimensions.\n\n![Visualization Dashboard Cohorts](./img/Interpretability-DatasetExplorer.png)\n\nThe following plots provide a global view of the trained model along with its predictions and explanations.\n\n### Aggregate feature importance (global explanation)\n\nThis view consists of two charts:\n\n| Plot | Description |\n| --- | --- |\n| Feature Importance | Explore the top K important features that impact your overall model predictions (a.k.a. global explanation). Use the slider to show additional less important feature values. Select up to three cohorts to see their feature importance values side by side. |\n| Dependence Plot | Click on any of the feature bars in the feature importance graph to see the relationship of the values of the selected feature to its corresponding feature importance values. Overall, this plot show how values of the selected feature impact model prediction. |\n\n![Visualization Dashboard Global](./img/Interpretability-GlobalExplanation.png)\n\n### Individual feature importance (local explanation) and what-if\n\nYou can click on any individual data point on the scatter plot to view its local feature importance values (local explanation) and individual conditional expectation (ICE) plot below. These are the capabilities covered in this tab:\n\n| Plot | Description |\n| --- | --- |\n| Feature Importance Plot | Shows the top K (configurable K) important features for an individual prediction. Helps illustrate the local behavior of the underlying model on a specific data point. |\n| Individual Conditional Expectation (ICE) | Allows feature value changes from a minimum value to a maximum value. Helps illustrate how the data point's prediction changes when a feature changes. |\n| Perturbation Exploration (what-if analysis) | Allows changes to feature values of the selected data point to observe resulting changes to prediction value. You can then save your hypothetical what-if data point. |\n\n![Visualization Dashboard Global](./img/Interpretability-LocalExplanation.png)\n\n![Visualization Dashboard Global](./img/Interpretability-WhatIf.gif)\n\n<a name=\"error analysis dashboard \"></a>\n\n## Error Analysis Dashboard\n\nIntroducing the latest addition to the Responsible AI open-source toolkit collection, Error Analysis drives deeper to provide a better understanding of your machine learning model's behaviors. Use Error Analysis to identify cohorts with higher error rates and diagnose the root causes behind these errors. Combined with [Fairlearn](github.com/fairlearn/fairlearn) and [Interpret-Community](https://github.com/interpretml/interpret-community), practitioners can perform a wide variety of assessment operations to build responsible machine learning. Use this dashboard to:\n\n1. Evaluate Cohorts: Learn how errors distribute across different cohorts at different levels of granularity \n2. Explore Predictions: Use built-in interpretability features or combine with InterpretML for boosted debugging capability \n3. Interactive Dashboard View customizable pre-built visuals to quickly identify errors and diagnose root causes\n\nRun the dashboard via:\n\n```python\nfrom raiwidgets import ErrorAnalysisDashboard\n\nErrorAnalysisDashboard(global_explanation, dashboard_pipeline, dataset=X_test_original,\n                       true_y=y_test, categorical_features=categorical_features)\n```\nOnce you load the visualization dashboard, you can investigate different aspects of your dataset and trained model via two stages:\n\n* Identification\n* Diagnosis\n\n---\n**NOTE**\n\nClick on \"Open in a new tab\" on the top left corner to get a better view of the dashboard in a new tab.\n\n---\n\n### Identification of Errors\n\nError Analysis identifies cohorts of data with higher error rate than the overall benchmark. These discrepancies might occur when the system or model underperforms for specific demographic groups or infrequently observed input conditions in the training data.\n\n#### Different Methods for Error Identification\n\n1. Decision Tree: Discover cohorts with high error rates across multiple features using the binary tree visualization. Investigate indicators such as error rate, error coverage, and data representation for each discovered cohort. ![Error Analysis tree map](./img/EA-TreeMap.png)\n\n2. Error Heatmap: Once you form hypotheses of the most impactful features for failure, use the Error Heatmap to further investigate how one or two input features impact the error rate across cohorts. ![Error Analysis heat map](./img/EA-Heatmap.png)\n\n### Diagnosis of Errors\n\nAfter identifying cohorts with higher error rates, Error Analysis enables debugging and exploring these cohorts further. Gain deeper insights about the model or the data through data exploration and model explanation. Different Methods for Error Diagnosis:\n\n1. Data Exploration which explores dataset statistics and feature distributions. Compare cohort data stats with other cohorts or to benchmark data. Investigate whether certain cohorts are underrepresented or if their feature distribution is significantly different from the overall data.\n\n2. Global Explanation which explore the top K important features that impact the overall model global explanation for a selected cohort of data. Understand how values of features impact model prediction. Compare explanations with those from other cohorts or benchmark.\n\n3. Local Explanation which enables observing the raw data in the Instance View. Understand how each data point has correct or incorrect prediction. Visually identify any missing features or label noise that could lead to issues. Explore local feature importance values (local explanation) and individual conditional expectation (ICE) plots.\n\n4. What-if analysis (Perturbation Exploration) which applies changes to feature values of selected data point and observe resulting changes to the prediction.\n\n<a name=\"fairness dashboard\"></a>\n\n## Fairness Dashboard\n\nPlease refer to [Fairlearn](https://github.com/fairlearn/fairlearn)'s README and [user guide](https://fairlearn.github.io/v0.5.0/user_guide/index.html) to learn how you can assess and mitigate model's fairness issues.  Once your model is trained, load the Fairness dashboard in your notebook to understand how your model\u2019s predictions impact different groups (e.g., different ethnicities). Compare multiple models along different fairness and performance metrics.\n\n### Setup and single-model assessment\nTo assess a single model\u2019s fairness and performance, the dashboard widget can be launched within a Jupyter notebook as follows:\n\n```python\nfrom raiwidgets import FairnessDashboard\n\n# A_test contains your sensitive features (e.g., age, binary gender)\n# y_true contains ground truth labels\n# y_pred contains prediction labels\n\nFairnessDashboard(sensitive_features=A_test,\n                  y_true=Y_test.tolist(),\n                  y_pred=[y_pred.tolist()])\n```\n\nOnce you load the visualization dashboard, the widget walks the user through the assessment setup, where the user is asked to select\n![Fairness Dashboard Sensitive Feature](./img/Fairness-Intro.png)\n\n1. The sensitive feature of interest (e.g., ```binary gender``` or ```age```).\n![Fairness Dashboard Fairness Metric](./img/Fairness-SensitiveMetric.png)\n\n2. The performance metric (e.g., model precision) along which to evaluate the overall model performance. \n![Fairness Dashboard Fairness Metric](./img/Fairness-PerformanceMetric.png)\n\n3. The fairness metric (e.g., demographic parity ratio) along which to evaluate any disparities across groups. \n![Fairness Dashboard Fairness Metric](./img/Fairness-FairnessMetric.png)\n\nThese selections are then used to obtain the visualization of the model\u2019s impact on the subgroups.  (e.g., one is interested to consider non-binary gender for fairness testing and selects \"demographic parity ratio\" as a metric of interest to see how females and males are selected to get a loan).\n\n![Fairness Dashboard Fairness Assessment View 1](./img/Fairness-SelectionRate.png)\n\n![Fairness Dashboard Fairness Assessment View 2](./img/Fairness-DisparityInPerformance.png)\n\n### Comparing multiple models\n\nThe dashboard also enables comparison of multiple models, such as the models produced by different learning algorithms and different mitigation approaches, including Fairlearn's [GridSearch](https://fairlearn.github.io/v0.5.0/api_reference/fairlearn.reductions.html#fairlearn.reductions.GridSearch), [ExponentiatedGradient](https://fairlearn.github.io/v0.5.0/api_reference/fairlearn.reductions.html#fairlearn.reductions.ExponentiatedGradient), and [ThresholdOptimizer](https://fairlearn.github.io/v0.5.0/api_reference/fairlearn.postprocessing.html#fairlearn.postprocessing.ThresholdOptimizer).\n\nAs before, select the sensitive feature and the performance metric. The model comparison view then depicts the performance and disparity of all the provided models in a scatter plot. This allows the you to examine trade-offs between performance and fairness. Each of the dots can be clicked to open the assessment of the corresponding model. The figure below shows the model comparison view with ```binary gender``` selected as a sensitive feature and accuracy rate selected as the performance metric.\n\n![Fairness Dashboard Model Comparison](./img/Fairness-ModelComparison.png)\n \n<a name=\"supported models\"></a>\n\n## Supported Models\n\nThis interpretability and error analysis API supports models that are trained on datasets in Python `numpy.array`, `pandas.DataFrame`, `iml.datatypes.DenseData`, or `scipy.sparse.csr_matrix` format.\n\nThe explanation functions of [Interpret-Community](https://github.com/interpretml/interpret-community) accept both models and pipelines as input as long as the model or pipeline implements a `predict` or `predict_proba` function that conforms to the Scikit convention. If not compatible, you can wrap your model's prediction function into a wrapper function that transforms the output into the format that is supported (predict or predict_proba of Scikit), and pass that wrapper function to your selected interpretability techniques.  \n\nIf a pipeline script is provided, the explanation function assumes that the running pipeline script returns a prediction. The repository also supports models trained via **PyTorch**, **TensorFlow**, and **Keras** deep learning frameworks.\n\n<a name=\"getting started\"></a>\n\n## Getting Started\n\nThis repository uses Anaconda to simplify package and environment management.\n\nTo setup on your local machine:\n\n<details><summary><strong><em>Install Python module, packages and necessary distributions</em></strong></summary>\n\n```\npip install raiwidgets\n```\n\nIf you intend to run repository tests:\n\n```\npip install -r requirements.txt\n```\n\n</details>\n\n<details>\n<summary><strong><em>Set up and run Jupyter Notebook server </em></strong></summary>\n\nInstall and run Jupyter Notebook\n\n```\nif needed:\n          pip install jupyter\nthen:\njupyter notebook\n```\n</details>\n\n## Maintainers\n\n- [Ke Xu](https://github.com/KeXu444)\n- [Roman Lutz](https://github.com/romanlutz)\n- [Ilya Matiach](https://github.com/imatiach-msft)\n- [Dawei Li](https://github.com/chnldw)\n"
 },
 {
  "repo": "microsoft/azure-devops-auth-samples",
  "language": "PowerShell",
  "readme_contents": "# Auth samples for Azure DevOps Services\n\n![status](https://dev.azure.com/mseng/_apis/public/build/definitions/b924d696-3eae-4116-8443-9a18392d8544/5326/badge)\n\nSamples that show how to authenticate with Azure DevOps and Azure DevOps Server.\n\nLearn more about [integrating with Azure DevOps](https://docs.microsoft.com/en-us/azure/devops/extend/overview?view=vsts) and [specific authentication guidance](https://docs.microsoft.com/en-us/azure/devops/integrate/get-started/authentication/authentication-guidance?view=vsts)\n\n## Samples\n\n* [Managed client sample (using Azure Active Directory Library)](./ManagedClientConsoleAppSample/README.md)\n* [Device profile sample (.NET Core)](./DeviceProfileSample/README.md)\n* [ASP.NET Web app OAuth sample](./OAuthWebSample/README.md)\n* [Client library sample (using VSSConnection)](./ClientLibraryConsoleAppSample/README.md)\n* [Javascript web app sample (using Microsoft Authentication Library for JavaScript)](./JavascriptWebAppSample/README.md)\n* [Dual Support (Azure DevOps/TFS) Client Sample (using Azure Active Directory Library and Windows Authentication)](./DualSupportClientSample/README.md)\n* [Non-interactive PAT Generation Sample (using Azure Active Directory Library with a Username Password credential)](./NonInteractivePatGenerationSample/README.md)\n* [PAT lifecycle management API sample (using Microsoft Authentication Library with authentication code)](./PersonalAccessTokenAPIAppSample/README.md)\n"
 },
 {
  "repo": "microsoft/angular-react",
  "language": "TypeScript",
  "readme_contents": "# React support for Angular\n\n[![CircleCI](https://circleci.com/gh/microsoft/angular-react.svg?style=svg)](https://circleci.com/gh/microsoft/angular-react)\n\nIndustry trends, organizational pressures, and other factors can lead to mandates regarding the use of component libraries or migration from one technology to another. In the case of [Office UI Fabric][fab], where its use is required, the client must be written in React (there is no Angular component library for the latest version). Rewrite from Angular to React may be cost-prohibitive or ill advised for other reasons.\n\nUse of Angular-React allows consuming any React elements, but specifically Office UI Fabric, within an Angular [2+] application. The library of wrappers for Office UI Fabric simplifies the use of these components with Angular. However, any React code can make use of the custom Angular-React renderer.\n\n## Libraries\n\n@angular-react contains two separate libraries:\n\n- [**core**][lib-core]: [![npm version](https://badge.fury.io/js/%40angular-react%2Fcore.svg)](https://www.npmjs.com/package/@angular-react/core) \n\n    Includes the Renderer and supporting logic to render Angular components with React implementations as React components. \n\n- [**fabric**][lib-fab]: [![npm version](https://badge.fury.io/js/%40angular-react%2Ffabric.svg)](https://www.npmjs.com/package/@angular-react/fabric)\n    \n    The light-weight Angular component wrappers that expose the Fabric React component API through common Angular components (including both imperative AND declarative syntax in many cases).\n\n\n### Quick links\n\n[Documentation, quick start, and guides][ard] |\n[Demo][ard-demo] |\n[Contributing](https://github.com/microsoft/angular-react/blob/master/CONTRIBUTING.md) |\n[StackBlitz Template](https://stackblitz.com/edit/angular-react) |\n[Office UI Fabric](https://developer.microsoft.com/en-us/fabric)\n\n### Typical Use Cases\n\n- Use React component libraries with Angular\n- Incrementally rewrite an Angular application into React \n(moving from atomic/leaf nodes upward into full features/pages until the entire app is re-written)\n\n## Getting started\n\nSee a simple [StackBlitz Template](https://stackblitz.com/edit/angular-react)\n\n# Roadmap & Support\n\nBoth the `core` and `fabric` libraries are in production use in consumer-facing applications at Microsoft. That said, \nwe (the team that currently maintains this project) are a product team, and @angular-react is not our primary focus. \nWe maintain this because we need it and we share it with the wider community with the hope that it will prove useful to others.\nOf course, we attempt to provide help when possible and we love getting pull requests for \nimprovements/enhancement/fixes from community members. But we don't have any specific plans for the future of this project.\n\nPlease take this in to consideration when evaluating this project's suitability for your own needs. \n\n## Contributing\n\nIf you'd like to contribute, you must follow our [contributing guidelines](https://github.com/microsoft/angular-react/blob/master/CONTRIBUTING.md).\nYou can look through the issues (which should be up-to-date on who is working on which features and which pieces are blocked) and make a comment.\n\n[ard]: https://microsoft.github.io/angular-react\n[ard-demo]: https://microsoft.github.io/angular-react/demo\n[getting-started]: https://microsoft.github.io/angular-react/docs/getting-started\n[fab]: https://developer.microsoft.com/en-us/fabric\n[fab-c]: https://developer.microsoft.com/en-us/fabric#/components\n[lib-core]: ./libs/core/README.md\n[lib-fab]: ./libs/fabric/README.md\n"
 },
 {
  "repo": "microsoft/health-cards-tests",
  "language": "TypeScript",
  "readme_contents": "# SMART Health Card Tests\n\nThis fork provides additional tests to the [base project](https://github.com/smart-on-fhir/health-cards-tests). See the original [README.md](https://github.com/smart-on-fhir/health-cards-tests/blob/master/README.md).\n\nThe `demo` folder constains a project illustrating the issuance and validation of SMART Health Cards; see its [README.md](demo/README.md) for details.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft \ntrademarks or logos is subject to and must follow \n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/gather",
  "language": "Jupyter Notebook",
  "readme_contents": "# nbgather: \ud83e\uddfd\u2728 Spit shine for Jupyter notebooks \n\nTools for cleaning code, recovering lost code, and comparing\nversions of code in Jupyter Lab.\n\nDownload the alpha extension with the following command:\n\n```bash\njupyter labextension install nbgather\n```\n\nThen you can clean and compare versions of your code like so:\n\n<img src=docs/demo.gif alt=\"Code gathering tools can help you clean your code and review versions of results.\"/>\n\nWant to try it out first? [Play around with `nbgather` on an example notebook on BinderHub.](https://gke.mybinder.org/v2/gh/microsoft/gather/master?urlpath=lab/tree/binder%2FTry%20out%20nbgather.ipynb)\n\n**Did the `install` fail?** Make sure Jupyter Lab is\nup-to-date, and that you are running Jupyter Lab from Python 3.\n\n**This project is in alpha**: The code this collects will\nsometimes be more than you want. It saves your a history of\nall code you've executed and the outputs it produces to the\nnotebook's metadata. The user interface has a few quirks.\n\nHelp us make this a real, practical, and really useful tool.\nWe welcome any and all feedback and contributions. We are\nparticularly in need of the opinions and efforts of those\nwith a penchant for hacking code analysis.\n\n## Usage Tips\n\n**Can it extract more precise slices of code?** Yes. First submit\na pull request telling us the desired extraction behavior, so we\ncan incorporate this behavior into the tool.\n\nMeanwhile, you can help the backend make more precise slices by\ntelling the tool which functions don't modify their\narguments. By default, the tool assumes that functions change all\narguments they're called with, and the objects they're called on,\nwith [exceptions for some common APIs](https://github.com/andrewhead/python-program-analysis/tree/master/src/specs).\nTo edit the slicing rules, open the *Advanced Settings Editor* in the Jupyter Lab\nSettings menu and choose the \"nbgather\" tab. In your\nuser-defined settings, override `moduleMap`, following\n[this format](https://github.com/andrewhead/python-program-analysis#api-specs)\nto specify which functions don't modify their arguments.\n\n**How do I clear the notebook's history?** Open up your `.ipynb`\nfile in a text editor, find the `history` key in the\ntop-level `metadata` object, and set `history` to `[]`.\n\n## Contributing\n\nTo run the development version of nbgather, run:\n\n```bash\ngit clone <this-repository-url>  # clone the repository\nnpm install                      # download dependencies\njupyter labextension link .      # install this package in Jupyter Lab\nnpm run watch                    # automatically recompile source code\njupyter lab --watch              # launch Jupyter Lab, automatically re-load extension\n```\n\nThis requires npm version 4 or later, and was tested most\nrecently with Node v9.5.0.\n\nSubmit all change as a pull request. Feel free to author the\nthe lead contributor (Andrew Head, <andrewhead@berkeley.edu>) if\nyou have any questions about getting started with the code or\nabout features or updates you'd like to contribute.\n\nAlso, make sure to format the code and test it before submitting\na pull request, as described below:\n\n### Formatting the code\n\nBefore submitting a pull request with changed code, format the code\nfiles by running `npm run format:all`.\n\n### Testing the code\n\nTo run the tests from the command line, call:\n\n```bash\nnpm run test\n```\n\nThe first time you run tests, they will take about a minute\nto finish. The second time, and all subsequent times, the\ntests will take only a few seconds. The first test run takes\nlonger because the Jest test runner transpiles dependencies\nlike the '@jupyterlab' libraries into a dialect of\nJavaScript it expects before running the tests.\n\n### Troubleshooting\n\nHere are some tips for dealing with build errors we've encountered\nwhile developing code gathering tools:\n\n* **Errors about missing semicolons in React types files**: upgrade the `typescript` and `ts-node` packages\n* **Conflicting dependencies**: upgrade either the Python Jupyter Lab (may require Python upgrade to Python 3 to get the most recent version of Jupyter Lab) or the Jupyter Lab npm pacakges\n* **Other build issues**: we've found some issues can be solved by just deleting your `node_modules/` directory and reinstalling it.\n"
 },
 {
  "repo": "microsoft/GSL",
  "language": "C++",
  "readme_contents": "# GSL: Guidelines Support Library\n[![Build Status](https://dev.azure.com/cppstat/GSL/_apis/build/status/microsoft.GSL?branchName=main)](https://dev.azure.com/cppstat/GSL/_build/latest?definitionId=1&branchName=main)\n\nThe Guidelines Support Library (GSL) contains functions and types that are suggested for use by the\n[C++ Core Guidelines](https://github.com/isocpp/CppCoreGuidelines) maintained by the [Standard C++ Foundation](https://isocpp.org).\nThis repo contains Microsoft's implementation of GSL.\n\nThe entire implementation is provided inline in the headers under the [gsl](./include/gsl) directory. The implementation generally assumes a platform that implements C++14 support.\n\nWhile some types have been broken out into their own headers (e.g. [gsl/span](./include/gsl/span)),\nit is simplest to just include [gsl/gsl](./include/gsl/gsl) and gain access to the entire library.\n\n> NOTE: We encourage contributions that improve or refine any of the types in this library as well as ports to\nother platforms. Please see [CONTRIBUTING.md](./CONTRIBUTING.md) for more information about contributing.\n\n# Project Code of Conduct\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Usage of Third Party Libraries\nThis project makes use of the [Google Test](https://github.com/google/googletest) testing library. Please see the [ThirdPartyNotices.txt](./ThirdPartyNotices.txt) file for details regarding the licensing of Google Test.\n\n# Supported features\n## Microsoft GSL implements the following from the C++ Core Guidelines:\n\nFeature                            | Supported? | Description\n-----------------------------------|:----------:|-------------\n[**1. Views**][cg-views]           |            |\nowner                              | &#x2611;   | an alias for a raw pointer\nnot_null                           | &#x2611;   | restricts a pointer / smart pointer to hold non-null values\nspan                               | &#x2611;   | a view over a contiguous sequence of memory. Based on the standardized verison of `std::span`, however `gsl::span` enforces bounds checking. See the [wiki](https://github.com/microsoft/GSL/wiki/gsl::span-and-std::span) for additional information.\nspan_p                             | &#x2610;   | spans a range starting from a pointer to the first place for which the predicate is true\nbasic_zstring                      | &#x2611;   | A pointer to a C-string (zero-terminated array) with a templated char type\nzstring                            | &#x2611;   | An alias to `basic_zstring` with a char type of char\nczstring                           | &#x2611;   | An alias to `basic_zstring` with a char type of const char\nwzstring                           | &#x2611;   | An alias to `basic_zstring` with a char type of wchar_t\ncwzstring                          | &#x2611;   | An alias to `basic_zstring` with a char type of const wchar_t\nu16zstring                         | &#x2611;   | An alias to `basic_zstring` with a char type of char16_t\ncu16zstring                        | &#x2611;   | An alias to `basic_zstring` with a char type of const char16_t\nu32zstring                         | &#x2611;   | An alias to `basic_zstring` with a char type of char32_t\ncu32zstring                        | &#x2611;   | An alias to `basic_zstring` with a char type of const char32_t\n[**2. Owners**][cg-owners]         |            |\nunique_ptr                         | &#x2611;   | an alias to `std::unique_ptr`\nshared_ptr                         | &#x2611;   | an alias to `std::shared_ptr`\nstack_array                        | &#x2610;   | a stack-allocated array\ndyn_array                          | &#x2610;   | a heap-allocated array\n[**3. Assertions**][cg-assertions] |            |\nExpects                            | &#x2611;   | a precondition assertion; on failure it terminates\nEnsures                            | &#x2611;   | a postcondition assertion; on failure it terminates\n[**4. Utilities**][cg-utilities]   |            |\nmove_owner                         | &#x2610;   | a helper function that moves one `owner` to the other\nbyte                               | &#x2611;   | either an alias to std::byte or a byte type\nfinal_action                       | &#x2611;   | a RAII style class that invokes a functor on its destruction\nfinally                            | &#x2611;   | a helper function instantiating `final_action`\nGSL_SUPPRESS                       | &#x2611;   | a macro that takes an argument and turns it into `[[gsl::suppress(x)]]` or `[[gsl::suppress(\"x\")]]`\n[[implicit]]                       | &#x2610;   | a \"marker\" to put on single-argument constructors to explicitly make them non-explicit\nindex                              | &#x2611;   | a type to use for all container and array indexing (currently an alias for std::ptrdiff_t)\njoining_thread                     | &#x2610;   | a RAII style version of `std::thread` that joins\nnarrow                             | &#x2611;   | a checked version of narrow_cast; it can throw `narrowing_error`\nnarrow_cast                        | &#x2611;   | a narrowing cast for values and a synonym for static_cast\nnarrowing_error                    | &#x2611;   | a custom exception type thrown by `narrow()`\n[**5. Concepts**][cg-concepts]     | &#x2610;   |\n\n## The following features do not exist in or have been removed from the C++ Core Guidelines:\nFeature                            | Supported? | Description\n-----------------------------------|:----------:|-------------\nstrict_not_null                    | &#x2611;   | A stricter version of `not_null` with explicit constructors\nmulti_span                         | &#x2610;   | Deprecated. Multi-dimensional span.\nstrided_span                       | &#x2610;   | Deprecated. Support for this type has been discontinued.\nbasic_string_span                  | &#x2610;   | Deprecated. Like `span` but for strings with a templated char type\nstring_span                        | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of char\ncstring_span                       | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of const char\nwstring_span                       | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of wchar_t\ncwstring_span                      | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of const wchar_t\nu16string_span                     | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of char16_t\ncu16string_span                    | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of const char16_t\nu32string_span                     | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of char32_t\ncu32string_span                    | &#x2610;   | Deprecated. An alias to `basic_string_span` with a char type of const char32_t\n\nThis is based on [CppCoreGuidelines semi-specification](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#gsl-guidelines-support-library).\n\n[cg-views]: https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#gslview-views\n[cg-owners]: https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#gslowner-ownership-pointers\n[cg-assertions]: https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#gslassert-assertions\n[cg-utilities]: https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#gslutil-utilities\n[cg-concepts]: https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#gslconcept-concepts\n\n# Quick Start\n## Supported Compilers\nThe GSL officially supports the current and previous major release of MSVC, GCC, Clang, and XCode's Apple-Clang.\nSee our latest test results for the most up-to-date list of supported configurations.\n\nCompiler |Toolset Versions Currently Tested\n:------- |--:\n XCode |11.4 & 10.3\n GCC |9 & 8\n Clang |11 &  10\n Visual Studio with MSVC | VS2017 (15.9) & VS2019 (16.4) \n Visual Studio with LLVM | VS2017 (Clang 9) & VS2019 (Clang 10)\n\n---\nIf you successfully port GSL to another platform, we would love to hear from you!\n- Submit an issue specifying the platform and target.\n- Consider contributing your changes by filing a pull request with any necessary changes.\n- If at all possible, add a CI/CD step and add the button to the table below!\n\nTarget | CI/CD Status\n:------- | -----------:\niOS | ![CI_iOS](https://github.com/microsoft/GSL/workflows/CI_iOS/badge.svg)\nAndroid | ![CI_Android](https://github.com/microsoft/GSL/workflows/CI_Android/badge.svg)\n\nNote: These CI/CD steps are run with each pull request, however failures in them are non-blocking.\n\n## Building the tests\nTo build the tests, you will require the following:\n\n* [CMake](http://cmake.org), version 3.1.3 (3.2.3 for AppleClang) or later to be installed and in your PATH.\n\nThese steps assume the source code of this repository has been cloned into a directory named `c:\\GSL`.\n\n1. Create a directory to contain the build outputs for a particular architecture (we name it c:\\GSL\\build-x86 in this example).\n\n        cd GSL\n        md build-x86\n        cd build-x86\n\n2. Configure CMake to use the compiler of your choice (you can see a list by running `cmake --help`).\n\n        cmake -G \"Visual Studio 15 2017\" c:\\GSL\n\n3. Build the test suite (in this case, in the Debug configuration, Release is another good choice).\n\n        cmake --build . --config Debug\n\n4. Run the test suite.\n\n        ctest -C Debug\n\nAll tests should pass - indicating your platform is fully supported and you are ready to use the GSL types!\n\n## Building GSL - Using vcpkg\n\nYou can download and install GSL using the [vcpkg](https://github.com/Microsoft/vcpkg) dependency manager:\n\n    git clone https://github.com/Microsoft/vcpkg.git\n    cd vcpkg\n    ./bootstrap-vcpkg.sh\n    ./vcpkg integrate install\n    vcpkg install ms-gsl\n\nThe GSL port in vcpkg is kept up to date by Microsoft team members and community contributors. If the version is out of date, please [create an issue or pull request](https://github.com/Microsoft/vcpkg) on the vcpkg repository.\n\n## Using the libraries\nAs the types are entirely implemented inline in headers, there are no linking requirements.\n\nYou can copy the [gsl](./include/gsl) directory into your source tree so it is available\nto your compiler, then include the appropriate headers in your program.\n\nAlternatively set your compiler's *include path* flag to point to the GSL development folder (`c:\\GSL\\include` in the example above) or installation folder (after running the install). Eg.\n\nMSVC++\n\n    /I c:\\GSL\\include\n\nGCC/clang\n\n    -I$HOME/dev/GSL/include\n\nInclude the library using:\n\n    #include <gsl/gsl>\n\n## Usage in CMake\n\nThe library provides a Config file for CMake, once installed it can be found via\n\n    find_package(Microsoft.GSL CONFIG)\n\nWhich, when successful, will add library target called `Microsoft.GSL::GSL` which you can use via the usual\n`target_link_libraries` mechanism.\n\n### FetchContent\n\nIf you are using cmake version 3.11+ you can use the offical FetchContent module.\nThis allows you to easily incorporate GSL into your project.\n\n```cmake\n# NOTE: This example uses cmake version 3.14 (FetchContent_MakeAvailable).\n# Since it streamlines the FetchContent process\ncmake_minimum_required(VERSION 3.14)\n\ninclude(FetchContent)\n\n# In this example we are picking a specific tag.\n# You can also pick a specific commit, if you need to.\nFetchContent_Declare(GSL\n    GIT_REPOSITORY \"https://github.com/microsoft/GSL\"\n    GIT_TAG \"v3.1.0\"\n)\n\nFetchContent_MakeAvailable(GSL)\n\n# Now you can link against the GSL interface library\nadd_executable(foobar)\n\n# Link against the interface library (IE header only library)\ntarget_link_libraries(foobar PRIVATE GSL)\n```\n\n## Debugging visualization support\nFor Visual Studio users, the file [GSL.natvis](./GSL.natvis) in the root directory of the repository can be added to your project if you would like more helpful visualization of GSL types in the Visual Studio debugger than would be offered by default.\n\nIf you are using cmake this will be done automatically for you.\nSee 'GSL_VS_ADD_NATIVE_VISUALIZERS'\n"
 },
 {
  "repo": "microsoft/GLUECoS",
  "language": "Python",
  "readme_contents": "# GLUECoS: An Evaluation Benchmark for Code-Switched NLP\n**NEW (Mar - 2021): We have added a new Code-Mixed Machine Translation Dataset to GLUECoS. Please check [this](#code-mixed-machine-translation-task) section**\n\n**NEW (Oct - 2020): Please check our updated policy about making submissions for evaluation [here](#submission-policy)**\n\n**NEW (Sep - 2020): NLI dataset preprocess script updated to fix repetitions in data. If you have downloaded the datasets before, please check [this](#nli-preprocess-script-update) section**\n\n**NEW (Aug - 2020): Evaluation is now automated and results are presented instantly. Please check [this](#submitting-predictions-for-evaluation) section**\n\nThis is the repo for the ACL 2020 paper [GLUECoS: An Evaluation Benchmark for Code-Switched NLP](https://www.aclweb.org/anthology/2020.acl-main.329/)\n\nGLUECoS is a benchmark comprising of multiple code-mixed tasks across 2 language pairs (En-Es and En-Hi)\n\nRecording of talk given at ACL: [Link](https://slideslive.com/38928983)\n\nBelow are instructions for obtaining the datasets that comprise the benchmark and training transformer based models on this data. Both steps can be run on separate systems and the instructions are structured in such a way. All the user has to do is to copy over the `Data/Processed_Data` folder over to perform training\n\n## Obtaining Datasets\nFollow the following instructions to download and process the datasets. All the steps should work in a brand new conda environment with `python==3.6.10` or a docker container with the `python:3.6` image. Please note that the splits for some of the datasets are different from their original releases.\n1. Install the requirements for the preprocessing scripts\n    ```\n    pip install -r requirements.txt\n    ```\n2. Create a twitter developer account and fill in the 4 keys, one per line,  in `twitter_authentication.txt`. The file should look like this\n    ```\n    consumer_key\n    secret_key\n    access_token\n    access_secret_token\n    ```\n    \n3. Obtain a key for Microsoft Translator. This is needed as the preprocessing steps involve conversion of Romanized datasets into Devanagari. Instructions for obtaining this key can be found [here](https://docs.microsoft.com/en-us/azure/cognitive-services/translator/translator-how-to-signup). While creating the translator instance, please set the region to global. The number of queries made fall within the free tier. This key will be referred to as SUBSCRIPTION_KEY in the next step\n4. To download the data, run the command below. This will download the original datasets, perform all the preprocessing needed and bring them into a format that the training scripts can use\n    ```\n    ./download_data.sh SUBSCRIPTION_KEY\n    ```\n    The dowloaded and processed data is stored in `Data/Processed_Data`. \n    \n    Some of the datasets did not have predefined splits, so the splits used for those can be found in `Data/Original_Data`.\n\n    Please note that the labels for the test sets are not the gold labels. They have been assigned a separate token to maintain fairness in the benchmarking.\n\n    This will not download/preprocess the QA dataset. For that, please check the next step\n\n5. The original QA dataset (Chandu et. al, 2018) contains contexts only for some examples. To obtain contexts for the rest, [DrQA](https://github.com/facebookresearch/DrQA) is used to obtain contexts from a Wikipedia dump. To run this, you will need atleast 20GB of disk storage (to store the wikidump) and 16GB+ of RAM (to run DrQA). DrQA uses PyTorch, so having a GPU will help speed it up (although it isn't necessary).\n\n    First, install a suitable version of PyTorch for your system. In most cases, a `pip install torch` should do\n\n    To download and process the QA dataset, run the following command\n    ```\n    bash Data/Preprocess_Scripts/preprocess_qa.sh\n    ```\n### NLI Preprocess Script Update\nThe data downloading and preprocessing scripts were updated in Sep - 2020 to fix an issue with the creation of the NLI train and test sets. Running the scripts as is will download all the datasets, so you do not have to make any changes if you're doing it for the first time. If you downloaded the datasets before this fix was added, you can follow these steps to get the updated NLI data alone.  \n1. Make sure you have the latest version of the repo\n2. Comment out lines 390-397 and 399-401 of `download_data.sh`\n3. Run the updated `download_data.sh` to create the new NLI dataset alone\n\n## Training models on the data\nThe code contains 4 different evaluation scripts\n1. One script for token level tasks:\n    - LID (en_es/en_hi)\n    - NER (en_es/en_hi),\n    - POS (en_es/en_hi_fg/en_hi_ud)\n2. One script for the sentence level tasks:\n    - Sentiment (en_es/en_hi)\n3. One script for the QA task \n    - QA (en_hi)\n4. One script for the NLI task\n    - NLI (en_hi)\n\nYou can train the models on your system or via Azure Machine Learning. To know more about the latter, please refer to [this README](azure_ml/README.md).\n\n### Install the training requirements  \nNote: The requirements for dataset preprocessing and training have been separately mentioned, as you may run them on different systems\n1. Install a suitable version of pytorch for your system, `pip install torch` should work in most cases\n2. The requirements from the file in `Code/requirements.txt`\n    ```\n    pip install -r Code/requirements.txt\n    ```\n### Training\nRun the below command to fine-tune your model on any of the task. The training scripts uses the Huggingface library and support any models based on BERT, XLM, XLM-Roberta and similar models.\n\n```\nbash train.sh MODEL MODEL_TYPE TASK \n```\nExample Usage :\n```    \nbash train.sh bert-base-multilingual-cased bert POS_EN_HI_FG\n```\nYou can also run fine-tuning for all tasks with the following command :\n```\nbash train.sh bert-base-multilingual-cased bert ALL\n```\n\n## Submitting Predictions for Evaluation\nSubmission is done by uploading the results to a fork of this repo and making a pull request to the main repo. The evaluation is done automatically by a set of actions that run for the PR.\n\nThe training scripts supplied write predictions for the test set into the `Results` folder.\n1. Zip this folder into results.zip with `zip results.zip -r Results`.\n2. Create a fork of `microsoft/GLUECoS` on Github.\n3. Add this `results.zip` file to the root directory of your fork and make a pull request to the main repo.\n\nA set of actions will run for your pull request. Clicking on \"Show all checks\" will reveal that one of these is named \"Eval script\". Clicking on \"Details\" will take you to the sequence of steps run for the action. Expanding the \"Run Eval\" stage will show you the results of the eval script.\n<p float=\"left\">\n  <img src=\"docs/github_pr.png\" width=\"500\" />\n  <img src=\"docs/eval_script.png\" width=\"300\" /> \n</p>\n\nIf you would like to make another submission, you can update the same PR with the new `results.zip` file and the action will run again. You DO NOT need to open a new PR each time. Please wait till the current action finishes running before updating the PR with the new submission.\n\nPlease ensure that this is the exact structure of the zip file. The eval script will fail if there are any differences in the names or the structure\n```\nresults.zip\n    \u2514\u2500\u2500 Results\n        \u251c\u2500\u2500 NLI_EN_HI\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 test_predictions.txt\n        \u251c\u2500\u2500 QA_EN_HI\n        \u2502\u00a0\u00a0 \u2514\u2500\u2500 predictions.json\n        .\n        .\n        .\n        \u2514\u2500\u2500 Sentiment_EN_HI\n            \u2514\u2500\u2500 test_predictions.txt\n\n```\n<p id=\"submission-policy\">\nYou can make as many submissions as you want. Beyond the 5th submission, your best score will be added to the leaderboard. We will use your Github username for the leaderboard. Instead, if you would like your group's name/affilication to appear on the leaderboard, please mention this along with details about the model in the pull request.\n</p>\n\n## Code-Mixed Machine Translation Task\nWe have added a code-mixed machine translation dataset to GLUECoS. The dataset and task are for translation from English to Hindi-English. The dataset has been provided by Prof. Alan Black's group from CMU. Since BERT like models aren't suitable for this task, we offer this as a separate part of the benchmark with a separate leaderboard. The baseline method for this task is mBART finetuned on this dataset.\n\n### Obtaining the dataset\nThe `download_data.sh` script does the downloading and preprocessing of this dataset, but the MT dataset part is disabled by deafult. To enable this, you'll have to comment out lines 409-420 and uncomment line 421, and then run the script just like before.\n\n### Train Scripts\nWe have supplied training scripts that can be used to finetune mBART or related models on the dataset. The train script is at `Code/run_seq2seq.py`. You can run that script directly, or alternatively start training this way\n```\nbash train.sh facebook/mbart-large-cc25 mbart MT_EN_HI\n```\nYou can have a look at the training arguments in `Code/train_mt.sh` and modify them as per your needs. You might need to adjust batch size depending on the GPU that you are using.\n\n### Evaluation\nThe train scripts write the predictions on the test set to the `Results` directory and you can submit these for evaluation similar to how you do for the other tasks. The predictions are written to `Results/MT_EN_HI/translations.txt`. The zip file that gets uploaded is expected to follow this structure\n```\nresults.zip\n    \u2514\u2500\u2500 Results\n        \u2514\u2500\u2500 MT_EN_HI\n            \u2514\u2500\u2500 translations.txt\n```\nThe MT task will have a leaderboard that is separate from the other tasks. The evaluation for the MT task (via pull requests) will be enabled in April.\n\n## Citation\nPlease use the following citation if you use this benchmark:\n```\n@inproceedings{khanuja-etal-2020-gluecos,\n    title = \"{GLUEC}o{S}: An Evaluation Benchmark for Code-Switched {NLP}\",\n    author = \"Khanuja, Simran  and\n      Dandapat, Sandipan  and\n      Srinivasan, Anirudh  and\n      Sitaram, Sunayana  and\n      Choudhury, Monojit\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = jul,\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.329\",\n    pages = \"3575--3585\"\n}\n```\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/service-fabric-services-and-actors-dotnet",
  "language": "C#",
  "readme_contents": "# Azure/service-fabric-services-and-actors-dotnet\r\n\r\nReliable Services and Reliable Actors are Service Fabric application frameworks for building highly-scalable distributed cloud applications.\r\n\r\nReliable Services is a light-weight framework for writing services that integrate with the Service Fabric platform and benefit from the full set of platform features. Built on top of Reliable Services, the Reliable Actor framework is an application framework that implements the Virtual Actor model, based on the actor design pattern. More information on Service Fabric programming models can be found in the [Service Fabric documentation](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-choose-framework).\r\n\r\nThis repo builds the following packages:\r\n - Microsoft.ServiceFabric.Services\r\n - Microsoft.ServiceFabric.Services.Remoting\r\n - Microsoft.ServiceFabric.Services.Wcf\r\n - Microsoft.ServiceFabric.Actors\r\n - Microsoft.ServiceFabric.Actors.Wcf\r\n\r\nFor more Service Fabric open source projects, visit the Service Fabric [home repo](https://github.com/microsoft/service-fabric).\r\n\r\n## Getting Started\r\n\r\n### Prerequesites\r\nEach project is a normal C# Visual Studio 2019 project. At minimum, you need [MSBuild 16](https://docs.microsoft.com/en-us/visualstudio/msbuild/whats-new-msbuild-16-0), [PowerShell](https://msdn.microsoft.com/powershell/mt173057.aspx), [.NET Core SDK](https://www.microsoft.com/net/download/windows) and [.NET Framework 4.6](https://www.microsoft.com/en-US/download/details.aspx?id=48130) to build and generate NuGet packages.\r\n\r\nWe recommend installing [Visual Studio 2019](https://www.visualstudio.com/vs/) which will set you up with all the .NET build tools and allow you to open the solution files. Community Edition is free and can be used to build everything here.\r\n\r\n### Build\r\nTo build everything and generate NuGet packages, run the **build.ps1** script. NuGet packages will be dropped in a *drop* directory at the repo root.\r\n\r\nEach project can also be built individually directly through Visual Studio or by running the solution file through MSBuild.\r\n\r\nBinaries in the build are delay signed, these are fully signed in the official builds released by Microsoft. To use the binaries or to run unit tests from the build of this repository, strong name validation needs to be skipped for these assemblies. This can be done by running **SkipStrongName.ps1** script available in the root of the repository.\r\n\r\nFor branches, please see [Branching Information](CONTRIBUTING.md#BranchingInformation)\r\n\r\n## Releases and Support\r\nOfficial releases from Microsoft of the NuGet packages in this repo are released directly to NuGet and Web Platform Installer. Get the latest official release [here](http://www.microsoft.com/web/handlers/webpi.ashx?command=getinstallerredirect&appid=MicrosoftAzure-ServiceFabric-VS2015).\r\n\r\n**Only officially released NuGet packages from Microsoft are supported for use in production.** If you have a feature or bug fix that you would like to use in your application, please issue a pull request so we can get it into an official release.\r\n\r\n## Reporting issues and feedback\r\nPlease refer to [Contributing.md](https://github.com/Microsoft/service-fabric/blob/master/CONTRIBUTING.md) at the Service Fabric home repo for details on issue reporting and feedback.\r\n\r\n## Contributing code\r\nIf you would like to become an active contributor to this project please\r\nfollow the instructions provided in [Microsoft Azure Projects Contribution Guidelines](http://azure.github.io/guidelines.html).\r\n\r\nFor details on contributing to Service Fabric projects, please refer to [Contributing.md](https://github.com/Microsoft/service-fabric/blob/master/CONTRIBUTING.md) at the Service Fabric home repo for details on contributing code.\r\n\r\n## How to reflect changes done in Nugets\r\nNugets from this repo are published via Service Fabric SDK. Once the changes are made in this repo and if there are some changes in nuprojs files, they should reflect in Service Fabric Repo (src\\BuildSteps\\GenerateNuget\\PublicSDK) in respective nuprojs.\r\n\r\n## Documentation\r\nService Fabric has conceptual and reference documentation available at [https://docs.microsoft.com/azure/service-fabric](https://docs.microsoft.com/azure/service-fabric).\r\n\r\nThese articles will help get you started with Reliable Services and Reliable Actors:\r\n\r\n  - [Reliable Services overview](https://docs.microsoft.com/azure/service-fabric/service-fabric-reliable-services-introduction)\r\n  - [Reliable Actors overview](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-actors-introduction)\r\n\r\n## Samples\r\nFor Service Fabric sample code, check out the [Azure Code Sample gallery](https://azure.microsoft.com/en-us/resources/samples/?service=service-fabric) or go straight to [Azure-Samples on GitHub](https://github.com/Azure-Samples?q=service-fabric).\r\n\r\n## License\r\n[MIT](License.txt)\r\n\r\n---\r\n*This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.*\r\n\u2003\r\n"
 },
 {
  "repo": "microsoft/AISchoolTutorials",
  "language": "C#",
  "readme_contents": "\n# AI School Tutorials\n\nThis repository contains a collection of AI tutorials that are featured on [Microsoft AI School](https://aischool.microsoft.com).\n\n## [Sketch2Code](./sketch2code)\nSee how Azure Custom Vision can create a model that takes a hand drawn wireframe and turns it into valid HTML code.\n\n## [Snip Insights](./snipinsights)\nApply Azure Cognitive Services to gain intelligent insights within a screen capture application.\n\n## Other Labs\n\nYou can find other AI Labs in this [Github repo](https://github.com/Microsoft/ailab).\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/rushstack",
  "language": "TypeScript",
  "readme_contents": "<table><tr><td>\n<a href=\"https://rushstack.io/\"><img src=\"https://rushstack.io/images/rushstack.svg\" width=\"300px\" /></a>\n<p align=\"center\"><a href=\"https://rushstack.io/\">https://rushstack.io/</a></p>\n</td></tr></table>\n\n[![Zulip chat room](https://img.shields.io/badge/zulip-join_chat-brightgreen.svg)](https://rushstack.zulipchat.com/) &nbsp; [![Build Status](https://dev.azure.com/RushStack/GitHubProjects/_apis/build/status/rushstack/rushstack%20CI%20Build?branchName=master)](https://dev.azure.com/RushStack/GitHubProjects/_build/latest?definitionId=3&branchName=master)\n\nThe home for various projects maintained by the Rush Stack community, whose mission is to develop reusable tooling\nfor large scale TypeScript monorepos.\n\n\n## Documentation Links\n\n- [What is Rush Stack?](https://rushstack.io/) - learn about the mission behind these projects\n- [API reference](https://rushstack.io/pages/api/) - browse API documentation for NPM packages\n- [Zulip chat room](https://rushstack.zulipchat.com/) - chat with the Rush Stack developers\n- [Rush](https://rushjs.io/) - a build orchestrator for large scale TypeScript monorepos\n- [API Extractor](https://api-extractor.com/) - create .d.ts rollups and track your TypeScript API signatures\n- [API Documenter](https://api-extractor.com/pages/setup/generating_docs/) - use TSDoc comments to publish an API documentation website\n\n<!-- GENERATED PROJECT SUMMARY START -->\n\n## Published Packages\n\n<!-- the table below was generated using the ./repo-scripts/repo-toolbox script -->\n\n| Folder | Version | Changelog | Package |\n| ------ | ------- | --------- | ------- |\n| [/apps/api-documenter](./apps/api-documenter/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fapi-documenter.svg)](https://badge.fury.io/js/%40microsoft%2Fapi-documenter) | [changelog](./apps/api-documenter/CHANGELOG.md) | [@microsoft/api-documenter](https://www.npmjs.com/package/@microsoft/api-documenter) |\n| [/apps/api-extractor](./apps/api-extractor/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fapi-extractor.svg)](https://badge.fury.io/js/%40microsoft%2Fapi-extractor) | [changelog](./apps/api-extractor/CHANGELOG.md) | [@microsoft/api-extractor](https://www.npmjs.com/package/@microsoft/api-extractor) |\n| [/apps/api-extractor-model](./apps/api-extractor-model/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fapi-extractor-model.svg)](https://badge.fury.io/js/%40microsoft%2Fapi-extractor-model) | [changelog](./apps/api-extractor-model/CHANGELOG.md) | [@microsoft/api-extractor-model](https://www.npmjs.com/package/@microsoft/api-extractor-model) |\n| [/apps/heft](./apps/heft/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fheft.svg)](https://badge.fury.io/js/%40rushstack%2Fheft) | [changelog](./apps/heft/CHANGELOG.md) | [@rushstack/heft](https://www.npmjs.com/package/@rushstack/heft) |\n| [/apps/rundown](./apps/rundown/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Frundown.svg)](https://badge.fury.io/js/%40rushstack%2Frundown) | [changelog](./apps/rundown/CHANGELOG.md) | [@rushstack/rundown](https://www.npmjs.com/package/@rushstack/rundown) |\n| [/apps/rush](./apps/rush/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush.svg)](https://badge.fury.io/js/%40microsoft%2Frush) | [changelog](./apps/rush/CHANGELOG.md) | [@microsoft/rush](https://www.npmjs.com/package/@microsoft/rush) |\n| [/apps/rush-lib](./apps/rush-lib/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-lib.svg)](https://badge.fury.io/js/%40microsoft%2Frush-lib) | | [@microsoft/rush-lib](https://www.npmjs.com/package/@microsoft/rush-lib) |\n| [/core-build/gulp-core-build](./core-build/gulp-core-build/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build.svg)](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build) | [changelog](./core-build/gulp-core-build/CHANGELOG.md) | [@microsoft/gulp-core-build](https://www.npmjs.com/package/@microsoft/gulp-core-build) |\n| [/core-build/gulp-core-build-mocha](./core-build/gulp-core-build-mocha/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-mocha.svg)](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-mocha) | [changelog](./core-build/gulp-core-build-mocha/CHANGELOG.md) | [@microsoft/gulp-core-build-mocha](https://www.npmjs.com/package/@microsoft/gulp-core-build-mocha) |\n| [/core-build/gulp-core-build-sass](./core-build/gulp-core-build-sass/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-sass.svg)](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-sass) | [changelog](./core-build/gulp-core-build-sass/CHANGELOG.md) | [@microsoft/gulp-core-build-sass](https://www.npmjs.com/package/@microsoft/gulp-core-build-sass) |\n| [/core-build/gulp-core-build-serve](./core-build/gulp-core-build-serve/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-serve.svg)](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-serve) | [changelog](./core-build/gulp-core-build-serve/CHANGELOG.md) | [@microsoft/gulp-core-build-serve](https://www.npmjs.com/package/@microsoft/gulp-core-build-serve) |\n| [/core-build/gulp-core-build-typescript](./core-build/gulp-core-build-typescript/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-typescript.svg)](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-typescript) | [changelog](./core-build/gulp-core-build-typescript/CHANGELOG.md) | [@microsoft/gulp-core-build-typescript](https://www.npmjs.com/package/@microsoft/gulp-core-build-typescript) |\n| [/core-build/gulp-core-build-webpack](./core-build/gulp-core-build-webpack/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-webpack.svg)](https://badge.fury.io/js/%40microsoft%2Fgulp-core-build-webpack) | [changelog](./core-build/gulp-core-build-webpack/CHANGELOG.md) | [@microsoft/gulp-core-build-webpack](https://www.npmjs.com/package/@microsoft/gulp-core-build-webpack) |\n| [/core-build/node-library-build](./core-build/node-library-build/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fnode-library-build.svg)](https://badge.fury.io/js/%40microsoft%2Fnode-library-build) | [changelog](./core-build/node-library-build/CHANGELOG.md) | [@microsoft/node-library-build](https://www.npmjs.com/package/@microsoft/node-library-build) |\n| [/core-build/web-library-build](./core-build/web-library-build/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fweb-library-build.svg)](https://badge.fury.io/js/%40microsoft%2Fweb-library-build) | [changelog](./core-build/web-library-build/CHANGELOG.md) | [@microsoft/web-library-build](https://www.npmjs.com/package/@microsoft/web-library-build) |\n| [/heft-plugins/heft-webpack4-plugin](./heft-plugins/heft-webpack4-plugin/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fheft-webpack4-plugin.svg)](https://badge.fury.io/js/%40rushstack%2Fheft-webpack4-plugin) | [changelog](./heft-plugins/heft-webpack4-plugin/CHANGELOG.md) | [@rushstack/heft-webpack4-plugin](https://www.npmjs.com/package/@rushstack/heft-webpack4-plugin) |\n| [/heft-plugins/heft-webpack5-plugin](./heft-plugins/heft-webpack5-plugin/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fheft-webpack5-plugin.svg)](https://badge.fury.io/js/%40rushstack%2Fheft-webpack5-plugin) | [changelog](./heft-plugins/heft-webpack5-plugin/CHANGELOG.md) | [@rushstack/heft-webpack5-plugin](https://www.npmjs.com/package/@rushstack/heft-webpack5-plugin) |\n| [/libraries/debug-certificate-manager](./libraries/debug-certificate-manager/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fdebug-certificate-manager.svg)](https://badge.fury.io/js/%40rushstack%2Fdebug-certificate-manager) | [changelog](./libraries/debug-certificate-manager/CHANGELOG.md) | [@rushstack/debug-certificate-manager](https://www.npmjs.com/package/@rushstack/debug-certificate-manager) |\n| [/libraries/heft-config-file](./libraries/heft-config-file/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fheft-config-file.svg)](https://badge.fury.io/js/%40rushstack%2Fheft-config-file) | [changelog](./libraries/heft-config-file/CHANGELOG.md) | [@rushstack/heft-config-file](https://www.npmjs.com/package/@rushstack/heft-config-file) |\n| [/libraries/load-themed-styles](./libraries/load-themed-styles/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Fload-themed-styles.svg)](https://badge.fury.io/js/%40microsoft%2Fload-themed-styles) | [changelog](./libraries/load-themed-styles/CHANGELOG.md) | [@microsoft/load-themed-styles](https://www.npmjs.com/package/@microsoft/load-themed-styles) |\n| [/libraries/node-core-library](./libraries/node-core-library/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fnode-core-library.svg)](https://badge.fury.io/js/%40rushstack%2Fnode-core-library) | [changelog](./libraries/node-core-library/CHANGELOG.md) | [@rushstack/node-core-library](https://www.npmjs.com/package/@rushstack/node-core-library) |\n| [/libraries/package-deps-hash](./libraries/package-deps-hash/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fpackage-deps-hash.svg)](https://badge.fury.io/js/%40rushstack%2Fpackage-deps-hash) | [changelog](./libraries/package-deps-hash/CHANGELOG.md) | [@rushstack/package-deps-hash](https://www.npmjs.com/package/@rushstack/package-deps-hash) |\n| [/libraries/rig-package](./libraries/rig-package/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Frig-package.svg)](https://badge.fury.io/js/%40rushstack%2Frig-package) | [changelog](./libraries/rig-package/CHANGELOG.md) | [@rushstack/rig-package](https://www.npmjs.com/package/@rushstack/rig-package) |\n| [/libraries/stream-collator](./libraries/stream-collator/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fstream-collator.svg)](https://badge.fury.io/js/%40rushstack%2Fstream-collator) | [changelog](./libraries/stream-collator/CHANGELOG.md) | [@rushstack/stream-collator](https://www.npmjs.com/package/@rushstack/stream-collator) |\n| [/libraries/terminal](./libraries/terminal/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fterminal.svg)](https://badge.fury.io/js/%40rushstack%2Fterminal) | [changelog](./libraries/terminal/CHANGELOG.md) | [@rushstack/terminal](https://www.npmjs.com/package/@rushstack/terminal) |\n| [/libraries/tree-pattern](./libraries/tree-pattern/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Ftree-pattern.svg)](https://badge.fury.io/js/%40rushstack%2Ftree-pattern) | [changelog](./libraries/tree-pattern/CHANGELOG.md) | [@rushstack/tree-pattern](https://www.npmjs.com/package/@rushstack/tree-pattern) |\n| [/libraries/ts-command-line](./libraries/ts-command-line/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fts-command-line.svg)](https://badge.fury.io/js/%40rushstack%2Fts-command-line) | [changelog](./libraries/ts-command-line/CHANGELOG.md) | [@rushstack/ts-command-line](https://www.npmjs.com/package/@rushstack/ts-command-line) |\n| [/libraries/typings-generator](./libraries/typings-generator/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Ftypings-generator.svg)](https://badge.fury.io/js/%40rushstack%2Ftypings-generator) | [changelog](./libraries/typings-generator/CHANGELOG.md) | [@rushstack/typings-generator](https://www.npmjs.com/package/@rushstack/typings-generator) |\n| [/rigs/heft-node-rig](./rigs/heft-node-rig/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fheft-node-rig.svg)](https://badge.fury.io/js/%40rushstack%2Fheft-node-rig) | [changelog](./rigs/heft-node-rig/CHANGELOG.md) | [@rushstack/heft-node-rig](https://www.npmjs.com/package/@rushstack/heft-node-rig) |\n| [/rigs/heft-web-rig](./rigs/heft-web-rig/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fheft-web-rig.svg)](https://badge.fury.io/js/%40rushstack%2Fheft-web-rig) | [changelog](./rigs/heft-web-rig/CHANGELOG.md) | [@rushstack/heft-web-rig](https://www.npmjs.com/package/@rushstack/heft-web-rig) |\n| [/stack/eslint-config](./stack/eslint-config/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Feslint-config.svg)](https://badge.fury.io/js/%40rushstack%2Feslint-config) | [changelog](./stack/eslint-config/CHANGELOG.md) | [@rushstack/eslint-config](https://www.npmjs.com/package/@rushstack/eslint-config) |\n| [/stack/eslint-patch](./stack/eslint-patch/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Feslint-patch.svg)](https://badge.fury.io/js/%40rushstack%2Feslint-patch) | [changelog](./stack/eslint-patch/CHANGELOG.md) | [@rushstack/eslint-patch](https://www.npmjs.com/package/@rushstack/eslint-patch) |\n| [/stack/eslint-plugin](./stack/eslint-plugin/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Feslint-plugin.svg)](https://badge.fury.io/js/%40rushstack%2Feslint-plugin) | [changelog](./stack/eslint-plugin/CHANGELOG.md) | [@rushstack/eslint-plugin](https://www.npmjs.com/package/@rushstack/eslint-plugin) |\n| [/stack/eslint-plugin-packlets](./stack/eslint-plugin-packlets/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Feslint-plugin-packlets.svg)](https://badge.fury.io/js/%40rushstack%2Feslint-plugin-packlets) | [changelog](./stack/eslint-plugin-packlets/CHANGELOG.md) | [@rushstack/eslint-plugin-packlets](https://www.npmjs.com/package/@rushstack/eslint-plugin-packlets) |\n| [/stack/eslint-plugin-security](./stack/eslint-plugin-security/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Feslint-plugin-security.svg)](https://badge.fury.io/js/%40rushstack%2Feslint-plugin-security) | [changelog](./stack/eslint-plugin-security/CHANGELOG.md) | [@rushstack/eslint-plugin-security](https://www.npmjs.com/package/@rushstack/eslint-plugin-security) |\n| [/stack/rush-stack-compiler-2.4](./stack/rush-stack-compiler-2.4/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.4.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.4) | [changelog](./stack/rush-stack-compiler-2.4/CHANGELOG.md) | [@microsoft/rush-stack-compiler-2.4](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-2.4) |\n| [/stack/rush-stack-compiler-2.7](./stack/rush-stack-compiler-2.7/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.7.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.7) | [changelog](./stack/rush-stack-compiler-2.7/CHANGELOG.md) | [@microsoft/rush-stack-compiler-2.7](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-2.7) |\n| [/stack/rush-stack-compiler-2.8](./stack/rush-stack-compiler-2.8/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.8.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.8) | [changelog](./stack/rush-stack-compiler-2.8/CHANGELOG.md) | [@microsoft/rush-stack-compiler-2.8](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-2.8) |\n| [/stack/rush-stack-compiler-2.9](./stack/rush-stack-compiler-2.9/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.9.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-2.9) | [changelog](./stack/rush-stack-compiler-2.9/CHANGELOG.md) | [@microsoft/rush-stack-compiler-2.9](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-2.9) |\n| [/stack/rush-stack-compiler-3.0](./stack/rush-stack-compiler-3.0/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.0.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.0) | [changelog](./stack/rush-stack-compiler-3.0/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.0](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.0) |\n| [/stack/rush-stack-compiler-3.1](./stack/rush-stack-compiler-3.1/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.1.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.1) | [changelog](./stack/rush-stack-compiler-3.1/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.1](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.1) |\n| [/stack/rush-stack-compiler-3.2](./stack/rush-stack-compiler-3.2/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.2.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.2) | [changelog](./stack/rush-stack-compiler-3.2/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.2](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.2) |\n| [/stack/rush-stack-compiler-3.3](./stack/rush-stack-compiler-3.3/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.3.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.3) | [changelog](./stack/rush-stack-compiler-3.3/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.3](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.3) |\n| [/stack/rush-stack-compiler-3.4](./stack/rush-stack-compiler-3.4/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.4.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.4) | [changelog](./stack/rush-stack-compiler-3.4/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.4](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.4) |\n| [/stack/rush-stack-compiler-3.5](./stack/rush-stack-compiler-3.5/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.5.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.5) | [changelog](./stack/rush-stack-compiler-3.5/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.5](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.5) |\n| [/stack/rush-stack-compiler-3.6](./stack/rush-stack-compiler-3.6/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.6.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.6) | [changelog](./stack/rush-stack-compiler-3.6/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.6](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.6) |\n| [/stack/rush-stack-compiler-3.7](./stack/rush-stack-compiler-3.7/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.7.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.7) | [changelog](./stack/rush-stack-compiler-3.7/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.7](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.7) |\n| [/stack/rush-stack-compiler-3.8](./stack/rush-stack-compiler-3.8/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.8.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.8) | [changelog](./stack/rush-stack-compiler-3.8/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.8](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.8) |\n| [/stack/rush-stack-compiler-3.9](./stack/rush-stack-compiler-3.9/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.9.svg)](https://badge.fury.io/js/%40microsoft%2Frush-stack-compiler-3.9) | [changelog](./stack/rush-stack-compiler-3.9/CHANGELOG.md) | [@microsoft/rush-stack-compiler-3.9](https://www.npmjs.com/package/@microsoft/rush-stack-compiler-3.9) |\n| [/webpack/loader-load-themed-styles](./webpack/loader-load-themed-styles/) | [![npm version](https://badge.fury.io/js/%40microsoft%2Floader-load-themed-styles.svg)](https://badge.fury.io/js/%40microsoft%2Floader-load-themed-styles) | [changelog](./webpack/loader-load-themed-styles/CHANGELOG.md) | [@microsoft/loader-load-themed-styles](https://www.npmjs.com/package/@microsoft/loader-load-themed-styles) |\n| [/webpack/loader-raw-script](./webpack/loader-raw-script/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Floader-raw-script.svg)](https://badge.fury.io/js/%40rushstack%2Floader-raw-script) | [changelog](./webpack/loader-raw-script/CHANGELOG.md) | [@rushstack/loader-raw-script](https://www.npmjs.com/package/@rushstack/loader-raw-script) |\n| [/webpack/localization-plugin](./webpack/localization-plugin/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Flocalization-plugin.svg)](https://badge.fury.io/js/%40rushstack%2Flocalization-plugin) | [changelog](./webpack/localization-plugin/CHANGELOG.md) | [@rushstack/localization-plugin](https://www.npmjs.com/package/@rushstack/localization-plugin) |\n| [/webpack/module-minifier-plugin](./webpack/module-minifier-plugin/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fmodule-minifier-plugin.svg)](https://badge.fury.io/js/%40rushstack%2Fmodule-minifier-plugin) | [changelog](./webpack/module-minifier-plugin/CHANGELOG.md) | [@rushstack/module-minifier-plugin](https://www.npmjs.com/package/@rushstack/module-minifier-plugin) |\n| [/webpack/set-webpack-public-path-plugin](./webpack/set-webpack-public-path-plugin/) | [![npm version](https://badge.fury.io/js/%40rushstack%2Fset-webpack-public-path-plugin.svg)](https://badge.fury.io/js/%40rushstack%2Fset-webpack-public-path-plugin) | [changelog](./webpack/set-webpack-public-path-plugin/CHANGELOG.md) | [@rushstack/set-webpack-public-path-plugin](https://www.npmjs.com/package/@rushstack/set-webpack-public-path-plugin) |\n\n\n## Unpublished Local Projects\n\n<!-- the table below was generated using the ./repo-scripts/repo-toolbox script -->\n\n| Folder | Description |\n| ------ | -----------|\n| [/build-tests/api-documenter-test](./build-tests/api-documenter-test/) | Building this project is a regression test for api-documenter |\n| [/build-tests/api-extractor-lib1-test](./build-tests/api-extractor-lib1-test/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-lib2-test](./build-tests/api-extractor-lib2-test/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-lib3-test](./build-tests/api-extractor-lib3-test/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-scenarios](./build-tests/api-extractor-scenarios/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-test-01](./build-tests/api-extractor-test-01/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-test-02](./build-tests/api-extractor-test-02/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-test-03](./build-tests/api-extractor-test-03/) | Building this project is a regression test for api-extractor |\n| [/build-tests/api-extractor-test-04](./build-tests/api-extractor-test-04/) | Building this project is a regression test for api-extractor |\n| [/build-tests/heft-action-plugin](./build-tests/heft-action-plugin/) | This project contains a Heft plugin that adds a custom action |\n| [/build-tests/heft-action-plugin-test](./build-tests/heft-action-plugin-test/) | This project exercises a custom Heft action |\n| [/build-tests/heft-copy-files-test](./build-tests/heft-copy-files-test/) | Building this project tests copying files with Heft |\n| [/build-tests/heft-example-plugin-01](./build-tests/heft-example-plugin-01/) | This is an example heft plugin that exposes hooks for other plugins |\n| [/build-tests/heft-example-plugin-02](./build-tests/heft-example-plugin-02/) | This is an example heft plugin that taps the hooks exposed from heft-example-plugin-01 |\n| [/build-tests/heft-jest-reporters-test](./build-tests/heft-jest-reporters-test/) | This project illustrates configuring Jest reporters in a minimal Heft project |\n| [/build-tests/heft-minimal-rig-test](./build-tests/heft-minimal-rig-test/) | This is a minimal rig package that is imported by the 'heft-minimal-rig-usage-test' project |\n| [/build-tests/heft-minimal-rig-usage-test](./build-tests/heft-minimal-rig-usage-test/) | A test project for Heft that resolves its compiler from the 'heft-minimal-rig-test' package |\n| [/build-tests/heft-node-everything-test](./build-tests/heft-node-everything-test/) | Building this project tests every task and config file for Heft when targeting the Node.js runtime |\n| [/build-tests/heft-oldest-compiler-test](./build-tests/heft-oldest-compiler-test/) | Building this project tests Heft with the oldest supported TypeScript compiler version |\n| [/build-tests/heft-sass-test](./build-tests/heft-sass-test/) | This project illustrates a minimal tutorial Heft project targeting the web browser runtime |\n| [/build-tests/heft-web-rig-library-test](./build-tests/heft-web-rig-library-test/) | A test project for Heft that exercises the '@rushstack/heft-web-rig' package |\n| [/build-tests/heft-webpack4-everything-test](./build-tests/heft-webpack4-everything-test/) | Building this project tests every task and config file for Heft when targeting the web browser runtime using Webpack 4 |\n| [/build-tests/heft-webpack5-everything-test](./build-tests/heft-webpack5-everything-test/) | Building this project tests every task and config file for Heft when targeting the web browser runtime using Webpack 5 |\n| [/build-tests/localization-plugin-test-01](./build-tests/localization-plugin-test-01/) | Building this project exercises @microsoft/localization-plugin. This tests that the plugin works correctly without any localized resources. |\n| [/build-tests/localization-plugin-test-02](./build-tests/localization-plugin-test-02/) | Building this project exercises @microsoft/localization-plugin. This tests that the loader works correctly with the exportAsDefault option unset. |\n| [/build-tests/localization-plugin-test-03](./build-tests/localization-plugin-test-03/) | Building this project exercises @microsoft/localization-plugin. This tests that the plugin works correctly with the exportAsDefault option set to true. |\n| [/build-tests/node-library-build-eslint-test](./build-tests/node-library-build-eslint-test/) |  |\n| [/build-tests/node-library-build-tslint-test](./build-tests/node-library-build-tslint-test/) |  |\n| [/build-tests/rush-stack-compiler-2.4-library-test](./build-tests/rush-stack-compiler-2.4-library-test/) |  |\n| [/build-tests/rush-stack-compiler-2.7-library-test](./build-tests/rush-stack-compiler-2.7-library-test/) |  |\n| [/build-tests/rush-stack-compiler-2.8-library-test](./build-tests/rush-stack-compiler-2.8-library-test/) |  |\n| [/build-tests/rush-stack-compiler-2.9-library-test](./build-tests/rush-stack-compiler-2.9-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.0-library-test](./build-tests/rush-stack-compiler-3.0-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.1-library-test](./build-tests/rush-stack-compiler-3.1-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.2-library-test](./build-tests/rush-stack-compiler-3.2-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.3-library-test](./build-tests/rush-stack-compiler-3.3-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.4-library-test](./build-tests/rush-stack-compiler-3.4-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.5-library-test](./build-tests/rush-stack-compiler-3.5-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.6-library-test](./build-tests/rush-stack-compiler-3.6-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.7-library-test](./build-tests/rush-stack-compiler-3.7-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.8-library-test](./build-tests/rush-stack-compiler-3.8-library-test/) |  |\n| [/build-tests/rush-stack-compiler-3.9-library-test](./build-tests/rush-stack-compiler-3.9-library-test/) |  |\n| [/build-tests/ts-command-line-test](./build-tests/ts-command-line-test/) | Building this project is a regression test for ts-command-line |\n| [/build-tests/web-library-build-test](./build-tests/web-library-build-test/) |  |\n| [/libraries/rushell](./libraries/rushell/) | Execute shell commands using a consistent syntax on every platform |\n| [/repo-scripts/doc-plugin-rush-stack](./repo-scripts/doc-plugin-rush-stack/) | API Documenter plugin used with the rushstack.io website |\n| [/repo-scripts/generate-api-docs](./repo-scripts/generate-api-docs/) | Used to generate API docs for the rushstack.io website |\n| [/repo-scripts/repo-toolbox](./repo-scripts/repo-toolbox/) | Used to execute various operations specific to this repo |\n| [/stack/rush-stack-compiler-shared](./stack/rush-stack-compiler-shared/) |  |\n| [/tutorials/heft-node-basic-tutorial](./tutorials/heft-node-basic-tutorial/) | This project illustrates a minimal tutorial Heft project targeting the Node.js runtime |\n| [/tutorials/heft-node-jest-tutorial](./tutorials/heft-node-jest-tutorial/) | Building this project validates that various Jest features work correctly with Heft |\n| [/tutorials/heft-node-rig-tutorial](./tutorials/heft-node-rig-tutorial/) | This project illustrates a minimal tutorial Heft project targeting the Node.js runtime and using a rig package |\n| [/tutorials/heft-webpack-basic-tutorial](./tutorials/heft-webpack-basic-tutorial/) | This project illustrates a minimal tutorial Heft project targeting the web browser runtime |\n| [/tutorials/packlets-tutorial](./tutorials/packlets-tutorial/) | This project illustrates how to use @rushstack/eslint-plugin-packlets |\n<!-- GENERATED PROJECT SUMMARY END -->\n\n## Contributor Notice\n\nThis repo welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis repo has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n"
 },
 {
  "repo": "microsoft/fluentui-react-native",
  "language": "TypeScript",
  "readme_contents": "# FluentUI React Native\n\n[![npm version](https://badge.fury.io/js/%40fluentui%2Freact-native.svg)](https://badge.fury.io/js/%40fluentui%2Freact-native) [![Build Status](https://dev.azure.com/ms/ui-fabric-react-native/_apis/build/status/PR?branchName=master)](https://dev.azure.com/ms/ui-fabric-react-native/_build/latest?definitionId=226&branchName=master) [![Build Status](https://dev.azure.com/ms/ui-fabric-react-native/_apis/build/status/Publish?branchName=master)](https://dev.azure.com/ms/ui-fabric-react-native/_build/latest?definitionId=229&branchName=master)\n\nFluentUI React Native is a javascript component library that provides developers with controls that are part of the [Fluent Design System](https://www.microsoft.com/design/fluent/). These controls are built on [React Native](https://reactnative.dev/) and fully customizable.\n\nFluentUI React Native is still in the alpha stages of development for both the components and the repo. We encourage anyone who is interested in getting an early glimpse of our plans to download and use our components, but please note that you may hit bumps along the way. Please leave us feedback or file issues if you run into bumps, and we will continue to improve the quality of the repo.\n\nDevelopment status on each platform:\n| Windows | macOS | iOS | Android |\n|---------------------|---------------------|-------------|-------------|\n| Alpha (in progress) | Alpha (in progress) | Alpha (in progress) | Coming Soon |\n\n## Getting Started\n\nIf you have an existing React Native project, it's easy to begin using FluentUI React Native. If you need to setup a new React Native project, please see the [React Native Windows Getting Started documentation](https://microsoft.github.io/react-native-windows/docs/getting-started).\n\n### Prerequisites\n\n- [Standard React Native dependencies](https://microsoft.github.io/react-native-windows/docs/rnw-dependencies#manual-setup)\n- [Node.js](https://nodejs.org/en/download/)\n- [Setting up your React Native Development Environment](https://reactnative.dev/docs/environment-setup)\n\n### Create New React Native project (if needed)\n\n1. Follow the instructions on the [React Native Windows Getting Started documentation](https://microsoft.github.io/react-native-windows/docs/getting-started) to create a React Native project.\n\n2. Navigate to the root folder of your project, and use npm to install the package:\n\n```\n npm i @fluentui/react-native\n```\n\n3. After successful installation, you can test the package by importing components at the top of your app's entry file, e.g. `App.js`:\n\n```jsx\nimport { Checkbox } from '@fluentui/react-native';\n```\n\n4. After importing the @fluentui/react-native package, you can use components such as `Text` and `Checkbox` in your JSX.\n\n```jsx\n// In App.js in a new project\nimport React from 'react';\nimport { View, Text } from 'react-native';\nimport { Checkbox } from '@fluentui/react-native';\nfunction HelloWorldApp() {\n  return (\n    <View\n      style={{\n        flex: 1,\n        justifyContent: 'center',\n        alignItems: 'center'\n      }}\n    >\n      <Text>Hello, world!</Text>\n      <Checkbox label=\"Hello World Checkbox\" />\n    </View>\n  );\n}\nexport default HelloWorldApp;\n```\n\n## Documentation\n\n### Components and Controls\n\nOur component documentation is hosted on the [FluentUI documentation](https://developer.microsoft.com/fluentui).\n\n#### Expanding Component documentation\n\nThe FluentUI website is built out of the [FluentUI repository](https://github.com/microsoft/fluentui/tree/master/apps/public-docsite). React-Native components and controls are documented in a 'cross' (cross-platform) directory in each component page directory, e.g. [Button 'cross' directory](https://github.com/microsoft/fluentui/tree/master/apps/public-docsite/src/pages/Controls/ButtonPage/docs/cross). The FluentUI website can be run locally to verify changes, and should reflect the current state of controls that have established the _v1_ set of properties on any one platform.\n\nSince the FluentUI React Native controls are cross-platform, but represented by a single page, it's important to distinguish platform differences and limitations. Examples include:\n\n- If the component is not available on all supported platforms.\n- If the component has properties not available on all supported platforms.\n- If the component has limited support for a given property on any supported platforms.\n- If the component has distinguishable behavior on a supported platform that must be minded while used.\n\n### Theming framework\n\nOur FluentUI framework documentation is found in this repository alongside the implementation.\n\n- [Theming Overview](./packages/framework/theming-react-native/README.md)\n- [StyleSheets](./packages/framework/themed-stylesheet/README.md)\n- [Customizing Theme Settings](./packages/framework/themed-settings/README.md)\n- [Theme Registry](./packages/framework/theme-registry/README.md)\n- [Tokens](./packages/framework/foundation-tokens/README.md)\n- [Settings and Slots](./packages/framework/foundation-settings/README.md)\n- [Compose](./packages/framework/foundation-compose/README.md) and [Composable](./packages/framework/foundation-composable/README.md)\n\n## Developing in the repo\n\n### Yarn + Lage\n\nThis repo is set up as a monorepo using Yarn workspaces. To install yarn, please follow instructions in the [Yarn documentation](https://classic.yarnpkg.com/en/docs/install/).\n\nFor running tasks the repo has switched to using [Lage](https://github.com/microsoft/lage) for task running. The primary tasks that can be executed at the root are:\n\n- `yarn build` - does the typescript build for all packages in the repository\n- `yarn test` - will build, lint, and run any applicable tests on all packages in the repo\n- `yarn bundle` - will bundle all packages in the repo\n- `yarn buildci` - will build, lint, run tests, and bundle everything in the repo\n\nNote that Lage uses caching to avoid redundant steps and has very minimal output. To avoid caching add `--no-cache` as a command line argument. Similarly adding `--verbose` will give more detailed output.\n\n### Setup your development environment\n\nTo start developing in the repository you can:\n\n1. `git clone https://github.com/microsoft/fluentui-react-native.git`\n1. `cd fluentui-react-native`\n1. `yarn`\n1. `yarn build`\n\nAfter a successful yarn build, you can explore FluentUI Tester, our demo application to play with each of the controls. To run FluentUI Tester, please follow instructions in the [FluentUI Tester readme](./apps/fluent-tester/README.md).\n\n### Beachball\n\nThis repo manages semantic versioning and publishing using [Beachball](https://github.com/microsoft/beachball). When contributing, make sure to run the following before making a pull request:\n\n1. `yarn change` will take you through a command line wizard to generate change files\n2. Make sure to commit and push the newly generated change file\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/pxt-blockly",
  "language": "JavaScript",
  "readme_contents": "# Blockly (Microsoft MakeCode fork)\n\nThis is a fork of [Blockly](https://github.com/google/blockly/), an open source visual programming environment.\nThe fork is maintained by the Microsoft MakeCode team, and is used to power the blocks environment in [PXT](https://github.com/Microsoft/pxt).\n\n\nMajor additions and changes in this fork:\n* [scratch-blocks](https://github.com/llk/scratch-blocks) rendering of the blocks [block_render_svg.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/block_render_svg.js)\n* Using insertion markers instead of dragged connections [insertion_marker_manager.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/insertion_marker_manager.js)\n* Inverted and coloured toolbox modes [toolbox.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/toolbox.js#L428) \n* Supports disabled categories [toolbox.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/toolbox.js#L360)\n* Supports icons in the toolbox\n* Adds a number slider field [field_slider.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/field_slider.js)\n* Zoom in / out with touch gestures [touch_gesture.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/touch_gesture.js)\n* Workspace comments that appear like sticky notes [workspace_comment.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/workspace_comment.js)\n* A number of Edge & IE fixes\n* Support underlining and icons in flyout labels [flyout_button.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/flyout_button.js#L203)\n* Support for multiple flyouts per toolbox for performance reasons [pxt_blockly_functions.js](https://github.com/Microsoft/pxt-blockly/blob/develop/core/pxt_blockly_functions.js#L650)\n\n## Prerequisites\n\n* node, npm\n* python\n\n## Development\n\n```\ngit clone https://github.com/google/closure-library\ncd closure-library\ngit checkout v20180805\ncd ../\ngit clone https://github.com/Microsoft/pxt-blockly\ncd pxt-blockly\nnpm install .\n```\n\n## Building\n\n* `npm run build:core --closure-library` to build blockly (install ``gulp`` if needed ``npm install -g gulp``)\n\n## Update Blockly.d.ts\n\n* `gulp typings` to regenerate blockly.d.ts\n\n## Testing local changes in PXT\n\n* `gulp publish --closure-library` from the ``develop`` branch to generate the blockly-compressed, blocks-compressed, and typings files, and copy them to pxt-blockly\n* run `gulp` in pxt to rebuild the pxt blockly files\n* run `pxt clean && pxt serve` in the **target** directory (eg pxt-arcade, or pxt-minecraft)\n\nThis can be combined into one command (starting from the target directory):\n\n```\ncd ../pxt && gulp && cd ../pxt-arcade && pxt clean && pxt serve --rebundle\n```\n\n**Make sure you've checked out the correct closure-library (see above)**\n\nSee [more tips about **pxt+pxt-blockly** testing](https://github.com/Microsoft/pxt/tree/master/scripts).\n\n## Updating pxt-blockly in PXT\n\n* `gulp bump --closure-library` to bump blockly version, commit, and tag.\n\n* After the Travis has deployed the package to npm, update the pxt-blockly version in `package.json` in the pxt repo.\n\n## Playground\n\nThere is a playground manual testing page at [tests/playground.html](./tests/playground.html), which requires no build step or server running.\n\n## License\n\nThe original Google/Blockly is licensed under Apache License (Version 2.0).\n\nNew code is licensed under MIT.\n"
 },
 {
  "repo": "microsoft/refreshing-config",
  "language": "JavaScript",
  "readme_contents": "![Version](https://img.shields.io/npm/v/refreshing-config.svg)\n![License](https://img.shields.io/github/license/Microsoft/refreshing-config.svg)\n![Downloads](https://img.shields.io/npm/dt/refreshing-config.svg)\n\n# refreshing-config\nConfiguration library that can dynamically refresh configuration values.\n\n# Usage\n1. Construct your configuration store\n2. Instantiate an instance of ```RefreshingConfig``` passing your store to the constructor\n3. Optionally, instantiate your refresh policies and/or change notifiers and add them by calling ```withExtension(extension: object)```\n4. Call ```get(name: string)``` or ```getAll()``` to retrieve configuration values\n5. Call ```set(name: string, value: any)``` or ```delete(name: string)``` to manipulate configuration values\n\nIt is important to note that the configuration values are manipulated in place when they are refreshed so if you have an instance of an object returned from ```get``` or ```getAll``` it may be modified\nwhenever a refresh occurs (this is intentional), if you don't want the values to change you should clone the object and use the clone.\n\n# Stores\nrefreshing-config requires a store that will store the configuration values. We provide a Redis-backed store in https://npmjs.org/package/refreshing-config-redis but you can implement your own store for\nyour configuration backend.\n\n### Writing a store\nStores must implement ```getAll(): IPromise<object>``` and can optionally implement ```set(name: string, value: any): IPromise<any>``` and ```delete(name: string): IPromise<void>```. The ```getAll()```\nfunction should return an object whose keys are the names of the configuration values and the value is the configuration value itself. Stores should support the full set of JavaScript data types.\n\n# Events\nThe following events are emitted from ```RefreshingConfig```:\n* ```set(name, value)```: Emitted when a configuration value has been set in the underlying store where ```name```\nis the name of the configuration value and ```value``` is the new value.\n* ```delete(name)```: Emitted when a configuration value has been deleted where ```name``` is the name\nof the configuration value that was deleted.\n* ```changed(config, patch)```: Emitted when a change is detected in the configuration values after a refresh where\n```config``` is the updated configuration (including unchanged values) and ```patch``` is a JSON patch describing\nthe changes that were detected.\n* ```refresh(config)```: Emitted whenever the configuration is refreshed from the store where ```config```\nis the configuration after the refresh.\n\nThe object returned from ```getAll()``` also has the ```RefreshingConfig``` instance itself in the ```_config``` property. This is\nuseful if you want to pass the configuration object around your application and allowing it to subscribe to updates or otherwise\nmanage the configuration.\n\n# Extensions\nYou can extend refreshing-config's behavior by attaching extensions using ```withExtension```:\n\n```javascript\nconst config = new RefreshingConfig.RefreshingConfig(store)\n  .withExtension(myExtension1)\n  .withExtension(myExtension2);\n```\n\n## Refresh policies\nRefresh policies define when refreshing-config should go back to the store to get updated configuration values. Refresh policies can either be reactive (refreshing-config asks them if it should go back to the store)\nor proactive (they notify refreshing-config that it needs to refresh). If there are multiple refresh policies attached then refreshing-config will go back to the store if **any** of them say a refresh is required.\n\nRefresh policies are bypassed in the following scenarios:\n\n* The read of the first configuration value (to get the initial set of configuration values)\n* After a set or delete (because we know the configuration values are stale)\n\nIf you do not have a refresh policy in place you can explicitly call ```refresh()``` to force a refresh.\n\n### NeverRefreshPolicy (reactive)\nThis is the default policy and will only go to the store when the first setting is read or when we know the values have changed (for example, if ```set``` or ```delete``` is called).\n\n```javascript\nconst config = new RefreshingConfig.RefreshingConfig(store)\n  .withExtension(new RefreshingConfig.RefreshPolicy.NeverRefreshPolicy());\n```\n\n### AlwaysRefreshPolicy (reactive)\nThis policy will go back to the store everytime a configuration value is read.\n\n```javascript\nconst config = new RefreshingConfig.RefreshingConfig(store)\n  .withExtension(new RefreshingConfig.RefreshPolicy.AlwaysRefreshPolicy());\n```\n\n### StaleRefreshPolicy (reactive)\nThis policy will go back to the store if it hasn't been back to the store for the specified number of milliseconds. In this example the store will be accessed at most every 30 seconds:\n\n```javascript\nconst config = new RefreshingConfig.RefreshingConfig(store)\n  .withExtension(new RefreshingConfig.RefreshPolicy.StaleRefreshPolicy(30000));\n```\n\n### IntervalRefreshPolicy (proactive)\nThis policy will proactively refresh the configuration values from the store at the defined interval. In this example the configuration values will be refreshed every 30 seconds.\n\n```javascript\nconst config = new RefreshingConfig.RefreshingConfig(store)\n  .withExtension(new RefreshingConfig.RefreshPolicy.IntervalRefreshPolicy(30000));\n```\n\n### Writing a refresh policy\nA refresh policy must implement either ```shouldRefresh(): boolean``` (for reactive refresh policies) or ```subscribe(subscriber: RefreshingConfig)``` (for proactive refresh policies). Proactive refresh\npolicies should call ```subscriber.refresh()``` whenever they want the configuration values refreshed from the store.\n\n## Change notifiers\nChange notifiers are notified when refreshing-config has modified a configuration value (for example, when ```set``` or ```delete``` is called). This can be used to notify others about the need to refresh config.\nNote that these are not called when configuration values are changed externally in the store, if you want to know about those you should subscribe to the ```changed``` event on ```RefreshingConfig```.\n\nChange notifiers are generally paired with a refresh policy, in this pattern the change notifier is told about the change and communicates it to interested consumers, these consumers consume the notification\nin their refresh policy which then tells the configuration library to retrieve the new values from the store.\n\nThere are no out of the box change notifiers but see https://github.com/Microsoft/refreshing-config-redis to see an example refresh policy/change notifier that use Redis pub/sub to refresh configuration\nvalues automatically when they change.\n\n### Writing a change notifier\nA change notifier must implement the ```publish(operation: string, name: string, value: string)``` method which will be called whenever a ```set``` or ```delete``` is performed. The operation will either\nbe ```set``` or ```delete```, the ```name``` will be the name of the configuration value impacted, and the ```value``` will be the new value (for ```set``` operations).\n\n# Contributing\nPull requests will gladly be considered!\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see\nthe [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)\nwith any additional questions or comments."
 },
 {
  "repo": "microsoft/Kusto-Query-Language",
  "language": "C#",
  "readme_contents": "# Kusto Query Language\n\nKusto Query Language is a simple yet powerful language to query structured, semi-structured and unstructured data. It assumes relational data model of tables and columns with a minimal set of data types. The language is very expressive, easy to read and understand the query intent, and optimized for authoring experiences. \n\n## Content\nThis repo contains a C# parser and a semantic analyzer as well as a translator project that generates the same libraries in Java Script. See [usage examples](src/Kusto.Language/readme.md)\n\n## API Package\nThis source code is also available as a [package on nuget.org](https://www.nuget.org/packages/Microsoft.Azure.Kusto.Language/)\n\n## Query Editor\nIf you need to provide a query authoring experience for the language, consider using the [Kusto language plugin for the Monaco Editor](https://github.com/Azure/monaco-kusto)\n\n## Contribute\n  There are many ways to contribute to Kusto Query Language.\n* [Submit bugs](https://github.com/microsoft/Kusto-Query-Language/issues) and help us verify fixes as they are checked in.\n* Review the [source code changes](https://github.com/microsoft/Kusto-Query-Language/commits/master).\n* Engage with other Kusto Query Language users and developers on [StackOverflow](https://stackoverflow.com/questions/tagged/kusto-query-language).\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see\nthe [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com)\nwith any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/fast-blazor",
  "language": "C#",
  "readme_contents": "# Microsoft.Fast\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![.NET C#](https://img.shields.io/badge/.NET-C%23-blue)](https://img.shields.io/badge/.NET-C%23-blue)\n[![NuGet version](https://badge.fury.io/nu/Microsoft.Fast.Components.FluentUI.svg)](https://badge.fury.io/nu/Microsoft.Fast.Components.FluentUI)\n\n[![Discord](https://img.shields.io/badge/chat%20on-discord-7289da.svg)](https://discord.gg/FcSNfg4)\n[![Twitter](https://img.shields.io/twitter/follow/fast_ui.svg?style=social&label=Follow)](https://twitter.com/intent/follow?screen_name=fast_ui)\n\n:star: We appreciate your star, it helps!\n\n## Introduction\n\nThe `Microsoft.Fast.Components.FluentUI` package provides a lightweight set of wrappers around Microsoft's official FluentUI Web Components. The FluentUI Web Components are built on [FAST](https://www.fast.design/) and work in every major browser. To get up and running with `Microsoft.Fast.Components.FluentUI` see [the Blazor guide](https://www.fast.design/docs/integrations/blazor).\n\nThe source for `@fluentui/web-components` is hosted in [the Fluent UI monorepo](https://github.com/microsoft/fluentui/tree/master/packages/web-components).\n\n## Joining the Community\n\nLooking to get answers to questions or engage with us in realtime? Our community is most active [on Discord](https://discord.gg/FcSNfg4). Submit requests and issues on [GitHub](https://github.com/dotnet/blazor-fluentui/issues/new/choose), or join us by contributing on [some good first issues via GitHub](https://github.com/dotnet/blazor-fluentui/labels/community:good-first-issue).\n\nWe look forward to building an amazing open source community with you!\n\n## Contact\n\n* Join the community and chat with us in real-time on [Discord](https://discord.gg/FcSNfg4).\n* Submit requests and issues on [GitHub](https://github.com/dotnet/blazor-fluentui/issues/new/choose).\n* Contribute by helping out on some of our recommended first issues on [GitHub](https://github.com/dotnet/blazor-fluentui/labels/community:good-first-issue).\n"
 },
 {
  "repo": "microsoft/sonder-ui",
  "language": "HTML",
  "readme_contents": "# Sonder UI\n> a collection of tested, accessible components and component pattern documentation.\n\nThe purpose of this project is to run usability tests on experimental UI patterns, and showcase the component patterns that have been thoroughly tested for accessibility. Each component's readme will include a description of how it was tested, bugs found, expected functionality, and design considerations for extension or authoring similar patterns.\n\nEach pattern is authored as a web component, and can be dropped directly into a project. However, since this is primarily intended as accessibility documentation + reference implementation, they may not be as fully featured and are not guaranteed to be stable or consistently maintained (translation: don't use this directly in production, but try it out and borrow the patterns you find useful).\n\nSuggestions for additional components to include are very welcome; please file an issue.\n\n## Components\n- [Combobox (optionally filterable)](src/components/combobox)\n- [Disclosure](src/components/disclosure)\n- [Modal](src/components/modal)\n- [Multiselect](src/components/multiselect)\n- [Select](src/components/select)\n- [Tooltip (WIP)](src/components/tooltip)\n\n## Repository Structure\n\n- `src/assets`: Shared assets and sample data.\n- `src/components`: Tested, polished components are in here, and each component has its own readme and documentation.\n- `src/draft-components`: Experimental patterns live here. There are often multiple variations of the same UI pattern that co-exist for testing.\n- `src/shared`: Shared utils used by components in `src/components`.\n- `src/studies`: Environments and sample pages used for running usability tests.\n\n## Try it out\n\nTo try out the components and usability study environments in this repository, clone it and run the following:\n\n```\nnpm install\n```\n\nthen:\n\n```\nnpm start\n```\n\nYou should then be able to access the main index at `localhost:3333`, and the usability studies at `localhost:3333/studies`.\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/banner-settings-ado-extension",
  "language": "TypeScript",
  "readme_contents": "[![Build Status](https://dev.azure.com/ms/banner-settings-ado-extension/_apis/build/status/microsoft.banner-settings-ado-extension?branchName=master)](https://dev.azure.com/ms/banner-settings-ado-extension/_build/latest?definitionId=259&branchName=master)\r\n\r\nBanner Settings provides a settings pane under Organization Settings to allow Project Collection Administrators to show sitewide banners. Alert your Azure DevOps users to upcoming changes or events without sending out mass emails. Compatible with Azure DevOps Services and Server.\r\n\r\n![](static/screenshot.png)\r\n\r\n### Features\r\n\r\n- Show banners on any page in Azure DevOps.\r\n- Choose between three types (levels) of messages: Info, Warning, and Error.\r\n- Choose an expiration date for a message.\r\n- Include hyperlinks in your banners using markdown syntax like the banner message below.\r\n\r\n```markdown\r\nWindows October Update released! Please visit the [Windows Insider Blog](https://blogs.windows.com/windowsexperience/tag/windows-insider-program/) for more info.\r\n```\r\n\r\n### Restrictions\r\n\r\n- Only one banner can be shown at a time to keep the interface clean. Banners are prioritized by level. For example, if you have posted a warning message and an info message, the info message will only be shown after a user closes the warning message, or you delete the warning message.\r\n- Banners are restricted to a length of thirty words.\r\n\r\n### Building the project\r\n\r\nJust run:\r\n\r\n    npm run build:dev\r\n    npm run package:dev\r\n\r\nThis produces a .vsix file which can be uploaded to the [Visual Studio Marketplace](https://marketplace.visualstudio.com/azuredevops)\r\n\r\nPublish it to your own publisher by running:\r\n\r\n    npm run publish:dev\r\n\r\nYou can then serve the extension locally and visit your newly published dev environment extension using\r\n\r\n    npm run dev\r\n\r\n### Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments."
 },
 {
  "repo": "microsoft/SandDance",
  "language": "TypeScript",
  "readme_contents": "# SandDance\n\nVisually explore, understand, and present your data.\n\n![sanddance-animation](https://user-images.githubusercontent.com/11507384/54236654-52d42800-44d1-11e9-859e-6c5d297a46d2.gif)\n\nBy using easy-to-understand views, SandDance helps you find insights about your data, which in turn help you tell stories supported by data, build cases based on evidence, test hypotheses, dig deeper into surface explanations, support decisions for purchases, or relate data into a wider, real world context.\n\nSandDance uses unit visualizations, which apply a one-to-one mapping between rows in your database and marks on the screen.\nSmooth animated transitions between views help you to maintain context as you interact with your data.\n\n> This new version of SandDance has been rebuilt from scratch with the goal of being modular, extensible, and embeddable into your custom applications. We are now on GitHub so that we are open and driven by the community through contributions, feature requests, and discussion.\n\nSandDance was created by the [Microsoft Research VIDA Group](https://aka.ms/vida) which explores novel technologies for visualization and immersive data analytics.\n\n## Where can I use SandDance?\n* [Try it now on the web](https://microsoft.github.io/SandDance/app/)\n* Microsoft apps:\n  * [Power BI](https://appsource.microsoft.com/en-us/product/power-bi-visuals/WA200000430) - [*see additional info*](https://github.com/microsoft/SandDance/blob/master/powerbi.md)\n  * [Azure Data Studio](https://docs.microsoft.com/en-us/sql/azure-data-studio/sanddance-extension?view=sql-server-2017)\n  * [VSCode extension](https://marketplace.visualstudio.com/items?itemName=msrvida.vscode-sanddance)\n* 3rd Party apps:\n  * [Observable](https://observablehq.com/collection/@danmarshall/sanddance)\n  * [Jupyter widget](https://github.com/microsoft/SandDance/tree/master/python/jupyter-widget#sanddance-jupyter-widget)\n  * [HASH Core IDE](https://core.hash.ai/) - [*see 'Step Explorer' documentation*](https://docs.hash.ai/core/views#step-explorer)\n* In your own JavaScript apps - see below\n\n## Component architecture\n\nSandDance is an offering of several JavaScript components:\n\n* [sanddance](packages/sanddance/README.md) - the core SandDance visualization canvas.\n* [sanddance-react](packages/sanddance-react/README.md) - the core SandDance visualization canvas for use in React based applications.\n* [sanddance-vue](packages/sanddance-vue/README.md) - the core SandDance visualization canvas for use in Vue based applications.\n* [sanddance-explorer](packages/sanddance-explorer/README.md) - the core SandDance visualization canvas with UI to enable data exploration, for use in React based applications.\n\n## Publications\n\n* 2018 - [Atom: A Grammar for Unit Visualizations](https://www.microsoft.com/en-us/research/uploads/prod/2019/01/atom.pdf)\n  * Deokgun Park, Steven Drucker, Roland Fernandez, Niklas Elmqvist\n  * IEEE Transactions on Visualization and Computer Graphics | December 2018, Vol 24(12): pp. 3032-3043\n* 2015 - [A Unifying Framework for Animated and Interactive Unit Visualizations](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/sanddance.pdf)\n  * Steven Drucker, Roland Fernandez \n  * MSR-TR-2015-65 | August 2015\n\n## Articles & videos\n\n* [SandDance project @ Microsoft Research](https://www.microsoft.com/en-us/research/project/sanddance/)\n* [Microsoft Research webinar / Data Visualization: Bridging the Gap Between Users and Information](https://note.microsoft.com/MSR-Webinar-Data-Visualization-Registration-On-Demand.html).\n* [SQL Server Blog / The August release of Azure Data Studio is now available](https://cloudblogs.microsoft.com/sqlserver/2019/08/15/the-august-release-of-azure-data-studio-is-now-available/)\n* [Open Source Blog / What\u2019s new in SandDance 3](https://cloudblogs.microsoft.com/opensource/2020/06/23/whats-new-sanddance-3-microsoft-research/)\n* [Channel 9 - Data Exposed / Introducing SandDance: Data Visualization in Azure Data Studio](https://channel9.msdn.com/Shows/Data-Exposed/Introducing-SandDance-Data-Visualization-in-Azure-Data-Studio)\n* [Channel 9 - Data Exposed / What is SandDance?](https://channel9.msdn.com/Shows/Data-Exposed/What-is-SandDance)\n* [Hacker News / Microsoft open sources SandDance, a visual data exploration tool](https://news.ycombinator.com/item?id=21224685)\n* [analyticsindiamag.com / Visualizations With SandDance Using Visual Studio Code](https://analyticsindiamag.com/visualizations-with-sanddance-using-visual-studio-code/)\n* [codeburst.io / Exploring Titanic Dataset using Microsoft\u2019s Sandance](https://codeburst.io/exploring-titanic-dataset-using-microsofts-sandance-175eb04b3ac2)\n* [mathkuro.com / VS Code\u306e\u30a4\u30b1\u30e1\u30f3\u3059\u304e\u308b\u5206\u6790\uff06\u53ef\u8996\u5316\u30c4\u30fc\u30ebSand Dance\u306e\u4f7f\u3044\u65b9](https://www.mathkuro.com/vs-code/sand-dance/)\n* [mathkuro.com / \u3010SandDance\u30b0\u30e9\u30d5\u30b5\u30f3\u30d7\u30eb\u3011\u7528\u9014\u306b\u5408\u308f\u305b\u3066\u9078\u629e\u3057\u307e\u3057\u3087\u3046\u25ce](https://www.mathkuro.com/vs-code/sanddance-charts/)\n* [medium.com - @sefaoguzsaglam / how to start data visualizing with Microsoft\u2019s SandDance (for beginners)](https://medium.com/@sefaoguzsaglam/how-to-start-data-visualizing-with-microsofts-sanddance-for-beginners-abe5c0552750)\n* [mssqltips.com / SandDance for Azure Data Studio](https://www.mssqltips.com/sqlservertip/6045/sanddance-for-azure-data-studio/)\n* [sqlshack.com / Exploring the SandDance Visualizations extension in Azure Data Studio](https://www.sqlshack.com/exploring-the-sanddance-visualizations-extension-in-azure-data-studio/)\n* [torbjornzetterlund.com / I got to do some SandDance visualization](https://torbjornzetterlund.com/i-got-to-do-some-sanddance-vizualisation/)\n* [YouTube - Anjani Prasad Atluri / SandDance: A tutorial](https://www.youtube.com/watch?v=sI4WIQEz07w)\n* [YouTube - BI Tracks / SandDance Visualizations Tutorial - Azure Data Studio](https://www.youtube.com/watch?v=iUhvYMggzAQ)\n\n## Changelog\n\n* June 2020 - Major version bump to v3: Now using Deck.gl@8.\n* December 2019 - Major version bump to v2: Now using Vega@5.\n* August 2019 - Initial release to AppSource (Power BI marketplace).\n* April 2019 - Initial release to GitHub.\n\n## Known issues\n\n* Animations require a WebGL2 enabled browser.\n\n## Roadmap\n\n* ~~PowerBI custom visual based on this new architecture.~~ done!\n* ~~Additional views, such as stacks.~~ done!\n* Code examples and tutorials.\n* ~~Faceting for all chart types.~~ done!\n* Better date handling.\n\n## Dependencies\n\nSandDance is created with open source libraries, using [Vega](https://vega.github.io) for chart layout and [Deck.gl](https://deck.gl) for WebGL rendering.\n\n## Development\n\nSee [dev.md](dev.md)\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/fhir-server",
  "language": "C#",
  "readme_contents": "# FHIR Server for Azure\n\nA .NET Core implementation of the FHIR standard.\n\n| CI Build & Deployment | Azure Government Deployment |\n|---|---|\n| [![Build Status](https://microsofthealthoss.visualstudio.com/FhirServer/_apis/build/status/CI%20Build%20%26%20Deploy?branchName=master)](https://microsofthealthoss.visualstudio.com/FhirServer/_build/latest?definitionId=27&branchName=master) | [![Build Status](https://microsofthealthoss.visualstudio.com/FhirServer/_apis/build/status/CI%20Deployment%20MAG?branchName=master)](https://microsofthealthoss.visualstudio.com/FhirServer/_build/latest?definitionId=28&branchName=master)\n\nFHIR Server for Azure is an open-source implementation of the emerging\u202f[HL7 Fast Healthcare Interoperability Resources (FHIR) specification](https://www.hl7.org/fhir/)\u202fdesigned for the Microsoft cloud. The FHIR specification defines how clinical health data can be made interoperable across systems, and the FHIR Server for Azure helps facilitate that interoperability in the cloud. The goal of this Microsoft Healthcare project is to enable developers to rapidly deploy a FHIR service.\n \nWith data in the FHIR format, the FHIR Server for Azure enables developers to quickly ingest and manage FHIR datasets in the cloud, track and manage data access and normalize data for machine learning workloads. FHIR Server for Azure is optimized for the Azure ecosystem: \n* Scripts and ARM templates are available for immediate provisioning in the Microsoft Cloud \n* Scripts are available to map to Azure AAD and enable role-based access control (RBAC) \n\nFHIR Server for Azure is built with logical separation, enabling developers with flexibility to modify how it is implemented, and extend its capabilities as needed. The logic layers of the FHIR server are:\n\n* Hosting Layer \u2013 Supports hosting in different environments, with custom configuration of Inversion of Control (IoC) containers.\n* RESTful API Layer \u2013 The implementation of the APIs defined by the HL7 FHIR specification.\n* Core Logic Layer \u2013 The implementation of the core FHIR logic.\n* Persistence Layer \u2013 A pluggable persistence provider enabling the FHIR server to connect to virtually any data persistence utility. FHIR Server for Azure includes a ready-to-use data persistence provider for Azure Cosmos DB (a globally replicated database service that offers rich querying over data).\n\nFHIR Server for Azure empowers developers \u2013 saving time when they need to quickly integrate a FHIR server into their own applications or providing them with a foundation on which they can customize their own FHIR service. As an open source project, contributions and feedback from the FHIR developer community will continue to improve this project.\n\nPrivacy and security are top priorities and the FHIR Server for Azure has been developed in support of requirements for Protected Health Information (PHI). All the Azure services used in FHIR Server for Azure [meet the compliance requirements for Protected Health Information](https://www.microsoft.com/en-us/trustcenter/compliance/complianceofferings).\n\nThis open source project is fully backed by the Microsoft Healthcare team, but we know that this project will only get better with your feedback and contributions. We are leading the development of this code base, and test builds and deployments daily.\n\nThere is also a managed offering in Azure called the [Azure API for FHIR](https://azure.microsoft.com/services/azure-api-for-fhir/). This Platform as a Service (PaaS) FHIR server is backed by the open source project in this repository and it offers a turn key solution to provisioning a compliant, secure FHIR service.\n\n# Release Notes\nTo see what is releasing in the FHIR Server, please refer to the [releases](https://github.com/microsoft/fhir-server/releases) section on GitHub. Starting in November 2020, we have tags on the PRs to better describe what is releasing. We have also released documentation on how to test the most recently build [here](docs/Testing-Releases.md). \n\n# Documentation\n\n## Getting Started\n- Quickstart guides to deploy open source using [portal](docs/QuickstartDeployPortal.md), [CLI](docs/QuickstartDeployCLI.md), and [PowerShell](docs/QuickstartDeployPowershell.md).\n- [Sql Schema Migration Guide](docs/SchemaMigrationGuide.md): Describes how to upgrade Schema for Sql Server.\n- [Register a resource application](docs/Register-Resource-Application.md): Learn how to register a resource application, which is an Azure Active Directory representation of the FHIR server API.\n- [Register a client application](docs/Register-Client-Application.md): Learn how to register a client application registration, which is an Azure Active Directory representation of an application that can be used to authenticate on behalf of a user and request access to resource applications.\n\n## Core FHIR Capabilities\n- [Azure API for FHIR documentation](https://docs.microsoft.com/azure/healthcare-apis/): Includes all Azure API for FHIR documentation which has many conceptual, how-to guides, and tutorials that can be leveraged in open-source as well.\n- [Features](https://docs.microsoft.com/en-us/azure/healthcare-apis/fhir-features-supported): This document lists the main features of the FHIR Server for Azure and Azure API for FHIR.\n- [Authentication](docs/Authentication.md): Describes the authentication settings for the FHIR server and how to make use of it in development and test scenarios.\n- [Roles](docs/Roles.md): Describes how the FHIR Server for Azure role-based access control (RBAC) system works.\n- [Search](docs/SearchArchitecture.md): Describes how search is implemented for the FHIR Server for Azure.\n\n## Additional Capabilities\n- [Bulk Export](docs/BulkExport.md): Describes using Bulk Export within the FHIR Server.\n- [Convert Data](docs/ConvertDataOperation.md): Describes how to use $convert to convert data into FHIR.\n- [FHIR Proxy](https://github.com/microsoft/health-architectures/tree/master/FHIR/FHIRProxy): Secure FHIR Gateway and Proxy to FHIR Servers.\n\n## Tutorials & How-to Guides\n- [Health Architectures](https://aka.ms/healtharchitectures): A collection of reference architectures illustrating end-to-end best practices for using the Azure API for FHIR and related technologies.\n- [FHIR Server Samples Repo](https://github.com/Microsoft/fhir-server-samples): A demo sandbox using the Azure API for FHIR.\n- [SMART on FHIR Proxy tutorial](docs/SMARTonFHIR.md): Describes how to use the proxy to enable SMART on FHIR applications with the FHIR Server.\n- [FHIR Postman tutorial](https://docs.microsoft.com/azure/healthcare-apis/access-fhir-postman-tutorial): Describes how to access a FHIR API using Postman.\n- [Debugging](docs/HowToDebug.md): Describes how to debug FHIR Server for Azure using Visual Studio.\n\n## Blog Posts\n* Blog: [FHIR Server for Azure, an open source project for modern healthcare](https://cloudblogs.microsoft.com/industry-blog/health/2018/11/12/fhir-server-for-azure-an-open-source-project-for-cloud-based-health-solutions/).\n* Blog: [Azure API for FHIR moves to general availability](https://azure.microsoft.com/en-us/blog/azure-api-for-fhir-moves-to-general-availability/).\n* Twitter: [Health_IT](https://twitter.com/Health_IT)\n\n## Contributing\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThere are many other ways to contribute to FHIR Server for Azure.\n* [Submit bugs](https://github.com/Microsoft/fhir-server/issues) and help us verify fixes as they are checked in.\n* Review the [source code changes](https://github.com/Microsoft/fhir-server/pulls).\n* Engage with FHIR Server for Azure users and developers on [StackOverflow](https://stackoverflow.com/questions/tagged/fhir-server-for-azure).\n* Join the [#fhirforazure](https://twitter.com/hashtag/fhirserverforazure?f=tweets&vertical=default) discussion on Twitter.\n* [Contribute bug fixes](CONTRIBUTING.md).\n\nSee [Contributing to FHIR Server for Azure](CONTRIBUTING.md) for more information.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\nFHIR&reg; is the registered trademark of HL7 and is used with the permission of HL7. \n\n"
 },
 {
  "repo": "microsoft/powerbi-visuals-enhancedscatter",
  "language": "TypeScript",
  "readme_contents": "# EnhancedScatter\n![Build](https://github.com/microsoft/powerbi-visuals-utils-testutils/workflows/build/badge.svg)[![Coverage Status](https://coveralls.io/repos/github/Microsoft/powerbi-visuals-enhancedscatter/badge.svg?branch=master)](https://coveralls.io/github/Microsoft/powerbi-visuals-enhancedscatter?branch=master)\n\n> A few more properties were added to the existing scatter chart visual, including shapes as markers, background image support, and developer crosshairs for positioning elements onto an image background.\n\n![Enhancedscatter screenshot](https://raw.githubusercontent.com/microsoft/powerbi-visuals-enhancedscatter/master/assets/screenshot.png)\n\n# Overview\nEnhanced Scatter introduces a few more properties that were added on top of the existing scatter chart visual, including shapes as markers, background image support, and developer crosshairs for positioning elements onto an image background.\n\nSee also [Enhanced Scatter at Microsoft Office store](https://store.office.com/en-us/app.aspx?assetid=WA104380762&sourcecorrid=dfd34541-621e-4f3b-a6ab-398e528af4ab&searchapppos=0&ui=en-US&rs=en-US&ad=US&appredirect=false)\n"
 },
 {
  "repo": "microsoft/ts-parsec",
  "language": "TypeScript",
  "readme_contents": "# ts-parsec\r\n\r\n## Contributing\r\n\r\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\r\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\r\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\r\n\r\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\r\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\r\nprovided by the bot. You will only need to do this once across all repos using our CLA.\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\r\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\r\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n## Using ts-parsec with npm\r\n\r\n```cmd\r\nnpm install -g typescript-parsec\r\n```\r\n\r\n## Building this repo\r\n\r\n```cmd\r\nyarn\r\nyarn build\r\nyarn test\r\n```\r\n\r\n## Packages\r\n\r\n- **ts-parsec**: Parser combinator for TypeScript\r\n- **tspc-test**: Unit test project\r\n- **tspc-utilities**: Code generator for developing **ts-parsec**\r\n  - At this moment, running `npm run update` will write overloadings for `alt` and `seq` for you\r\n\r\n## Introduction\r\n\r\nts-parsec is a parser combinator library prepared for typescript. By using this library, you are able to create parsers very quickly using just a few lines of code. It provides the following features:\r\n\r\n- **Tokenizer based on regular expressions**. This tokenizer is designed for convenience. For some cases its performance may be unsatisfying. In this case, you could write your own tokenizer. It is very easy to plug your tokenizer into ts-parsec.\r\n- **Parser combinators**.\r\n- The ability to support recursive syntax.\r\n\r\nYou are recommended to learn [EBNF](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form) before using this library.\r\n\r\nPlease read [Getting Started](./doc/GettingStarted.md) for ramping up, or our [document page](./doc/README.md) for deeper understanding.\r\n\r\n## More Examples\r\n\r\n- [A simple calculator](./packages/tspc-test/src/TestRecursiveParser.ts)\r\n- [A minimum Flow parser](https://github.com/microsoft/react-native-tscodegen/blob/master/packages/minimum-flow-parser/src/Parser.ts)\r\n\r\n## In the Future\r\n\r\nFollowing combinators will be released soon:\r\n\r\n- A context sensitive **apply** combinator.\r\n\r\nContext sensitive tokenizer is also comming.\r\n"
 },
 {
  "repo": "microsoft/superbenchmark",
  "language": "Python",
  "readme_contents": "# SuperBenchmark\n\n[![Lint](https://github.com/microsoft/superbenchmark/workflows/Lint/badge.svg)](https://github.com/microsoft/superbenchmark/actions?query=workflow%3ALint)\n[![Codecov](https://codecov.io/gh/microsoft/superbenchmark/branch/main/graph/badge.svg?token=DDiDLW7pSd)](https://codecov.io/gh/microsoft/superbenchmark)\n\n| Azure Pipelines | Build Status |\n| :---: | :---: |\n| cpu-unit-test | [![Build Status](https://dev.azure.com/msrasrg/SuperBenchmark/_apis/build/status/microsoft.superbenchmark?branchName=main)](https://dev.azure.com/msrasrg/SuperBenchmark/_build/latest?definitionId=77&branchName=main) |\n| gpu-unit-test | [![Build Status](https://dev.azure.com/msrasrg/SuperBenchmark/_apis/build/status/cuda-unit-test?branchName=main)](https://dev.azure.com/msrasrg/SuperBenchmark/_build/latest?definitionId=80&branchName=main) |\n\n\nSuperBench is a benchmarking and diagnosis tool for AI infrastructure,\nwhich supports:\n* Comprehensive AI infrastructure validation\n    * Distributed validation tools to validate hundreds or thousands of servers automatically\n    * Consider both raw hardware and E2E model performance with ML workload patterns\n    * Provide a fast and accurate way to detect and locate hardware problems\n    * Performance/Quality Gates for hardware and system release\n* Benchmarking with typical AI workload patterns\n    * Provide comprehensive performance comparison between different existing hardware\n    * Give a better understanding for new DL software & hardware\n* Detailed performance analysis and diagnosis\n    * Provide detailed performance report and advanced analysis tool  \u00a0\n\nIt includes micro-benchmark for primitive computation and communication benchmarking,\nand model-benchmark to measure domain-aware end-to-end deep learning workloads.\n\n> \ud83d\udd34 __Note__:\nSuperBench is in the early pre-alpha stage for open source, and not ready for general public yet.\nIf you want to jump in early, you can try building latest code yourself.\n\n\n## Installation\n\n### Using Docker (_Preferred_)\n\n__System Requirements__\n\n* Platform: Ubuntu 18.04 or later (64-bit)\n* Docker: Docker CE 19.03 or later\n\n__Install SuperBench__\n\n* Using Pre-Build Images\n\n    ```sh\n    docker pull superbench/superbench:dev-cuda11.1.1\n    docker run -it --rm \\\n        --privileged --net=host --ipc=host --gpus=all \\\n        superbench/superbench:dev-cuda11.1.1 bash\n    ```\n\n* Building the Image\n\n    ```sh\n    docker build -f dockerfile/cuda11.1.1.dockerfile -t superbench/superbench:dev .\n    ```\n\n### Using Python\n\n__System Requirements__\n\n* Platform: Ubuntu 18.04 or later (64-bit); Windows 10 (64-bit) with WSL2\n* Python: Python 3.6 or later, pip 18.0 or later\n\n    Check whether Python environment is already configured:\n    ```sh\n    # check Python version\n    python3 --version\n    # check pip version\n    python3 -m pip --version\n    ```\n    If not, install the followings:\n    * [Python](https://www.python.org/)\n    * [pip](https://pip.pypa.io/en/stable/installing/)\n    * [venv](https://docs.python.org/3/library/venv.html)\n\n    It's recommended to use a virtual environment (optional):\n    ```sh\n    # create a new virtual environment\n    python3 -m venv --system-site-packages ./venv\n    # activate the virtual environment\n    source ./venv/bin/activate\n\n    # exit the virtual environment later\n    # after you finish running superbench\n    deactivate\n    ```\n\n__Install SuperBench__\n\n* PyPI Binary\n\n    ```sh\n    # not available yet\n    ```\n\n* From Source\n\n    ```sh\n    # get source code\n    git clone https://github.com/microsoft/superbenchmark\n    cd superbenchmark\n\n    # install superbench\n    python3 -m pip install .\n    ```\n\n\n## Usage\n\n### Run SuperBench\n\n```sh\n# run benchmarks in default settings\nsb exec\n\n# use a custom config\nsb exec --config-file ./superbench/config/default.yaml\n```\n\n### Benchmark Gallary\n\nPlease find more benchmark examples [here](examples/benchmarks/).\n\n\n## Developer Guide\n\nFollow [Installation using Python](#using-python).\n\n### Set Up\n\n```sh\n# get latest code\ngit clone https://github.com/microsoft/superbenchmark\ncd superbenchmark\n\n# install superbench\npython3 -m pip install -e .[dev,test]\n```\n\n### Lint and Test\n\n```sh\n# format code using yapf\npython3 setup.py format\n\n# check code style with mypy and flake8\npython3 setup.py lint\n\n# run all unit tests\npython3 setup.py test\n```\n\n### Submit a Pull Request\n\nPlease install `pre-commit` before `git commit` to run all pre-checks.\n\n```sh\npre-commit install\n```\n\nOpen a pull request to main branch on GitHub.\n\n\n## Contributing\n\n### Contributor License Agreement\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n### Contributing principles\n\nSuperBenchmark is an open-source project. Your participation and contribution are highly appreciated. There are several important things you need know before contributing to this project:\n\n#### What content can be added to SuperBenchmark\n\n1. Bug fixes for existing features.\n2. New features for benchmark module (micro-benchmark, model-benchmark, etc.)\n\n   If you would like to contribute a new feature on SuperBenchmark, please submit your proposal first. In [GitHub Issues](https://github.com/microsoft/superbenchmark/issues) module, choose `Enhancement Request` to finish the submission. If the proposal is accepted, you can submit pull requests to origin main branch.\n\n#### Contribution steps\n\nIf you would like to contribute to the project, please follow below steps of joint development on GitHub.\n\n1. `Fork` the repo first to your personal GitHub account.\n2. Checkout from main branch for feature development.\n3. When you finish the feature, please fetch the latest code from origin repo, merge to your branch and resolve conflict.\n4. Submit pull requests to origin main branch.\n5. Please note that there might be comments or questions from reviewers. It will need your help to update the pull request.\n\n## Trademarks\n\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft\ntrademarks or logos is subject to and must follow\n[Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).\nUse of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.\nAny use of third-party trademarks or logos are subject to those third-party's policies.\n"
 },
 {
  "repo": "microsoft/sarif-sdk",
  "language": "C#",
  "readme_contents": "# sarif-sdk\n[![Build Status](https://dev.azure.com/mseng/1ES/_apis/build/status/microsoft.sarif-sdk?branchName=master)](https://dev.azure.com/mseng/1ES/_build/latest?definitionId=9978&branchName=master)\n\nThe SARIF SDK contains .NET code and supporting files for working with the Static Analysis Results Interchange Format (SARIF). For more information about SARIF, see the [SARIF Home Page](http://sarifweb.azurewebsites.net). You can read the [SARIF specification](https://rawgit.com/sarif-standard/sarif-spec/master/Static%20Analysis%20Results%20Interchange%20Format%20(SARIF).html), or file [issues](https://github.com/sarif-standard/sarif-spec/issues) in the [SARIF GitHub repo](https://github.com/sarif-standard/sarif-spec).\n\n## Getting started\n\nTo add the SARIF SDK to your project, install the Sarif.Sdk [NuGet package](https://www.nuget.org/packages/Sarif.Sdk). Sarif.Sdk depends on [Newtonsoft.Json](http://www.newtonsoft.com/json), which is installed automatically when you install Sarif.Sdk.\n\nThe types in the SARIF SDK are in the `Microsoft.CodeAnalysis.Sarif` namespace.\n\nThe SARIF SDK provides a set of classes which represent the elements of the SARIF format. We refer to this as the \"SARIF object model\". The root type that represents a SARIF log file is `SarifLog`. Other types in the SARIF object model are `Result`, `PhysicalLocation`, _etc._.\n\nNote: The SARIF SDK's build process automatically generates the SARIF object model classes from the SARIF JSON schema, which you can find at [`src/Sarif/Schemata/sarif-schema.json`](https://github.com/Microsoft/sarif-sdk/blob/master/src/Sarif/Schemata/sarif-schema.json). Although these files do exist in the repo (under [`src/Sarif/Autogenerated`](https://github.com/Microsoft/sarif-sdk/tree/master/src/Sarif/Autogenerated)), you should never edit them by hand.\n\nIn addition to the object model, the SARIF SDK provides a set of helper classes to facilitate using Newtonsoft.Json to read and write SARIF log files.\n\n## Building the SDK\n\nIf you want to build the SDK from source, rather than consuming the NuGet package,\nproceed as follows:\n\n1. Install .NET Core SDK 2.1 and 3.1 from https://dotnet.microsoft.com/download\n\n2. Ensure that Visual Studio 2019 is installed on your machine.\n\n    You can build in VS 2017 as well.\n\n3. Ensure that your Visual Studio installation includes the components that support\n    - C# development\n\n4. Open a Visual Studio 2019 Developer Command Prompt Window.\n\n5. From the root directory of your local repo, run the command `BuildAndTest.cmd`.\n    This restores all necessary NuGet packages, builds the SDK, and runs all the tests.\n\n    All build output appears in the `bld\\` subdirectory of the repo root directory.\n\n    NOTE: You must run `BuildAndTest.cmd` once _before_ attempting to build in\n    Visual Studio, to ensure that all required NuGet packages are available.\n\n6. After you have run `BuildAndTest.cmd` once, you can open any of the solution files\nin the `src\\` directory in Visual Studio 2017, and build them by running **Rebuild Solution**.\n\n\n## Accomplishing common tasks\n\nTo learn how to accomplish common tasks with the SARIF SDK, such as reading and writing files from disk,\nsee the [How To](https://github.com/Microsoft/sarif-sdk/blob/master/docs/how-to.md) page.\n\n## Code of conduct\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information, see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/),\nor contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n "
 },
 {
  "repo": "microsoft/epic-supervisor",
  "language": "TypeScript",
  "readme_contents": "# @mixer/epic-supervisor\n\n> Project status: this repo is actively maintained and currently used in production code.\n\n[redux-observable](https://github.com/redux-observable/redux-observable) is an RxJS-based side effects module for Redux. Unfortunately, it lacks a built-in way to handle uncaught errors, which by default are unlogged and break all epics in the application. The maintainers [have indicated](https://github.com/redux-observable/redux-observable/issues/94#issuecomment-454968018) that there's no immediate plans to implement a 'first-party' solution for error handling. So, this is ours! This module implements an [Erlang/OTP-style supervisor](http://erlang.org/doc/design_principles/sup_princ.html) pattern for epics. Out of the box it provides a `combineEpics`-compatible function which instruments epics with error logging, and provides an additional `superviseEpics` method which provides additional supervision options for epics.\n\n```ts\n// 1. import from this module, instead of redux-observable:\nimport { combineEpics } from '@mixer/epic-supervisor';\n\n// 2. Define your epics...\nconst fooEpic = /* ... */;\nconst barEpic = /* ... */;\n\n// 3. combineEpics() like you normall would:\nexport const myEpics = combineEpics(fooEpic, barEpic);\n```\n\n# API\n\n## `combineEpics(...epics)`\n\nBy default, this method functions identically to [`combineEpics`](https://redux-observable.js.org/docs/api/combineEpics.html) from `redux-observable`.\n\n## `superviseEpics(options, ...epics)`\n\nThis works like `combineEpics`, except with an options argument in front. The options object can take several parameters, all optional:\n\n- **restart**: defines how epics should be restarted if they error. May be one of `noRestarts`, `oneForOne`, `oneForAll`, or `restForOne`. See the [erlang supervisor page](http://erlang.org/doc/design_principles/sup_princ.html#restart-strategy) for nice diagrams of these. Defaults to `noRestarts`, indicating restarts will not occur.\n- **onError**: a function with the same mechanism as RxJS `catchError()`-- it will be invoked with the error context object (see beow) that occurs, followed by the actions, state, and services just like a normal epic. If restart is enabled we'll wait for the returned observable to emit before restarting epics. If an error is thrown or rethrown from this method, it will bubble up to any parent supervisor.\n- **onRestart**: a function invoked after epics are restarted. Same call signature as `onError`.\n\nExample:\n\n```ts\nimport { superviseEpics, oneForOne } from '@mixer/epic-supervisor';\nimport { timer } from 'rxjs';\n\nconst fooEpic = /* ... */;\nconst barEpic = /* ... */;\n\nconst options = {\n  restart: oneForOne,\n  onError: ({ epicName, error }, actions, state, services) => {\n    // Send another action when the error occurs:\n    actions.dispatch(doLogErrorAction({ message: `An error occurred in epic ${epicName}`, error }));\n    // Wait a second before restarting epics:\n    return timer(1000);\n  },\n  onRestart (_, actions) => {\n    actions.dispatch(restartMyService());\n  },\n};\n\nsuperviseEpics(options, fooEpic, barEpic);\n```\n\n## `configure(options)`\n\nConfigures the global/default options for epic-supervisor. The options object can take several parameters, all optional:\n\n- **onAnyError**: A method invoked with any error that gets observed. The first any only argument is the ErrorContext object.\n- **onUnhandledError**: A method invoked with any error not handled by (or thrown-from) the user-supplied `onError` method.\n\n```ts\nimport { configure } from '@mixer/epic-supervisor';\n\nconfigure({\n  onAnyError: context => myLogger.warn(context),\n  onUnhandledError: context => myLogger.error(context),\n});\n```\n\n## Error Context Object\n\nThe error context (`IErrorContext` for TypeScript consumers) captures thrown errors along with some metadata--as rxjs stacktraces are often inscrutable. It has the following properties:\n\n- **error**: the original error that was thrown;\n- **epicName**: the function name of the epic that the error came from. This may be `null` for epics that lack a function name.\n- **epicSource**: the epic source string; useful for tracking down errors from unnamed or minified epics.\n- **innerError**: can be set if an error happened whilst handling a previous error. The 'outer' error will be second error, while the innerError will be the original one.\n- **innermostError**: gets the deepest `innerError`, the original error that occurred. Returns the current error context if there is no innerError.\n"
 },
 {
  "repo": "microsoft/windows-rs",
  "language": "Rust",
  "readme_contents": "[![crates.io](https://img.shields.io/crates/v/windows.svg)](https://crates.io/crates/windows)\n[![docs.rs](https://docs.rs/windows/badge.svg)](https://docs.rs/windows)\n[![Build and Test](https://github.com/microsoft/windows-rs/workflows/Build%20and%20Test/badge.svg?event=push)](https://github.com/microsoft/windows-rs/actions)\n\n## Rust for Windows\n\nThe `windows` crate lets you call any Windows API past, present, and future using code generated on the fly directly from the metadata describing the API and right into your Rust package where you can call them as if they were just another Rust module.\n\nThe Rust language projection follows in the tradition established by [C++/WinRT](https://github.com/microsoft/cppwinrt) of building language projections for Windows using standard languages and compilers, providing a natural and idiomatic way for Rust developers to call Windows APIs.\n\nWatch the [Getting Started](https://www.youtube.com/watch?v=-oZrsCPKsn4) video! Microsoft Docs also has content on [developing with Rust on Windows](https://docs.microsoft.com/en-us/windows/dev-environment/rust/).\n\nCheck out the [FAQ](./docs/FAQ.md) for answers to frequently asked questions.\n\n## Getting started\n\nStart by adding the following to your Cargo.toml file:\n\n```toml\n[dependencies]\nwindows = \"0.9.1\"\n\n[build-dependencies]\nwindows = \"0.9.1\"\n```\n\nThis will allow Cargo to download, build, and cache Windows support as a package. Next, specify which types you need inside of a `build.rs` build script and the `windows` crate will generate the necessary bindings:\n\n```rust\nfn main() {\n    windows::build!(\n        Windows::Data::Xml::Dom::*,\n        Windows::Win32::System::Threading::{\n            CreateEventW, SetEvent, WaitForSingleObject\n        },\n        Windows::Win32::System::WindowsProgramming::CloseHandle,\n        Windows::Win32::UI::WindowsAndMessaging::MessageBoxA,\n    );\n}\n```\n\nFinally, make use of any Windows APIs as needed.\n\n```rust\nmod bindings {\n    windows::include_bindings!();\n}\n\nuse bindings::{\n    Windows::Data::Xml::Dom::*,\n    Windows::Win32::System::Threading::{CreateEventW, SetEvent, WaitForSingleObject},\n    Windows::Win32::System::WindowsProgramming::CloseHandle,\n    Windows::Win32::UI::WindowsAndMessaging::{MessageBoxA, MESSAGEBOX_STYLE},\n};\n\nfn main() -> windows::Result<()> {\n    let doc = XmlDocument::new()?;\n    doc.LoadXml(\"<html>hello world</html>\")?;\n\n    let root = doc.DocumentElement()?;\n    assert!(root.NodeName()? == \"html\");\n    assert!(root.InnerText()? == \"hello world\");\n\n    unsafe {\n        let event = CreateEventW(std::ptr::null_mut(), true, false, None);\n        SetEvent(event).ok()?;\n        WaitForSingleObject(event, 0);\n        CloseHandle(event).ok()?;\n\n        MessageBoxA(None, \"Text\", \"Caption\", MESSAGEBOX_STYLE::MB_OK);\n    }\n\n    Ok(())\n}\n```\n\nTo reduce build time, use a `bindings` crate rather than simply a module. This will allow Cargo to cache the results and build your project far more quickly.\n\nThere is an experimental [documentation generator](https://github.com/microsoft/windows-docs-rs) for the Windows API. The documentation [is published here](https://microsoft.github.io/windows-docs-rs/). This can be useful to figure out how the various Windows APIs map to Rust modules and which `use` paths you need to use from within the `build` macro.\n\nMore examples [can be found here](examples). Robert Mikhayelyan's [Minesweeper](https://github.com/robmikh/minesweeper-rs) is also a great example.\n\nA more in-depth getting started guide can also be found [here](docs/getting-started.md).\n"
 },
 {
  "repo": "microsoft/tabster",
  "language": "TypeScript",
  "readme_contents": "# Tabster\n*Tabindex on steroids.*\n\nA set of tools and concepts for making a dynamic web application properly accessible and keyboard-navigable.\n\n## About\n\n*This project is pretty much in a work-in-progress proof-of-concept state. More docs and examples are to come.*\n\nThe way a browser and the screen readers handle a web application is evolved from the static web era. A process of making a modern dynamic web application accessible presents a number of challenges like, for example, the proper focus management between modal dialogs, popups, lists and other parts of the dynamically changing application. This project is an attempt to solve some of those challenges.\n\n## Dependencies\n\nThis project is framework-agnostic. It operates on the DOM level and has no external runtime dependencies. Though it is possible that your framework or application might have own logic to achieve similar result, in that case runtime conflicts and behavioural inconsistencies are definitely possible. At the same time, it does not do things automatically and parts of it should be explicitly enabled.\n\n## Parts\n\n### Focusable\n\nAn API for traversing focusable elements.\n\n### Deloser\n\nWhen you remove, for example, a button which has focus from the DOM, the focus gets lost which is confusing for the screen reader and keyboard navigation users. Deloser is a concept which helps to automatically restore the focus when it gets lost without manually calling `.focus()` method from the application code.\n\n### FocusedElementState\n\nAn event and a couple of methods to track and change currently focused element.\n\n### KeyboardNavigationState\n\nAn event and a method to determine if the user is using keyboard to navigate through the application.\n\n### Groupper\n\nKeyboard navigation for the lists should allow to avoid going through every list item when the users use Tab key (only one item of the list should be tabbable), also the arrow keys and Home/End/PageUp/PageDown keys should be handled to move between the list items. This is an API to easily make properly behaving lists.\n\n### Modalizer\n\nWhen you show, for example, a modal dialog, the rest of the application might need to be excluded from the keyboard and screen reader navigation flow. Modalizer is a concept to conveniently make that possible.\n\n### Outline\n\nWhen people navigate with the keyboard, the currently focused element should be properly highlighted. There is a CSS property called `outline`, which is unfortunately insufficient: the outline of an element gets cropped when a parent element has `overflow: hidden`, there is no way to limit the outline visibility to only the cases when the user is navigating with keyboard. So, we have a custom outline component which is supposed to solve both of the problems.\n\n## Contributing\n\nContributions are welcome (see the [CONTRIBUTING](./CONTRIBUTING.md) file), though please keep in mind the work-in-progress proof-of-concept state. Might make sense to just observe/discuss until the thing gets stable and well-documented.\n\nThe repo now has an examples project powered by Storybook. Just run `npm start`\n\n## License\nThis project is licensed under the MIT License, see the [LICENSE](LICENSE) file for details.\n"
 },
 {
  "repo": "microsoft/fluentui-android",
  "language": "Kotlin",
  "readme_contents": "# Fluent UI for Android\n\n##### The Android UI framework for building experiences for Office and Office 365.\n\nFluent UI for Android is a native library that provides the Office UI experience for the Android platform. It contains information about colors and typography, as well as custom controls and customizations for platform controls, all from the official Fluent design language used in Office and Office 365 products.\n\n\n### Build status (master branch)\n\n| Build Service   | Status                                                                                                                                                                                                                                                           |\n| --------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n| App Center      | [![Build status](https://build.appcenter.ms/v0.1/apps/7acc51be-c1e6-4351-8fa4-c4536fd42dd8/branches/master/badge)](https://appcenter.ms)                                                                                                                         |\n| Azure Pipelines | [![Build Status](https://dev.azure.com/microsoftdesign/fluentui-native/_apis/build/status/fluentui-android/fluentui-android-build?branchName=refs%2Fpull%2F3249%2Fmerge)](https://dev.azure.com/microsoftdesign/fluentui-native/_build/latest?definitionId=145&branchName=master) |\n\n## Contents\n\n- [Colors and typography](#colors-and-typography)\n- [Controls](#controls)\n- [Install and use Fluent UI](#install-and-use-fluent-ui)\n- [Demo app](#demo-app)\n- [Contributing](#contributing)\n- [License](#license)\n- [Changelog](#changelog)\n\n## Colors and typography\n\nFluent UI for Android provides [colors](FluentUI/src/main/res/values/colors.xml) and [typography](FluentUI/src/main/res/values/styles_font.xml) based on the Fluent design language.\n\n## Controls\n\nFluent UI for Android includes an expanding library of controls written in Kotlin. These controls implement the Fluent design language and bring consistency across Office app experiences.\n\nSome of the controls available include:\n- AvatarView\n- Button styles\n- BottomSheet\n- CalendarView\n- CircularProgress styles\n- DateTimePickerDialog\n- Drawer\n- ListItemView\n- PeoplePickerView\n- PersonaChipView\n- PersonaListView\n- PersonaView\n- Snackbar\n- TemplateView\n- Tooltip\n\nA full list of currently supported controls can be found here: [FluentUI](FluentUI/src/main/java/com/microsoft/fluentui).\n\n## Install and use Fluent UI\n\n### Requirements\n\nAPI 21+\n\n### 1. Using Gradle\n\n- Our library is published through JCenter, so make sure the `jcenter()` repository has been added to your project level build.gradle file (which usually is automatic).\n\n- Inside the dependency block in your build.gradle, add this line for the FluentUI library:\n```gradle\ndependencies {\n    ...\n    implementation 'com.microsoft.fluentui:FluentUIAndroid:$version'\n    ...\n}\n```\n- Make sure you replace `$version` with the latest version of FluentUI.\n\n#### a) Develop for Surface-Duo:\n- Please also add the following lines to your repositories section in your gradle script:\n```gradle\nmaven {\n    url \"https://pkgs.dev.azure.com/MicrosoftDeviceSDK/DuoSDK-Public/_packaging/Duo-SDK-Feed/maven/v1\"\n}\n```\n- Also add the SDK dependency to the module-level build.gradle file(current version may be  different\nfrom what's shown here):\n```gradle\nimplementation \"com.microsoft.device:dualscreen-layout:1.0.0-alpha01\"\n```\n\n### 2. Using Maven\n\n- Add the FluentUI library as a dependency:\n```xml\n<dependency>\n  <groupId>com.microsoft.fluentui</groupId>\n  <artifactId>FluentUIAndroid</artifactId>\n  <version>${version}</version>\n</dependency>\n```\n\n- Make sure you replace `${version}` with the latest version of FluentUI.\n\n### 3. Manual installation\n\n- Download the latest changes from the [Fluent UI Android](https://github.com/microsoft/fluentui-android) repository.\n\n- Follow [these instructions](https://developer.android.com/studio/projects/android-library) to build and output an AAR file from the FluentUI module, import the module to your project, and add it as a dependency. If you're having trouble generating an AAR file for the module, make sure you select it and run \"Make Module 'FluentUI'\" from the Build menu.\n\n- Some components have dependencies you will need to manually add to your app if you are using this library as an AAR artifact because these dependencies do not get included in the output.\n  - If using **PeoplePickerView**, include this dependency in your gradle file:\n    ```gradle\n    implementation 'com.splitwise:tokenautocomplete:2.0.8'\n    ```\n  - If using **CalendarView** or **DateTimePickerDialog**, include this dependency in your gradle file:\n    ```gradle\n    implementation 'com.jakewharton.threetenabp:threetenabp:1.1.0'\n    ```\n  - Double check that these library versions correspond to the latest versions we implement in the FluentUI [build.gradle](FluentUI/build.gradle).\n\n### Import and use the library\n\nIn code:\n```kotlin\nimport com.microsoft.fluentui.persona.AvatarView\n```\n\nIn XML:\n```xml\n<com.microsoft.fluentui.persona.AvatarView\n    android:layout_width=\"wrap_content\"\n    android:layout_height=\"wrap_content\"\n    app:name=\"Mona Kane\" />\n```\n\n## Demo app\n\nIncluded in this repository is a demo of currently implemented controls. A full list of implemented controls available in the demo can be found here:  [Demos](FluentUI.Demo/src/main/java/com/microsoft/fluentuidemo/demos).\n\nTo see samples of all of our implemented controls and design language, run the [FluentUI.Demo](FluentUI.Demo) module in Android Studio.\n\n## Contributing\n\nPost bug reports, feature requests, and questions in [Issues](https://github.com/microsoft/fluentui-android/issues).\n\n## Changelog\n\nWe use [GitHub Releases](https://github.com/blog/1547-release-your-software) to manage our releases, including the changelog between every release. You'll find a complete list of additions, fixes, and changes on the [Releases page](https://github.com/microsoft/fluentui-android/releases).\n\n## License\n\nAll files on the Fluent UI for Android GitHub repository are subject to the MIT license. Please read the [LICENSE](LICENSE) file at the root of the project.\n\nUsage of the logos and icons referenced in Fluent UI for Android is subject to the terms of the [assets license agreement](https://aka.ms/fabric-assets-license).\n"
 },
 {
  "repo": "microsoft/Windows-AppConsult-Samples-UWP",
  "language": "C#",
  "readme_contents": "\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/powerquery-language",
  "language": "TypeScript",
  "readme_contents": "# Overview\n\nThis repository stores the .tmLanguage file for the Power Query / M language.\n\n## Usage\n\nThe Power Query TextMate grammar file ([PowerQuery.tmLanguage](https://raw.githubusercontent.com/Microsoft/powerquery-language/master/PowerQuery.tmLanguage)) can be consumed directly.\n\n### Update and test\n\nEdit the PowerQuery.YAML-tmLanguage file. Running the build process will generate the PowerQuery.tmLanguage file.\n\nRun the following to build and test:\n\n```\nnpm install\nnpm run-script build\nnpm test\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/ApplicationInsights-node.js-native-metrics",
  "language": "C++",
  "readme_contents": "# ApplicationInsights Node.js Native Metrics\nNative Metrics Agent for the Application Insights Node.js SDK\n\n## Getting Started\nYour app must be using the [Application Insights Node.js SDK](https://github.com/microsoft/applicationinsights-node.js).\n\nOnce your app is using the Application Insights SDK, you can add native metrics capabilities by simply adding the native-metrics package to your app.\nNo further configuration is required!\n```zsh\nnpm i --save applicationinsights-native-metrics\n```\n\n## Contributing\nFor details on contributing to this repository, see the [contributing guide](https://github.com/microsoft/ApplicationInsights-node.js-native-metrics/master/CONTRIBUTING.md).\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit\nhttps://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/CBL-Mariner",
  "language": "Go",
  "readme_contents": "# CBL-Mariner\r\n\r\n| Release Branch | Status                                                                                                                                                                                                 |\r\n| -------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\r\n| 1.0            | [![1.0 Status](https://github.com/microsoft/CBL-Mariner/workflows/Verify%20Quickstart%201.0/badge.svg)](https://github.com/microsoft/CBL-Mariner/actions?query=workflow%3A%22Verify+Quickstart+1.0%22) |\r\n\r\nCBL-Mariner is an internal Linux distribution for Microsoft\u2019s cloud infrastructure and edge products and services. CBL-Mariner is designed to provide a consistent platform for these devices and services and will enhance Microsoft\u2019s ability to stay current on Linux updates. This initiative is part of Microsoft\u2019s increasing investment in a wide range of Linux technologies, such as [SONiC](https://azure.microsoft.com/en-us/blog/sonic-the-networking-switch-software-that-powers-the-microsoft-global-cloud/), [Azure Sphere OS](https://docs.microsoft.com/en-us/azure-sphere/product-overview/what-is-azure-sphere) and [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/about). CBL-Mariner is being shared publicly as part of Microsoft\u2019s commitment to Open Source and to contribute back to the Linux community. CBL-Mariner does not change our approach or commitment to any existing third-party Linux distribution offerings. \r\n\r\nCBL-Mariner has been engineered with the notion that a small common core set of packages can address the universal needs of first party cloud and edge services while allowing individual teams to layer additional packages on top of the common core to produce images for their workloads. This is made possible by a simple build system that enables:\r\n\r\n- **Package Generation:** This produces the desired set of RPM packages from SPEC files and source files. \r\n- **Image Generation:** This produces the desired image artifacts like ISOs or VHDs from a given set of packages. \r\n\r\nWhether deployed as a container or a container host, CBL-Mariner consumes limited disk and memory resources. The lightweight characteristics of CBL-Mariner also provides faster boot times and a minimal attack surface. By focusing the features in the core image to just what is needed for our internal cloud customers there are fewer services to load, and fewer attack vectors. \r\n\r\nWhen security vulnerabilities arise, CBL-Mariner supports both a package-based update model and an image based update model.  Leveraging the common [RPM Package Manager](https://rpm.org/) system, CBL-Mariner makes the latest security patches and fixes available for download with the goal of fast turn-around times.   \r\n\r\n# Getting Started with CBL-Mariner: \r\n\r\nInstructions for building CBL-Mariner may be found here: [Toolkit Documentation](./toolkit/README.md)\r\n\r\n# Trademarks\r\n\r\nThis project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow [Microsoft's Trademark & Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general). Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies.\r\n\r\n# Acknowledgments \r\n\r\nAny Linux distribution, including CBL-Mariner, benefits from contributions by the open software community. We gratefully acknowledge all contributions made from the broader open source community, in particular:\r\n\r\n1) The [Photon OS Project](https://vmware.github.io/photon/) for SPEC files originating from the Photon distribution.   \r\n\r\n2) [The Fedora Project](https://start.fedoraproject.org/) for SPEC files, particularly with respect to QT, DNF and several of their dependencies. \r\n\r\n3) [GNU](https://www.gnu.org/) and the [Free Software Foundation](https://www.fsf.org/)\r\n\r\n4) [Linux from Scratch](http://www.linuxfromscratch.org)\r\n\r\n5) [Openmamba](https://openmamba.org/en/) for SPEC files\r\n"
 },
 {
  "repo": "microsoft/vscode-dev-containers",
  "language": "Shell",
  "readme_contents": "# VS Code Remote / GitHub Codespaces Container Definitions\n\n<table style=\"width: 100%; border-style: none;\"><tr>\n<td style=\"width: 140px; text-align: center;\"><a href=\"https://aka.ms/vscode-remote/download/extension\"><img width=\"128px\" src=\"https://microsoft.github.io/vscode-remote-release/images/remote-extensionpack.png\" alt=\"Visual Studio Code logo\"/></a></td>\n<td>\n<strong>Visual Studio Code Remote Development and GitHub Codespaces</strong><br />\n<i>Open your code in the cloud, in a local container, on a remote machine, or in WSL and take advantage of VS Code's full feature set.\n</td>\n</tr></table>\n\nA **development container** is a running [Docker](https://www.docker.com) container with a well-defined tool/runtime stack and its prerequisites. The [VS Code Remote - Containers](https://aka.ms/vscode-remote/download/containers) extension and [GitHub Codespaces](https://github.com/features/codespaces) allow you to open or clone code in a local or cloud-hosted dev container and take advantage of VS Code's full development feature set.\n\nThis repository contains a set of **dev container definitions** to help get you up and running with a containerized environment. The definitions describe the appropriate container image, runtime arguments for starting the container, and VS Code extensions that should be installed. Each provides a container configuration file (`devcontainer.json`) and other needed files that you can drop into any existing folder as a starting point for containerizing your project. You can use the the **Add Development Container Configuration Files...** command to add one to your project or codespace.\n\nThe [vscode-remote-try-*](https://github.com/search?q=org%3Amicrosoft+vscode-remote-try-&type=Repositories) repositories may also be of interest if you are looking for complete sample projects.\n\n## Adding a definition to a project or codespace\n  \n  1. Either [create a codespace for your repository](https://aka.ms/ghcs-open-codespace) or [set up your local machine](https://aka.ms/vscode-remote/containers/getting-started) for use with the Remote - Containers extension, start VS Code, and open your project folder.\n  2. Press <kbd>F1</kbd>, and select the **Add Development Container Configuration Files...** command for **Remote-Containers** or **Codespaces**.\n  3. Pick one of the recommended definitions from the list or select **Show All Definitions...** to see all of them. You may need to choose the **From a predefined container configuration definition...** option if your project has an existing Dockerfile or Docker Compose file. Answer any questions that appear.\n  4. See the definition's `README` for configuration options. A link is available in the `.devcontainer/devcontainer.json` file added to your folder.\n  5. Run **Remote-Containers: Reopen in Container** to use it locally, or **Codespaces: Rebuild Container** from within a codespace.\n\n### Adding a definition to a repository\n\nYou can share a customized dev container definition for your project by adding the files under `.devcontainer` to source control.\n\nAnyone who then opens a local copy of your repo in VS Code will be prompted to reopen the folder in a container, provided they have the [Remote - Containers](https://aka.ms/vscode-remote/download/containers) extension installed. Additionally, this will be used whenever someone creates a codespace in [GitHub Codespaces](https://github.com/features/codespaces) for the repository.\n\nYour team now has a consistent environment and tool-chain and new contributors or team members can be productive quickly. First-time contributors will require less guidance and there will be fewer issues related to environment setup.\n\n## Sample projects\n\nIf you want to try a sample project which already has a dev container, check out one of the following repositories:\n\n- [Node Sample](https://github.com/Microsoft/vscode-remote-try-node)\n- [Python Sample](https://github.com/Microsoft/vscode-remote-try-python)\n- [Go Sample](https://github.com/Microsoft/vscode-remote-try-go)\n- [Java Sample](https://github.com/Microsoft/vscode-remote-try-java)\n- [.NET Core Sample](https://github.com/Microsoft/vscode-remote-try-dotnetcore)\n- [Rust Sample](https://github.com/microsoft/vscode-remote-try-rust)\n- [C++ Sample](https://github.com/microsoft/vscode-remote-try-cpp)\n- [PHP Sample](https://github.com/microsoft/vscode-remote-try-php)\n\n## Contents\n\n- [`containers`](containers) - Contains reusable dev container definitions.\n- [`script-library`](script-library) - Includes scripts used in this repository to install things. Also useful in your own Dockerfiles.\n- [`repository-containers`](repository-containers) - Dev container definitions for working public source code repositories. Only used by Remote - Containers.\n- [`container-templates`](container-templates) - Contains templates for creating your own container definitions or to [contribute back](CONTRIBUTING.md#contributing-dev-container-definitions).\n\n## Common Questions\n\n### Can I just reuse an existing container image or Docker / Docker Compose configuration?\n\nYes! If you have a Dockerfile or Docker Compose file in your project/repository, follow the [same steps to add a definition](#adding) and you'll be prompted to select a Dockerfile or Docker Compose file and customize from there. If you then commit these files to a Git repository, you can use it with [GitHub Codespaces](https://github.com/features/codespaces) as well. If you prefer, you can also start up the container manually and [attach to it](https://aka.ms/vscode-remote/containers/attach). However, note that many images will be missing things like `git` that you will want to use. There are scripts in the [script-library](script-library) like the [common script](script-library/docs/common.md) that can help adding these to your existing Dockerfile or image.\n\n### What is the goal of `devcontainer.json`?\n\nA `devcontainer.json` file is similar to `launch.json` for debugging, but designed to launch (or attach to) a development container instead. At its simplest, all you need is a `.devcontainer/devcontainer.json` file in your project that references an image, `Dockerfile`, or `docker-compose.yml`, and a few properties. You can [adapt it for use](https://aka.ms/vscode-remote/containers/folder-setup) in a wide variety of situations.\n\n### Why do Dockerfiles in this repo use `RUN` statements with commands separated by `&&`?\n\nEach `RUN` statement creates a Docker image \"layer\". If one `RUN` statement adds temporary contents, these contents remain in this layer in the image even if they are deleted in a subsequent `RUN`. This means the image takes more storage locally and results in slower image download times if you publish the image to a registry. You can resolve this problem by using a `RUN` statement that includes any clean up steps (separated by `&&`) after a given operation. See [CONTRIBUTING.md](./CONTRIBUTING.md#why-do-dockerfiles-in-this-repository-use-run-statements-with-commands-separated-by-) for more tips.\n\n## Contributing and feedback\n\nHave a question or feedback?\n\n- Contribute or provide feedback for the [VS Code Remote](https://github.com/Microsoft/vscode-remote-release/blob/master/CONTRIBUTING.md) extensions or [GitHub Codespaces](https://github.com/github/feedback/discussions/categories/codespaces-feedback).\n- Search [existing issues](https://github.com/Microsoft/vscode-dev-containers/issues) with dev container definitions or [report a problem](https://github.com/Microsoft/vscode-dev-containers/issues/new).\n- Contribute a [development container definition](CONTRIBUTING.md#contributing-dev-container-definitions) to the repository.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## License\n\nCopyright (c) Microsoft Corporation. All rights reserved. <br />\nLicensed under the MIT License. See [LICENSE](LICENSE).\n\nFor images generated from this repository, see [LICENSE](https://github.com/microsoft/containerregistry/blob/master/legal/Container-Images-Legal-Notice.md) and [NOTICE.txt](NOTICE.txt).\n"
 },
 {
  "repo": "microsoft/beachball",
  "language": "TypeScript",
  "readme_contents": "<!--\nIf making changes, don't forget to update the version under packages/beachball/README.md too!\n-->\n\n# beachball\n\nthe sunniest version bumping tool\n\n## Prerequisites\n\ngit and a remote named \"origin\"\n\n## Usage\n\n```\nbeachball [command] [options]\n```\n\n## Commands\n\n### change (default)\n\na tool to help create change files in the change/ folder\n\n### check\n\nchecks whether a change file is needed for this branch\n\n### changelog\n\nbased on change files, create changelogs and then unlinks the change files\n\n### bump\n\nbumps versions as well as generating changelogs\n\n### publish\n\nbumps, publishes to npm registry (optionally does dist-tags), and pushes changelogs back into master\n\n### sync\n\nsynchronizes published versions of packages from a registry, makes local package.json changes to match what is published\n\n## Options\n\n### --config, -c\n\nExplicit configuration file to use instead of the configuration automatically detected by cosmicconfig.\n\n### --registry, -r\n\nregistry, defaults to https://registry.npmjs.org\n\n### --tag, -t\n\n- for the publish command: dist-tag for npm publishes\n- for the sync command: will use specified tag to set the version\n\n### --branch, -b\n\ntarget branch from origin (default: master)\n\n### --message, -m\n\ncustom message for the checkin (default: applying package updates)\n\n### --no-push\n\nskip pushing changes back to git remote origin\n\n### --no-publish\n\nskip publishing to the npm registry\n\n### --help, -?, -h\n\nshow help message\n\n### --yes, -y\n\nskips the prompts for publish\n\n## Examples\n\n```\n  $ beachball\n\n  $ beachball check\n\n  $ beachball publish -r http://localhost:4873 -t beta\n```\n\n<!--\nIf making changes, don't forget to update the version under packages/beachball/README.md too!\n-->\n"
 },
 {
  "repo": "microsoft/vscode-test",
  "language": "TypeScript",
  "readme_contents": "# vscode-test\n\n![Test Status Badge](https://github.com/microsoft/vscode-test/workflows/Tests/badge.svg)\n\nThis module helps you test VS Code extensions.\n\nSupported:\n\n- Node >= 12.x\n- Windows >= Windows Server 2012+ / Win10+ (anything with Powershell >= 5.0)\n- macOS\n- Linux\n\n## Usage\n\nSee [./sample](./sample) for a runnable sample, with [Azure DevOps Pipelines](https://github.com/microsoft/vscode-test/blob/master/sample/azure-pipelines.yml) and [Travis CI](https://github.com/microsoft/vscode-test/blob/master/.travis.yml) configuration.\n\n```ts\nasync function go() {\n\ttry {\n\t\tconst extensionDevelopmentPath = path.resolve(__dirname, '../../../')\n\t\tconst extensionTestsPath = path.resolve(__dirname, './suite')\n\n\t\t/**\n\t\t * Basic usage\n\t\t */\n\t\tawait runTests({\n\t\t\textensionDevelopmentPath,\n\t\t\textensionTestsPath\n\t\t})\n\n\t\tconst extensionTestsPath2 = path.resolve(__dirname, './suite2')\n\t\tconst testWorkspace = path.resolve(__dirname, '../../../test-fixtures/fixture1')\n\n\t\t/**\n\t\t * Running another test suite on a specific workspace\n\t\t */\n\t\tawait runTests({\n\t\t\textensionDevelopmentPath,\n\t\t\textensionTestsPath: extensionTestsPath2,\n\t\t\tlaunchArgs: [testWorkspace]\n\t\t})\n\n\t\t/**\n\t\t * Use 1.36.1 release for testing\n\t\t */\n\t\tawait runTests({\n\t\t\tversion: '1.36.1',\n\t\t\textensionDevelopmentPath,\n\t\t\textensionTestsPath,\n\t\t\tlaunchArgs: [testWorkspace]\n\t\t})\n\n\t\t/**\n\t\t * Use Insiders release for testing\n\t\t */\n\t\tawait runTests({\n\t\t\tversion: 'insiders',\n\t\t\textensionDevelopmentPath,\n\t\t\textensionTestsPath,\n\t\t\tlaunchArgs: [testWorkspace]\n\t\t})\n\n\t\t/**\n\t\t * Noop, since 1.36.1 already downloaded to .vscode-test/vscode-1.36.1\n\t\t */\n\t\tawait downloadAndUnzipVSCode('1.36.1')\n\n\t\t/**\n\t\t * Manually download VS Code 1.35.0 release for testing.\n\t\t */\n\t\tconst vscodeExecutablePath = await downloadAndUnzipVSCode('1.35.0')\n\t\tawait runTests({\n\t\t\tvscodeExecutablePath,\n\t\t\textensionDevelopmentPath,\n\t\t\textensionTestsPath,\n\t\t\tlaunchArgs: [testWorkspace]\n\t\t})\n\n\t\t/**\n\t\t * Install Python extension\n\t\t */\n\t\tconst cliPath = resolveCliPathFromVSCodeExecutablePath(vscodeExecutablePath)\n\t\tcp.spawnSync(cliPath, ['--install-extension', 'ms-python.python'], {\n\t\t\tencoding: 'utf-8',\n\t\t\tstdio: 'inherit'\n\t\t})\n\n\t\t/**\n\t\t * - Add additional launch flags for VS Code\n\t\t * - Pass custom environment variables to test runner\n\t\t */\n\t\tawait runTests({\n\t\t\tvscodeExecutablePath,\n\t\t\textensionDevelopmentPath,\n\t\t\textensionTestsPath,\n\t\t\tlaunchArgs: [\n\t\t\t\ttestWorkspace,\n\t\t\t\t// This disables all extensions except the one being tested\n\t\t\t\t'--disable-extensions'\n\t\t\t],\n\t\t\t// Custom environment variables for extension test script\n\t\t\textensionTestsEnv: { foo: 'bar' }\n\t\t})\n\n\t\t/**\n\t\t * Use win64 instead of win32 for testing Windows\n\t\t */\n\t\tif (process.platform === 'win32') {\n\t\t\tawait runTests({\n\t\t\t\textensionDevelopmentPath,\n\t\t\t\textensionTestsPath,\n\t\t\t\tversion: '1.40.0',\n\t\t\t\tplatform: 'win32-x64-archive'\n\t\t\t});\n\t\t}\n\n\t} catch (err) {\n\t\tconsole.error('Failed to run tests')\n\t\tprocess.exit(1)\n\t}\n}\n\ngo()\n```\n\n## Development\n\n- `yarn install`\n- Make necessary changes in [`lib`](./lib)\n- `yarn compile` (or `yarn watch`)\n- In [`sample`](./sample), run `yarn install`, `yarn compile` and `yarn test` to make sure integration test can run successfully\n\n## License\n\n[MIT](LICENSE)\n\n## Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/terraform-provider-azuredevops",
  "language": "Go",
  "readme_contents": "# Terraform Provider for Azure DevOps (Devops Resource Manager)\n\n[![Gitter](https://badges.gitter.im/terraform-provider-azuredevops/community.svg)](https://gitter.im/terraform-provider-azuredevops/community?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n[![Go Report Card](https://goreportcard.com/badge/github.com/microsoft/terraform-provider-azuredevops)](https://goreportcard.com/report/github.com/microsoft/terraform-provider-azuredevops)\n\nThe AzureRM Provider supports Terraform 0.12.x and later.\n\n* [Terraform Website](https://www.terraform.io)\n* [Azure DevOps Website](https://azure.microsoft.com/en-us/services/devops/)\n* [Provider Documentation](./website/docs/index.html.markdown)\n* [Resources Documentation](./website/docs/r/)\n* [Data Sources Documentation](./website/docs/d/)\n* [Usage Examples](./examples/)\n* [Gitter Channel](https://gitter.im/terraform-provider-azuredevops/community)\n\n## Usage Example\n\n```hcl\n# Make sure to set the following environment variables:\n#   AZDO_PERSONAL_ACCESS_TOKEN\n#   AZDO_ORG_SERVICE_URL\nterraform {\n  required_providers {\n    azuredevops = {\n      source = \"microsoft/azuredevops\"\n      version = \">=0.1.0\"\n    }\n  }\n}\n\nresource \"azuredevops_project\" \"project\" {\n  name = \"My Awesome Project\"\n  description  = \"All of my awesomee things\"\n}\n\nresource \"azuredevops_git_repository\" \"repository\" {\n  project_id = azuredevops_project.project.id\n  name       = \"My Awesome Repo\"\n  initialization {\n    init_type = \"Clean\"\n  }\n}\n\nresource \"azuredevops_build_definition\" \"build_definition\" {\n  project_id = azuredevops_project.project.id\n  name       = \"My Awesome Build Pipeline\"\n  path       = \"\\\\\"\n\n  repository {\n    repo_type   = \"TfsGit\"\n    repo_id     = azuredevops_git_repository.repository.id\n    branch_name = azuredevops_git_repository.repository.default_branch\n    yml_path    = \"azure-pipelines.yml\"\n  }\n}\n```\n\n## Developer Requirements\n\n* [Terraform](https://www.terraform.io/downloads.html) version 0.13.x +\n* [Go](https://golang.org/doc/install) version 1.16.x (to build the provider plugin)\n\nIf you're on Windows you'll also need:\n\n* [Git for Windows](https://git-scm.com/download/win)\n\nIf you what to use the `makefile` build strategy on Windows it's required to install\n\n* [Make for Windows](http://gnuwin32.sourceforge.net/packages/make.htm)\n\nFor *GNU32 Make*, make sure its bin path is added to PATH environment variable.*\n\nFor *Git Bash for Windows*, at the step of \"Adjusting your PATH environment\", please choose \"Use Git and optional Unix tools from Windows Command Prompt\".*\n\nAs [described below](#build-using-powerShell-scripts) we provide some PowerShell scripts to build the provider on Windows, without the requiremet to install any Unix based tools aside Go.\n\n## Developing the Provider\n\nIf you wish to work on the provider, you'll first need [Go](http://www.golang.org) installed on your machine (version 1.16+ is **required**). You'll also need to correctly setup a [GOPATH](http://golang.org/doc/code.html#GOPATH), as well as adding `$GOPATH/bin` to your `$PATH`.\n\n### Using the GOPATH model\n\nFirst clone the repository to: `$GOPATH/src/github.com/microsoft/terraform-provider-azuredevops`\n\n```sh\n$ mkdir -p $GOPATH/src/github.com/terraform-providers && cd \"$_\"\n$ git clone git@github.com:microsoft/terraform-provider-azuredevops.git\n$ cd terraform-provider-azuredevops\n```\n\nOnce you've cloned, run the `./scripts/build.sh` and `./scripts/local-install.sh`, as recommended [here](https://github.com/microsoft/terraform-provider-azuredevops/blob/master/docs/contributing.md#3-build--install-provider).\nThese commands will sideload the plugin for Terraform.\n\n### Using a directory separate from GOPATH\n\nThe infrastructure supports building and testing the provider outside `GOPATH` in an arbitrary directory.\nIn this scenario all required packages of the provider during build will be managed via the `pkg` in `$GOPATH`. As with the [GOPATH Model](#using-the-gopath-model), you can redefine the `GOPATH` environment variable to prevent existing packages in the current `GOPATH` directory from being changed.\n\n### Build using make\n\nOnce inside the provider directory, you can run `make tools` to install the dependent tooling required to compile the provider.\n\nAt this point you can compile the provider by running `make build`, which will build the provider and put the provider binary in the `$GOPATH/bin` directory.\n\n```sh\n$ make build\n...\n$ $GOPATH/bin/terraform-provider-azuredevops\n...\n```\n\nYou can also cross-compile if necessary:\n\n```sh\nGOOS=windows GOARCH=amd64 make build\n```\n\n#### Unit tests\n\nIn order to run the Unit Tests for the provider, you can run:\n\n```sh\n$ make test\n```\n\nWith VSCode Golang extension you can also run and debug the tests using `run test`, `debug test` `run package tests`, `run file tests` buttons.\n\n#### Acceptance tests\n\nThe majority of tests in the provider are acceptance tests - which provisions real resources in Azure Devops and Azure. To run any acceptance tests you need to set `AZDO_ORG_SERVICE_URL`, `AZDO_PERSONAL_ACCESS_TOKEN` environment variables, some test have additional environment variables required to run. You can find out the required environment variables by running the test. Most of these variables can be set to dummy values.\n\nThe several options to run the tests are:\n\n* Run the entire acceptance test suite\n\n  ```sh\n  make testacc\n  ```\n\n* Run a subset using a prefix\n\n  ```sh\n  make testacc TESTARGS='-run=TestAccBuildDefinitionBitbucket_Create' TESTTAGS='resource_build_definition'\n  ```\n\n* With VSCode Golang extension you can also run the tests using `run test`, `run package tests`, `run file tests` buttons above the test\n\n### Build using PowerShell scripts\n\nIf you like to develop on Windows, we provide a set of PowerShell scripts to build and test the provider.\nThey don't offer the luxury of a Makefile environment but are quite sufficient to develop on Windows.\n\n#### `scripts\\build.ps1`\n\nThe `build.ps1`is used to build the provider. Aside this the script runs (if not skipped) the defined unit tests and is able to install the compiled provider locally.\n\n| Parameter   | Description                                                                               |\n| ----------- | ----------------------------------------------------------------------------------------- |\n| -SkipTests  | Skip running unit tests during build                                                      |\n| -Install    | Install the provider locally, after a successful build                                    |\n| -DebugBuild | Build the provider with extra debugging information                                       |\n| -GoMod      | Control the `-mod` build parameter: Valid values: '' (Empty string), 'vendor', 'readonly' |\n\n#### `scripts\\unittest.ps1`\n\nThe script is used to execute unit tests. The script is also executed by `build.ps1` if the `-SkipTest` are not specified.\n\n| Parameter   | Description                                                                                                                       |\n| ----------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| -TestFilter | A GO regular expression which filters the test functions to be executed                                                           |\n| -Tag        | Tests in the provider project are organized with GO build tags. The parameter accepts a list of tag names which should be tested. |\n| -GoMod      | Control the `-mod` build parameter: Valid values: '' (Empty string), 'vendor', 'readonly'                                         |\n\n#### `scripts\\acctest.ps1`\n\nThe script is used to execute unit tests.\n\n| Parameter   | Description                                                                                                                       |\n| ----------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| -TestFilter | A GO regular expression which filters the test functions to be executed                                                           |\n| -Tag        | Tests in the provider project are organized with GO build tags. The parameter accepts a list of tag names which should be tested. |\n| -GoMod      | Control the `-mod` build parameter: Valid values: '' (Empty string), 'vendor', 'readonly'                                         |\n\n#### `scripts\\gofmtcheck.ps1`\n\nTo validate if all `.go` files adhere to the required formatting rules, execute `gofmtcheck.ps1`\n\n| Parameter | Description                                                                                                    |\n| --------- | -------------------------------------------------------------------------------------------------------------- |\n| -Fix      | Fix any formatting rule deviations automatically. If the parameter is not set, the script runs in report mode. |\n\n#### `scripts\\lint-check-go.ps1`\n\nLike with `gofmtcheck.ps1` the script validate if all `.go` files adhere to the required formatting rules and if any style mistakes exist. In difference to `gofmtcheck.ps1` the script uses Golint instead of Gofmt.\n\n## Environment variables for acceptance tests\n\nThe following Environment Variables must be set in your shell prior to running acceptance tests:\n\n- `AZDO_ORG_SERVICE_URL`\n- `AZDO_PERSONAL_ACCESS_TOKEN`\n- `AZDO_DOCKERREGISTRY_SERVICE_CONNECTION_EMAIL`\n- `AZDO_DOCKERREGISTRY_SERVICE_CONNECTION_PASSWORD`\n- `AZDO_DOCKERREGISTRY_SERVICE_CONNECTION_USERNAME`\n- `AZDO_GITHUB_SERVICE_CONNECTION_PAT`\n- `AZDO_TEST_AAD_USER_EMAIL`\n\n**Note:** Acceptance tests create real resources in Azure DevOps which often cost money to run.\n"
 },
 {
  "repo": "microsoft/adaptivecards-templates",
  "language": "JavaScript",
  "readme_contents": "\r\n# Adaptive Cards Template Service\r\n\r\nThe Adaptive Cards Template Service is a proof-of-concept service that allows anyone to find, contribute to, and share a broad set card templates. Templates are great if you want to display some data but want to save time by not having to write a custom adaptive card for it.\r\n\r\nTo learn more about Adaptive Cards visit https://adaptivecards.io\r\n\r\nCheck this our for an [overview of Adaptive Card Templating](https://docs.microsoft.com/en-us/adaptive-cards/templating/)\r\n\r\n> *Terms and agreement* \r\n> \r\n> This **preview** service is provided \"as-is\", with all faults and is not supported in any way. The service does not store or collect any data beyond the default Azure Function collection. Any data collection from the service is subject to the [Microsoft privacy statement](https://go.microsoft.com/fwlink/?LinkID=824704).\r\n> \r\n> These features are **in preview and subject to change**. Your feedback is not only welcome, but  critical to ensure we deliver the features **you** need.\r\n\r\n## How does the service help me?\r\n\r\nLet's say I just got a piece of data, maybe it's financial data, Microsoft Graph data, schema.org data, or custom data from within my organization. \r\n\r\nNow I want to display the data to a user. \r\n\r\nTraditionally that means writing custom UI code in all of the front-end stacks that I deliver to end-users.\r\n\r\nBut what if there were a world where my app could \"learn\" new UI templates based on the type of data? A world where anyone could contribute, enhance, and share common UI templates, within their own projects, within an organization, or for the entire internet.\r\n\r\n## What is the card template service?\r\n\r\nThe card template service is a simple REST endpoint that helps:\r\n\r\n* **Find** a template by analyzing the structure of your data\r\n* **Get** a template so you can bind it directly on the client, *without sending your data to the server or ever leaving the device*\r\n* **Populate** a template on the server, when client-side data binding isn't appropriate or possible\r\n\r\nBehind it all, is:\r\n\r\n* A shared, open-source template repository backed by GitHub. *(The repo is currently private but will be made public as soon as we tie up some loose ends)*\r\n* All the templates are flat JSON files in the repo, which makes editing, contributing, and sharing a natural part of a developer workflow.\r\n* The code for the service will be made available so you can host wherever makes the most sense to you. \r\n\r\n## Using the service\r\n\r\n### Get all templates \r\n\r\nThis endpoint returns a list of all known templates.\r\n\r\n> `HTTP GET https://templates.adaptivecards.io/list`\r\n\r\n**Response excerpt**\r\n\r\n```json\r\n{\r\n  \"graph.microsoft.com\": {\r\n    \"templates\": [\r\n      {\r\n        \"file\": \"Files.json\",\r\n        \"fullPath\": \"graph.microsoft.com/Files.json\"\r\n      },\r\n      {\r\n        \"file\": \"Profile.json\",\r\n        \"fullPath\": \"graph.microsoft.com/Profile.json\"\r\n      }\r\n   ]\r\n}\r\n```\r\n\r\n### Find a template\r\n\r\nYou can find templates one of two ways.\r\n\r\nThe first is by `POST`ing your data to the endpoint, which will analyze the structure of your data and see if any templates can be found.\r\n\r\n> `HTTP POST https://templates.adaptivecards.io/find`\r\n\r\nThe other option is by passing an `odata.type` via query string, for example:\r\n\r\n> `HTTP GET https://templates.adaptivecards.io/find?odata.type=%23microsoft.graph.user`\r\n\r\n#### Example\r\n\r\nLet's say I just hit a [Microsoft Graph](https://graph.microsoft.com) endpoint to get organizational data about me.\r\n\r\n> `HTTP GET https://graph.microsoft.com/v1.0/me/`\r\n\r\n![Graph Explorer screenshot](https://docs.microsoft.com/en-us/adaptive-cards/templating/content/2019-08-01-12-08-13.png)\r\n\r\nThat API returned **JSON data**, but how do I **display it** to users using Adaptive Cards? \r\n\r\nFirst I want to see if a template exists for this type of data, so I make an HTTP request to the `/find` endpoint with my data in the `POST body`.\r\n\r\n```\r\nHTTP POST https://templates.adaptivecards.io/find\r\n\r\n{\r\n    \"@odata.context\": \"https://graph.microsoft.com/v1.0/$metadata#users/$entity\",\r\n    \"businessPhones\": [\r\n        \"+1 412 555 0109\"\r\n    ],\r\n    \"displayName\": \"Megan Bowen\",\r\n    \"givenName\": \"Megan\",\r\n    \"jobTitle\": \"Auditor\",\r\n    \"mail\": \"MeganB@M365x214355.onmicrosoft.com\",\r\n    \"mobilePhone\": null,\r\n    \"officeLocation\": \"12/1110\",\r\n    \"preferredLanguage\": \"en-US\",\r\n    \"surname\": \"Bowen\",\r\n    \"userPrincipalName\": \"MeganB@M365x214355.onmicrosoft.com\",\r\n    \"id\": \"48d31887-5fad-4d73-a9f5-3c356e68a038\"\r\n}\r\n```\r\n\r\n**Response:**\r\n\r\n```json\r\n[\r\n  {\r\n    \"templateUrl\": \"graph.microsoft.com/Profile.json\",\r\n    \"confidence\": 1\r\n  }\r\n]\r\n```\r\n\r\nThe service returns a list of any matching templates, along with a `confidence` indicating how close the match is. Now I can use that template URL to **get** the template, or **populate** it server-side.\r\n\r\n### Get a template\r\n\r\nA template retrieved from this endpoint can be populated with data at runtime [using the templatng SDKs](sdk.md).\r\n\r\n> `HTTP GET https://templates.adaptivecards.io/[TEMPLATE-PATH]`\r\n\r\nYou can also include \"sample data\" with the template, which makes editing in the designer more friendly:\r\n\r\n> `HTTP GET https://templates.adaptivecards.io/[TEMPLATE-PATH]?sampleData=true`\r\n\r\n#### Example\r\n\r\nLet's get the Microsoft Graph profile template that was returned from `/find` above.\r\n\r\n`HTTP GET https://templates.adaptivecards.io/graph.microsoft.com/Profile.json`\r\n\r\n**Response excerpt**\r\n\r\n```json\r\n{\r\n  \"type\": \"AdaptiveCard\",\r\n  \"version\": \"1.0\",\r\n  \"body\": [\r\n    {\r\n      \"type\": \"TextBlock\",\r\n      \"size\": \"Medium\",\r\n      \"weight\": \"Bolder\",\r\n      \"text\": \"{name}\"\r\n    },\r\n    {\r\n        // ...snip\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nNow use this template with the [templating SDKs](https://docs.microsoft.com/en-us/adaptive-cards/templating/sdk) to create a ready-to-render Adaptive Card.\r\n\r\n### Populate a template server-side\r\n\r\nIn some cases it may not make sense to populate a template on the client.  For these use cases, you can have the service return a fully-populated Adaptive Card, ready to be passed to any Adaptive Card Renderer.\r\n\r\n> `HTTP POST https://templates.adaptivecards.io/[TEMPLATE-PATH]`\r\n\r\n#### Example\r\n\r\nLet's populate the Microsoft Graph profile template that was returned from `/find` using the data above.\r\n\r\n```\r\nHTTP POST https://templates.adaptivecards.io/graph.microsoft.com/Profile.json\r\n\r\n{\r\n    \"@odata.context\": \"https://graph.microsoft.com/v1.0/$metadata#users/$entity\",\r\n    \"businessPhones\": [\r\n        \"+1 412 555 0109\"\r\n    ],\r\n    \"displayName\": \"Megan Bowen\",\r\n    \"givenName\": \"Megan\",\r\n    \"jobTitle\": \"Auditor\",\r\n    \"mail\": \"MeganB@M365x214355.onmicrosoft.com\",\r\n    \"mobilePhone\": null,\r\n    \"officeLocation\": \"12/1110\",\r\n    \"preferredLanguage\": \"en-US\",\r\n    \"surname\": \"Bowen\",\r\n    \"userPrincipalName\": \"MeganB@M365x214355.onmicrosoft.com\",\r\n    \"id\": \"48d31887-5fad-4d73-a9f5-3c356e68a038\"\r\n}\r\n```\r\n\r\n**Response excerpt**\r\n\r\n```json\r\n{\r\n  \"type\": \"AdaptiveCard\",\r\n  \"version\": \"1.0\",\r\n  \"body\": [\r\n    {\r\n      \"type\": \"TextBlock\",\r\n      \"size\": \"Medium\",\r\n      \"weight\": \"Bolder\",\r\n      \"text\": \"Megan Bowen\"\r\n    },\r\n    {\r\n        // ...snip\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\nNotice how the response replaced the text of the first `TextBlock` with `\"Megan Bowen\"` instead of `\"{name}\"`, as in the `GET` request. This AdaptiveCard can now be passed to any Adaptive Card renderer without going through client-side templating.\r\n\r\n## Contributing templates\r\n\r\nAll templates are stored in this repo, in the `templates` directory. \r\n\r\nOur hope is that by using GitHub as a backing store for the templates, we can \"democratize\" the process of contributing and sharing templates. Anyone can submit a Pull Request that includes an entirely new template, or make enhancements to existing ones... all within the developer-friendly experience of GitHub.\r\n\r\n## Self-hosting the service\r\n\r\nWe realize that not all types of data are appropriate for the \"central\" Adaptive Cards template service hosted at `https://templates.adaptivecards.io`. \r\n\r\nThe source code for the service is authored as a Azure Function in TypeScript. You can take the code as-is and deploy it to your own Function. \r\n\r\n## Building templating service\r\n\r\n### Install Azure Functions Tools \r\n\r\n**On macOS**, install using Homebrew\r\n\r\n```console\r\n$ brew tap azure/functions\r\n$ brew install azure-functions-core-tools\r\n```\r\n\r\n**On Windows**, install using npm.\r\n\r\n```console\r\n$ npm install -g azure-functions-core-tools\r\n```\r\n\r\n**On Linux**, follow the instructions in the Azure Functions Core Tools [GitHub repository](https://github.com/Azure/azure-functions-core-tools#linux).\r\n\r\n\r\n### Update `local.settings.json` to point to a Storage account\r\n\r\n```json\r\n\"AzureWebJobsStorage\": \"DefaultEndpointsProtocol=https;AccountName=XXXXXXX;AccountKey=XXXXXXXXXX\",\r\n```\r\n\r\n\r\nThe JSON template files get copied from the Git repo into Blob storage and the Function serves them from there.\r\n\r\n### Build and run \r\n\r\n```console\r\ncd src\r\nfunc extensions sync\r\n```\r\n\r\nPress `F5` to run\r\n\r\n## Code of Conduct\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see \r\nthe [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n"
 },
 {
  "repo": "microsoft/Reference-Guide-For-Quantum-Computing-A-Microsoft-Garage-Project",
  "language": "Jupyter Notebook",
  "readme_contents": "**Reference Guide for Quantum Computing, a Microsoft Garage project**\n\n**A Hands-On Introduction to Quantum Computing**\n\n**Authors: Kitty Yeung, Pavan Kumar, Michael Beverland, Ravindra Ramouthar,** \n**Alex Talarico, Delbert Murphy, Waldemir Cambiucci, Karl Tietze, Benjamin Tokg\u00f6z, Alexandra Schroeder**\n\n**Q# exercise: Pavan Kumar, Mariia Mykhailova, Nafisa Barlaskar, Devika Mehra**\n\n**Illustration: Kitty Yeung**\n\n**Reviewers: the book is written by a community of quantum computing enthusiasts and reviewed by individuals at The Microsoft Garage and Quantum Systems teams**\n\n\n## Introduction <a name=\"Introduction\" /> ##\n\n**Phase 1 \u2013 Quantum Computing Basic Concepts**\n\n**Kitty Yeung, Ravindra Ramouthar, Alex Talarico, Delbert Murphy**\n\n## 1.0 BACKGROUND\n\nNow two decades into the new millennium, the field of quantum computing has developed\nsignificantly at an industrial scale over the recent years and made tremendous progress in hardware and\nsoftware advancements. Companies and governments across the world are competing and investing\nheavily to build the first scalable quantum computer to unlock the unprecedented powers promised by\nharnessing the new technology. We often read news about its potential and promises and new discoveries\nin the field. However, these articles rarely go beyond a major headline followed by a quick mention about\nsuperposition and entanglement. On the other hand, comprehensive textbooks and research publications\noften assume professional knowledge in physics and math, which makes it difficult for beginning hobbyists\nto understand.\n\nOur goal is to make quantum computing more accessible and easier to learn. Analogous to open-\nsource tutorials that helped democratize hardware electronics and programming, the tutorials in this\npublication aim to achieve the same \u2013 helping anyone interested in the subject get started with the basic\nconcepts of quantum computing and quickly gain hands-on experience programming in a quantum\ncomputing language. When a quantum computer is available, we would already have the necessary tools\nand knowledge to utilize it effectively.\n\nThe subject is a combination of physics, math, hardware and software, which will all be discussed\nholistically without deviating from the big picture. We will demonstrate concepts and definitions with\ntools and representations and divide the contents into three phases. Phase 1 will introduce the basics,\nsuch as quantum states, circuit representations, qubits, gates and measurements. If you do not yet know\nthese terminologies, do not worry. We will define and explain them \u2013 this is what this book is for! Phase\n2 will use all the tools obtained from Phase 1 and derive step-by-step algorithms that laid milestone\nfoundations for quantum computing development. Every session in Phase 1 and 2 has corresponding\nprogramming exercises we will present in Q# (Q-sharp) a domain-specific programming language used for\nexpressing quantum algorithms. The goal is for you to familiarize yourself with the concepts learned. We\nwill also cover state-of -the-art hardware systems and real-world applications of quantum computing in\nPhase 3.\n\n>_Math and Physics inserts_ ----------------------------------------------------------------------------------\n>\n>Throughout the book, you will find inserts. These are deeper sections than the\n>main texts that function as expansions for interested readers. They can be skipped without\n>affecting reading of the main texts.\n\n\nQuantum computing is a practical subject \u2013 engineering applying quantum phenomena in building\na computing system that surpasses classical computing capabilities in certain tasks. It is a sub-field of\nquantum information science and has its roots founded in the application of quantum mechanics which\nis a physics theory describing nature at its smallest constituent scales of atoms and subatomic particles.\nOther sub-fields of quantum information science include: quantum teleportation, quantum dense coding,\nquantum communication complexity, quantum cryptography, quantum complexity theory, quantum\ninformation theory and quantum error correction.\n\nYou may be familiar with the concept of bits in a classical computer, with each bit being in either\na 1 or 0 position, whereas i n a quantum computer, a sequence of qubits is maintained which can represent\na 1, a 0, or any quantum superposition of those two qubit states. A pair of qubits can be in any quantum\nsuperposition of 4 states and three qubits in any superposition of 8 states, and so on. As a result, quantum\ncomputers can store far more information than classical computers and yield the potential to compute at\nspeeds exponentially higher than classical computers while consuming much less energy. Elemental\nparticles such as electrons, photons or ions could be used to manifest a qubit, with either their charge or\npolarization representing a 0 and/or 1 state.\n\nThe basic principles of a quantum computer take place through operations on its qubits via\nquantum logic gates. Measurements are typically observed as a probability outcome, as quantum\nalgorithms are probabilistic. To run a quantum algorithm, the computer's qubits are first initialized, and\noperations are performed on these qubits through a sequence of logic gates that take advantage of\nquantum mechanics phenomena. Correct solutions manifest themselves through a favorable probability\nresult. If no measurement is yielded from the algorithm, we call this an unobserved quantum state. To\nyield trusted outcomes, quantum computers must often run their algorithms multiples of time.\nSpecialized systems are designed to be fault-tolerant through higher quantum volume, namely having\nmore qubits. More qubits equate to more states that can be manipulated and stored and purposed for\nerror correction. As systems continue to increase their quantum volume, we can expect to see quantum\ncomputers gain a significant advantage over classical counterparts.\n\nClassical computers based on transistor bits have been used to simulate the laws of physics in\nhopes to better understand how the universe works. We can simulate how far a ball will go based on\nwhere it starts and how fast it is thrown. Programming the laws of physics into classical computers, albeit\nobsolete ones by today's standards, is ultimately what got us on the moon. But using bits to simulate\nphysics doesn't always make sense, as the laws of physics at the smallest scale are rooted in the rules of\nquantum mechanics. Classical computing simply breaks down and cannot process information fast or\nefficiently enough to solve or simulate real world nondeterministic models. Quantum computing takes a\ngiant leap forward from today's technology \u2013 one that will forever alter our economic, industrial, academic,\nand societal landscape. In just hours or days, a quantum computer will be able to solve complex problems\nthat would otherwise take billions of years for today's computers to solve. This yields multi-, inter- and\ntrans-disciplinary implications for research in healthcare, energy, environmental systems, smart materials,\nand more. For example, simulations of quantum interactions between chemical molecules, elementary\nparticles or materials can help us find solutions in pharmaceutical, agricultural or renewable energy\napplications. Quantum computing algorithms that solve certain mathematic problems more efficiently\nthan classical computing can assist with optimization and cryptography.\n\nQuantum computing was incubated in the early 1980s when Richard Feynman and Yuri Manin\npostulated that a quantum computer could perform simulations that a classical computer could not. In\n1994, Peter Shor published a cryptography algorithm which could efficiently solve some problems\nconsidered hard for classical computers. A quantum computer can be implemented through analog or\ndigital means through qubits or quantum bits; analog manifestations include quantum simulation,\nquantum annealing and adiabatic quantum computation, whilst digital approaches use quantum logic\ngates to perform computation.\n\nYou may be surprised to learn that the first-generation quantum computers, were not what we\nwould call computers or new devices at all. Remarkably, it all began with physicists tinkering with\nmathematics and biochemistry equipment for curiosity's sake. \"It was not motivated in any way by making\nbetter computers,\" Neil Gershenfeld, director of MIT's Center for Bits and Atoms and a member of one of\nthe two teams that first experimentally realized quantum algorithms says. \"It was understanding whether\nthe universe computes, and how the universe computes. (Quote from [The Unlikely Origins of the First\nQuantum Computer](https://gizmodo.com/the-unlikely-origins-of-the-first-quantum-computer-1831054476))\"\n\nSeveral independent groups realized that the medical and biochemistry industry had long been\nusing a 'quantum computer' in research: Nuclear Magnetic Resonance (NMR) spectrometers. This is the\ntechnology behind Magnetic Resonance Imaging (MRI), which commonly consists of a molecule of interest\ndissolved in a liquid solvent, placed in a strong magnetic field. The nuclei of the atoms in these molecules\nhave an innate quantum mechanical property called \"spin,\" which can be in either of two states, \"up\" or\n\"down\" as we will explore later. These spins align with the direction of the field when hit with additional\nsmaller oscillating magnetic fields ( radio-frequency pulses) causing the atoms to release characteristic\nsignals that offer physical information about the molecule. MRI machines use this signal to create a picture,\nbut the physicists realized by the late 1990's that they could treat certain molecules in this magnetic field\nas quantum computers, where the nuclei served as qubits, the spin states were qubit values, and the\nradio-frequency pulses were both the instructions and controllers. These are the operations of quantum\ncomputers, also called logic gates as they are in classical computers.\n\nWe don't often hear about NMR quantum computers today, because even then, physicists knew\nthat the technique had its limits. The techniques relied on special workarounds such that each additional\nqubit would make it harder to pick the signal out of the background noise, unable to not scale beyond a\nfew qubits. Despite notable shortcomings, the experiments gave the field the credibility needed to prove\nquantum computing hardware viability and pave the way for research and development investments in a\nhardware of the future for quantum computing.\n\nAt the time of this writing, nearly 20 years after the NMR experiments, we have seen several\ncompanies heavily invested in the development and promotion of commercially available quantum\ncomputing hardware, luring software developers with the promise to most efficiently compute quantum\ncircuits and algorithms. Companies across the board are periodically joining the quantum race, as\nHoneywell recently announced its own quantum computing program for niche industries (see [Investing\nin Quantum Computing \u2013 The TQD Guide](https://thequantumdaily.com/2020/01/13/investing-in-quantum-computing-the-tqd-guide/)).\n\nNot all quantum computers are created equal, as you might expect, especially in such a fast-paced\nlandscape. Some manufacturers, namely IBM and Rigetti, claim their systems are truly universal quantum\ncomputers, also known as Quantum Turing Machines (QTM), capable of handling any quantum algorithm.\n\nOther manufacturers, such as D-Wave Systems, focus strictly on optimization problems \u2013 travelling\nsalesman, for example \u2013 and are thereby limited to what sorts of processing they can perform.\n\nAlthough every hardware manufacturer brings forward a unique architecture to their quantum\ncomputing hardware, one common theme emerges: classical computing is not going to be replaced\nanytime soon. For the foreseeable future, we will be using a hybrid of classical computing and quantum\ncomputers as each is optimal for different tasks. We leverage our classical computing investments to setup\nalgorithms and quantum circuits that are then passed along for the quantum computer to resolve and\nproduce an output our classical computers can then make sense of and display.\n\nAs we have seen throughout history, sometimes technological breakthroughs occur by tinkering\nwith existing equipment. The technology to build a quantum computer today is certain to evolve over the\nnext decades, as we have just begun to scratch the surface of hardware design.\n\n## EXERCISES\n\nAt the end of each chapter, you will find a set of hands-on excercises to practice knowledge learned from that chapter. They are contained in the [QuantumComputingViaQSharpSolution](https://github.com/microsoft/Reference-Guide-For-Quantum-Computing-A-Microsoft-Garage-Project/tree/main/QuantumComputingViaQSharpSolution) folder of this repository. \n"
 },
 {
  "repo": "microsoft/PowerBI-visuals-AttributeSlicer",
  "language": "TypeScript",
  "readme_contents": "[![Build Status](https://travis-ci.org/Microsoft/PowerBI-visuals-AttributeSlicer.svg?branch=develop)](https://travis-ci.org/Microsoft/PowerBI-visuals-AttributeSlicer)\n\n# AttributeSlicer\n\n Attribute Slicer lets you filter a dataset on a given column by selecting attribute values of interest. The initial display is a helpful overview that lists the most common values first and shows the overall distribution of values as a horizontal bar chart. Whenever you select an attribute value, it is moved to the list of applied filters and all records containing that value are added to the result set for further analysis.\n\n ![Attribute Slicer](/assets/screenshot.png?raw=true)\n\n> This visual is experimental and not actively being developed, only major issues will be addressed.\n\n## Usage\n* Install [node.js 6+](https://nodejs.org)\n* Install [yarn](https://yarnpkg.com/lang/en/docs/install)\n* Run `yarn` on the project directory, which will install all the dependencies\n* Run `yarn test` which will lint, test, and compile the `attribute-slicer` and `attribute-slicer-powerbi` packages.\n    * Compiling `attribute-slicer-powerbi` will also create a `.pbiviz` file in the `packages/attribute-slicer/powerbi/dist` directory, which can be imported directly in [Power BI](https://app.powerbi.com/)\n* Run `yarn start`, which will load the powerbi visual into live reload mode.\n"
 },
 {
  "repo": "microsoft/tsyringe",
  "language": "TypeScript",
  "readme_contents": "[![Travis](https://img.shields.io/travis/Microsoft/tsyringe.svg)](https://travis-ci.org/Microsoft/tsyringe/)\n[![npm](https://img.shields.io/npm/v/tsyringe.svg)](https://www.npmjs.com/package/tsyringe)\n[![npm](https://img.shields.io/npm/dt/tsyringe.svg)](https://www.npmjs.com/package/tsyringe)\n\n# TSyringe\n\nA lightweight dependency injection container for TypeScript/JavaScript for\nconstructor injection.\n\n<!-- TOC depthFrom:1 depthTo:3 -->\n\n- [TSyringe](#tsyringe)\n  - [Installation](#installation)\n- [API](#api)\n  - [Decorators](#decorators)\n    - [injectable()](#injectable)\n    - [singleton()](#singleton)\n    - [autoInjectable()](#autoinjectable)\n    - [inject()](#inject)\n    - [injectAll()](#injectall)\n    - [injectWithTransform()](#injectWithTransform)\n    - [injectAllWithTransform()](#injectAllWithTransform)\n    - [scoped()](#scoped)\n  - [Container](#container)\n    - [Injection Token](#injection-token)\n    - [Providers](#providers)\n    - [Register](#register)\n    - [Registry](#registry)\n    - [Resolution](#resolution)\n    - [Interception](#interception)\n    - [Child Containers](#child-containers)\n    - [Clearing Instances](#clearing-instances)\n- [Circular dependencies](#circular-dependencies)\n  - [The `delay` helper function](#the-delay-helper-function)\n  - [Interfaces and circular dependencies](#interfaces-and-circular-dependencies)\n- [Full examples](#full-examples)\n  - [Example without interfaces](#example-without-interfaces)\n  - [Example with interfaces](#example-with-interfaces)\n  - [Injecting primitive values (Named injection)](#injecting-primitive-values-named-injection)\n- [Non goals](#non-goals)\n- [Contributing](#contributing)\n\n<!-- /TOC -->\n\n## Installation\n\nInstall by `npm`\n\n```sh\nnpm install --save tsyringe\n```\n\n**or** install with `yarn` (this project is developed using `yarn`)\n\n```sh\nyarn add tsyringe\n```\n\nModify your `tsconfig.json` to include the following settings\n\n```json\n{\n  \"compilerOptions\": {\n    \"experimentalDecorators\": true,\n    \"emitDecoratorMetadata\": true\n  }\n}\n```\n\nAdd a polyfill for the Reflect API (examples below use reflect-metadata). You can use:\n\n- [reflect-metadata](https://www.npmjs.com/package/reflect-metadata)\n- [core-js (core-js/es7/reflect)](https://www.npmjs.com/package/core-js)\n- [reflection](https://www.npmjs.com/package/@abraham/reflection)\n\nThe Reflect polyfill import should only be added once, and before DI is used:\n\n```typescript\n// main.ts\nimport \"reflect-metadata\";\n\n// Your code here...\n```\n\n### Babel\n\nIf you're using Babel (e.g. using React Native), you will need to configure it to emit TypeScript metadata.\n\nFirst get the Babel plugin\n\n#### Yarn\n\n```\nyarn add --dev babel-plugin-transform-typescript-metadata\n```\n\n#### npm\n\n```\nnpm install --save-dev babel-plugin-transform-typescript-metadata\n```\n\nThen add it to your Babel config\n\n```\nplugins: [\n            'babel-plugin-transform-typescript-metadata',\n            /* ...the rest of your config... */\n         ]\n```\n\n# API\n\nTSyringe performs [Constructor Injection](https://en.wikipedia.org/wiki/Dependency_injection#Constructor_injection)\non the constructors of decorated classes.\n\n## Decorators\n\n### injectable()\n\nClass decorator factory that allows the class' dependencies to be injected at\nruntime. TSyringe relies on several decorators in order to collect metadata about classes\nto be instantiated.\n\n#### Usage\n\n```typescript\nimport {injectable} from \"tsyringe\";\n\n@injectable()\nclass Foo {\n  constructor(private database: Database) {}\n}\n\n// some other file\nimport \"reflect-metadata\";\nimport {container} from \"tsyringe\";\nimport {Foo} from \"./foo\";\n\nconst instance = container.resolve(Foo);\n```\n\n### singleton()\n\nClass decorator factory that registers the class as a singleton within the\nglobal container.\n\n#### Usage\n\n```typescript\nimport {singleton} from \"tsyringe\";\n\n@singleton()\nclass Foo {\n  constructor() {}\n}\n\n// some other file\nimport \"reflect-metadata\";\nimport {container} from \"tsyringe\";\nimport {Foo} from \"./foo\";\n\nconst instance = container.resolve(Foo);\n```\n\n### autoInjectable()\n\nClass decorator factory that replaces the decorated class' constructor with\na parameterless constructor that has dependencies auto-resolved.\n\n**Note** Resolution is performed using the global container.\n\n#### Usage\n\n```typescript\nimport {autoInjectable} from \"tsyringe\";\n\n@autoInjectable()\nclass Foo {\n  constructor(private database?: Database) {}\n}\n\n// some other file\nimport {Foo} from \"./foo\";\n\nconst instance = new Foo();\n```\n\nNotice how in order to allow the use of the empty constructor `new Foo()`, we\nneed to make the parameters optional, e.g. `database?: Database`.\n\n### inject()\n\nParameter decorator factory that allows for interface and other non-class\ninformation to be stored in the constructor's metadata.\n\n#### Usage\n\n```typescript\nimport {injectable, inject} from \"tsyringe\";\n\ninterface Database {\n  // ...\n}\n\n@injectable()\nclass Foo {\n  constructor(@inject(\"Database\") private database?: Database) {}\n}\n```\n\n### injectAll()\n\nParameter decorator for array parameters where the array contents will come from the container.\nIt will inject an array using the specified injection token to resolve the values.\n\n#### Usage\n\n```typescript\nimport {injectable, injectAll} from \"tsyringe\";\n\n@injectable\nclass Foo {}\n\n@injectable\nclass Bar {\n  constructor(@injectAll(Foo) fooArray: Foo[]) {\n    // ...\n  }\n}\n```\n\n### injectWithTransform\n\nParameter decorator which allows for a transformer object to take an action on the resolved object\nbefore returning the result.\n\n```typescript\nclass FeatureFlags {\n  public getFlagValue(flagName: string): boolean {\n    // ...\n}\n\nclass Foo() {}\n\nclass FeatureFlagsTransformer implements Transform<FeatureFlags, bool> {\n  public transform(flags: FeatureFlags, flag: string) {\n    return flags.getFlagValue(flag);\n  }\n}\n\n@injectable()\nclass MyComponent(foo: Foo, @injectWithTransform(FeatureFlags, FeatureFlagsTransformer, \"IsBlahEnabled\") blahEnabled: boolean){\n  // ...\n}\n```\n\n### injectAllWithTransform\n\nThis parameter decorator allows for array contents to be passed through a transformer. The transformer can return any type, so this\ncan be used to map or fold an array.\n\n```typescript\n@injectable\nclass Foo {\n  public value;\n}\n\nclass FooTransform implements Transform<Foo[], string[]>{\n  public transform(foos: Foo[]): string[]{\n    return foos.map(f => f.value));\n  }\n}\n\n@injectable\nclass Bar {\n  constructor(@injectAllWithTransform(Foo, FooTransform) stringArray: string[]) {\n    // ...\n  }\n}\n```\n\n### scoped()\n\nClass decorator factory that registers the class as a scoped dependency within the global container.\n\n#### Available scopes\n\n- Transient\n  - The **default** registration scope, a new instance will be created with each resolve\n- Singleton\n  - Each resolve will return the same instance (including resolves from child containers)\n- ResolutionScoped\n  - The same instance will be resolved for each resolution of this dependency during a single\n    resolution chain\n- ContainerScoped\n  - The dependency container will return the same instance each time a resolution for this dependency\n    is requested. This is similar to being a singleton, however if a child container is made, that child\n    container will resolve an instance unique to it.\n\n#### Usage\n\n```typescript\n@scoped(Lifecycle.ContainerScoped)\nclass Foo {}\n```\n\n## Container\n\nThe general principle behind [Inversion of Control](https://en.wikipedia.org/wiki/Inversion_of_control) (IoC) containers\nis you give the container a _token_, and in exchange you get an instance/value. Our container automatically figures out the tokens most of the time, with 2 major exceptions, interfaces and non-class types, which require the `@inject()` decorator to be used on the constructor parameter to be injected (see above).\n\nIn order for your decorated classes to be used, they need to be registered with the container. Registrations take the\nform of a Token/Provider pair, so we need to take a brief diversion to discuss tokens and providers.\n\n### Injection Token\n\nA token may be either a string, a symbol, a class constructor, or a instance of [`DelayedConstructor`](#circular-dependencies).\n\n```typescript\ntype InjectionToken<T = any> =\n  | constructor<T>\n  | DelayedConstructor<T>\n  | string\n  | symbol;\n```\n\n### Providers\n\nOur container has the notion of a _provider_. A provider is registered with the DI\ncontainer and provides the container the information\nneeded to resolve an instance for a given token. In our implementation, we have the following 4\nprovider types:\n\n#### Class Provider\n\n```TypeScript\n{\n  token: InjectionToken<T>;\n  useClass: constructor<T>;\n}\n```\n\nThis provider is used to resolve classes by their constructor. When registering a class provider\nyou can simply use the constructor itself, unless of course you're making an alias (a\nclass provider where the token isn't the class itself).\n\n#### Value Provider\n\n```TypeScript\n{\n  token: InjectionToken<T>;\n  useValue: T\n}\n```\n\nThis provider is used to resolve a token to a given value. This is useful for registering\nconstants, or things that have a already been instantiated in a particular way.\n\n#### Factory provider\n\n```TypeScript\n{\n  token: InjectionToken<T>;\n  useFactory: FactoryFunction<T>;\n}\n```\n\nThis provider is used to resolve a token using a given factory. The factory has full access\nto the dependency container.\n\nWe have provided 2 factories for you to use, though any function that matches the `FactoryFunction<T>` signature\ncan be used as a factory:\n\n```typescript\ntype FactoryFunction<T> = (dependencyContainer: DependencyContainer) => T;\n```\n\n##### instanceCachingFactory\n\nThis factory is used to lazy construct an object and cache result, returning the single instance for each subsequent\nresolution. This is very similar to `@singleton()`\n\n```typescript\nimport {instanceCachingFactory} from \"tsyringe\";\n\n{\n  token: \"SingletonFoo\";\n  useFactory: instanceCachingFactory<Foo>(c => c.resolve(Foo));\n}\n```\n\n##### predicateAwareClassFactory\n\nThis factory is used to provide conditional behavior upon resolution. It caches the result by default, but\nhas an optional parameter to resolve fresh each time.\n\n```typescript\nimport {predicateAwareClassFactory} from \"tsyringe\";\n\n{\n  token: useFactory: predicateAwareClassFactory<Foo>(\n    c => c.resolve(Bar).useHttps, // Predicate for evaluation\n    FooHttps, // A FooHttps will be resolved from the container if predicate is true\n    FooHttp // A FooHttp will be resolved if predicate is false\n  );\n}\n```\n\n#### Token Provider\n\n```TypeScript\n{\n  token: InjectionToken<T>;\n  useToken: InjectionToken<T>;\n}\n```\n\nThis provider can be thought of as a redirect or an alias, it simply states that given token _x_,\nresolve using token _y_.\n\n### Register\n\nThe normal way to achieve this is to add `DependencyContainer.register()` statements somewhere\nin your program some time before your first decorated class is instantiated.\n\n```typescript\ncontainer.register<Foo>(Foo, {useClass: Foo});\ncontainer.register<Bar>(Bar, {useValue: new Bar()});\ncontainer.register<Baz>(\"MyBaz\", {useValue: new Baz()});\n```\n\n#### Registration options\n\nAs an optional parameter to `.register()` you may provide [`RegistrationOptions`](./src/types/registration-options.ts)\nwhich customize how the registration behaves. See the linked source code for up to date documentation\non available options.\n\n### Registry\n\nYou can also mark up any class with the `@registry()` decorator to have the given providers registered\nupon importing the marked up class. `@registry()` takes an array of providers like so:\n\n```TypeScript\n@registry([\n  { token: Foobar, useClass: Foobar },\n  { token: \"theirClass\", useFactory: (c) => {\n       return new TheirClass( \"arg\" )\n    },\n  }\n])\nclass MyClass {}\n```\n\nThis is useful when you want to [register multiple classes for the same token](#register).\nYou can also use it to register and declare objects that wouldn't be imported by anything else,\nsuch as more classes annotated with `@registry` or that are otherwise responsible for registering objects.\nLastly you might choose to use this to register 3rd party instances instead of the `container.register(...)` method.\nnote: if you want this class to be `@injectable` you must put the decorator before `@registry`, this annotation is not\nrequired though.\n\n### Resolution\n\nResolution is the process of exchanging a token for an instance. Our container will recursively fulfill the\ndependencies of the token being resolved in order to return a fully constructed object.\n\nThe typical way that an object is resolved is from the container using `resolve()`.\n\n```typescript\nconst myFoo = container.resolve(Foo);\nconst myBar = container.resolve<Bar>(\"Bar\");\n```\n\nYou can also resolve all instances registered against a given token with `resolveAll()`.\n\n```typescript\ninterface Bar {}\n\n@injectable()\nclass Foo implements Bar {}\n@injectable()\nclass Baz implements Bar {}\n\n@registry([\n  // registry is optional, all you need is to use the same token when registering\n  {token: \"Bar\", useToken: Foo}, // can be any provider\n  {token: \"Bar\", useToken: Baz}\n])\nclass MyRegistry {}\n\nconst myBars = container.resolveAll<Bar>(\"Bar\"); // myBars type is Bar[]\n```\n\n### Interception\n\nInterception allows you to register a callback that will be called before or after the resolution of a specific token.\nThis callback can be registered to execute only once (to perform initialization, for example),\non each resolution to do logging, for example.\n\n`beforeResolution` is used to take an action before an object is resolved.\n\n```typescript\nclass Bar {}\n\ncontainer.beforeResolution(\n  Bar,\n  // Callback signature is (token: InjectionToken<T>, resolutionType: ResolutionType) => void\n  () => {\n    console.log(\"Bar is about to be resolved!\");\n  },\n  {frequency: \"Always\"}\n);\n```\n\n`afterResolution` is used to take an action after the object has been resolved.\n\n```typescript\nclass Bar {\n  public init(): void {\n    // ...\n  }\n}\n\ncontainer.afterResolution(\n  Bar,\n  // Callback signature is (token: InjectionToken<T>, result: T | T[], resolutionType: ResolutionType)\n  (_t, result) => {\n    result.init();\n  },\n  {frequency: \"Once\"}\n);\n```\n\n### Child Containers\n\nIf you need to have multiple containers that have disparate sets of registrations, you can create child containers:\n\n```typescript\nconst childContainer1 = container.createChildContainer();\nconst childContainer2 = container.createChildContainer();\nconst grandChildContainer = childContainer1.createChildContainer();\n```\n\nEach of the child containers will have independent registrations, but if a registration is absent in the child container at resolution, the token will be resolved from the parent. This allows for a set of common services to be registered at the root, with specialized services registered on the child. This can be useful, for example, if you wish to create per-request containers that use common stateless services from the root container.\n\n### Clearing Instances\n\nThe `container.clearInstances()` method allows you to clear all previously created and registered instances:\n\n```typescript\nclass Foo {}\n@singleton()\nclass Bar {}\n\nconst myFoo = new Foo();\ncontainer.registerInstance(\"Test\", myFoo);\nconst myBar = container.resolve(Bar);\n\ncontainer.clearInstances();\n\ncontainer.resolve(\"Test\"); // throws error\nconst myBar2 = container.resolve(Bar); // myBar !== myBar2\nconst myBar3 = container.resolve(Bar); // myBar2 === myBar3\n```\n\nUnlike with `container.reset()`, the registrations themselves are not cleared.\nThis is especially useful for testing:\n\n```typescript\n@singleton()\nclass Foo {}\n\nbeforeEach(() => {\n  container.clearInstances();\n});\n\ntest(\"something\", () => {\n  container.resolve(Foo); // will be a new singleton instance in every test\n});\n```\n\n# Circular dependencies\n\nSometimes you need to inject services that have cyclic dependencies between them. As an example:\n\n```typescript\n@injectable()\nexport class Foo {\n  constructor(public bar: Bar) {}\n}\n\n@injectable()\nexport class Bar {\n  constructor(public foo: Foo) {}\n}\n```\n\nTrying to resolve one of the services will end in an error because always one of the constructor will not be fully defined to construct the other one.\n\n```typescript\ncontainer.resolve(Foo);\n```\n\n```\nError: Cannot inject the dependency at position #0 of \"Foo\" constructor. Reason:\n    Attempted to construct an undefined constructor. Could mean a circular dependency problem. Try using `delay` function.\n```\n\n### The `delay` helper function\n\nThe best way to deal with this situation is to do some kind of refactor to avoid the cyclic dependencies. Usually this implies introducing additional services to cut the cycles.\n\nBut when refactor is not an option you can use the `delay` function helper. The `delay` function wraps the constructor in an instance of `DelayedConstructor`.\n\nThe _delayed constructor_ is a kind of special `InjectionToken` that will eventually be evaluated to construct an intermediate proxy object wrapping a factory for the real object.\n\nWhen the proxy object is used for the first time it will construct a real object using this factory and any usage will be forwarded to the real object.\n\n```typescript\n@injectable()\nexport class Foo {\n  constructor(@inject(delay(() => Bar)) public bar: Bar) {}\n}\n\n@injectable()\nexport class Bar {\n  constructor(@inject(delay(() => Foo)) public foo: Foo) {}\n}\n\n// construction of foo is possible\nconst foo = container.resolve(Foo);\n\n// property bar will hold a proxy that looks and acts as a real Bar instance.\nfoo.bar instanceof Bar; // true\n```\n\n### Interfaces and circular dependencies\n\nWe can rest in the fact that a `DelayedConstructor` could be used in the same contexts that a constructor and will be handled transparently by tsyringe. Such idea is used in the next example involving interfaces:\n\n```typescript\nexport interface IFoo {}\n\n@injectable()\n@registry([\n  {\n    token: \"IBar\",\n    // `DelayedConstructor` of Bar will be the token\n    useToken: delay(() => Bar)\n  }\n])\nexport class Foo implements IFoo {\n  constructor(@inject(\"IBar\") public bar: IBar) {}\n}\nexport interface IBar {}\n\n@injectable()\n@registry([\n  {\n    token: \"IFoo\",\n    useToken: delay(() => Foo)\n  }\n])\nexport class Bar implements IBar {\n  constructor(@inject(\"IFoo\") public foo: IFoo) {}\n}\n```\n\n# Full examples\n\n## Example without interfaces\n\nSince classes have type information at runtime, we can resolve them without any\nextra information.\n\n```typescript\n// Foo.ts\nexport class Foo {}\n```\n\n```typescript\n// Bar.ts\nimport {Foo} from \"./Foo\";\nimport {injectable} from \"tsyringe\";\n\n@injectable()\nexport class Bar {\n  constructor(public myFoo: Foo) {}\n}\n```\n\n```typescript\n// main.ts\nimport \"reflect-metadata\";\nimport {container} from \"tsyringe\";\nimport {Bar} from \"./Bar\";\n\nconst myBar = container.resolve(Bar);\n// myBar.myFoo => An instance of Foo\n```\n\n## Example with interfaces\n\nInterfaces don't have type information at runtime, so we need to decorate them\nwith `@inject(...)` so the container knows how to resolve them.\n\n```typescript\n// SuperService.ts\nexport interface SuperService {\n  // ...\n}\n```\n\n```typescript\n// TestService.ts\nimport {SuperService} from \"./SuperService\";\nexport class TestService implements SuperService {\n  //...\n}\n```\n\n```typescript\n// Client.ts\nimport {injectable, inject} from \"tsyringe\";\n\n@injectable()\nexport class Client {\n  constructor(@inject(\"SuperService\") private service: SuperService) {}\n}\n```\n\n```typescript\n// main.ts\nimport \"reflect-metadata\";\nimport {Client} from \"./Client\";\nimport {TestService} from \"./TestService\";\nimport {container} from \"tsyringe\";\n\ncontainer.register(\"SuperService\", {\n  useClass: TestService\n});\n\nconst client = container.resolve(Client);\n// client's dependencies will have been resolved\n```\n\n## Injecting primitive values (Named injection)\n\nPrimitive values can also be injected by utilizing named injection\n\n```typescript\nimport {singleton, inject} from \"tsyringe\";\n\n@singleton()\nclass Foo {\n  private str: string;\n  constructor(@inject(\"SpecialString\") value: string) {\n    this.str = value;\n  }\n}\n\n// some other file\nimport \"reflect-metadata\";\nimport {container} from \"tsyringe\";\nimport {Foo} from \"./foo\";\n\nconst str = \"test\";\ncontainer.register(\"SpecialString\", {useValue: str});\n\nconst instance = container.resolve(Foo);\n```\n\n# Non goals\n\nThe following is a list of features we explicitly plan on not adding:\n\n- Property Injection\n\n# Contributing\n\nThis project welcomes contributions and suggestions. Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit [https://cla.microsoft.com](https://cla.microsoft.com).\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/gatsby-starter-uifabric",
  "language": "TypeScript",
  "readme_contents": "<h1 align=\"center\">\n  UI Fabric Gatsby.js\n</h1>\n\nKick off your project with this UI Fabric boilerplate. This starter ships with the main Gatsby configuration files you might need to get up and running blazing fast with the blazing fast app generator for React.\n\n## \ud83d\ude80 Quick start\n\n1.  **Create a Gatsby site.**\n\n    Use the Gatsby CLI to create a new site, specifying the UI Fabric starter.\n\n    ```sh\n    # create a new Gatsby site using the UI Fabric starter\n    gatsby new my-uifabric-starter https://github.com/microsoft/gatsby-starter-uifabric\n    ```\n\n1.  **Start developing.**\n\n    Navigate into your new site\u2019s directory and start it up.\n\n    ```sh\n    cd my-uifabric-starter/\n    gatsby develop\n    ```\n\n1.  **Open the source code and start editing!**\n\n    Your site is now running at `http://localhost:8000`!\n\n    _Note: You'll also see a second link: _`http://localhost:8000/___graphql`_. This is a tool you can use to experiment with querying your data. Learn more about using this tool in the [Gatsby tutorial](https://www.gatsbyjs.org/tutorial/part-five/#introducing-graphiql)._\n\n    Open the `my-uifabric-starter` directory in your code editor of choice and edit `src/pages/index.js`. Save your changes and the browser will update in real time!\n\n## \ud83e\uddd0 What's inside?\n\nA quick look at the top-level files and directories you'll see in a Gatsby project.\n\n    .\n    \u251c\u2500\u2500 node_modules\n    \u251c\u2500\u2500 src\n    \u251c\u2500\u2500 .gitignore\n    \u251c\u2500\u2500 .prettierrc\n    \u251c\u2500\u2500 gatsby-browser.js\n    \u251c\u2500\u2500 gatsby-config.js\n    \u251c\u2500\u2500 gatsby-node.js\n    \u251c\u2500\u2500 gatsby-ssr.js\n    \u251c\u2500\u2500 LICENSE\n    \u251c\u2500\u2500 package-lock.json\n    \u251c\u2500\u2500 package.json\n    \u2514\u2500\u2500 README.md\n\n1.  **`/node_modules`**: This directory contains all of the modules of code that your project depends on (npm packages) are automatically installed.\n\n2.  **`/src`**: This directory will contain all of the code related to what you will see on the front-end of your site (what you see in the browser) such as your site header or a page template. `src` is a convention for \u201csource code\u201d.\n\n3.  **`.gitignore`**: This file tells git which files it should not track / not maintain a version history for.\n\n4.  **`.prettierrc`**: This is a configuration file for [Prettier](https://prettier.io/). Prettier is a tool to help keep the formatting of your code consistent.\n\n5.  **`gatsby-browser.js`**: This file is where Gatsby expects to find any usage of the [Gatsby browser APIs](https://www.gatsbyjs.org/docs/browser-apis/) (if any). These allow customization/extension of default Gatsby settings affecting the browser.\n\n6.  **`gatsby-config.js`**: This is the main configuration file for a Gatsby site. This is where you can specify information about your site (metadata) like the site title and description, which Gatsby plugins you\u2019d like to include, etc. (Check out the [config docs](https://www.gatsbyjs.org/docs/gatsby-config/) for more detail).\n\n7.  **`gatsby-node.js`**: This file is where Gatsby expects to find any usage of the [Gatsby Node APIs](https://www.gatsbyjs.org/docs/node-apis/) (if any). These allow customization/extension of default Gatsby settings affecting pieces of the site build process.\n\n8.  **`gatsby-ssr.js`**: This file is where Gatsby expects to find any usage of the [Gatsby server-side rendering APIs](https://www.gatsbyjs.org/docs/ssr-apis/) (if any). These allow customization of default Gatsby settings affecting server-side rendering.\n\n9.  **`LICENSE`**: Gatsby is licensed under the MIT license.\n\n10. **`package-lock.json`** (See `package.json` below, first). This is an automatically generated file based on the exact versions of your npm dependencies that were installed for your project. **(You won\u2019t change this file directly).**\n\n11. **`package.json`**: A manifest file for Node.js projects, which includes things like metadata (the project\u2019s name, author, etc). This manifest is how npm knows which packages to install for your project.\n\n12. **`README.md`**: A text file containing useful reference information about your project.\n\n## \ud83c\udf93 Learning Gatsby\n\nLooking for more guidance? Full documentation for Gatsby lives [on the website](https://www.gatsbyjs.org/). Here are some places to start:\n\n- **For most developers, we recommend starting with our [in-depth tutorial for creating a site with Gatsby](https://www.gatsbyjs.org/tutorial/).** It starts with zero assumptions about your level of ability and walks through every step of the process.\n\n- **To dive straight into code samples, head [to our documentation](https://www.gatsbyjs.org/docs/).** In particular, check out the _Guides_, _API Reference_, and _Advanced Tutorials_ sections in the sidebar.\n\n## \ud83d\udcab Deploy\n\n[![Deploy to Azure](http://azuredeploy.net/deploybutton.png)](https://azuredeploy.net/?repository=https://github.com/kenotron/gatsby-starter-uifabric)\n\n[![Deploy to Netlify](https://www.netlify.com/img/deploy/button.svg)](https://app.netlify.com/start/deploy?repository=https://github.com/kenotron/gatsby-starter-uifabric)\n\n\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/MSMARCO-Document-Ranking-Submissions",
  "language": "Python",
  "readme_contents": "# MS MARCO Document Ranking Submissions\n\nThis repo holds the official MS MARCO document ranking leaderboard and describes the process for submitting runs.\nAll associated data for the task (corpus, training data, eval queries, etc.) are held in [this repo](https://github.com/microsoft/MSMARCO-Document-Ranking).\n\n## Submission Instructions\n\nTo make a submission, please follow these instructions:\n\n1. Decide on a submission id, which will be a permanent (public) unique key. The submission id should be of the form `yyyymmdd-foo`, where `foo` can be a suffix of your choice, e.g., your group's name.\nPlease keep the length reasonable.\nSee [here](https://github.com/microsoft/MSMARCO-Document-Ranking-Archive/tree/main/submissions) for examples.\n`yyyymmdd` should correspond to the submission date of your run.\n\n2. In the directory `submissions/`, create the following files:\n   1. `submissions/yyyymmdd-foo/dev.txt.bz2` - run file on the dev queries (`msmarco-docdev-queries.tsv`), bz2-compressed\n   2. `submissions/yyyymmdd-foo/eval.txt.bz2` - run file on the eval queries (`docleaderboard-queries.tsv`), bz2-compressed\n   3. `submissions/yyyymmdd-foo-metadata.json`, in the following format:\n\n       ```\n        {\n          \"team\": \"team name\",\n          \"model_description\": \"model description\",\n          \"paper\": \"url\",              // URL to paper\n          \"code\": \"url\",               // URL to code\n          \"type\": \"full ranking\"       // either 'full ranking' or 'reranking'\n        }\n       ```\n       Leave the value of `paper` and `code` empty (i.e., the empty string) if not available.\n       These fields correspond to what is shown on the leaderboard.\n\n3. Run our evaluation script to make sure everything is in order (and fix any errors):\n   ```bash\n   $ python eval/run_eval.py --id yyyymmdd-foo\n   ```\n\n4. Package (i.e., encrypt) the submission using the following script:\n   ```bash\n   $ eval/pack.sh yyyymmdd-foo\n   ```\n\n5. Open a pull request against this repository.\nThe subject (title) of the pull request should be \"Submission yyyymmdd-foo\", where `yyyymmdd-foo` is the submission id you decided on.\nThis pull request should contain exactly three files:\n   1. `submissions/yyyymmdd-foo.key.bin.enc` - the encrypted key\n   2. `submissions/yyyymmdd-foo.tar.enc` - the encrypted tarball\n   3. `submissions/yyyymmdd-foo-metadata.json.enc` - the encrypted metadata\n\n**IMPORTANT NOTE:**\nYou might want to save the _unencrypted_ version of the key you've generated, i.e., `submissions/yyyymmdd-foo.key.bin`.\nYou'll need it if you want to, for example, change your metadata later on.\nIf you don't keep it, you'll lose it forever, because the `pack.sh` script generates a random key each time, see [here](https://github.com/microsoft/MSMARCO-Document-Ranking-Submissions/blob/main/eval/pack.sh#L6).\n\n## Additional Submission Guidelines\n\nThe goal of the MS MARCO leaderboard is to encourage [coopetition](https://en.wikipedia.org/wiki/Coopetition) (cooperation + competition) among various groups working on deep learning and other methods for search that requires or benefits from large-scale training data.\nSo, while we encourage friendly competition between different participating groups for top positions on the leaderboard, our core motivation is to ensure that over time the leaderboard provides meaningful scientific insights about how different methods compare to each other and answer questions like whether we are making real progress as a research community.\nAll participants are requested to abide by this spirit of coopetition and strictly observe good scientific principles when participating.\nWe will follow an honour system and expect participants to ensure that they are acting in compliance with both the policies and the spirit of this leaderboard.\nWe will also periodically audit all submissions ourselves and may flag issues as appropriate. \n\n### Frequency of Submission\nThe eval set is meant to be a blind set.\nWe want to discourage modeling decisions based eval numbers to avoid overfitting to the set.\nTo ensure this, we request participants to submit:\n\n1. No more than 2 runs in any given period of 30 days.\n2. No more than 1 run with very small changes, such as different random seeds or different hyper-parameters (e.g., small changes in number of layers or number of training epochs).\n\nParticipants who may want to run ablation studies on their models are encouraged to do so on the dev set, but not on the eval set.\n\n### Metadata Updates\n\nThe metadata you provide during run submission is meant to be permanent.\nHowever, we do allow \"reasonable\" updates to the metadata as long as it abides by the spirit of the leaderboard (see above).\nThese reasons might include adding links to a paper or a code repository, fixing typos, clarifying the description of a run, etc.\nHowever, we reserve the right to reject any changes.\n\nIt is generally expected that the team description in the metadata file will include the name of the organization (e.g., university or company).\nIn many cases, submissions explicitly list the contributors of the run.\nIt is _not_ permissible to submit a run under an alias (or a generic, nondescript team) to first determine \"how you did\", and then ask for a metadata change only after you've been shown to \"do well\".\nWe will reject metadata change requests in these circumstances.\nThus, you're advised to make the team description as specific as possible, so that you can claim \"credit\" for doing well.\n\nTo update the metadata of a particular run, you'll need to encrypt a new metadata JSON file _with the same key_ that you used in the original submission.\nThe command to encrypt the metadata is [here](https://github.com/microsoft/MSMARCO-Document-Ranking-Submissions/blob/main/eval/pack.sh#L11).\nHopefully, you've saved the key?\nIf you've lost it, get in touch with us and we'll send you the key back via another channel (e.g., email).\nOnce you've created a new metadata JSON file (i.e., `submissions/yyyymmdd-foo-metadata.json.enc`), send us a pull request with it.\nPlease make the subject of the pull request something obvious like \"Metadata change for yyyymmdd-foo\".\nAlso, please make it clear to us that _you_ have \"permission\" to change the metadata, e.g., the person making the change request is the same person who performed the original submission. \n\n### Anonymous Submissions\n\nWe allow anonymous submissions.\nNote that the purpose of an anonymous submission is to support blind reviewing for corresponding publications, not as a probing mechanism to see how well you do, and then only make your identity known if you do well.\n\nAnonymous submissions should still contain accurate team and model information in the metadata JSON file, but on the leaderboard we will anonymize your entry.\nBy default, we allow an embargo period of anonymous submissions for up to nine months.\nThat is, after nine months, your identity will be revealed and the leaderboard will be updated accordingly.\nAdditional extensions to the embargo period based on exceptional circumstances can be discussed on a case-by-case basis; please get in touch with the organizers.\n\nFor an anonymous submission, the metadata JSON file should have an additional field:\n\n```\n\"embargo_until\": \"yyyy/mm/dd\"\n```\n\nWhere the date in `yyyy/mm/dd` format cannot be more than nine months past the submission date.\nFor example, if the submission date is 2020/11/01, the longest possible embargo period is 2021/07/31.\nOf course, you are free to specify a shorter embargo period if you wish.\n\nNote that even with an anonymous submission, the submission id is publicly known, as well as the person performing the submission.\nYou might consider using a random string as the submission id, and you might consider creating a separate GitHub account for the sole purpose of submitting an anonymous run.\nNeither is necessary; we only provide this information for your reference.\n\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n## Legal Notices\n\nMicrosoft and any contributors grant you a license to the Microsoft documentation and other content\nin this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),\nsee the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the\n[LICENSE-CODE](LICENSE-CODE) file.\n\nMicrosoft, Windows, Microsoft Azure and/or other Microsoft products and services referenced in the documentation\nmay be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.\nThe licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.\nMicrosoft's general trademark guidelines can be found at http://go.microsoft.com/fwlink/?LinkID=254653.\n\nPrivacy information can be found at https://privacy.microsoft.com/en-us/\n\nMicrosoft and any contributors reserve all other rights, whether under their respective copyrights, patents,\nor trademarks, whether by implication, estoppel or otherwise.\n"
 },
 {
  "repo": "microsoft/IgniteTheTour",
  "language": "C#",
  "readme_contents": "\n# Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/react-popout-component",
  "language": "TypeScript",
  "readme_contents": "# React Popout Component\n\n[![Build Status](https://travis-ci.org/Microsoft/react-popout-component.svg?branch=v1.0.0)](https://travis-ci.org/Microsoft/react-popout-component) [![npm](https://img.shields.io/npm/v/react-popout-component.svg)](https://www.npmjs.com/package/react-popout-component)\n\nThis is a React component designed for React 16 with complete Typescript support.\n\n## Features\n\n1. This is developed along side with the React 16 fix to allow mounting across frames *even for Edge and IE* browsers\n2. Typescript support for all the options (especially hard to remember window features)\n3. Reflects style-loader injected styles from the main window to the children window\n\n## Installation\n\n```sh\nnpm install react-popout-component\n```\n\nor\n\n```sh\nyarn add react-popout-component\n```\n\n## Usage\n\n```tsx\nimport * as React from 'react';\nimport {Popout} from 'react-popout-component';\n\nexport default class App extends React.Component<any, any> {\n    constructor(props: any) {\n        super(props);\n        this.state = {showPopout: false};\n    }\n\n    onClick = () => {\n        this.setState({showPopout: true});\n    }\n\n    render() {\n        return (\n            <div>\n                <h1>Now you too have the power to POP OUT</h1>\n                <button onClick={this.onClick}>POP IT OUT!</button>\n                {this.state.showPopout && (\n                    <Popout>\n                        <div>You can put anything here!</div>\n                    </Popout>\n                )}\n            </div>\n        );\n    }\n}\n\n```\n\n## API\n\nPopOut Component has the following props:\n\n```ts\nexport interface PopoutProps {\n    hidden?: boolean;\n    name?: string;\n    onClose?: () => void;\n    onBeforeUnload?: (evt: BeforeUnloadEvent) => string | null | undefined;\n    children?: any;\n    options?: Partial<WindowFeaturesOptions>;\n    html?: string;\n}\n```\n\nThe `options` prop is of the following type:\n\n```ts\nexport interface WindowFeaturesOptions {\n    left: number;\n    top: number;\n    height: number;\n    width: number;\n    menubar: boolean;\n    toolbar: boolean;\n    location: boolean;\n    status: boolean;\n    resizable: boolean;\n    scrollbars: boolean;\n}\n```\n\n## Injection Mode\n\nThis component works well for both modes of style loading:\n1. Appending Style blocks (e.g. style-loader)\n2. Manual insertRule() into a CSSStyleSheet\n\nFor the second case with insertRule(), since there is nothing that can observe the insert event, a callback must be registered when a\nrule is inserted. For an example usage with the Microsoft [Office Fabric](https://github.com/officedev/office-ui-fabric-react), \nset it up as a global like so:\n\n```js\nimport {insertPopoutStylesheetRule} from 'react-popout-component';\n\nwindow.FabricConfig = {\n    mergeStyles: {\n        onInsertRule: insertPopoutStylesheetRule\n    }\n}\n```\n\n## Contributing\n\nThis project welcomes contributions and suggestions.  Most contributions require you to agree to a\nContributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us\nthe rights to use your contribution. For details, visit https://cla.microsoft.com.\n\nWhen you submit a pull request, a CLA-bot will automatically determine whether you need to provide\na CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions\nprovided by the bot. You will only need to do this once across all repos using our CLA.\n\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).\nFor more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or\ncontact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n"
 },
 {
  "repo": "microsoft/DeepSpeed",
  "language": "Python",
  "readme_contents": "[![Build Status](https://github.com/microsoft/deepspeed/workflows/Build/badge.svg)](https://github.com/microsoft/DeepSpeed/actions)\n[![PyPI version](https://badge.fury.io/py/deepspeed.svg)](https://pypi.org/project/deepspeed/)\n[![Documentation Status](https://readthedocs.org/projects/deepspeed/badge/?version=latest)](https://deepspeed.readthedocs.io/en/latest/?badge=latest)\n[![License MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://github.com/Microsoft/DeepSpeed/blob/master/LICENSE)\n[![Downloads](https://pepy.tech/badge/deepspeed/month)](https://pepy.tech/project/deepspeed)\n\n### 03/2021: DeepSpeed is hiring! Come join us: [SDE 2](https://careers.microsoft.com/us/en/job/1013160/Software-Engineer-2), [Sr. SDE](https://careers.microsoft.com/us/en/job/1017151/Senior-Software-Engineer), [Sr. Researcher](https://careers.microsoft.com/us/en/job/1016440/Senior-Researcher)\n\n[DeepSpeed](https://www.deepspeed.ai/) is a deep learning optimization\nlibrary that makes distributed training easy, efficient, and effective.\n\n<p align=\"center\"><i><b>10x Larger Models</b></i></p>\n<p align=\"center\"><i><b>10x Faster Training</b></i></p>\n<p align=\"center\"><i><b>Minimal Code Change</b></i></p>\n\nDeepSpeed delivers extreme-scale model training for everyone, from data scientists training on massive supercomputers to those training on low-end clusters or even on a single GPU:\n* Extreme scale: Using current generation of GPU clusters with hundreds of devices,  3D parallelism of DeepSpeed can efficiently train deep learning models with trillions of parameters.  \n* Extremely memory efficient: With just a single GPU, ZeRO-Offload of DeepSpeed can train models with over 10B parameters, 10x bigger than the state of arts, democratizing multi-billion-parameter model training such that many deep learning scientists can explore bigger and better models.\n* Extremely long sequence length: Sparse attention of DeepSpeed powers an order-of-magnitude longer input sequence and obtains up to 6x faster execution comparing with dense transformers.  \n* Extremely communication efficient: 3D parallelism improves communication efficiency allows users to train multi-billion-parameter models 2\u20137x faster on clusters with limited network bandwidth.  1-bit Adam/1-bit LAMB reduce communication volume by up to 5x while achieving similar convergence efficiency to Adam/LAMB, allowing for scaling to different types of GPU clusters and networks.\n\nEarly adopters of DeepSpeed have already produced\na language model (LM) with over 17B parameters called\n[Turing-NLG](https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft),\nestablishing a new SOTA in the LM category.\n\nDeepSpeed is an important part of Microsoft\u2019s new\n[AI at Scale](https://www.microsoft.com/en-us/research/project/ai-at-scale/)\ninitiative to enable next-generation AI capabilities at scale, where you can find more\ninformation [here](https://innovation.microsoft.com/en-us/exploring-ai-at-scale).\n\n**_For further documentation, tutorials, and technical deep-dives please see [deepspeed.ai](https://www.deepspeed.ai/)!_**\n\n\n# News\n* [2021/04/20] [1-bit LAMB: up to 4.6x less communication and 2.8x faster training, together with LAMB's convergence speed at large batch sizes](https://www.deepspeed.ai/tutorials/onebit-lamb/)\n* [2021/04/19] [ZeRO-Infinity unlocks unprecedented model scale for deep learning training](https://www.microsoft.com/en-us/research/blog/zero-infinity-and-deepspeed-unlocking-unprecedented-model-scale-for-deep-learning-training/)\n  * [Tutorial on how to use different stages of ZeRO](https://www.deepspeed.ai/tutorials/zero/)\n* [2021/04/01] [[DeepSpeed on AzureML] Transformers and CIFAR examples are now available on AzureML GitHub](https://github.com/Azure/azureml-examples/tree/main/workflows/train/deepspeed)\n* [2021/03/30] [[PyTorch Lightning Blog] Accessible Multi-Billion Parameter Model Training with PyTorch Lightning + DeepSpeed](https://medium.com/pytorch-lightning/accessible-multi-billion-parameter-model-training-with-pytorch-lightning-deepspeed-c9333ac3bb59)\n* [2021/03/16] [1-bit Adam v2: NCCL-based implementation and more](https://www.deepspeed.ai/tutorials/onebit-adam/)\n* [2021/03/08] [ZeRO-3 Offload: Scale your models to trillion parameters without code changes while leveraging both CPUs & GPUs](https://www.deepspeed.ai/news/2021/03/07/zero3-offload.html)\n* [2021/01/19] [[\ud83e\udd17Hugging Face Blog] Fit More and Train Faster With ZeRO via DeepSpeed and FairScale](https://huggingface.co/blog/zero-deepspeed-fairscale)\n* [2020/11/12] [Simplified install, JIT compiled ops, PyPI releases, and reduced dependencies](#installation)\n* [2020/11/10] [Efficient and robust compressed training through progressive layer dropping](https://www.deepspeed.ai/news/2020/10/28/progressive-layer-dropping-news.html)\n* [2020/09/10] [DeepSpeed v0.3: Extreme-scale model training for everyone](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/)\n\n\n# Table of Contents\n| Section                                 | Description                                 |\n| --------------------------------------- | ------------------------------------------- |\n| [Why DeepSpeed?](#why-deepspeed)        |  DeepSpeed overview                         |\n| [Install](#installation)                |  Installation details                       |\n| [Features](#features)                   |  Feature list and overview                  |\n| [Further Reading](#further-reading)     |  Documentation, tutorials, etc.             |\n| [Contributing](#contributing)           |  Instructions for contributing              |\n| [Publications](#publications)           |  Publications related to DeepSpeed          |\n| [Videos](#videos)                       |  Videos related to DeepSpeed                |\n\n# Why DeepSpeed?\nTraining advanced deep learning models is challenging. Beyond model design,\nmodel scientists also need to set up the state-of-the-art training techniques\nsuch as distributed training, mixed precision, gradient accumulation, and\ncheckpointing. Yet still, scientists may not achieve the desired system\nperformance and convergence rate. Large model sizes are even more challenging:\na large model easily runs out of memory with pure data parallelism and it is\ndifficult to use model parallelism. DeepSpeed addresses these challenges to\naccelerate model development *and* training.\n\n# Installation\n\nThe quickest way to get started with DeepSpeed is via pip, this will install\nthe latest release of DeepSpeed which is not tied to specific PyTorch or CUDA\nversions. DeepSpeed includes several C++/CUDA extensions that we commonly refer\nto as our 'ops'.  By default, all of these extensions/ops will be built\njust-in-time (JIT) using [torch's JIT C++ extension loader that relies on\nninja](https://pytorch.org/docs/stable/cpp_extension.html) to build and\ndynamically link them at runtime.\n\n**Note:** [PyTorch](https://pytorch.org/) must be installed _before_ installing\nDeepSpeed.\n\n```bash\npip install deepspeed\n```\n\nAfter installation, you can validate your install and see which extensions/ops\nyour machine is compatible with via the DeepSpeed environment report.\n\n```bash\nds_report\n```\n\nIf you would like to pre-install any of the DeepSpeed extensions/ops (instead\nof JIT compiling) or install pre-compiled ops via PyPI please see our [advanced\ninstallation instructions](https://www.deepspeed.ai/tutorials/advanced-install/).\n\n# Features\nBelow we provide a brief feature list, see our detailed [feature\noverview](https://www.deepspeed.ai/features/) for descriptions and usage.\n\n* [Distributed Training with Mixed Precision](https://www.deepspeed.ai/features/#distributed-training-with-mixed-precision)\n  * 16-bit mixed precision\n  * Single-GPU/Multi-GPU/Multi-Node\n* [Model Parallelism](https://www.deepspeed.ai/features/#model-parallelism)\n  * Support for Custom Model Parallelism\n  * Integration with Megatron-LM\n* [Pipeline Parallelism](https://www.deepspeed.ai/tutorials/pipeline/)\n  * 3D Parallelism\n* [The Zero Redundancy Optimizer (ZeRO)](https://www.deepspeed.ai/tutorials/zero/)\n  * Optimizer State and Gradient Partitioning\n  * Activation Partitioning\n  * Constant Buffer Optimization\n  * Contiguous Memory Optimization\n* [ZeRO-Offload](https://www.deepspeed.ai/tutorials/zero-offload/)\n  * Leverage both CPU/GPU memory for model training\n  * Support 10B model training on a single GPU\n* [Ultra-fast dense transformer kernels](https://www.deepspeed.ai/news/2020/05/18/bert-record.html)\n* [Sparse attention](https://www.deepspeed.ai/news/2020/09/08/sparse-attention.html)\n  * Memory- and compute-efficient sparse kernels\n  * Support 10x longer sequences than dense\n  * Flexible support to different sparse structures\n* [1-bit Adam](https://www.deepspeed.ai/news/2020/09/08/onebit-adam-blog-post.html) and [1-bit LAMB](https://www.deepspeed.ai/tutorials/onebit-lamb/)\n  * Custom communication collective\n  * Up to 5x communication volume saving\n* [Additional Memory and Bandwidth Optimizations](https://www.deepspeed.ai/features/#additional-memory-and-bandwidth-optimizations)\n  * Smart Gradient Accumulation\n  * Communication/Computation Overlap\n* [Training Features](https://www.deepspeed.ai/features/#training-features)\n  * Simplified training API\n  * Gradient Clipping\n  * Automatic loss scaling with mixed precision\n* [Training Optimizers](https://www.deepspeed.ai/features/#training-optimizers)\n  * Fused Adam optimizer and arbitrary `torch.optim.Optimizer`\n  * Memory bandwidth optimized FP16 Optimizer\n  * Large Batch Training with LAMB Optimizer\n  * Memory efficient Training with ZeRO Optimizer\n  * CPU-Adam\n* [Training Agnostic Checkpointing](https://www.deepspeed.ai/features/#training-agnostic-checkpointing)\n* [Advanced Parameter Search](https://www.deepspeed.ai/features/#advanced-parameter-search)\n  * Learning Rate Range Test\n  * 1Cycle Learning Rate Schedule\n* [Simplified Data Loader](https://www.deepspeed.ai/features/#simplified-data-loader)\n* [Performance Analysis and Debugging](https://www.deepspeed.ai/features/#performance-analysis-and-debugging)\n\n\n\n# Further Reading\n\nAll DeepSpeed documentation can be found on our website: [deepspeed.ai](https://www.deepspeed.ai/)\n\n\n| Article                                                                                        | Description                                  |\n| ---------------------------------------------------------------------------------------------- | -------------------------------------------- |\n| [DeepSpeed Features](https://www.deepspeed.ai/features/)                                       |  DeepSpeed features                          |\n| [Getting Started](https://www.deepspeed.ai/getting-started/)                                   |  First steps with DeepSpeed                         |\n| [DeepSpeed JSON Configuration](https://www.deepspeed.ai/docs/config-json/)                     |  Configuring DeepSpeed                       |\n| [API Documentation](https://deepspeed.readthedocs.io/en/latest/)                               |  Generated DeepSpeed API documentation       |\n| [CIFAR-10 Tutorial](https://www.deepspeed.ai/tutorials/cifar-10)                               |  Getting started with CIFAR-10 and DeepSpeed |\n| [Megatron-LM Tutorial](https://www.deepspeed.ai/tutorials/megatron/)                           |  Train GPT2 with DeepSpeed and Megatron-LM   |\n| [BERT Pre-training Tutorial](https://www.deepspeed.ai/tutorials/bert-pretraining/)             |  Pre-train BERT with DeepSpeed |\n| [Learning Rate Range Test Tutorial](https://www.deepspeed.ai/tutorials/lrrt/)                  |  Faster training with large learning rates   |\n| [1Cycle Tutorial](https://www.deepspeed.ai/tutorials/1Cycle/)                                  |  SOTA learning schedule in DeepSpeed         |\n\n\n\n# Contributing\nDeepSpeed welcomes your contributions! Please see our\n[contributing](CONTRIBUTING.md) guide for more details on formatting, testing,\netc.\n\n## Contributor License Agreement\nThis project welcomes contributions and suggestions. Most contributions require you to\nagree to a Contributor License Agreement (CLA) declaring that you have the right to, and\nactually do, grant us the rights to use your contribution. For details, visit\nhttps://cla.opensource.microsoft.com.\n\nWhen you submit a pull request, a CLA bot will automatically determine whether you need\nto provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply\nfollow the instructions provided by the bot. You will only need to do this once across\nall repos using our CLA.\n\n## Code of Conduct\nThis project has adopted the [Microsoft Open Source Code of\nConduct](https://opensource.microsoft.com/codeofconduct/). For more information see the\n[Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact\n[opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\n\n# Publications\n1. Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, Yuxiong He. (2019) ZeRO: memory optimizations toward training trillion parameter models. [arXiv:1910.02054](https://arxiv.org/abs/1910.02054) and [In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC '20)](https://dl.acm.org/doi/10.5555/3433701.3433727).\n2. Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. (2020) DeepSpeed: System Optimizations Enable Training Deep Learning Models with Over 100 Billion Parameters. [In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD '20, Tutorial)](https://dl.acm.org/doi/10.1145/3394486.3406703).\n3. Minjia Zhang, Yuxiong He. (2020) Accelerating Training of Transformer-Based Language Models with Progressive Layer Dropping. [arXiv:2010.13369](https://arxiv.org/abs/2010.13369) and [NeurIPS 2020](https://proceedings.neurips.cc/paper/2020/hash/a1140a3d0df1c81e24ae954d935e8926-Abstract.html).\n4. Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, Yuxiong He. (2021) ZeRO-Offload: Democratizing Billion-Scale Model Training. [arXiv:2101.06840](https://arxiv.org/abs/2101.06840).\n5. Hanlin Tang, Shaoduo Gan, Ammar Ahmad Awan, Samyam Rajbhandari, Conglong Li, Xiangru Lian, Ji Liu, Ce Zhang, Yuxiong He. (2021) 1-bit Adam: Communication Efficient Large-Scale Training with Adam's Convergence Speed. [arXiv:2102.02888](https://arxiv.org/abs/2102.02888).\n6. Samyam Rajbhandari, Olatunji Ruwase, Jeff Rasley, Shaden Smith, Yuxiong He. (2021) ZeRO-Infinity: Breaking the GPU Memory Wall for Extreme Scale Deep Learning. [arXiv:2104.07857](https://arxiv.org/abs/2104.07857).\n7. Conglong Li, Ammar Ahmad Awan, Hanlin Tang, Samyam Rajbhandari, Yuxiong He. (2021) 1-bit LAMB: Communication Efficient Large-Scale Large-Batch Training with LAMB's Convergence Speed. [arXiv:2104.06069](https://arxiv.org/abs/2104.06069).\n\n# Videos\n1. DeepSpeed KDD 2020 Tutorial\n    1. [Overview](https://www.youtube.com/watch?v=CaseqC45DNc&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=29)\n    2. [ZeRO + large model training](https://www.youtube.com/watch?v=y4_bCiAsIAk&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=28)\n    3. [17B T-NLG demo](https://www.youtube.com/watch?v=9V-ZbP92drg&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=27)\n    4. [Fastest BERT training + RScan tuning](https://www.youtube.com/watch?v=o1K-ZG9F6u0&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=26)\n    5. DeepSpeed hands on deep dive: [part 1](https://www.youtube.com/watch?v=_NOk-mBwDYg&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=92), [part 2](https://www.youtube.com/watch?v=sG6_c4VXLww&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=94), [part 3](https://www.youtube.com/watch?v=k9yPkBTayos&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=93)\n    6. [FAQ](https://www.youtube.com/watch?v=nsHu6vEgPew&list=PLa85ZdUjfWS21mgibJ2vCvLziprjpKoW0&index=24)\n2. Microsoft Research Webinar\n    * Registration is free and all videos are available on-demand.\n    * [ZeRO & Fastest BERT: Increasing the scale and speed of deep learning training in DeepSpeed](https://note.microsoft.com/MSR-Webinar-DeepSpeed-Registration-On-Demand.html).\n3. [DeepSpeed on AzureML](https://youtu.be/yBVXR8G8Bg8)\n4. Community Tutorials\n    * [DeepSpeed: All the tricks to scale to gigantic models](https://www.youtube.com/watch?v=pDGI668pNg0)\n    * [Turing-NLG, DeepSpeed and the ZeRO optimizer](https://www.youtube.com/watch?v=tC01FRB0M7w)\n"
 },
 {
  "repo": "microsoft/vscode-html-languageservice",
  "language": "TypeScript",
  "readme_contents": "# vscode-html-languageservice\nHTML language service extracted from VSCode to be reused, e.g in the Monaco editor.\n\n[![npm Package](https://img.shields.io/npm/v/vscode-html-languageservice.svg?style=flat-square)](https://www.npmjs.org/package/vscode-html-languageservice)\n[![NPM Downloads](https://img.shields.io/npm/dm/vscode-html-languageservice.svg)](https://npmjs.org/package/vscode-html-languageservice)\n[![Azure DevOps Build Status](https://img.shields.io/azure-devops/build/vscode/4c3636fe-3a50-40b9-b8b4-f820ca92886f/22.svg?label=Azure%20DevOps)](https://dev.azure.com/vscode/vscode-html-languageservice/_build?definitionId=22)\n[![Travis Build Status](https://travis-ci.org/Microsoft/vscode-html-languageservice.svg?branch=master)](https://travis-ci.org/Microsoft/vscode-html-languageservice)\n\n\nWhy?\n----\n\nThe _vscode-html-languageservice_ contains the language smarts behind the HTML editing experience of Visual Studio Code\nand the Monaco editor.\n\n - *doComplete* / *doComplete2* (async) provide completion proposals for a given location.\n - *setCompletionParticipants* allows participant to provide suggestions for specific tokens.\n - *doHover* provides hover information at a given location.\n \n - *format* formats the code at the given range.\n - *findDocumentLinks* finds all links in the document.\n - *findDocumentSymbols* finds all the symbols in the document.\n - *getFoldingRanges* return folding ranges for the given document.\n - *getSelectionRanges* return the selection ranges for the given document.\n ...\n\n For the complete API see [htmlLanguageService.ts](./src/htmlLanguageService.ts) and [htmlLanguageTypes.ts](./src/htmlLanguageTypes.ts) \n\nInstallation\n------------\n\n    npm install --save vscode-html-languageservice\n\nDevelopment\n-----------\n\n- clone this repo, run yarn\n- `yarn test` to compile and run tests\n\n\nHow can I run and debug the service?\n\n- open the folder in VSCode.\n- set breakpoints, e.g. in `htmlCompletion.ts`\n- run the Unit tests from the run viewlet and wait until a breakpoint is hit:\n![image](https://user-images.githubusercontent.com/6461412/94239202-bdad4e80-ff11-11ea-99c3-cb9dbeb1c0b2.png)\n\n\nHow can I run and debug the service inside an instance of VSCode?\n\n- run VSCode out of sources setup as described here: https://github.com/Microsoft/vscode/wiki/How-to-Contribute\n- link the fodler of the `vscode-html-languageservice` repo to `vscode/extensions/html-language-features/server` to run VSCode with the latest changes from that folder:\n  - cd `vscode-html-languageservice`, `yarn link`\n  - cd `vscode/extensions/html-language-features/server`, `yarn link vscode-html-languageservice`\n- run VSCode out of source (`vscode/scripts/code.sh|bat`) and open a `.html` file\n- in VSCode window that is open on the `vscode-html-languageservice` sources, run command `Debug: Attach to Node process` and pick the `code-oss` process with the `html-language-features` path\n![image](https://user-images.githubusercontent.com/6461412/94239296-dfa6d100-ff11-11ea-8e30-6444cf5defb8.png)\n- set breakpoints, e.g. in `htmlCompletion.ts`\n- in the instance run from sources, invoke code completion in the `.html` file\n\n\nLicense\n-------\n\n(MIT License)\n\nCopyright 2016-2020, Microsoft\n\nWith the exceptions of `data/*.json`, which is built upon content from [Mozilla Developer Network](https://developer.mozilla.org/en-US/docs/Web)\nand distributed under CC BY-SA 2.5.\n"
 },
 {
  "repo": "microsoft/satcheljs",
  "language": "TypeScript",
  "readme_contents": "# Satchel\n\nSatchel is a dataflow framework based on the [Flux architecture](http://facebook.github.io/react/blog/2014/05/06/flux.html).  It is characterized by exposing an observable state that makes view updates painless and efficient.\n\n[![npm](https://img.shields.io/npm/v/satcheljs.svg)](https://www.npmjs.com/package/satcheljs)\n[![Build Status](https://travis-ci.org/Microsoft/satcheljs.svg?branch=master)](https://travis-ci.org/Microsoft/satcheljs)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n## Influences\n\nSatchel is an attempt to synthesize the best of several dataflow patterns typically used to drive a React-based UI.  In particular:\n\n* [Flux](http://facebook.github.io/react/blog/2014/05/06/flux.html) is not a library itself, but is a dataflow pattern conceived for use with React.  In Flux, dataflow is unidirectional, and the only way to modify state is by dispatching actions through a central dispatcher.\n* [Redux](http://redux.js.org/index.html) is an implementation of Flux that consolidates stores into a single state tree and attempts to simplify state changes by making all mutations via pure functions called reducers.  Ultimately, however, we found reducers and immutable state cumbersome to deal with, particularly in a large, interconnected app.\n* [MobX](http://mobxjs.github.io/mobx/index.html) provides a seamless way to make state observable, and allows React to listen to state changes and rerender in a very performant way.  Satchel uses MobX under the covers to allow React components to observe the data they depend on.\n\n## Advantages\n\nThere are a number of advantages to using Satchel to maintain your application state:\n\n* Satchel enables a very **performant UI**, only rerendering the minimal amount necessary.  MobX makes UI updates very efficient by automatically detecting specifically what components need to rerender for a given state change.\n* Satchel's datastore allows for **isomorphic JavaScript** by making it feasible to render on the server and then serialize and pass the application state down to the client.\n* Satchel supports **middleware** that can act on each action that is dispatched.  (For example, for tracing or performance instrumentation.)\n* Satchel is **type-safe** out of the box, without any extra effort on the consumer's part.\n\n## Installation\n\nInstall via NPM:\n\n`npm install satcheljs --save`\n\nIn order to use Satchel with React, you'll also need MobX and the MobX React bindings:\n\n`npm install mobx --save`\n\n`npm install mobx-react --save`\n\n## Usage\n\nThe following examples assume you're developing in Typescript.\n\n### Create a store with some initial state\n\n```typescript\nimport { createStore } from 'satcheljs';\n\nlet getStore = createStore(\n    'todoStore',\n    { todos: [] }\n);\n```\n\n### Create a component that consumes your state\n\nNotice the `@observer` decorator on the component\u2014this is what tells MobX to rerender the component whenever the data it relies on changes.\n\n```javascript\nimport { observer } from 'mobx-react';\n\n@observer\nclass TodoListComponent extends React.Component<any, any> {\n    render() {\n        return (\n            <div>\n                {getStore().todos.map(todo => <div>{todo.text}</div>)}\n            </div>\n        );\n    }\n}\n```\n\n### Implement an action creator\n\nNote that, as a convenience, Satchel action creators created with the `action` API both *create* and *dispatch* the action.\nThis is typically how you want to use action creators.\nIf you want to create and dispatch the actions separately you can use the `actionCreator` and `dispatch` APIs.\n\n```typescript\nimport { action } from 'satcheljs';\n\nlet addTodo = action(\n    'ADD_TODO',\n    (text: string) => ({ text: text })\n);\n\n// This creates and dispatches an ADD_TODO action\naddTodo('Take out trash');\n```\n\n### Implement a mutator\n\nYou specify what action a mutator subscribes to by providing the corresponding action creator.\nIf you're using TypeScript, the type of `actionMessage` is automatically inferred.\n\n```typescript\nimport { mutator } from 'satcheljs';\n\nmutator(addTodo, (actionMessage) => {\n    getStore().todos.push({\n        id: Math.random(),\n        text: actionMessage.text\n    });\n};\n```\n\n### Orchestrators\n\nOrchestrators are like mutators\u2014they subscribe to actions\u2014but they serve a different purpose.\nWhile mutators modify the store, orchestrators are responsible for side effects.\nSide effects might include making a server call or even dispatching further actions.\n\nThe following example shows how an orchestrator can persist a value to a server before updating the store.\n\n```typescript\nimport { action, orchestrator } from 'satcheljs';\n\nlet requestAddTodo = action(\n    'REQUEST_ADD_TODO',\n    (text: string) => ({ text: text })\n);\n\norchestrator(requestAddTodo, async (actionMessage) => {\n    await addTodoOnServer(actionMessage.text);\n    addTodo(actionMessage.text);\n});\n```\n\n### mutatorAction\n\nIn many cases a given action only needs to be handled by one mutator.\nSatchel provides this utility API which encapsulates action creation, dispatch, and handling in one simple function call.\n\nThe `addTodo` mutator above could be implemented as follows:\n\n```typescript\nlet addTodo = mutatorAction(\n    'ADD_TODO',\n    function addTodo(text: string) {\n        getStore().todos.push({\n            id: Math.random(),\n            text: actionMessage.text\n        });\n    });\n```\n\nThis is a succinct and easy way to write mutators, but it comes with a restriction:\nthe action creator is not exposed, so no *other* mutators or orchestrators can subscribe to it.\nIf an action needs multiple handlers then it must use the full pattern with action creators and handlers implemented separately.\n\n## License - MIT\n"
 },
 {
  "repo": "microsoft/unilm",
  "language": "Python",
  "readme_contents": "# UniLM\r\n**Pre-trained models for natural language understanding (NLU) and generation (NLG) tasks**\r\n\r\nThe family of UniLM:\r\n> [**UniLM**](https://github.com/microsoft/unilm/tree/master/unilm) (```v1@NeurIPS'19 | v2@ICML'20 | v3@ACL'21```): **unified pre-training for language understanding and generation**\r\n\r\n> [**InfoXLM**](https://github.com/microsoft/unilm/tree/master/infoxlm) (```v1@NAACL'21 | v2@ACL'21```): **multilingual/cross-lingual pre-trained models for language understanding and generation**\r\n\r\n> [**MiniLM**](https://github.com/microsoft/unilm/tree/master/minilm) (```v1@NeurIPS'20 | v2@ACL'21```): **small and fast pre-trained models for language understanding and generation**\r\n\r\n> [**AdaLM**](https://github.com/microsoft/unilm/tree/master/adalm) (```v1@ACL'21```): **domain, language, and task adaptation of pre-trained models**\r\n\r\n> [**LayoutLM**](https://github.com/microsoft/unilm/tree/master/layoutlm) (```v1@KDD'20 | v2@ACL'21```): **multimodal (text + layout/format + image) pre-training for document understanding** (e.g. scanned documents, PDF, etc.)\r\n\r\n> [**LayoutXLM**](https://github.com/microsoft/unilm/tree/master/layoutxlm) (```NEW```): **multimodal (text + layout/format + image) pre-training for multilingual document understanding**\r\n\r\n> [**s2s-ft**](https://github.com/microsoft/unilm/tree/master/s2s-ft): **sequence-to-sequence fine-tuning toolkit**\r\n\r\n> [**XLM-T**](https://github.com/microsoft/unilm/tree/master/xlmt) (```NEW```): **Multilingual NMT w/ pretrained cross-lingual encoders**\r\n\r\n\r\n## News\r\n- May, 2021: [LayoutLMv2](https://github.com/microsoft/unilm/tree/master/layoutlmv2), InfoXLMv2, MiniLMv2, UniLMv3, and AdaLM were accepted by ACL 2021.\r\n- April, 2021: [LayoutXLM](https://github.com/microsoft/unilm/tree/master/layoutxlm) is coming by extending the LayoutLM into multilingual support! A multilingual form understanding benchmark XFUN is also introduced, which includes forms with human labeled key-value pairs in 7 languages (Chinese, Japanese, Spanish, French, Italian, German, Portuguese).\r\n- March, 2021: [InfoXLM](https://github.com/microsoft/unilm/tree/master/infoxlm) was accepted by NAACL 2021.\r\n- December 29th, 2020: [LayoutLMv2](https://arxiv.org/abs/2012.14740) is coming with the new SOTA on a wide varierty of document AI tasks, including [DocVQA](https://rrc.cvc.uab.es/?ch=17&com=evaluation&task=1) and [SROIE](https://rrc.cvc.uab.es/?ch=13&com=evaluation&task=3) leaderboard.\r\n- October 8th, 2020: T-ULRv2 (aka [InfoXLM](https://arxiv.org/abs/2007.07834)) as the SOTA on the [XTREME](https://sites.research.google/xtreme) leaderboard. // [Blog](https://www.microsoft.com/en-us/research/blog/microsoft-turing-universal-language-representation-model-t-ulrv2-tops-xtreme-leaderboard/)\r\n- September, 2020: [MiniLM](https://github.com/microsoft/unilm/tree/master/minilm) was accepted by NeurIPS 2020.\r\n- July 16, 2020: [**InfoXLM** (Multilingual UniLM)](https://github.com/microsoft/unilm/tree/master/infoxlm) [arXiv](https://arxiv.org/pdf/2007.07834.pdf)\r\n- June, 2020: [UniLMv2](https://github.com/microsoft/unilm/tree/master/unilm) was accepted by ICML 2020; [LayoutLM](https://github.com/microsoft/unilm/tree/master/layoutlm) was accepted by KDD 2020.\r\n- April 5, 2020: [**Multilingual MiniLM**](https://github.com/microsoft/unilm/tree/master/minilm) released!\r\n- September, 2019: [UniLMv1](https://github.com/microsoft/unilm/tree/master/unilm-v1) was accepted by NeurIPS 2019.\r\n\r\n## Release\r\n\r\n**\\*\\*\\*\\*\\* ```New May, 2021```: [LayoutLMv2](https://github.com/microsoft/unilm/tree/master/layoutlmv2) | [LayoutXLM](https://github.com/microsoft/unilm/tree/master/layoutxlm) release \\*\\*\\*\\*\\***\r\n\r\n- [x] [**LayoutLM 2.0**](https://github.com/microsoft/unilm/tree/master/layoutlmv2) (December 29, 2020): multimodal pre-training for visually-rich document understanding by leveraging text, layout and image information in a single framework. It is coming with new SOTA on a wide range of document understanding tasks, including FUNSD (0.7895 -> 0.8420), CORD (0.9493 -> 0.9601), SROIE (0.9524 -> 0.9781), Kleister-NDA (0.834 -> 0.852), RVL-CDIP (0.9443 -> 0.9564), and DocVQA (0.7295 -> 0.8672). \"[LayoutLMv2: Multi-modal Pre-training for Visually-Rich Document Understanding](https://arxiv.org/abs/2012.14740) ```ACL 2021```\"\r\n- [x] [**LayoutXLM**](https://github.com/microsoft/unilm/tree/master/layoutxlm) (April, 17, 2021): multimodal pre-training for multilingual visually-rich document understanding. The pre-trained LayoutXLM model has significantly outperformed the existing SOTA cross-lingual pre-trained models on the FUNSD and multilingual XFUN dataset including 7 languages (Chinese, Japanese, Spanish, French, Italian, German, Portuguese). \"[LayoutXLM: Multimodal Pre-training for Multilingual Visually-rich Document Understanding](https://arxiv.org/abs/2104.08836)\"\r\n\r\n**\\*\\*\\*\\*\\* ```February, 2020```: [UniLM v2](https://github.com/microsoft/unilm/tree/master/unilm) | [MiniLM v1](https://github.com/microsoft/unilm/tree/master/minilm) | [LayoutLM v1](https://github.com/microsoft/unilm/tree/master/layoutlm) | [s2s-ft v1](https://github.com/microsoft/unilm/tree/master/s2s-ft) release \\*\\*\\*\\*\\***\r\n\r\n- [x] [**LayoutLM 1.0**](https://github.com/microsoft/unilm/tree/master/layoutlm) (February 18, 2020): pre-trained models for document (image) understanding (e.g. receipts, forms, etc.) . It achieves new SOTA results in several downstream tasks, including form understanding (the FUNSD dataset from 70.72 to 79.27), receipt understanding (the [ICDAR 2019 SROIE leaderboard](https://rrc.cvc.uab.es/?ch=13&com=evaluation&task=3) from 94.02 to 95.24) and document image classification (the RVL-CDIP dataset from 93.07 to 94.42). \"[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318) ```KDD 2020```\"\r\n- [x] [**s2s-ft 1.0**](https://github.com/microsoft/unilm/tree/master/s2s-ft) (February 26, 2020): A PyTorch package used to fine-tune pre-trained Transformers for sequence-to-sequence language generation. \"[s2s-ft: Fine-Tuning Pre-Trained Transformers for Sequence-to-Sequence Learning](#)\"\r\n- [x] [**MiniLM 1.0**](https://github.com/microsoft/unilm/tree/master/minilm) (February 26, 2020): deep self-attention distillation is all you need (for task-agnostic knowledge distillation of pre-trained Transformers). MiniLM (12-layer, 384-hidden) achieves 2.7x speedup and comparable results over BERT-base (12-layer, 768-hidden) on NLU tasks as well as strong results on NLG tasks. The even smaller MiniLM (6-layer, 384-hidden) obtains 5.3x speedup and produces very competitive results. \"[MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers](https://arxiv.org/abs/2002.10957) ```NeurIPS 2020```\"\r\n- [x] [**UniLM 2.0**](https://github.com/microsoft/unilm/tree/master/unilm) (February 28, 2020): **unified pre-training** of bi-directional LM (via autoencoding) and sequence-to-sequence LM (via partially autoregressive) w/ **Pseudo-Masked Language Model** for language understanding and generation. UniLM v2 achieves new SOTA in a wide range of natural language understanding and generation tasks. \"[UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training](https://arxiv.org/abs/2002.12804) ```ICML 2020```\"\r\n\r\n\r\n\r\n**\\*\\*\\*\\*\\* October 1st, 2019: UniLM v1 release \\*\\*\\*\\*\\***\r\n\r\n- [x] [**UniLM v1**](https://github.com/microsoft/unilm/tree/master/unilm-v1) (September 30, 2019): the code and pre-trained models for the ```NeurIPS 2019``` paper entitled \"[Unified Language Model Pre-training for Natural Language Understanding and Generation](https://arxiv.org/abs/1905.03197)\". UniLM (v1) achieves the **new SOTA results** in **NLG** (especially **sequence-to-sequence generation**) tasks, including abstractive summarization (the Gigaword and CNN/DM datasets), question generation (the SQuAD QG dataset), etc. \r\n\r\n## License\r\nThis project is licensed under the license found in the LICENSE file in the root directory of this source tree.\r\nPortions of the source code are based on the [transformers](https://github.com/huggingface/transformers) project.\r\n\r\n[Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct)\r\n\r\n### Contact Information\r\n\r\nFor help or issues using UniLM, please submit a GitHub issue.\r\n\r\nFor other communications related to UniLM, please contact Li Dong (`lidong1@microsoft.com`), Furu Wei (`fuwei@microsoft.com`).\r\n\r\n"
 },
 {
  "repo": "microsoft/vscode-java-test",
  "language": "Java",
  "readme_contents": "# Java Test Runner\n\n> Run and debug Java test cases in Visual Studio Code\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Microsoft/vscode-java-test/master/resources/logo.png\" width=\"128\" height=\"128\" alt=\"\">\n</p>\n<p align=\"center\">\n  <a href=\"https://github.com/microsoft/vscode-java-test/actions?query=workflow%3ACI+branch%3Amaster\">\n    <img src=\"https://img.shields.io/github/workflow/status/microsoft/vscode-java-test/CI/master?style=flat-square\" alt=\"\">\n  </a>\n  <a href=\"https://lgtm.com/projects/g/microsoft/vscode-java-test/alerts/?mode=list\">\n    <img src=\"https://img.shields.io/lgtm/alerts/g/microsoft/vscode-java-test.svg?style=flat-square\" alt=\"\">\n  </a>\n  <a href=\"https://gitter.im/microsoft/vscode-java-test\">\n    <img src=\"https://img.shields.io/gitter/room/microsoft/vscode-java-test.svg?style=flat-square\" alt=\"\">\n  </a>\n  <a href=\"https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-test\">\n    <img src=\"https://img.shields.io/visual-studio-marketplace/d/vscjava.vscode-java-test.svg?style=flat-square\" alt=\"\">\n  </a>\n</p>\n\n## Overview\n\nA lightweight extension to run and debug Java test cases in Visual Studio Code. The extension support following test frameworks:\n\n- JUnit 4 (v4.8.0+)\n- JUnit 5 (v5.1.0+)\n- TestNG (v6.8.0+)\n\n> Note: JUnit 3 styled tests are not supported in this extension (i.e. extends `junit.framework.TestCase`).\n\nThe [Java Test Runner](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-test) works with [Language Support for Java by Red Hat](https://marketplace.visualstudio.com/items?itemName=redhat.java) and [Debugger for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-debug) to provide the following features:\n\n- Run/Debug test cases\n- Customize test configurations\n- View test report\n- View tests in Test Explorer\n- Show test logs\n\n\n## Requirements\n\n- JDK (version 11 or later)\n- VS Code (version 1.44.0 or later)\n- [Language Support for Java by Red Hat](https://marketplace.visualstudio.com/items?itemName=redhat.java)\n- [Debugger for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-java-debug)\n\n## Quickstart\n\n![Run/debug JUnit test](demo/demo.gif)\n\n### Getting Started for JUnit 5\n\nPlease refer to [Getting Started](https://junit.org/junit5/docs/current/user-guide/#overview-getting-started) from the JUnit 5's official document for getting started guide.\n\n> Note: You can use [junit-platform-console-standalone.jar](https://search.maven.org/search?q=g:org.junit.platform%20AND%20a:junit-platform-console-standalone) in projects that manually manage their dependencies similar to the [plain-old JAR known from JUnit 4](https://github.com/junit-team/junit4/wiki/Download-and-Install#plain-old-jar).\n\n### Getting Started for JUnit 4\nPlease refer to [Download and Install](https://github.com/junit-team/junit4/wiki/Download-and-Install) from the JUnit 4's official document for the getting started guide.\n\n### Getting Started for TestNG\n\nPlease refer to [TestNG Docs](https://testng.org/doc/) from the TestNG's official document for getting started guide.\n\n## Features\n\n### Run/Debug Test Cases\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Microsoft/vscode-java-test/master/demo/run_codelens.png\" style=\"border-radius: 15px\" alt=\"Run Code Lens\"/>\n</p>\n\n- The extension will generate `Run Test` and `Debug Test` shortcuts (also known as Code Lens) above the class and method definition. Simply click on them will start running or debugging the target test cases.\n\n> Note: If you cannot see the Code Lens in your editor, please refer to this [issue comment](https://github.com/Microsoft/vscode-java-test/issues/470#issuecomment-444681714) as a workaround.\n\n---\n\n### Test Explorer\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Microsoft/vscode-java-test/master/demo/run_explorer.png\" style=\"border-radius: 15px\" alt=\"Run Explorer\"/>\n</p>\n\n- The Test Explorer is the place to show all the test cases in your project. You can also run/debug your test cases from here.\n- Click the node in the Test Explorer will navigate to the location of the source code.\n\n> Note: If the Test Explorer is empty, please refer to this [issue comment](https://github.com/Microsoft/vscode-java-test/issues/470#issuecomment-444681714) as a workaround.\n\n---\n\n### Customize Test Configurations\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Microsoft/vscode-java-test/master/demo/configuration.png\" style=\"border-radius: 15px\" alt=\"Customize Test Configurations\"/>\n</p>\n\n- Sometimes you may want to customize the configuration for running the test cases. To achieve this, you can add it into your workspace settings under the section: `java.test.config`.\n\n> Note: More details can be found [here](https://github.com/Microsoft/vscode-java-test/wiki/Run-with-Configuration).\n\n---\n\n### View Test Report\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Microsoft/vscode-java-test/master/demo/status_bar.png\" style=\"border-radius: 15px\" alt=\"Status Bar\"/>\n</p>\n\n- After running/debugging the test cases, the status bar will show the final results. Simply click on it to show the Test Report.\n- You can also click the \u2714\ufe0f or \u274c mark in Code Lens to open the Test Report.\n\n<p align=\"center\">\n  <img src=\"https://raw.githubusercontent.com/Microsoft/vscode-java-test/master/demo/report_navigate.png\" style=\"border-radius: 15px\" alt=\"Status Bar\"/>\n</p>\n\n- You can navigate to the source location of the target test case by clicking the navigate button.\n\n> Note: You can use `java.test.report.showAfterExecution` to configure whether to automatically show the test report after execution. By default, it will be shown when there are failed tests. \n\n\n## Settings\n\n| Setting Name | Description | Default Value |\n|---|---|---|\n| `java.test.report.position` | Specify where to show the test report. Supported values are: `sideView`, `currentView`. | `sideView` |\n| `java.test.report.showAfterExecution` | Specify if the test report will automatically be shown after execution. Supported values are: `always`, `onFailure`, `never`. | `onFailure` |\n| `java.test.editor.enableShortcuts` | Specify whether to show the Code Lenses in editor or not. | `true` |\n| `java.test.log.level` | Specify the level of the test logs. Supported values are: `error`, `info`, `verbose`. | `info` |\n| `java.test.config` | Specify the configuration for the test cases to run with. [More details](https://aka.ms/java-test-config). | `{}` |\n| `java.test.defaultConfig` | Specify the name of the default test configuration. | `\"\"` |\n\n## FAQ\nIf you meet any problem when using the extension, please refer to the [FAQ](https://github.com/microsoft/vscode-java-test/wiki/FAQ) to check if there is an answer to your problem.\n\n## Contributing and Feedback\n\nIf you are interested in providing feedback or contributing directly to the code base, please check the document [Contributing to Java Test Runner](https://github.com/Microsoft/vscode-java-test/blob/master/CONTRIBUTING.md), which covers the following parts:\n- [Questions and Feedback](https://github.com/Microsoft/vscode-java-test/blob/master/CONTRIBUTING.md#questions-and-feedback)\n- [Reporting Issues](https://github.com/Microsoft/vscode-java-test/blob/master/CONTRIBUTING.md#reporting-issues)\n- [Contributing Fixes](https://github.com/Microsoft/vscode-java-test/blob/master/CONTRIBUTING.md#contributing-fixes)\n\n## License\n\nThis extension is licensed under [MIT License](LICENSE.txt).\n\n## Telemetry\n\nThis extension collects telemetry data to help improve our products. Please read [Microsoft privacy statement](https://privacy.microsoft.com/en-us/privacystatement) to learn more. If you opt out to send telemetry data to Microsoft, please set below configuration in settings.json: `telemetry.enableTelemetry = false`. Learn more in our [FAQ](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting).\n"
 },
 {
  "repo": "microsoft/AirSim",
  "language": "C++",
  "readme_contents": "# Welcome to AirSim\r\n\r\nAirSim is a simulator for drones, cars and more, built on [Unreal Engine](https://www.unrealengine.com/) (we now also have an experimental [Unity](https://unity3d.com/) release). It is open-source, cross platform, and supports software-in-the-loop simulation with popular flight controllers such as PX4 & ArduPilot and hardware-in-loop with PX4 for physically and visually realistic simulations. It is developed as an Unreal plugin that can simply be dropped into any Unreal environment. Similarly, we have an experimental release for a Unity plugin.\r\n\r\nOur goal is to develop AirSim as a platform for AI research to experiment with deep learning, computer vision and reinforcement learning algorithms for autonomous vehicles. For this purpose, AirSim also exposes APIs to retrieve data and control vehicles in a platform independent way.\r\n\r\n**Check out the quick 1.5 minute demo**\r\n\r\nDrones in AirSim\r\n\r\n[![AirSim Drone Demo Video](docs/images/demo_video.png)](https://youtu.be/-WfTr1-OBGQ)\r\n\r\nCars in AirSim\r\n\r\n[![AirSim Car Demo Video](docs/images/car_demo_video.png)](https://youtu.be/gnz1X3UNM5Y)\r\n\r\n\r\n## How to Get It\r\n\r\n[![Build Status](https://travis-ci.org/Microsoft/AirSim.svg?branch=master)](https://travis-ci.org/Microsoft/AirSim)\r\n\r\n### Windows\r\n* [Download binaries](https://github.com/Microsoft/AirSim/releases)\r\n* [Build it](https://microsoft.github.io/AirSim/build_windows)\r\n\r\n### Linux\r\n* [Download binaries](https://github.com/Microsoft/AirSim/releases)\r\n* [Build it](https://microsoft.github.io/AirSim/build_linux)\r\n\r\n### macOS\r\n* [Build it](https://microsoft.github.io/AirSim/build_linux)\r\n\r\nFor more details, see the [use precompiled binaries](docs/use_precompiled.md) document. \r\n\r\n## How to Use It\r\n\r\n### Documentation\r\n\r\nView our [detailed documentation](https://microsoft.github.io/AirSim/) on all aspects of AirSim.\r\n\r\n### Manual drive\r\n\r\nIf you have remote control (RC) as shown below, you can manually control the drone in the simulator. For cars, you can use arrow keys to drive manually.\r\n\r\n[More details](https://microsoft.github.io/AirSim/remote_control/)\r\n\r\n![record screenshot](docs/images/AirSimDroneManual.gif)\r\n\r\n![record screenshot](docs/images/AirSimCarManual.gif)\r\n\r\n\r\n### Programmatic control\r\n\r\nAirSim exposes APIs so you can interact with the vehicle in the simulation programmatically. You can use these APIs to retrieve images, get state, control the vehicle and so on. The APIs are exposed through the RPC, and are accessible via a variety of languages, including C++, Python, C# and Java.\r\n\r\nThese APIs are also available as part of a separate, independent cross-platform library, so you can deploy them on a companion computer on your vehicle. This way you can write and test your code in the simulator, and later execute it on the real vehicles. Transfer learning and related research is one of our focus areas.\r\n\r\nNote that you can use [SimMode setting](https://microsoft.github.io/AirSim/settings#simmode) to specify the default vehicle or the new [ComputerVision mode](https://microsoft.github.io/AirSim/image_apis#computer-vision-mode-1) so you don't get prompted each time you start AirSim.\r\n\r\n[More details](https://microsoft.github.io/AirSim/apis/)\r\n\r\n### Gathering training data\r\n\r\nThere are two ways you can generate training data from AirSim for deep learning. The easiest way is to simply press the record button in the lower right corner. This will start writing pose and images for each frame. The data logging code is pretty simple and you can modify it to your heart's content.\r\n\r\n![record screenshot](docs/images/record_data.png)\r\n\r\nA better way to generate training data exactly the way you want is by accessing the APIs. This allows you to be in full control of how, what, where and when you want to log data.\r\n\r\n### Computer Vision mode\r\n\r\nYet another way to use AirSim is the so-called \"Computer Vision\" mode. In this mode, you don't have vehicles or physics. You can use the keyboard to move around the scene, or use APIs to position available cameras in any arbitrary pose, and collect images such as depth, disparity, surface normals or object segmentation.\r\n\r\n[More details](https://microsoft.github.io/AirSim/image_apis/)\r\n\r\n### Weather Effects\r\n\r\nPress F10 to see various options available for weather effects. You can also control the weather using [APIs](https://microsoft.github.io/AirSim/apis#weather-apis). Press F1 to see other options available.\r\n\r\n![record screenshot](docs/images/weather_menu.png)\r\n\r\n## Tutorials\r\n\r\n- [Video - Setting up AirSim with Pixhawk Tutorial](https://youtu.be/1oY8Qu5maQQ) by Chris Lovett\r\n- [Video - Using AirSim with Pixhawk Tutorial](https://youtu.be/HNWdYrtw3f0) by Chris Lovett\r\n- [Video - Using off-the-self environments with AirSim](https://www.youtube.com/watch?v=y09VbdQWvQY) by Jim Piavis\r\n- [Reinforcement Learning with AirSim](https://microsoft.github.io/AirSim/reinforcement_learning) by Ashish Kapoor\r\n- [The Autonomous Driving Cookbook](https://aka.ms/AutonomousDrivingCookbook) by Microsoft Deep Learning and Robotics Garage Chapter\r\n- [Using TensorFlow for simple collision avoidance](https://github.com/simondlevy/AirSimTensorFlow) by Simon Levy and WLU team\r\n\r\n## Participate\r\n\r\n### Paper\r\n\r\nMore technical details are available in [AirSim paper (FSR 2017 Conference)](https://arxiv.org/abs/1705.05065). Please cite this as:\r\n```\r\n@inproceedings{airsim2017fsr,\r\n  author = {Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor},\r\n  title = {AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles},\r\n  year = {2017},\r\n  booktitle = {Field and Service Robotics},\r\n  eprint = {arXiv:1705.05065},\r\n  url = {https://arxiv.org/abs/1705.05065}\r\n}\r\n```\r\n\r\n### Contribute\r\n\r\nPlease take a look at [open issues](https://github.com/microsoft/airsim/issues) if you are looking for areas to contribute to.\r\n\r\n* [More on AirSim design](https://microsoft.github.io/AirSim/design)\r\n* [More on code structure](https://microsoft.github.io/AirSim/code_structure)\r\n* [Contribution Guidelines](CONTRIBUTING.md)\r\n\r\n### Who is Using AirSim?\r\n\r\nWe are maintaining a [list](https://microsoft.github.io/AirSim/who_is_using) of a few projects, people and groups that we are aware of. If you would like to be featured in this list please [make a request here](https://github.com/microsoft/airsim/issues).\r\n\r\n## Contact\r\n\r\nJoin our [GitHub Discussions group](https://github.com/microsoft/AirSim/discussions) to stay up to date or ask any questions.\r\n\r\nWe also have an AirSim group on [Facebook](https://www.facebook.com/groups/1225832467530667/). \r\n\r\n\r\n## What's New\r\n\r\n- [Python wrapper for Open AI gym interfaces.](https://github.com/microsoft/AirSim/pull/3215)\r\n- [Python wrapper for Event camera simulation](https://github.com/microsoft/AirSim/pull/3202)\r\n- [Voxel grid construction](https://github.com/microsoft/AirSim/pull/3209)\r\n- [Programmable camera distortion](https://github.com/microsoft/AirSim/pull/3039)\r\n- [Wind simulation](https://github.com/microsoft/AirSim/pull/2867)\r\n- [Azure development environment with documentation](https://github.com/microsoft/AirSim/pull/2816)\r\n- ROS wrapper for [multirotor](https://github.com/microsoft/AirSim/blob/master/docs/airsim_ros_pkgs.md) and [car](https://github.com/microsoft/AirSim/pull/2743).\r\n\r\nFor complete list of changes, view our [Changelog](docs/CHANGELOG.md)\r\n\r\n## FAQ\r\n\r\nIf you run into problems, check the [FAQ](https://microsoft.github.io/AirSim/faq) and feel free to post issues in the  [AirSim](https://github.com/Microsoft/AirSim/issues) repository.\r\n\r\n## Code of Conduct\r\n\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n\r\n## License\r\n\r\nThis project is released under the MIT License. Please review the [License file](LICENSE) for more details.\r\n\r\n\r\n"
 },
 {
  "repo": "microsoft/vscode-cosmosdb",
  "language": "TypeScript",
  "readme_contents": "\r\n# Azure Databases for VS Code (Preview)\r\n\r\n<!-- region exclude-from-marketplace -->\r\n\r\n[![Version](https://vsmarketplacebadge.apphb.com/version/ms-azuretools.vscode-cosmosdb.svg)](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-cosmosdb) [![Installs](https://vsmarketplacebadge.apphb.com/installs-short/ms-azuretools.vscode-cosmosdb.svg)](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-cosmosdb) [![Build Status](https://dev.azure.com/ms-azuretools/AzCode/_apis/build/status/vscode-cosmosdb)](https://dev.azure.com/ms-azuretools/AzCode/_build/latest?definitionId=7)\r\n\r\n<!-- endregion exclude-from-marketplace -->\r\n\r\nBrowse and query your Azure databases both locally and in the cloud using [_scrapbooks_](#mongo-scrapbooks) with rich Intellisense then connect to Azure to manage your PostgreSQL and Cosmos DB databases with support for MongoDB, Graph (Gremlin), and SQL (previously known as DocumentDB).\r\n\r\n![Azure Databases Extension](resources/features.png)\r\n\r\n# Prerequisites\r\n\r\n- Some less-common commands in the Mongo [scrapbook](#mongo-scrapbooks) and use of the Mongo shell require installing [Mongo DB and Mongo shell](https://docs.mongodb.com/manual/installation/).\r\n\r\n# Features\r\n\r\n## Azure Databases Explorer\r\n\r\n- Create a database server by clicking the `+` button in the title\r\n- View database servers and open directly in the portal\r\n- View/Create/Delete databases, collections, graphs, stored procedures, documents, and queries\r\n- Click on a document, stored procedure, or query to open in the editor\r\n- Click on a graph to visualize data\r\n- Query graph using [Gremlin](https://docs.microsoft.com/azure/cosmos-db/gremlin-support)\r\n- Edit a document and persist changes to the cloud\r\n- Attach a Mongo server by clicking the plug icon in the title\r\n\r\n![Browse PostgreSQL, CosmosDB, and MongoDB databases](resources/Browse.png)\r\n\r\n## Mongo Scrapbooks\r\n### Run Mongo Commands with Rich Intellisense\r\n\r\n- View your MongoDB database account by [signing in to Azure](#managing-azure-subscriptions) or using \"Attach Database Account\" to connect via a connection string\r\n- Optionally configure the settings `mongo.shell.path` and `mongo.shell.args` if your mongo executable is not already on your system's PATH (many of the common commands have built-in support and do not require the Mongo shell to be installed - see [Prerequisites](#prerequisites))\r\n- Click on \"New Mongo Scrapbook\" in the tree title bar\r\n- Click on \"Connect to a database\" to indicate which database to run the commands against\r\n- Enter your commands and/or comments, eg: `db.<collectionName>.find()`\r\n- IntelliSense (auto-completions) will be provided\r\n- Click on \"Execute\" above a command to execute it, or press `CMD+\"` (Mac) or `CTRL+\"` (Windows and Linux) to execute the line with the cursor\r\n- To run all commands, click on \"Execute All\", or press `CMD+:` or `Ctrl+:`\r\n- Save and re-use later\r\n![Mongo Scrapbook](resources/Scrapbook.gif)\r\n\r\n## Import into Cosmos DB\r\n\r\n- You can now import documents from your workspace into CosmosDB. Use the context menu of a collection or a document file (json) to get started!\r\n![Import documents](resources/import_documents.gif)\r\n\r\n## Use [Gremlin](https://docs.microsoft.com/azure/cosmos-db/gremlin-support) to query graphs\r\n\r\n![Query Graphs](resources/Graph.gif)\r\n\r\n- <a name=\"graphSettings\"></a>Configure the user setting `cosmosDB.graph.viewSettings` to customize which properties to display and which colors to use based on vertex label.\r\n```javascript\r\n    \"cosmosDB.graph.viewSettings\": [\r\n        {\r\n            \"vertexSettings\": [\r\n                {\r\n                    // Default settings for all vertices\r\n                    \"displayProperty\": [\r\n                        // Display name property if exists, otherwise firstName if it exists, otherwise ID\r\n                        \"name\",\r\n                        \"firstName\"\r\n                    ],\r\n                    // Auto-choose color by label\r\n                    \"color\": \"auto\",\r\n                    // Show label after display property\r\n                    \"showLabel\": true\r\n                },\r\n                {\r\n                    // These setting apply to vertices with the label 'person'\r\n                    \"appliesToLabel\": \"person\",\r\n                    \"color\": \"blue\"\r\n                }\r\n            ]\r\n        }\r\n    ]\r\n```\r\n\r\n## Create an Azure Databases Server\r\n\r\n![Create Azure Databases Server](resources/create.gif)\r\n\r\n## Attach to the Cosmos DB Emulator\r\n\r\n* Install and run the [Cosmos DB Emulator](https://docs.microsoft.com/azure/cosmos-db/local-emulator) on your local machine\r\n* Right click 'Attached Database Accounts' and select 'Attach Emulator'\r\n\r\n![Attach Emulator](resources/attachEmulator.png)\r\n\r\n## Managing Azure Subscriptions\r\n\r\nIf you are not signed in to Azure, you will see a \"Sign in to Azure...\" link. Alternatively, you can select \"View->Command Palette\" in the VS Code menu, and search for \"Azure: Sign In\".\r\n\r\n![Sign in to Azure](resources/SignIn.gif)\r\n\r\nIf you don't have an Azure Account, you can sign up for one today for free and receive $200 in credits by selecting \"Create a Free Azure Account...\" or selecting \"View->Command Palette\" and searching for \"Azure: Create an Account\".\r\n\r\nYou may sign out of Azure by selecting \"View->Command Palette\" and searching for \"Azure: Sign Out\".\r\n\r\nTo select which subscriptions show up in the extension's explorer, click on the \"Select Subscriptions...\" button on any subscription node (indicated by a \"filter\" icon when you hover over it), or select \"View->Command Palette\" and search for \"Azure: Select Subscriptions\". Note that this selection affects all VS Code extensions that support the [Azure Account and Sign-In](https://github.com/Microsoft/vscode-azure-account) extension.\r\n\r\n![Select Azure Subscriptions](resources/SelectSubscriptions.gif)\r\n\r\n## Known Issues\r\n\r\n- Azure no longer supports gremlin queries on pre-GA graph accounts. If you see the error \"Could not find a valid gremlin endpoint for *graph*\", then choose \"Open Portal\" on the graph node and check the \"Gremlin Endpoint\" in the Overview tab. If it does not take the form of '...[graph-name].***gremlin***.cosmosdb.azure.com...', then you will need to create a new graph account using the Azure portal or the current version of the extension.\r\n- Graphs are not currently supported with the emulator\r\n- Viewing/editing tables is not currently supported\r\n- Support for escapes in the scrapbooks is preliminary. We currently do not support escaped characters as is inside a string - the characters need to be double escaped. For example, newlines in the string should be  '\\\\\\\\n' instead of '\\\\n' to be recognized correctly. If you find any issues with how the scrapbook handles escapes, please add to issue [#937](https://github.com/Microsoft/vscode-cosmosdb/issues/937).\r\n\r\n<!-- region exclude-from-marketplace -->\r\n\r\n# Contributing\r\nThere are several ways you can contribute to our [repo](https://github.com/Microsoft/vscode-cosmosdb):\r\n\r\n* **Ideas, feature requests and bugs**: We are open to all ideas and we want to get rid of bugs! Use the [Issues](https://github.com/Microsoft/vscode-cosmosdb/issues) section to report a new issue, provide your ideas or contribute to existing threads.\r\n* **Documentation**: Found a typo or strangely worded sentences? Submit a PR!\r\n* **Code**: Contribute bug fixes, features or design changes:\r\n  * Clone the repository locally and open in VS Code.\r\n  * Run \"Extensions: Show Recommended Extensions\" from the [command palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette) and install all extensions listed under \"Workspace Recommendations\"\r\n  * Open the terminal (press <kbd>CTRL</kbd>+ <kbd>\\`</kbd>) and run `npm install`.\r\n  * To build, press <kbd>F1</kbd> and type in `Tasks: Run Build Task`.\r\n  * Debug: press <kbd>F5</kbd> to start debugging the extension.\r\n\r\n## Legal\r\nBefore we can accept your pull request you will need to sign a **Contribution License Agreement**. All you need to do is to submit a pull request, then the PR will get appropriately labelled (e.g. `cla-required`, `cla-norequired`, `cla-signed`, `cla-already-signed`). If you already signed the agreement we will continue with reviewing the PR, otherwise system will tell you how you can sign the CLA. Once you sign the CLA all future PR's will be labeled as `cla-signed`.\r\n\r\n## Code of Conduct\r\nThis project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/). For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.\r\n\r\n<!-- endregion exclude-from-marketplace -->\r\n\r\n# Telemetry\r\nVS Code collects usage data and sends it to Microsoft to help improve our products and services. Read our [privacy statement](https://go.microsoft.com/fwlink/?LinkID=528096&clcid=0x409) to learn more. If you don\u2019t wish to send usage data to Microsoft, you can set the `telemetry.enableTelemetry` setting to `false`. Learn more in our [FAQ](https://code.visualstudio.com/docs/supporting/faq#_how-to-disable-telemetry-reporting).\r\n\r\n# License\r\n[MIT](LICENSE.md)\r\n"
 }
]