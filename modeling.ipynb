{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import acquire_microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire_microsoft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>is_TypeScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/roosterjs-react</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>\\n# Contributing\\n\\nThis project welcomes cont...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/vscode-azure-iot-toolkit</td>\n",
       "      <td>HTML</td>\n",
       "      <td># Azure IoT Hub\\n\\n[![Join the chat at https:/...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode-azuretools</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td># VSCode Azure SDK for Node.js\\n\\n[![Build Sta...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/knack</td>\n",
       "      <td>Python</td>\n",
       "      <td>Knack\\n=====\\n\\n.. image:: https://img.shields...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft/browsecloud</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>**BrowseCloud - Public Demo**\\n\\n[Try out Brow...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 repo    language  \\\n",
       "0           microsoft/roosterjs-react  TypeScript   \n",
       "1  microsoft/vscode-azure-iot-toolkit        HTML   \n",
       "2         microsoft/vscode-azuretools  TypeScript   \n",
       "3                     microsoft/knack      Python   \n",
       "4               microsoft/browsecloud  TypeScript   \n",
       "\n",
       "                                     readme_contents  is_TypeScript  \n",
       "0  \\n# Contributing\\n\\nThis project welcomes cont...           True  \n",
       "1  # Azure IoT Hub\\n\\n[![Join the chat at https:/...          False  \n",
       "2  # VSCode Azure SDK for Node.js\\n\\n[![Build Sta...           True  \n",
       "3  Knack\\n=====\\n\\n.. image:: https://img.shields...          False  \n",
       "4  **BrowseCloud - Public Demo**\\n\\n[Try out Brow...           True  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 261 entries, 0 to 269\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   repo             261 non-null    object\n",
      " 1   language         261 non-null    object\n",
      " 2   readme_contents  261 non-null    object\n",
      " 3   is_TypeScript    261 non-null    bool  \n",
      "dtypes: bool(1), object(3)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo               0\n",
       "language           0\n",
       "readme_contents    0\n",
       "is_TypeScript      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import prepare_microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.readme_contents = df.readme_contents.apply(prepare_microsoft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>is_TypeScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/roosterjs-react</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>contributing project welcome contribution sugg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/vscode-azure-iot-toolkit</td>\n",
       "      <td>HTML</td>\n",
       "      <td>azure iot hub join chat httpsgitterimmicrosoft...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode-azuretools</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>vscode azure sdk nodejs build statushttpsdevaz...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/knack</td>\n",
       "      <td>Python</td>\n",
       "      <td>knack image httpsimgshieldsiopypivknacksvg tar...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft/browsecloud</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>browsecloud public demo try browsecloud demons...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 repo    language  \\\n",
       "0           microsoft/roosterjs-react  TypeScript   \n",
       "1  microsoft/vscode-azure-iot-toolkit        HTML   \n",
       "2         microsoft/vscode-azuretools  TypeScript   \n",
       "3                     microsoft/knack      Python   \n",
       "4               microsoft/browsecloud  TypeScript   \n",
       "\n",
       "                                     readme_contents  is_TypeScript  \n",
       "0  contributing project welcome contribution sugg...           True  \n",
       "1  azure iot hub join chat httpsgitterimmicrosoft...          False  \n",
       "2  vscode azure sdk nodejs build statushttpsdevaz...           True  \n",
       "3  knack image httpsimgshieldsiopypivknacksvg tar...          False  \n",
       "4  browsecloud public demo try browsecloud demons...           True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contributing project welcome contribution suggestion contribution require agree contributor license agreement cla declaring right actually grant u right use contribution detail visit httpsclamicrosoftcom submit pull request clabot automatically determine whether need provide cla decorate pr appropriately eg label comment simply follow instruction provided bot need across repos using cla project ha adopted microsoft open source code conducthttpsopensourcemicrosoftcomcodeofconduct information see code conduct faqhttpsopensourcemicrosoftcomcodeofconductfaq contact opencodemicrosoftcommailtoopencodemicrosoftcom additional question comment'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.readme_contents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make TF-IDF object\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit object to list of words\n",
    "X = tfidf.fit_transform(df.readme_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=319):\n",
    "    \"\"\"\"\n",
    "    Seed everything.\n",
    "    \"\"\"   \n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without seed\n",
      "[100.17820269  99.99121479 102.03905608  99.47298494  99.94185588]\n",
      "[101.3088409  100.41584692  99.14934789  99.11562462  99.93629751]\n",
      "With the same seed\n",
      "[100.49671415  99.8617357  100.64768854 101.52302986  99.76584663]\n",
      "[100.49671415  99.8617357  100.64768854 101.52302986  99.76584663]\n",
      "Without seed\n",
      "[100.48004679  97.94668038  99.54537045 100.04552947  97.90894565]\n",
      "[100.18949146 100.38309751  99.80358534 100.19989723 100.12354108]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "print('Without seed')\n",
    "print(norm.rvs(100, size = 5))\n",
    "print(norm.rvs(100, size = 5))\n",
    "\n",
    "print('With the same seed')\n",
    "np.random.seed(42) \n",
    "print(norm.rvs(100, size = 5))\n",
    "np.random.seed(42) # reset the random seed back to 42\n",
    "print(norm.rvs(100, size = 5))\n",
    "\n",
    "print('Without seed')\n",
    "np.random.seed(None)\n",
    "print(norm.rvs(100, size = 5))\n",
    "print(norm.rvs(100, size = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4     True\n",
       "Name: is_TypeScript, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make the y variable of the target variable\n",
    "y = df.is_TypeScript\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up as dataframes\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    108\n",
       "True     100\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# establish baseline\n",
    "train.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline'] = False\n",
    "# most actual values are false, so we will use that as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline\n",
       "257    True     False\n",
       "65     True     False\n",
       "207   False     False\n",
       "136    True     False\n",
       "99     True     False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Baseline Accuracy: 51.92%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual    False  True \n",
      "baseline              \n",
      "False       108    100\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.52      1.00      0.68       108\n",
      "        True       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.52       208\n",
      "   macro avg       0.26      0.50      0.34       208\n",
      "weighted avg       0.27      0.52      0.35       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(' Baseline Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.baseline)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.baseline, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object and fit to train\n",
    "lm = LogisticRegression(random_state=319).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train['log_predicted'] = lm.predict(X_train)\n",
    "test['log_predicted'] = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>log_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline  log_predicted\n",
       "257    True     False           True\n",
       "65     True     False           True\n",
       "207   False     False          False\n",
       "136    True     False           True\n",
       "99     True     False           True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.12%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         False  True \n",
      "log_predicted              \n",
      "False            105      3\n",
      "True               3     97\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.97      0.97      0.97       108\n",
      "        True       0.97      0.97      0.97       100\n",
      "\n",
      "    accuracy                           0.97       208\n",
      "   macro avg       0.97      0.97      0.97       208\n",
      "weighted avg       0.97      0.97      0.97       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.log_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.log_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.log_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  log_predicted\n",
       "107   False          False\n",
       "49    False          False\n",
       "66    False          False\n",
       "62    False          False\n",
       "10    False          False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.81%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         False  True \n",
      "log_predicted              \n",
      "False             24     13\n",
      "True               3     13\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.89      0.75        27\n",
      "        True       0.81      0.50      0.62        26\n",
      "\n",
      "    accuracy                           0.70        53\n",
      "   macro avg       0.73      0.69      0.68        53\n",
      "weighted avg       0.73      0.70      0.69        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.log_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.log_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.log_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression did very well on train, however comparitively did very poorly on test\n",
    "\n",
    "- Rather low precision on false\n",
    "\n",
    "- More accurate than baseline, however"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object and fit to train\n",
    "dt = DecisionTreeClassifier(random_state=319).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train['dt_predicted'] = dt.predict(X_train)\n",
    "test['dt_predicted'] = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline  log_predicted  dt_predicted\n",
       "257    True     False           True          True\n",
       "65     True     False           True          True\n",
       "207   False     False          False         False\n",
       "136    True     False           True          True\n",
       "99     True     False           True          True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        False  True \n",
      "dt_predicted              \n",
      "False           108      1\n",
      "True              0     99\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00       108\n",
      "        True       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           1.00       208\n",
      "   macro avg       1.00      0.99      1.00       208\n",
      "weighted avg       1.00      1.00      1.00       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.dt_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.dt_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.dt_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  log_predicted  dt_predicted\n",
       "107   False          False         False\n",
       "49    False          False         False\n",
       "66    False          False         False\n",
       "62    False          False         False\n",
       "10    False          False         False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.04%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        False  True \n",
      "dt_predicted              \n",
      "False            19     10\n",
      "True              8     16\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.70      0.68        27\n",
      "        True       0.67      0.62      0.64        26\n",
      "\n",
      "    accuracy                           0.66        53\n",
      "   macro avg       0.66      0.66      0.66        53\n",
      "weighted avg       0.66      0.66      0.66        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.dt_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.dt_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.dt_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This model did better on train than logistic regression but even worse on test\n",
    "\n",
    "- low precision on both true and false\n",
    "\n",
    "- Still more accurate than baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object and fit to train\n",
    "rf = RandomForestClassifier(random_state=319).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train['rf_predicted'] = rf.predict(X_train)\n",
    "test['rf_predicted'] = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline  log_predicted  dt_predicted  rf_predicted\n",
       "257    True     False           True          True          True\n",
       "65     True     False           True          True          True\n",
       "207   False     False          False         False         False\n",
       "136    True     False           True          True          True\n",
       "99     True     False           True          True          True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.52%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        False  True \n",
      "rf_predicted              \n",
      "False           108      1\n",
      "True              0     99\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      1.00       108\n",
      "        True       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           1.00       208\n",
      "   macro avg       1.00      0.99      1.00       208\n",
      "weighted avg       1.00      1.00      1.00       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.rf_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  log_predicted  dt_predicted  rf_predicted\n",
       "107   False          False         False         False\n",
       "49    False          False         False         False\n",
       "66    False          False         False         False\n",
       "62    False          False         False         False\n",
       "10    False          False         False         False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.26%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual        False  True \n",
      "rf_predicted              \n",
      "False            20     13\n",
      "True              7     13\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.74      0.67        27\n",
      "        True       0.65      0.50      0.57        26\n",
      "\n",
      "    accuracy                           0.62        53\n",
      "   macro avg       0.63      0.62      0.62        53\n",
      "weighted avg       0.63      0.62      0.62        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.rf_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.rf_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.rf_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once again this model did very well on train but poorly on test \n",
    "\n",
    "- poor precision on both true and false\n",
    "\n",
    "- poor recall on true\n",
    "\n",
    "- slightly more accurate than baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object and fit to train\n",
    "knn = KNeighborsClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "train['knn_predicted'] = knn.predict(X_train)\n",
    "test['knn_predicted'] = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "      <th>knn_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  baseline  log_predicted  dt_predicted  rf_predicted  \\\n",
       "257    True     False           True          True          True   \n",
       "65     True     False           True          True          True   \n",
       "207   False     False          False         False         False   \n",
       "136    True     False           True          True          True   \n",
       "99     True     False           True          True          True   \n",
       "\n",
       "     knn_predicted  \n",
       "257           True  \n",
       "65            True  \n",
       "207          False  \n",
       "136           True  \n",
       "99            True  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.37%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         False  True \n",
      "knn_predicted              \n",
      "False             89     26\n",
      "True              19     74\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.82      0.80       108\n",
      "        True       0.80      0.74      0.77       100\n",
      "\n",
      "    accuracy                           0.78       208\n",
      "   macro avg       0.78      0.78      0.78       208\n",
      "weighted avg       0.78      0.78      0.78       208\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(train.actual, train.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(train.knn_predicted, train.actual))\n",
    "print('---')\n",
    "print(classification_report(train.actual, train.knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "      <th>knn_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  log_predicted  dt_predicted  rf_predicted  knn_predicted\n",
       "107   False          False         False         False          False\n",
       "49    False          False         False         False          False\n",
       "66    False          False         False         False           True\n",
       "62    False          False         False         False          False\n",
       "10    False          False         False         False           True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.81%\n",
      "---\n",
      "Confusion Matrix\n",
      "actual         False  True \n",
      "knn_predicted              \n",
      "False             21     10\n",
      "True               6     16\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.68      0.78      0.72        27\n",
      "        True       0.73      0.62      0.67        26\n",
      "\n",
      "    accuracy                           0.70        53\n",
      "   macro avg       0.70      0.70      0.70        53\n",
      "weighted avg       0.70      0.70      0.70        53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: {:.2%}'.format(accuracy_score(test.actual, test.knn_predicted)))\n",
    "print('---')\n",
    "print('Confusion Matrix')\n",
    "print(pd.crosstab(test.knn_predicted, test.actual))\n",
    "print('---')\n",
    "print(classification_report(test.actual, test.knn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This model didn't do as well on train, however did about just as well on test\n",
    "\n",
    "- more accurate than basline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling on all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>is_TypeScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/roosterjs-react</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>contributing project welcome contribution sugg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/vscode-azure-iot-toolkit</td>\n",
       "      <td>HTML</td>\n",
       "      <td>azure iot hub join chat httpsgitterimmicrosoft...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode-azuretools</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>vscode azure sdk nodejs build statushttpsdevaz...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/knack</td>\n",
       "      <td>Python</td>\n",
       "      <td>knack image httpsimgshieldsiopypivknacksvg tar...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft/browsecloud</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>browsecloud public demo try browsecloud demons...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 repo    language  \\\n",
       "0           microsoft/roosterjs-react  TypeScript   \n",
       "1  microsoft/vscode-azure-iot-toolkit        HTML   \n",
       "2         microsoft/vscode-azuretools  TypeScript   \n",
       "3                     microsoft/knack      Python   \n",
       "4               microsoft/browsecloud  TypeScript   \n",
       "\n",
       "                                     readme_contents  is_TypeScript  \n",
       "0  contributing project welcome contribution sugg...           True  \n",
       "1  azure iot hub join chat httpsgitterimmicrosoft...          False  \n",
       "2  vscode azure sdk nodejs build statushttpsdevaz...           True  \n",
       "3  knack image httpsimgshieldsiopypivknacksvg tar...          False  \n",
       "4  browsecloud public demo try browsecloud demons...           True  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find only the most common languages\n",
    "top_5 = df.language.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    126\n",
       "C#             32\n",
       "JavaScript     18\n",
       "Python         16\n",
       "C++            16\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_languages = ['TypeScript', 'C#', 'JavaScript', 'C++', 'Python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into a seperate dataframe\n",
    "top_5_df = df[df['language'].isin(top_5_languages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>is_TypeScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/roosterjs-react</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>contributing project welcome contribution sugg...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/vscode-azuretools</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>vscode azure sdk nodejs build statushttpsdevaz...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/knack</td>\n",
       "      <td>Python</td>\n",
       "      <td>knack image httpsimgshieldsiopypivknacksvg tar...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft/browsecloud</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>browsecloud public demo try browsecloud demons...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microsoft/FluidFramework</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>fluid fluid framework typescript library build...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          repo    language  \\\n",
       "0    microsoft/roosterjs-react  TypeScript   \n",
       "2  microsoft/vscode-azuretools  TypeScript   \n",
       "3              microsoft/knack      Python   \n",
       "4        microsoft/browsecloud  TypeScript   \n",
       "5     microsoft/FluidFramework  TypeScript   \n",
       "\n",
       "                                     readme_contents  is_TypeScript  \n",
       "0  contributing project welcome contribution sugg...           True  \n",
       "2  vscode azure sdk nodejs build statushttpsdevaz...           True  \n",
       "3  knack image httpsimgshieldsiopypivknacksvg tar...          False  \n",
       "4  browsecloud public demo try browsecloud demons...           True  \n",
       "5  fluid fluid framework typescript library build...           True  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    126\n",
       "C#             32\n",
       "JavaScript     18\n",
       "Python         16\n",
       "C++            16\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>is_TypeScript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>microsoft/cookie.gulp</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>contributing project welcome contribution sugg...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>microsoft/electionguard-ballot-box</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>microsoft defending democracy program election...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>microsoft/onnxruntime</td>\n",
       "      <td>C++</td>\n",
       "      <td>p aligncenterimg width50 srcdocsimagesonnxrunt...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>microsoft/fhir-server</td>\n",
       "      <td>C#</td>\n",
       "      <td>fhir server azure net core implementation fhir...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>microsoft/openpaimarketplace</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>p aligncenter img srcdocsimagesmarketplacesvg ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   repo    language  \\\n",
       "33                microsoft/cookie.gulp  JavaScript   \n",
       "39   microsoft/electionguard-ballot-box  TypeScript   \n",
       "47                microsoft/onnxruntime         C++   \n",
       "238               microsoft/fhir-server          C#   \n",
       "130        microsoft/openpaimarketplace  JavaScript   \n",
       "\n",
       "                                       readme_contents  is_TypeScript  \n",
       "33   contributing project welcome contribution sugg...          False  \n",
       "39   microsoft defending democracy program election...           True  \n",
       "47   p aligncenterimg width50 srcdocsimagesonnxrunt...          False  \n",
       "238  fhir server azure net core implementation fhir...          False  \n",
       "130  p aligncenter img srcdocsimagesmarketplacesvg ...          False  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, validate, test = split(top_5_df, 'language')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    71\n",
       "C#            17\n",
       "JavaScript    10\n",
       "Python         9\n",
       "C++            9\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish baseline\n",
    "train.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline'] = 'TypeScript'\n",
    "# 'TypeScript' will be used as baseline because it is the most common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>is_TypeScript</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>microsoft/cookie.gulp</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>contributing project welcome contribution sugg...</td>\n",
       "      <td>False</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>microsoft/electionguard-ballot-box</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>microsoft defending democracy program election...</td>\n",
       "      <td>True</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>microsoft/onnxruntime</td>\n",
       "      <td>C++</td>\n",
       "      <td>p aligncenterimg width50 srcdocsimagesonnxrunt...</td>\n",
       "      <td>False</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>microsoft/fhir-server</td>\n",
       "      <td>C#</td>\n",
       "      <td>fhir server azure net core implementation fhir...</td>\n",
       "      <td>False</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>microsoft/openpaimarketplace</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>p aligncenter img srcdocsimagesmarketplacesvg ...</td>\n",
       "      <td>False</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   repo    language  \\\n",
       "33                microsoft/cookie.gulp  JavaScript   \n",
       "39   microsoft/electionguard-ballot-box  TypeScript   \n",
       "47                microsoft/onnxruntime         C++   \n",
       "238               microsoft/fhir-server          C#   \n",
       "130        microsoft/openpaimarketplace  JavaScript   \n",
       "\n",
       "                                       readme_contents  is_TypeScript  \\\n",
       "33   contributing project welcome contribution sugg...          False   \n",
       "39   microsoft defending democracy program election...           True   \n",
       "47   p aligncenterimg width50 srcdocsimagesonnxrunt...          False   \n",
       "238  fhir server azure net core implementation fhir...          False   \n",
       "130  p aligncenter img srcdocsimagesmarketplacesvg ...          False   \n",
       "\n",
       "       baseline  \n",
       "33   TypeScript  \n",
       "39   TypeScript  \n",
       "47   TypeScript  \n",
       "238  TypeScript  \n",
       "130  TypeScript  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TypeScript', 'C#', 'JavaScript', 'Python', 'C++']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages = train.language.value_counts().index.tolist()\n",
    "\n",
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6120689655172413"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "(train.language == train.baseline).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript on baseline has 1.0\n",
      "Predicting C# on baseline has 0.0\n",
      "Predicting JavaScript on baseline has 0.0\n",
      "Predicting Python on baseline has 0.0\n",
      "Predicting C++ on baseline has 0.0\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = train[train.language == language]\n",
    "    accuracy = (language_repos.language == language_repos.baseline).mean()\n",
    "    print(f\"Predicting {language} on baseline has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00        17\n",
      "         C++       0.00      0.00      0.00         9\n",
      "  JavaScript       0.00      0.00      0.00        10\n",
      "      Python       0.00      0.00      0.00         9\n",
      "  TypeScript       0.61      1.00      0.76        71\n",
      "\n",
      "    accuracy                           0.61       116\n",
      "   macro avg       0.12      0.20      0.15       116\n",
      "weighted avg       0.37      0.61      0.46       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.language, train.baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our X variables\n",
    "X_train = train.readme_contents\n",
    "X_validate = validate.readme_contents\n",
    "X_test = test.readme_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33     contributing project welcome contribution sugg...\n",
       "39     microsoft defending democracy program election...\n",
       "47     p aligncenterimg width50 srcdocsimagesonnxrunt...\n",
       "238    fhir server azure net core implementation fhir...\n",
       "130    p aligncenter img srcdocsimagesmarketplacesvg ...\n",
       "Name: readme_contents, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our y variables\n",
    "y_train = train.language\n",
    "y_validate = validate.language\n",
    "y_test = test.language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33     JavaScript\n",
       "39     TypeScript\n",
       "47            C++\n",
       "238            C#\n",
       "130    JavaScript\n",
       "Name: language, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF object\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit on the training data\n",
    "tfidf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the object\n",
    "X_train_vectorized = tfidf.transform(X_train)\n",
    "X_validate_vectorized = tfidf.transform(X_validate)\n",
    "X_test_vectorized = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make logistic regression object\n",
    "lm = LogisticRegression(random_state = 319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=319)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit object to train data\n",
    "lm.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into pd dataframes\n",
    "train = pd.DataFrame(dict(actual=y_train))\n",
    "validate = pd.DataFrame(dict(actual=y_validate))\n",
    "test = pd.DataFrame(dict(actual=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual\n",
       "33   JavaScript\n",
       "39   TypeScript\n",
       "47          C++\n",
       "238          C#\n",
       "130  JavaScript"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions, add to dataframe\n",
    "train['log_predicted'] = lm.predict(X_train_vectorized)\n",
    "validate['log_predicted'] = lm.predict(X_validate_vectorized)\n",
    "test['log_predicted'] = lm.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C++</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C#</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual log_predicted\n",
       "33   JavaScript    TypeScript\n",
       "39   TypeScript    TypeScript\n",
       "47          C++    TypeScript\n",
       "238          C#    TypeScript\n",
       "130  JavaScript    TypeScript"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    114\n",
       "C#              2\n",
       "Name: log_predicted, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.log_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293103448275862"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "(train.actual == train.log_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 1.0\n",
      "Predicting C# has 0.12\n",
      "Predicting JavaScript has 0.0\n",
      "Predicting Python has 0.0\n",
      "Predicting C++ has 0.0\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = train[train.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.log_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       1.00      0.12      0.21        17\n",
      "         C++       0.00      0.00      0.00         9\n",
      "  JavaScript       0.00      0.00      0.00        10\n",
      "      Python       0.00      0.00      0.00         9\n",
      "  TypeScript       0.62      1.00      0.77        71\n",
      "\n",
      "    accuracy                           0.63       116\n",
      "   macro avg       0.32      0.22      0.20       116\n",
      "weighted avg       0.53      0.63      0.50       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.actual, train.log_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of sample accuracy\n",
    "(validate.actual == validate.log_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 1.0\n",
      "Predicting C# has 0.0\n",
      "Predicting JavaScript has 0.0\n",
      "Predicting Python has 0.0\n",
      "Predicting C++ has 0.0\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = validate[validate.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.log_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         8\n",
      "         C++       0.00      0.00      0.00         4\n",
      "  JavaScript       0.00      0.00      0.00         4\n",
      "      Python       0.00      0.00      0.00         4\n",
      "  TypeScript       0.60      1.00      0.75        30\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.12      0.20      0.15        50\n",
      "weighted avg       0.36      0.60      0.45        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validate.actual, validate.log_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistice Regression appeared to predict almost all repos in train were typescript, basically baseline\n",
    "\n",
    "- not very good performance overall\n",
    "\n",
    "- barely underperforms compared to baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make decision tree object\n",
    "dt = DecisionTreeClassifier(random_state = 319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=319)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit object to train data\n",
    "dt.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions, add to dataframe\n",
    "train['dt_predicted'] = dt.predict(X_train_vectorized)\n",
    "validate['dt_predicted'] = dt.predict(X_validate_vectorized)\n",
    "test['dt_predicted'] = dt.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C++</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C#</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual log_predicted dt_predicted\n",
       "33   JavaScript    TypeScript   JavaScript\n",
       "39   TypeScript    TypeScript   TypeScript\n",
       "47          C++    TypeScript          C++\n",
       "238          C#    TypeScript           C#\n",
       "130  JavaScript    TypeScript   JavaScript"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    70\n",
       "C#            16\n",
       "JavaScript    12\n",
       "Python         9\n",
       "C++            9\n",
       "Name: dt_predicted, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dt_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827586206896551"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "(train.actual == train.dt_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.99\n",
      "Predicting C# has 0.94\n",
      "Predicting JavaScript has 1.0\n",
      "Predicting Python has 1.0\n",
      "Predicting C++ has 1.0\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = train[train.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.dt_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       1.00      0.94      0.97        17\n",
      "         C++       1.00      1.00      1.00         9\n",
      "  JavaScript       0.83      1.00      0.91        10\n",
      "      Python       1.00      1.00      1.00         9\n",
      "  TypeScript       1.00      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       116\n",
      "   macro avg       0.97      0.99      0.97       116\n",
      "weighted avg       0.99      0.98      0.98       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.actual, train.dt_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of sample accuracy\n",
    "(validate.actual == validate.dt_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.8\n",
      "Predicting C# has 0.75\n",
      "Predicting JavaScript has 0.0\n",
      "Predicting Python has 0.25\n",
      "Predicting C++ has 0.25\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = validate[validate.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.dt_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.86      0.75      0.80         8\n",
      "         C++       0.25      0.25      0.25         4\n",
      "  JavaScript       0.00      0.00      0.00         4\n",
      "      Python       0.11      0.25      0.15         4\n",
      "  TypeScript       0.83      0.80      0.81        30\n",
      "\n",
      "    accuracy                           0.64        50\n",
      "   macro avg       0.41      0.41      0.40        50\n",
      "weighted avg       0.66      0.64      0.65        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validate.actual, validate.dt_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model performed almost perfectly on train, and while it didn't do so well on validate, it still outperformed logistic regression\n",
    "\n",
    "- slightly outperforms baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make random forest object\n",
    "rf = RandomForestClassifier(random_state = 319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=319)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit object to train data\n",
    "rf.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions, add to dataframe\n",
    "train['rf_predicted'] = rf.predict(X_train_vectorized)\n",
    "validate['rf_predicted'] = rf.predict(X_validate_vectorized)\n",
    "test['rf_predicted'] = rf.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C++</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C++</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C#</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C#</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual log_predicted dt_predicted rf_predicted\n",
       "33   JavaScript    TypeScript   JavaScript   JavaScript\n",
       "39   TypeScript    TypeScript   TypeScript   TypeScript\n",
       "47          C++    TypeScript          C++          C++\n",
       "238          C#    TypeScript           C#           C#\n",
       "130  JavaScript    TypeScript   JavaScript   JavaScript"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    70\n",
       "C#            16\n",
       "JavaScript    12\n",
       "Python         9\n",
       "C++            9\n",
       "Name: rf_predicted, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.rf_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827586206896551"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "(train.actual == train.rf_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.99\n",
      "Predicting C# has 0.94\n",
      "Predicting JavaScript has 1.0\n",
      "Predicting Python has 1.0\n",
      "Predicting C++ has 1.0\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = train[train.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.rf_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       1.00      0.94      0.97        17\n",
      "         C++       1.00      1.00      1.00         9\n",
      "  JavaScript       0.83      1.00      0.91        10\n",
      "      Python       1.00      1.00      1.00         9\n",
      "  TypeScript       1.00      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       116\n",
      "   macro avg       0.97      0.99      0.97       116\n",
      "weighted avg       0.99      0.98      0.98       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.actual, train.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of sample accuracy\n",
    "(validate.actual == validate.rf_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.9\n",
      "Predicting C# has 0.0\n",
      "Predicting JavaScript has 0.0\n",
      "Predicting Python has 0.0\n",
      "Predicting C++ has 0.0\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = validate[validate.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.rf_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.00      0.00      0.00         8\n",
      "         C++       0.00      0.00      0.00         4\n",
      "  JavaScript       0.00      0.00      0.00         4\n",
      "      Python       0.00      0.00      0.00         4\n",
      "  TypeScript       0.57      0.90      0.70        30\n",
      "\n",
      "    accuracy                           0.54        50\n",
      "   macro avg       0.11      0.18      0.14        50\n",
      "weighted avg       0.34      0.54      0.42        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validate.actual, validate.rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    47\n",
       "C#             3\n",
       "Name: rf_predicted, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate.rf_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model did very well on test, however on out of sample data it seemed to predict almomst everything was TypeScript which severly impacted its accuracy\n",
    "\n",
    "- does not outperform baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make knn object\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit object to train data\n",
    "knn.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions, add to dataframe\n",
    "train['knn_predicted'] = knn.predict(X_train_vectorized)\n",
    "validate['knn_predicted'] = knn.predict(X_validate_vectorized)\n",
    "test['knn_predicted'] = knn.predict(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "      <th>knn_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C++</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C++</td>\n",
       "      <td>C++</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>C#</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C#</td>\n",
       "      <td>C#</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual log_predicted dt_predicted rf_predicted knn_predicted\n",
       "33   JavaScript    TypeScript   JavaScript   JavaScript            C#\n",
       "39   TypeScript    TypeScript   TypeScript   TypeScript    TypeScript\n",
       "47          C++    TypeScript          C++          C++           C++\n",
       "238          C#    TypeScript           C#           C#            C#\n",
       "130  JavaScript    TypeScript   JavaScript   JavaScript    JavaScript"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    69\n",
       "C#            21\n",
       "JavaScript    16\n",
       "Python         6\n",
       "C++            4\n",
       "Name: knn_predicted, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.knn_predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155172413793104"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Accuracy\n",
    "(train.actual == train.knn_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.82\n",
      "Predicting C# has 0.82\n",
      "Predicting JavaScript has 0.3\n",
      "Predicting Python has 0.56\n",
      "Predicting C++ has 0.33\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = train[train.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.knn_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.67      0.82      0.74        17\n",
      "         C++       0.75      0.33      0.46         9\n",
      "  JavaScript       0.19      0.30      0.23        10\n",
      "      Python       0.83      0.56      0.67         9\n",
      "  TypeScript       0.84      0.82      0.83        71\n",
      "\n",
      "    accuracy                           0.72       116\n",
      "   macro avg       0.66      0.57      0.58       116\n",
      "weighted avg       0.75      0.72      0.72       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train.actual, train.knn_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of sample accuracy\n",
    "(validate.actual == validate.knn_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.6\n",
      "Predicting C# has 0.12\n",
      "Predicting JavaScript has 0.0\n",
      "Predicting Python has 0.25\n",
      "Predicting C++ has 0.5\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = validate[validate.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.knn_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.25      0.12      0.17         8\n",
      "         C++       0.67      0.50      0.57         4\n",
      "  JavaScript       0.00      0.00      0.00         4\n",
      "      Python       0.50      0.25      0.33         4\n",
      "  TypeScript       0.62      0.60      0.61        30\n",
      "\n",
      "    accuracy                           0.44        50\n",
      "   macro avg       0.41      0.30      0.34        50\n",
      "weighted avg       0.51      0.44      0.47        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validate.actual, validate.knn_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this model performed poorly on both train and validate data compared to the other models\n",
    "\n",
    "- very low accuracy on all languages\n",
    "\n",
    "- severly underperforms compared to baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate \n",
    "\n",
    "- The Decision Tree using default settings performed the best on validate data and was the only model to beat baseline, so I will use that model on the unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>log_predicted</th>\n",
       "      <th>dt_predicted</th>\n",
       "      <th>rf_predicted</th>\n",
       "      <th>knn_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>C#</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>Python</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>C++</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         actual log_predicted dt_predicted rf_predicted knn_predicted\n",
       "106  TypeScript    TypeScript   TypeScript   TypeScript    JavaScript\n",
       "261          C#    TypeScript   JavaScript   JavaScript            C#\n",
       "51   TypeScript    TypeScript       Python   TypeScript    TypeScript\n",
       "16   TypeScript    TypeScript          C++   TypeScript    TypeScript\n",
       "55   TypeScript    TypeScript   TypeScript   TypeScript    TypeScript"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TypeScript    25\n",
       "C#             7\n",
       "JavaScript     4\n",
       "Python         3\n",
       "C++            3\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test accuracy\n",
    "(test.actual == test.dt_predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting TypeScript has 0.72\n",
      "Predicting C# has 0.43\n",
      "Predicting JavaScript has 0.0\n",
      "Predicting Python has 0.67\n",
      "Predicting C++ has 0.33\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    language_repos = test[test.actual == language]\n",
    "    accuracy = (language_repos.actual == language_repos.dt_predicted).mean()\n",
    "    print(f\"Predicting {language} has {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          C#       0.75      0.43      0.55         7\n",
      "         C++       0.17      0.33      0.22         3\n",
      "  JavaScript       0.00      0.00      0.00         4\n",
      "      Python       0.40      0.67      0.50         3\n",
      "  TypeScript       0.72      0.72      0.72        25\n",
      "\n",
      "    accuracy                           0.57        42\n",
      "   macro avg       0.41      0.43      0.40        42\n",
      "weighted avg       0.59      0.57      0.57        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test.actual, test.dt_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- performed very poorly on unseen test data, did not beat baseline\n",
    "\n",
    "- may need to try to pull more repositories for future iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
